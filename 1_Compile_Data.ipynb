{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "1 - Compile Data",
      "provenance": [],
      "toc_visible": true,
      "machine_shape": "hm",
      "mount_file_id": "1h5Il3Q-VUhJZGqiiX72PKxQiFMGiw20q",
      "authorship_tag": "ABX9TyO/IvBMj3f2RGVW00La1Dv7",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Charles-Scott-Green/Argument-mining/blob/master/1_Compile_Data.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WIIXmbUYl4F7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D6kKdZxU2ONN",
        "colab_type": "code",
        "outputId": "148f1426-4935-4cce-e381-2e88ff4a2eef",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "!python -m spacy download en_core_web_lg --quiet"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n",
            "You can now load the model via spacy.load('en_core_web_lg')\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yhs2wfKqLhCW",
        "colab_type": "code",
        "outputId": "3b655b06-9b74-489f-bf52-f617421262a3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "!pip install vaderSentiment"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: vaderSentiment in /usr/local/lib/python3.6/dist-packages (3.2.1)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lRmqarKsMknz",
        "colab_type": "code",
        "outputId": "2b997071-04af-496b-832b-1c42d029c8ec",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 88
        }
      },
      "source": [
        "!pip install spacy-wordnet"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: spacy-wordnet in /usr/local/lib/python3.6/dist-packages (0.0.4)\n",
            "Requirement already satisfied: nltk<3.4,>=3.3 in /usr/local/lib/python3.6/dist-packages (from spacy-wordnet) (3.3)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from nltk<3.4,>=3.3->spacy-wordnet) (1.12.0)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "jJx65eT8l4ha"
      },
      "source": [
        "## Import Libraries and initialize settings"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "SlPmDlffl4ha",
        "colab": {}
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "sns.set()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "KLhXAWR5l4hf",
        "colab": {}
      },
      "source": [
        "import re\n",
        "import string\n",
        "import math\n",
        "from tqdm import tqdm"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "zQWKeNFwl4hg",
        "colab": {}
      },
      "source": [
        "import nltk\n",
        "from nltk import pos_tag\n",
        "from nltk.corpus import wordnet as wn\n",
        "from nltk.tokenize import sent_tokenize, word_tokenize\n",
        "from pprint import pprint\n",
        "from nltk.tokenize.punkt import PunktSentenceTokenizer, PunktTrainer"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "outputId": "20b1c66b-56e5-4569-e21a-1dd93d34e874",
        "id": "kPeSVMOel4hh",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 187
        }
      },
      "source": [
        "import nltk\n",
        "nltk.download('punkt')\n",
        "nltk.download('wordnet')\n",
        "nltk.download('averaged_perceptron_tagger')\n",
        "nltk.download('omw')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/wordnet.zip.\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Unzipping taggers/averaged_perceptron_tagger.zip.\n",
            "[nltk_data] Downloading package omw to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/omw.zip.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6HiWGQu21GJB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import spacy\n",
        "from spacy.matcher import Matcher \n",
        "from spacy.tokens import Span \n",
        "from spacy import displacy \n",
        "from spacy.lang.en.stop_words import STOP_WORDS\n",
        "from spacy_wordnet.wordnet_annotator import WordnetAnnotator\n",
        "\n",
        "nlp = spacy.load(\"en_core_web_lg\")\n",
        "nlp.add_pipe(WordnetAnnotator(nlp.lang), after='tagger')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8fgBKrZPqpP2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from glob import glob"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-e6_JYeW5oSW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import warnings\n",
        "\n",
        "warnings.filterwarnings('ignore')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xnB1h62XVNp2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.model_selection import train_test_split as tts \n",
        "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.naive_bayes import MultinomialNB"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pbtdTusiNX4y",
        "colab_type": "text"
      },
      "source": [
        "# Define Functions"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "adU4ykBYM4wO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def text_cleaner(text):\n",
        "    # visual inspection identifies a form of punctuation spaCy does not\n",
        "    # recognize: the double dash '--'.  better get rid of it now!\n",
        "    text = text.strip()\n",
        "    text = re.sub(r'--',' ',text)\n",
        "    text = re.sub(\"[\\[].*?[\\]]\", \"\", text)\n",
        "    text = re.sub(r\"(\\b|\\s+\\-?|^\\-?)(\\d+|\\d*\\.\\d+)\\b\", \" \", text)\n",
        "    text = text.replace(' .', '.')\n",
        "    text = text.replace('/', '')\n",
        "    text = re.sub(\"\\'s\", \"'s\", text)\n",
        "    text = ' '.join(text.split())\n",
        "\n",
        "    return text"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a-_1FHXpPiEr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def compile_train_corpus(text_folder):\n",
        "    train_doc = ''\n",
        "\n",
        "    for text_file in text_folder:\n",
        "            with open(text_file) as article:\n",
        "                doc = article.read()\n",
        "                train_doc += doc\n",
        "    return train_doc"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GTmm35Dc1gTn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def is_sentence(clause):\n",
        "    nn = 2\n",
        "    vb = 1\n",
        "    cls = nlp(clause)\n",
        "    for tok in cls:\n",
        "        if tok.pos_ in ['NOUN', 'PROPN', 'PRON']:\n",
        "            nn -= 1\n",
        "        elif tok.pos_ in ['VERB']:\n",
        "            vb -= 1\n",
        "    if nn < 1 and vb < 1:\n",
        "        return True\n",
        "    else:\n",
        "        return False"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MBlrGISWuJIt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def get_clauses(sentence):\n",
        "    \"\"\"Sentence type is a string.\"\"\"\n",
        "    subtree_phrases = []\n",
        "    \n",
        "    for tok in nlp(sentence):\n",
        "        if tok.head.pos_ == 'VERB':\n",
        "            if len([tok for tok in tok.subtree]) >= 3:\n",
        "                subtree_prhase = ''.join(tok.text_with_ws for tok in tok.subtree)\n",
        "                if subtree_prhase != sentence:\n",
        "                    if is_sentence(subtree_prhase):\n",
        "                        splits = subtree_prhase.split(',')\n",
        "                        if len(splits) == 1:\n",
        "                            subtree_phrases.append(subtree_prhase)\n",
        "                        else:\n",
        "                            for split in splits:\n",
        "                                if is_sentence(split):\n",
        "                                    if split not in subtree_phrases:\n",
        "                                        subtree_phrases.append(split) \n",
        "    \n",
        "    raw_clauses = []\n",
        "    clauses = []\n",
        "\n",
        "    for phrase in subtree_phrases:\n",
        "        tok_phrase = nlp(phrase)\n",
        "        for chunk in tok_phrase.noun_chunks:\n",
        "            span = tok_phrase[chunk.root.head.left_edge.i:chunk.root.head.right_edge.i+1]\n",
        "            if span[0].pos_ in ['DET', 'ADP']:\n",
        "                if span[1:].text not in raw_clauses:\n",
        "                    if is_sentence(span[1:].text):\n",
        "                        raw_clauses.append(span[1:].text)\n",
        "            elif span.text not in raw_clauses:\n",
        "                if is_sentence(span.text):\n",
        "                    raw_clauses.append(span.text)\n",
        "    \n",
        "    if len(raw_clauses) == 0:\n",
        "        clauses.append(sentence)\n",
        "    else:\n",
        "        for clause in raw_clauses:\n",
        "            dup_checks = [(clause in check_clause) for check_clause in raw_clauses]\n",
        "            if sum(dup_checks) == 1:\n",
        "                clauses.append(clause)\n",
        "                \n",
        "    return clauses"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DSn9KextNbne",
        "colab_type": "text"
      },
      "source": [
        "# Load Data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Qy6nC-sMw8q_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# paths to articles and topics\n",
        "path_topic = '/content/drive/My Drive/Colab Notebooks/Thinkful/Module 34 - Final Capstone/data/CDC Detection/debater_ce_acl/2014_7_18_ibm_CDCdata.xls'\n",
        "path_articles = '/content/drive/My Drive/Colab Notebooks/Thinkful/Module 34 - Final Capstone/data/CDC Detection/debater_ce_acl/articles'"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zNfXv95WQpUA",
        "colab_type": "text"
      },
      "source": [
        "## Load Reference data set"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pOR1HpTl3LUe",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Load topic/article index data\n",
        "ref_data = pd.read_excel(path_topic)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uLr6u-GGLEXo",
        "colab_type": "code",
        "outputId": "ccf1fcc0-1e36-45e7-965d-5fd480edd6ee",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "# Unique Claim counts\n",
        "ref_data['Claim'].nunique(), ref_data.shape[0]"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(1332, 1387)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Lo0Eyez3XbQc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "ref_data.drop_duplicates('Claim', inplace=True)\n",
        "ref_data['Claim'].nunique(), ref_data.shape[0]\n",
        "ref_data.reset_index(inplace=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hXKszP7uFQNB",
        "colab_type": "code",
        "outputId": "273b4724-53bf-45c5-fbc6-41a8e582c2a4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 391
        }
      },
      "source": [
        "ref_data.head()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>index</th>\n",
              "      <th>Topic</th>\n",
              "      <th>Article</th>\n",
              "      <th>Claim</th>\n",
              "      <th>Requires correction</th>\n",
              "      <th>Correction type</th>\n",
              "      <th>Corrected Text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>the sale of violent video games to minors</td>\n",
              "      <td>Video game controversies</td>\n",
              "      <td>exposure to violent video games causes at leas...</td>\n",
              "      <td>True</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Exposure to violent video games causes at leas...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>the sale of violent video games to minors</td>\n",
              "      <td>Video game controversies</td>\n",
              "      <td>video game violence is not related to serious ...</td>\n",
              "      <td>False</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>the sale of violent video games to minors</td>\n",
              "      <td>Video game controversies</td>\n",
              "      <td>some violent video games may actually have a p...</td>\n",
              "      <td>False</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3</td>\n",
              "      <td>the sale of violent video games to minors</td>\n",
              "      <td>Video game controversies</td>\n",
              "      <td>exposure to violent video games causes both sh...</td>\n",
              "      <td>False</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4</td>\n",
              "      <td>the sale of violent video games to minors</td>\n",
              "      <td>Video game controversies</td>\n",
              "      <td>they increase the violent tendencies among youth</td>\n",
              "      <td>True</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Violent video games increase the violent tende...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   index  ...                                     Corrected Text\n",
              "0      0  ...  Exposure to violent video games causes at leas...\n",
              "1      1  ...                                                NaN\n",
              "2      2  ...                                                NaN\n",
              "3      3  ...                                                NaN\n",
              "4      4  ...  Violent video games increase the violent tende...\n",
              "\n",
              "[5 rows x 7 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e0sVAemgFTUB",
        "colab_type": "code",
        "outputId": "5e3772c9-43df-4cb2-8f8b-1fad1c6a8498",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "ref_data['Article'].nunique()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "313"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xpPMlpMzRPlH",
        "colab_type": "text"
      },
      "source": [
        "## Clean Reference Data and Train tokenizer\n",
        "\n",
        "Some text preparation of the file names, as they relate to the article names in the reference data, is needed. Additionally, articles will be organized into an appropriate  list and/or dictionary for ease of use."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LqB83v5c3RzX",
        "colab_type": "code",
        "outputId": "bbb83f0b-6b25-4c17-c297-61042a6f81e8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "# Clean up article names to make them match filenames\n",
        "clean_article = [x.replace('.', '').replace('&', 'and'). \n",
        "                 replace('Mיrida', 'Merida').replace('?', '') for \n",
        "                 x in ref_data['Article']]\n",
        "\n",
        "ref_data['c_Article'] = clean_article\n",
        "\n",
        "# Unique Topic and article counts\n",
        "ref_data['Topic'].nunique(), ref_data['c_Article'].nunique()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(33, 313)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CM4-N74-iImW",
        "colab_type": "code",
        "outputId": "39842344-0688-49d8-93bf-8e2ed689ac0b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "topic_article_dict = {}\n",
        "\n",
        "for t in ref_data['Topic']:\n",
        "    topic_article_dict[t] = list(set(ref_data.loc[ref_data['Topic'] == t, 'c_Article']))\n",
        "\n",
        "topic_article_dict"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'Europe should weaken its austerity measures to guarantee its citizens greater social support ': ['Anti-austerity protests',\n",
              "  'Welfare state',\n",
              "  'Austerity',\n",
              "  'Greek government-debt crisis',\n",
              "  'Deficit spending'],\n",
              " \"Google shouldn't censor its search results in China \": ['Public Pledge on Self-Discipline for the Chinese Internet Industry',\n",
              "  'Internet censorship',\n",
              "  'Google China',\n",
              "  \"Internet censorship in the People's Republic of China\",\n",
              "  'Criticism of Google',\n",
              "  'Corporate social responsibility'],\n",
              " 'all collective bargaining rights claimed by trades unions ': ['Trade union',\n",
              "  'Federal Labor Relations Act',\n",
              "  'Demir and Baykara v Turkey',\n",
              "  'Collective bargaining',\n",
              "  'Industrial unionism',\n",
              "  'Opposition to trade unions'],\n",
              " 'all nations have a right to nuclear weapons ': ['Nuclear proliferation',\n",
              "  'History of nuclear weapons',\n",
              "  'Mutual assured destruction',\n",
              "  'Nuclear warfare',\n",
              "  'India and weapons of mass destruction',\n",
              "  'Deterrence theory',\n",
              "  'Treaty on the Non-Proliferation of Nuclear Weapons',\n",
              "  'Kenneth Waltz',\n",
              "  'Nuclear disarmament',\n",
              "  'Salted bomb',\n",
              "  'International Atomic Energy Agency',\n",
              "  'UK Trident programme',\n",
              "  'Iran and weapons of mass destruction',\n",
              "  'Stability-instability paradox',\n",
              "  'Nuclear weapons debate',\n",
              "  'Anti-nuclear movement',\n",
              "  'Nuclear weapon',\n",
              "  'Nuclear peace',\n",
              "  \"Japan's non-nuclear weapons policy\",\n",
              "  'Nuclear holocaust'],\n",
              " 'atheism is the only way ': ['Cosmological argument',\n",
              "  'Ultimate Boeing 747 gambit',\n",
              "  'Antitheism',\n",
              "  'Criticism of religion',\n",
              "  'Argument from morality',\n",
              "  'Naturalism (philosophy)',\n",
              "  'Criticism of atheism',\n",
              "  'Problem of evil',\n",
              "  'Agnosticism',\n",
              "  'God Is Not Great',\n",
              "  'Atheism',\n",
              "  'Richard Dawkins',\n",
              "  'God',\n",
              "  'The System of Nature',\n",
              "  'Existence of God',\n",
              "  'Quinque viae',\n",
              "  'The Root of All Evil',\n",
              "  'God of the gaps',\n",
              "  'The God Delusion'],\n",
              " 'boxing ': ['Combat sport',\n",
              "  'Boxing',\n",
              "  'Knockout',\n",
              "  'Amateur boxing',\n",
              "  'The distance (boxing)',\n",
              "  'Boxing in China',\n",
              "  'Boxing styles and technique',\n",
              "  'Concussion',\n",
              "  'Contact sport',\n",
              "  'Dementia pugilistica'],\n",
              " 'bribery is sometimes acceptable ': ['United Nations Convention against Corruption',\n",
              "  'Bribery',\n",
              "  \"Corruption in the People's Republic of China\",\n",
              "  'Political corruption'],\n",
              " 'countries with an imbalanced male female ratio skewed towards males should encourage parents to produce girls ': ['One-child policy',\n",
              "  'Sex selection',\n",
              "  'Human sex ratio',\n",
              "  'Sex-selective abortion'],\n",
              " 'democratic governments should require voters to present photo identification at the polling station ': ['Crawford v Marion County Election Board',\n",
              "  'Voter suppression',\n",
              "  'Help America Vote Act'],\n",
              " 'endangered species should be protected ': ['Deep ecology',\n",
              "  'Habitat destruction',\n",
              "  'Conservation in Australia',\n",
              "  'Extinction',\n",
              "  'Biodiversity',\n",
              "  'Conservation biology',\n",
              "  'Economics of biodiversity',\n",
              "  'Environmental ethics',\n",
              "  'Convention on Biological Diversity',\n",
              "  'Melbourne Principles',\n",
              "  'Habitat conservation',\n",
              "  'Ecological effects of biodiversity',\n",
              "  'Biocentrism (ethics)'],\n",
              " 'gambling ': ['Lottery',\n",
              "  'Economics of gambling',\n",
              "  'Online gambling',\n",
              "  'Gamblers Anonymous',\n",
              "  'Charity gambling',\n",
              "  'Casino',\n",
              "  'Gambling in the United States',\n",
              "  'Problem gambling',\n",
              "  'Gambling',\n",
              "  'Southern District of New York action against online poker players',\n",
              "  'Unlawful Internet Gambling Enforcement Act of 2006'],\n",
              " 'housewives should be paid for their work ': ['Care work',\n",
              "  'Feminist economics'],\n",
              " 'institute a mandatory retirement age ': ['Ageing',\n",
              "  'Mandatory retirement',\n",
              "  'Memory and aging',\n",
              "  'US age discrimination'],\n",
              " 'intellectual property rights ': ['Anti-copyright',\n",
              "  'Property',\n",
              "  'Copyright',\n",
              "  'Intellectual property',\n",
              "  'Patent',\n",
              "  'Philosophy of copyright',\n",
              "  'Societal views on patents',\n",
              "  'Missionary Church of Kopimism',\n",
              "  'Libertarian perspectives on intellectual property'],\n",
              " 'limit the right to bear arms ': ['Gun culture',\n",
              "  'Gun violence in the United States',\n",
              "  'Gun politics in the United States',\n",
              "  'Gun violence and gun control in Texas',\n",
              "  'Gun control',\n",
              "  'Gun politics',\n",
              "  'Second Amendment to the United States Constitution',\n",
              "  'Gun politics in Brazil',\n",
              "  'Political arguments of gun politics in the United States',\n",
              "  'National Rifle Association'],\n",
              " 'make physical education compulsory ': ['Recess (break)',\n",
              "  'Exercise trends',\n",
              "  'Physical education',\n",
              "  'Health',\n",
              "  'Overweight',\n",
              "  'Childhood obesity',\n",
              "  'Sedentary lifestyle',\n",
              "  'Obesity',\n",
              "  'Summerhill School',\n",
              "  'Active Living',\n",
              "  'Physical fitness',\n",
              "  'Physical exercise',\n",
              "  'Democratic education'],\n",
              " 'multiculturalism ': ['Nationalism',\n",
              "  'Declaration on the Rights of Indigenous Peoples',\n",
              "  'Multicultural education',\n",
              "  'Muscular liberalism',\n",
              "  'Leitkultur',\n",
              "  'Multiculturalism',\n",
              "  'Multiculturalism in Canada',\n",
              "  'Canadian identity',\n",
              "  'All for Australia',\n",
              "  'Interculturalism',\n",
              "  'Universal Declaration on Cultural Diversity',\n",
              "  'Acculturation',\n",
              "  'Alliance of Civilizations',\n",
              "  'Multiculturalism in the Netherlands',\n",
              "  'Melting pot',\n",
              "  'Cultural diversity',\n",
              "  'Multiculturalism in Australia',\n",
              "  'Criticism of multiculturalism',\n",
              "  'Cultural imperialism',\n",
              "  'Minority group',\n",
              "  'Cosmopolitanism',\n",
              "  'Convention on the Protection and Promotion of the Diversity of Cultural Expressions',\n",
              "  'Interminority racism',\n",
              "  'Cultural competence'],\n",
              " 'parents to genetically screen foetuses for heritable diseases ': ['Preimplantation genetic diagnosis',\n",
              "  'Genetic testing',\n",
              "  'In vitro fertilisation',\n",
              "  'Prenatal diagnosis',\n",
              "  'Human genetic engineering'],\n",
              " 'partial birth abortions ': ['Support for the legalization of abortion',\n",
              "  'Abortion and mental health',\n",
              "  'Religion and abortion',\n",
              "  'Legalized abortion and crime effect',\n",
              "  'Philosophical aspects of the abortion debate',\n",
              "  'Stenberg v Carhart',\n",
              "  'Partial-Birth Abortion Ban Act',\n",
              "  'Roe v Wade',\n",
              "  'Abortion debate',\n",
              "  'Intact dilation and extraction',\n",
              "  'Gonzales v Carhart',\n",
              "  'Judaism and abortion',\n",
              "  'Societal attitudes towards abortion',\n",
              "  'Abortion in the United States'],\n",
              " 're engage with Myanmar ': ['Maung Zarni',\n",
              "  'Foreign relations of Burma',\n",
              "  'International reaction to the 2007 Burmese anti-government protests',\n",
              "  '2007 Burmese anti-government protests',\n",
              "  'Burma',\n",
              "  'Burma Campaign UK',\n",
              "  'Burmese general election, 2010'],\n",
              " 'reintroduce national service ': ['Charles B Rangel',\n",
              "  'Counter-recruitment',\n",
              "  'Conscription in Germany',\n",
              "  'Conscription in the United States',\n",
              "  'National Service Act of 2006',\n",
              "  'Conscription'],\n",
              " 'subsidise poor communities ': ['Social safety net',\n",
              "  \"Welfare's effect on poverty\",\n",
              "  'Criticisms of welfare',\n",
              "  'Redistribution of wealth',\n",
              "  'Cycle of poverty',\n",
              "  'Poverty reduction',\n",
              "  'Economic inequality',\n",
              "  'Welfare culture',\n",
              "  'Prodesis',\n",
              "  'Subsidy'],\n",
              " 'that the right to asylum should not be absolute ': ['Refugee',\n",
              "  'Illegal immigration from Africa to Israel',\n",
              "  'Right of asylum',\n",
              "  'Russian Federation Law on Refugees',\n",
              "  'Illegal immigration',\n",
              "  'Boat people',\n",
              "  'United Nations High Commissioner for Refugees',\n",
              "  'Immigration and crime',\n",
              "  'Convention Relating to the Status of Refugees',\n",
              "  'UK Immigration Service',\n",
              "  'Immigration',\n",
              "  'Nativism (politics)',\n",
              "  'Immigration to the United Kingdom since 1922'],\n",
              " 'the US is justified in using force to prevent states from acquiring nuclear weapons ': ['Criticism of American foreign policy',\n",
              "  'Nuclear proliferation',\n",
              "  'Deterrence theory',\n",
              "  'Treaty on the Non-Proliferation of Nuclear Weapons',\n",
              "  'Nuclear weapons debate',\n",
              "  'Nuclear weapon',\n",
              "  'Nuclear peace'],\n",
              " \"the United States is responsible for Mexico's drugs war \": ['ATF gunwalking scandal',\n",
              "  'War on Drugs',\n",
              "  'Mexican Drug War',\n",
              "  'Smuggling of firearms into Mexico',\n",
              "  'Merida Initiative'],\n",
              " 'the monarchy ': ['Monarchy of the United Kingdom',\n",
              "  'Enlightened absolutism',\n",
              "  'Monarchy of New Zealand',\n",
              "  'Right-wing politics',\n",
              "  'Monarchy',\n",
              "  'Monarch',\n",
              "  'Debate on the monarchy in Canada',\n",
              "  'Republicanism in Canada',\n",
              "  'Republicanism in Australia',\n",
              "  'Republicanism in the United Kingdom',\n",
              "  'Constitutional monarchy',\n",
              "  'Monarchism'],\n",
              " 'the one child policy of the republic of China ': ['One-child policy',\n",
              "  'Family planning',\n",
              "  'Overpopulation',\n",
              "  'Human population control',\n",
              "  'Two-child policy',\n",
              "  'Demographics of China',\n",
              "  'Sex selection',\n",
              "  'Voluntary Human Extinction Movement',\n",
              "  \"Human rights in the People's Republic of China\",\n",
              "  'Only child',\n",
              "  'Little Emperor Syndrome',\n",
              "  'Reproductive rights',\n",
              "  'Compulsory sterilization'],\n",
              " 'the sale of violent video games to minors ': ['Graphic violence',\n",
              "  'Violence',\n",
              "  'Gender representation in video games',\n",
              "  'Video game',\n",
              "  'Video game culture',\n",
              "  'Nonviolent video game',\n",
              "  'Grand Theft Childhood',\n",
              "  'Brown v Entertainment Merchants Association',\n",
              "  'Media violence research',\n",
              "  'Video game controversies',\n",
              "  'California Assembly Bills 1792 and 1793',\n",
              "  'Media influence',\n",
              "  'Console game',\n",
              "  'Video game content rating system',\n",
              "  'School violence'],\n",
              " 'the use of affirmative action ': ['Civil Rights Act of 1964',\n",
              "  'Color blindness (race)',\n",
              "  'Equal opportunity',\n",
              "  'Minority group',\n",
              "  'Symbolic racism',\n",
              "  'Racial quota',\n",
              "  'Black Economic Empowerment',\n",
              "  'Reverse discrimination',\n",
              "  'Racism in the United States',\n",
              "  'Discrimination',\n",
              "  'Racism',\n",
              "  'Reservation in India',\n",
              "  'Convention on the Elimination of All Forms of Racial Discrimination',\n",
              "  'Affirmative action bake sale',\n",
              "  'United Kingdom employment equality law',\n",
              "  'Convention on the Elimination of All Forms of Discrimination Against Women',\n",
              "  'Affirmative action',\n",
              "  'Affirmative Action Around the World',\n",
              "  'Affirmative action in the United States',\n",
              "  'Meritocracy'],\n",
              " 'the use of performance enhancing drugs in professional sports ': ['Anabolic steroid',\n",
              "  'Doping in East Germany',\n",
              "  'Use of performance-enhancing drugs in sport',\n",
              "  'Ergogenic use of anabolic steroids',\n",
              "  'Substance abuse',\n",
              "  'Mitchell Report',\n",
              "  'Drug Enforcement Administration'],\n",
              " 'trade aid': ['Free trade debate',\n",
              "  'Poverty in Africa',\n",
              "  'Development aid',\n",
              "  'Poverty trap',\n",
              "  'Peter Thomas Bauer',\n",
              "  'Aid',\n",
              "  'Trade and development',\n",
              "  'Faith-based foreign aid',\n",
              "  'William Easterly',\n",
              "  'James Shikwati',\n",
              "  'Poverty reduction',\n",
              "  'Protectionism',\n",
              "  'Aid effectiveness',\n",
              "  'Development geography',\n",
              "  'Dambisa Moyo'],\n",
              " 'wind power should be a primary focus of future energy supply ': ['Environmental impact of the energy industry',\n",
              "  'Wind power in Scotland',\n",
              "  'Wind power in Austria',\n",
              "  'Cost of electricity by source',\n",
              "  'Energy development',\n",
              "  'Wind power grid integration',\n",
              "  'Environmental impact of wind power'],\n",
              " 'year round schooling ': ['Year-round school',\n",
              "  'Summer vacation',\n",
              "  'Summer learning loss',\n",
              "  'After-school activity']}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k9OqxLNcjUrw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Dictionary for paths for articles\n",
        "articles = [file.replace(path_articles+'/', '') for \n",
        "            file in glob(path_articles+'/*.txt')]\n",
        "article_paths = [file for file in glob(path_articles+'/*.txt')]\n",
        "\n",
        "articles_dict = dict(zip(articles,article_paths))\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Q4P1f-uDRdlA",
        "colab_type": "text"
      },
      "source": [
        "### Train 'PunktSentenceTokenizer' \n",
        "\n",
        "To organize data into a usabel format, partitioning sentences is necessary.  Since all sentences are from a common source (Wikipedia), training the tokenizer on the sentences is useful.  "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_YSq5YWZSrDW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# compile training corpus\n",
        "training_corpus = compile_train_corpus(article_paths)\n",
        "\n",
        "# train tokenizer\n",
        "trainer = PunktTrainer()\n",
        "trainer.INCLUDE_ALL_COLLOCS = True\n",
        "trainer.train(training_corpus)\n",
        " \n",
        "tokenizer = PunktSentenceTokenizer(trainer.get_params())"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wuNJ5CEWMVD6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eOIrHp3smSuS",
        "colab_type": "text"
      },
      "source": [
        "### Clean the claim sentences in the reference data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HvCHUf7dmSX6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "cleaned_claims = []\n",
        "\n",
        "for claim in ref_data['Claim']:\n",
        "    cleaned = text_cleaner(claim)\n",
        "    cleaned_claims.append(cleaned)\n",
        "\n",
        "ref_data['clean_Claim'] = cleaned_claims"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ThnVKpi8qbTD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Initialize dataframe that will be primary.\n",
        "df = pd.DataFrame(columns=['text', 'topic', 'article', 'text_clauses', \n",
        "                           'nm_clauses', 'cdc'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nJCguxnGiaw3",
        "colab_type": "text"
      },
      "source": [
        "## Load Articles and Compile Data by Topic\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "59izakjVxhjq",
        "colab_type": "text"
      },
      "source": [
        "### \"Google shouldn't censor its search results in China \""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "outputId": "ad3985b4-5218-44e7-d85d-8b29cf76e225",
        "id": "rKjnd3Co0-1c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 119
        }
      },
      "source": [
        "topic = \"Google shouldn't censor its search results in China \"\n",
        "\n",
        "articles = topic_article_dict[topic]\n",
        "articles"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['Public Pledge on Self-Discipline for the Chinese Internet Industry',\n",
              " 'Internet censorship',\n",
              " 'Google China',\n",
              " \"Internet censorship in the People's Republic of China\",\n",
              " 'Criticism of Google',\n",
              " 'Corporate social responsibility']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "ghXO3d3Q0-1h"
      },
      "source": [
        "#### Article 0 "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "azZ8d4ke0-1h",
        "colab": {}
      },
      "source": [
        "with open(articles_dict[articles[0].replace(' ','_')+'.txt']) as article:\n",
        "        doc = article.read()\n",
        "\n",
        "c_doc = text_cleaner(doc)\n",
        "sentences = nltk.sent_tokenize(c_doc)\n",
        "sentences = [[sent, topic, articles[0]] for sent in sentences]\n",
        "\n",
        "ndf = pd.DataFrame(sentences, columns=['text', 'topic', 'article'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XmxM_-uqr2ke",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "ndf['text_clauses'] = ndf['text'].apply(lambda x: get_clauses(x))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1PTEcWGRsWlO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "ndf['nm_clauses'] = ndf['text_clauses'].apply(lambda x: len(x))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k_-Kr1hZsjbC",
        "colab_type": "code",
        "outputId": "c5913c59-3b7b-46da-b9a2-17909c144d5a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 170
        }
      },
      "source": [
        "ndf['nm_clauses'].describe()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "count    20.000000\n",
              "mean      1.450000\n",
              "std       0.944513\n",
              "min       1.000000\n",
              "25%       1.000000\n",
              "50%       1.000000\n",
              "75%       1.000000\n",
              "max       4.000000\n",
              "Name: nm_clauses, dtype: float64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 39
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "outputId": "333e3d66-5b70-49a2-fdfd-beb18e7b08da",
        "id": "OcEgGwz70-1j",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "cdc_idx_dict = {}\n",
        "cdc_idx_sent = {}\n",
        "cdc_idx_art = {}\n",
        "\n",
        "for i,claim in enumerate(ref_data['clean_Claim']):\n",
        "    check_complete = False\n",
        "    while check_complete == False:\n",
        "        for idx,sentence in enumerate(ndf['text']):\n",
        "            test = claim.lower() in sentence.lower()\n",
        "            if test:\n",
        "                article = ref_data['Article'][i]\n",
        "                cdc_idx_dict[idx] = claim\n",
        "                cdc_idx_sent[idx] = [claim, sentence]\n",
        "                cdc_idx_art[idx] = [claim, article]\n",
        "                check_complete = True\n",
        "            elif idx == (len(ndf['text'])-1):\n",
        "                check_complete = True\n",
        "\n",
        "len(cdc_idx_dict), ref_data.shape[0]"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(2, 1332)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 41
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "outputId": "4d33d072-66b6-4439-a941-fbb5f55173fb",
        "id": "Y0yThwQk0-1l",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 71
        }
      },
      "source": [
        "cdc_idx_dict"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{7: 'their presence in China will support economic development leading to political change',\n",
              " 8: 'their activities are facilitating and sanctioning government censorship rather than challenging it'}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 42
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "m3sdpdvr0-1n",
        "colab": {}
      },
      "source": [
        "cdc = []\n",
        "\n",
        "for x in range(len(ndf)):\n",
        "    if x in list(cdc_idx_dict.keys()):\n",
        "        cdc.append(cdc_idx_dict.get(x))\n",
        "    else:\n",
        "        cdc.append('---')\n",
        "ndf['cdc'] = cdc\n",
        "\n",
        "df = pd.concat([ndf, df], axis=0, ignore_index=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "NCFcgdwr0-1q"
      },
      "source": [
        "#### Article 1 "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "mlJ-L9C10-1r",
        "colab": {}
      },
      "source": [
        "with open(articles_dict[articles[1].replace(' ','_')+'.txt']) as article:\n",
        "        doc = article.read()\n",
        "\n",
        "c_doc = text_cleaner(doc)\n",
        "sentences = nltk.sent_tokenize(c_doc)\n",
        "sentences = [[sent, topic, articles[1]] for sent in sentences]\n",
        "\n",
        "ndf = pd.DataFrame(sentences, columns=['text', 'topic', 'article'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m9exFBTitHc9",
        "colab_type": "code",
        "outputId": "886eab5d-94e0-4733-e93e-a859b46edbb1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 170
        }
      },
      "source": [
        "ndf['text_clauses'] = ndf['text'].apply(lambda x: get_clauses(x))\n",
        "ndf['nm_clauses'] = ndf['text_clauses'].apply(lambda x: len(x))\n",
        "ndf['nm_clauses'].describe()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "count    212.000000\n",
              "mean       1.382075\n",
              "std        0.848896\n",
              "min        1.000000\n",
              "25%        1.000000\n",
              "50%        1.000000\n",
              "75%        2.000000\n",
              "max        8.000000\n",
              "Name: nm_clauses, dtype: float64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 45
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jyYLuq-Zt3mK",
        "colab_type": "code",
        "outputId": "2064af7e-356d-4475-f70b-d181405ec89e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 193
        }
      },
      "source": [
        "chk = ndf.loc[ndf['nm_clauses'] > 4]\n",
        "chk.head()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>text</th>\n",
              "      <th>topic</th>\n",
              "      <th>article</th>\n",
              "      <th>text_clauses</th>\n",
              "      <th>nm_clauses</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>99</th>\n",
              "      <td>Examples include: Sex and erotic, fetishism, p...</td>\n",
              "      <td>Google shouldn't censor its search results in ...</td>\n",
              "      <td>Internet censorship</td>\n",
              "      <td>[Examples include: Sex and erotic, Gay and Les...</td>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>190</th>\n",
              "      <td>Facebook: Among other things the Facebook Stat...</td>\n",
              "      <td>Google shouldn't censor its search results in ...</td>\n",
              "      <td>Internet censorship</td>\n",
              "      <td>[other things the Facebook Statement of Rights...</td>\n",
              "      <td>8</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>191</th>\n",
              "      <td>Google: Google's general Terms of Service were...</td>\n",
              "      <td>Google shouldn't censor its search results in ...</td>\n",
              "      <td>Internet censorship</td>\n",
              "      <td>[Google's general Terms of Service were update...</td>\n",
              "      <td>6</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                  text  ... nm_clauses\n",
              "99   Examples include: Sex and erotic, fetishism, p...  ...          5\n",
              "190  Facebook: Among other things the Facebook Stat...  ...          8\n",
              "191  Google: Google's general Terms of Service were...  ...          6\n",
              "\n",
              "[3 rows x 5 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 50
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y8AzgckHuVUE",
        "colab_type": "code",
        "outputId": "5110cf78-ca74-4f68-a6b0-53c3c549f76e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        }
      },
      "source": [
        "chk['text'][191]"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'Google: Google\\'s general Terms of Service were updated on March , and state: \"We may suspend or stop providing our Services to you if you do not comply with our terms or policies or if we are investigating suspected misconduct\", \"We may review content to determine whether it is illegal or violates our policies, and we may remove or refuse to display content that we reasonably believe violates our policies or the law\", and \"We respond to notices of alleged copyright infringement and terminate accounts of repeat infringers according to the process set out in the U.S. Digital Millennium Copyright Act\".'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 53
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "outputId": "a581f81f-b44e-4a5c-ea50-2bbd3ed9e753",
        "id": "jZ2XeJks0-1t",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "cdc_idx_dict = {}\n",
        "cdc_idx_sent = {}\n",
        "cdc_idx_art = {}\n",
        "\n",
        "for i,claim in enumerate(ref_data['clean_Claim']):\n",
        "    check_complete = False\n",
        "    while check_complete == False:\n",
        "        for idx,sentence in enumerate(ndf['text']):\n",
        "            test = claim.lower() in sentence.lower()\n",
        "            if test:\n",
        "                article = ref_data['Article'][i]\n",
        "                cdc_idx_dict[idx] = claim\n",
        "                cdc_idx_sent[idx] = [claim, sentence]\n",
        "                cdc_idx_art[idx] = [claim, article]\n",
        "                check_complete = True\n",
        "            elif idx == (len(ndf['text'])-1):\n",
        "                check_complete = True\n",
        "\n",
        "len(cdc_idx_dict), ref_data.shape[0]"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(4, 1332)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 54
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "outputId": "393ee01f-5bcf-4542-bb48-688a276b2341",
        "id": "R36Ml6jp0-1v",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 105
        }
      },
      "source": [
        "cdc_idx_dict"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{67: 'the internet should never be regulated by any level of government anywhere',\n",
              " 71: 'access to the Internet was a fundamental right',\n",
              " 72: 'access to the Internet was a fundamental right of all people',\n",
              " 192: 'Google may temporarily or permanently remove sites from its index and search results if it believes it is obligated to do so by law'}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 55
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "pq_Cf8aR0-1x",
        "colab": {}
      },
      "source": [
        "cdc = []\n",
        "\n",
        "for x in range(len(ndf)):\n",
        "    if x in list(cdc_idx_dict.keys()):\n",
        "        cdc.append(cdc_idx_dict.get(x))\n",
        "    else:\n",
        "        cdc.append('---')\n",
        "ndf['cdc'] = cdc\n",
        "\n",
        "df = pd.concat([df, ndf], axis=0, ignore_index=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "FDd5JceP0-1z"
      },
      "source": [
        "#### Article 2 "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "oKy0tt010-1z",
        "colab": {}
      },
      "source": [
        "with open(articles_dict[articles[2].replace(' ','_')+'.txt']) as article:\n",
        "        doc = article.read()\n",
        "\n",
        "c_doc = text_cleaner(doc)\n",
        "sentences = nltk.sent_tokenize(c_doc)\n",
        "sentences = [[sent, topic, articles[2]] for sent in sentences]\n",
        "\n",
        "ndf = pd.DataFrame(sentences, columns=['text', 'topic', 'article'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "outputId": "1c66dcb9-2f9e-4f83-9320-0e5f8aada926",
        "id": "okg_llG4vEhO",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 170
        }
      },
      "source": [
        "ndf['text_clauses'] = ndf['text'].apply(lambda x: get_clauses(x))\n",
        "ndf['nm_clauses'] = ndf['text_clauses'].apply(lambda x: len(x))\n",
        "ndf['nm_clauses'].describe()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "count    80.000000\n",
              "mean      1.300000\n",
              "std       0.682512\n",
              "min       1.000000\n",
              "25%       1.000000\n",
              "50%       1.000000\n",
              "75%       1.000000\n",
              "max       5.000000\n",
              "Name: nm_clauses, dtype: float64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 58
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-8Lmzxq1vIxt",
        "colab_type": "code",
        "outputId": "58c5ecf0-4c28-4de3-9c9c-021e739a9531",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        }
      },
      "source": [
        "chk = ndf.loc[ndf['nm_clauses']>4]\n",
        "chk['text'][73]"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'People\\'s Daily published a scathing op-ed on Google which criticized western leaders for politicizing the way in which China controls citizen\\'s access to the Internet, saying \"implementing monitoring according to a country\\'s national context is what any government has to do,\" and that China\\'s need to censor the internet is greater than that of developed countries, \"The Chinese society has generally less information bearing capacity than developed countries such as the U.S.&nbsp;..\".'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 62
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "outputId": "4e98d40d-7199-4a3e-970b-3b2dacc01413",
        "id": "s8r7-R-m0-12",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "cdc_idx_dict = {}\n",
        "cdc_idx_sent = {}\n",
        "cdc_idx_art = {}\n",
        "\n",
        "for i,claim in enumerate(ref_data['clean_Claim']):\n",
        "    check_complete = False\n",
        "    while check_complete == False:\n",
        "        for idx,sentence in enumerate(ndf['text']):\n",
        "            test = claim.lower() in sentence.lower()\n",
        "            if test:\n",
        "                article = ref_data['Article'][i]\n",
        "                cdc_idx_dict[idx] = claim\n",
        "                cdc_idx_sent[idx] = [claim, sentence]\n",
        "                cdc_idx_art[idx] = [claim, article]\n",
        "                check_complete = True\n",
        "            elif idx == (len(ndf['text'])-1):\n",
        "                check_complete = True\n",
        "\n",
        "len(cdc_idx_dict), ref_data.shape[0]"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(4, 1332)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 63
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "outputId": "d1955a96-d1ac-46ef-a486-b3f90143d6d2",
        "id": "Dd93S85x0-14",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 105
        }
      },
      "source": [
        "cdc_idx_dict"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{43: \"it could play a role more useful to the cause of free speech by participating in China's IT industry than by refusing to comply\",\n",
              " 44: \"removing search results is inconsistent with Google's mission\",\n",
              " 49: 'Google China is a flagrant violation of the Google motto, \"Don\\'t be evil',\n",
              " 73: \"implementing monitoring according to a country's national context is what any government has to do\"}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 64
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "vf1JJZvG0-15",
        "colab": {}
      },
      "source": [
        "cdc = []\n",
        "\n",
        "for x in range(len(ndf)):\n",
        "    if x in list(cdc_idx_dict.keys()):\n",
        "        cdc.append(cdc_idx_dict.get(x))\n",
        "    else:\n",
        "        cdc.append('---')\n",
        "ndf['cdc'] = cdc\n",
        "\n",
        "df = pd.concat([ndf, df], axis=0, ignore_index=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "feBrRx0C0-17"
      },
      "source": [
        "#### Article 3 "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "xsFVYYtw0-18",
        "colab": {}
      },
      "source": [
        "with open(articles_dict[articles[3].replace(' ','_')+'.txt']) as article:\n",
        "        doc = article.read()\n",
        "\n",
        "c_doc = text_cleaner(doc)\n",
        "sentences = nltk.sent_tokenize(c_doc)\n",
        "sentences = [[sent, topic, articles[3]] for sent in sentences]\n",
        "\n",
        "ndf = pd.DataFrame(sentences, columns=['text', 'topic', 'article'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "outputId": "69a7e807-373d-40bd-ad2f-81755a1cf090",
        "id": "qS42GNi9vkZ8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 170
        }
      },
      "source": [
        "ndf['text_clauses'] = ndf['text'].apply(lambda x: get_clauses(x))\n",
        "ndf['nm_clauses'] = ndf['text_clauses'].apply(lambda x: len(x))\n",
        "ndf['nm_clauses'].describe()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "count    175.000000\n",
              "mean       1.354286\n",
              "std        0.727278\n",
              "min        1.000000\n",
              "25%        1.000000\n",
              "50%        1.000000\n",
              "75%        2.000000\n",
              "max        7.000000\n",
              "Name: nm_clauses, dtype: float64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 67
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "outputId": "8a42cc79-a480-42a1-ac7f-d22b03537eef",
        "id": "4mm4Nd0x0-19",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "cdc_idx_dict = {}\n",
        "cdc_idx_sent = {}\n",
        "cdc_idx_art = {}\n",
        "\n",
        "for i,claim in enumerate(ref_data['clean_Claim']):\n",
        "    check_complete = False\n",
        "    while check_complete == False:\n",
        "        for idx,sentence in enumerate(ndf['text']):\n",
        "            test = claim.lower() in sentence.lower()\n",
        "            if test:\n",
        "                article = ref_data['Article'][i]\n",
        "                cdc_idx_dict[idx] = claim\n",
        "                cdc_idx_sent[idx] = [claim, sentence]\n",
        "                cdc_idx_art[idx] = [claim, article]\n",
        "                check_complete = True\n",
        "            elif idx == (len(ndf['text'])-1):\n",
        "                check_complete = True\n",
        "\n",
        "len(cdc_idx_dict), ref_data.shape[0]"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(4, 1332)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "outputId": "da807c83-7f26-4362-e0a2-b6a9854bfe96",
        "id": "htvCEg0n0-2A",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "cdc_idx_dict"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{43: \"it could play a role more useful to the cause of free speech by participating in China's IT industry than by refusing to comply\",\n",
              " 44: \"removing search results is inconsistent with Google's mission\",\n",
              " 49: 'Google China is a flagrant violation of the Google motto, \"Don\\'t be evil',\n",
              " 73: \"implementing monitoring according to a country's national context is what any government has to do\"}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "S9xB11mN0-2C",
        "colab": {}
      },
      "source": [
        "cdc = []\n",
        "\n",
        "for x in range(len(ndf)):\n",
        "    if x in list(cdc_idx_dict.keys()):\n",
        "        cdc.append(cdc_idx_dict.get(x))\n",
        "    else:\n",
        "        cdc.append('---')\n",
        "ndf['cdc'] = cdc\n",
        "\n",
        "df = pd.concat([ndf, df], axis=0, ignore_index=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "AOe0v1A20-2D"
      },
      "source": [
        "#### Article 4 "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "JV74xkTb0-2E",
        "colab": {}
      },
      "source": [
        "with open(articles_dict[articles[4].replace(' ','_')+'.txt']) as article:\n",
        "        doc = article.read()\n",
        "\n",
        "c_doc = text_cleaner(doc)\n",
        "sentences = nltk.sent_tokenize(c_doc)\n",
        "sentences = [[sent, topic, articles[4]] for sent in sentences]\n",
        "\n",
        "ndf = pd.DataFrame(sentences, columns=['text', 'topic', 'article'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "outputId": "0960e7c3-e92c-49a4-c02c-bdc2e6959fda",
        "id": "F2Zd7NeP0-2F",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "cdc_idx_dict = {}\n",
        "cdc_idx_sent = {}\n",
        "cdc_idx_art = {}\n",
        "\n",
        "for i,claim in enumerate(ref_data['clean_Claim']):\n",
        "    check_complete = False\n",
        "    while check_complete == False:\n",
        "        for idx,sentence in enumerate(ndf['text']):\n",
        "            test = claim.lower() in sentence.lower()\n",
        "            if test:\n",
        "                article = ref_data['Article'][i]\n",
        "                cdc_idx_dict[idx] = claim\n",
        "                cdc_idx_sent[idx] = [claim, sentence]\n",
        "                cdc_idx_art[idx] = [claim, article]\n",
        "                check_complete = True\n",
        "            elif idx == (len(ndf['text'])-1):\n",
        "                check_complete = True\n",
        "\n",
        "len(cdc_idx_dict), ref_data.shape[0]"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(3, 1332)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 37
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "outputId": "b6dd5c7b-bb21-4f10-9949-b95f70572b06",
        "id": "1xnSnyxq0-2H",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "cdc_idx_dict"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{4: 'Google\\'s stated mission is \"to organize the world\\'s information and make it universally accessible',\n",
              " 174: 'some censorship is necessary in order to keep the Chinese government from blocking Google entirely',\n",
              " 177: 'Google for assisting the Chinese government in repressing its own citizens'}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 38
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "_MsKoJ2G0-2J",
        "colab": {}
      },
      "source": [
        "cdc = []\n",
        "\n",
        "for x in range(len(ndf)):\n",
        "    if x in list(cdc_idx_dict.keys()):\n",
        "        cdc.append(cdc_idx_dict.get(x))\n",
        "    else:\n",
        "        cdc.append('---')\n",
        "ndf['cdc'] = cdc\n",
        "\n",
        "df = pd.concat([ndf, df], axis=0, ignore_index=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "snCsacA-2ZHO"
      },
      "source": [
        "#### Article 5 "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "b5n6-cEI2ZHP",
        "colab": {}
      },
      "source": [
        "with open(articles_dict[articles[5].replace(' ','_')+'.txt']) as article:\n",
        "        doc = article.read()\n",
        "\n",
        "c_doc = text_cleaner(doc)\n",
        "sentences = nltk.sent_tokenize(c_doc)\n",
        "sentences = [[sent, topic, articles[5]] for sent in sentences]\n",
        "\n",
        "ndf = pd.DataFrame(sentences, columns=['text', 'topic', 'article'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "outputId": "48ee44f4-9d6f-48b7-802c-4ba79b08f6e9",
        "id": "k2a-Ec7G2ZHQ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "cdc_idx_dict = {}\n",
        "cdc_idx_sent = {}\n",
        "cdc_idx_art = {}\n",
        "\n",
        "for i,claim in enumerate(ref_data['clean_Claim']):\n",
        "    check_complete = False\n",
        "    while check_complete == False:\n",
        "        for idx,sentence in enumerate(ndf['text']):\n",
        "            test = claim.lower() in sentence.lower()\n",
        "            if test:\n",
        "                article = ref_data['Article'][i]\n",
        "                cdc_idx_dict[idx] = claim\n",
        "                cdc_idx_sent[idx] = [claim, sentence]\n",
        "                cdc_idx_art[idx] = [claim, article]\n",
        "                check_complete = True\n",
        "            elif idx == (len(ndf['text'])-1):\n",
        "                check_complete = True\n",
        "\n",
        "len(cdc_idx_dict), ref_data.shape[0]"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(4, 1332)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 41
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "outputId": "2da19ec9-7048-4a73-a938-c02aaa5a26f9",
        "id": "zMoF8VmA2ZHS",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "cdc_idx_dict"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{67: 'the internet should never be regulated by any level of government anywhere',\n",
              " 71: 'access to the Internet was a fundamental right',\n",
              " 72: 'access to the Internet was a fundamental right of all people',\n",
              " 192: 'Google may temporarily or permanently remove sites from its index and search results if it believes it is obligated to do so by law'}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 42
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "wt309Pay2ZHT",
        "colab": {}
      },
      "source": [
        "cdc = []\n",
        "\n",
        "for x in range(len(ndf)):\n",
        "    if x in list(cdc_idx_dict.keys()):\n",
        "        cdc.append(cdc_idx_dict.get(x))\n",
        "    else:\n",
        "        cdc.append('---')\n",
        "ndf['cdc'] = cdc\n",
        "\n",
        "df = pd.concat([ndf, df], axis=0, ignore_index=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "h8L5B_gCxl_0",
        "colab_type": "text"
      },
      "source": [
        "### 'all collective bargaining rights claimed by trades unions '"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "outputId": "1dc56d87-9f9b-4514-956f-8043eccf35c6",
        "id": "xmhUaEd-1CV5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "topic = 'all collective bargaining rights claimed by trades unions '\n",
        "\n",
        "articles = topic_article_dict[topic]\n",
        "articles"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['Demir and Baykara v Turkey',\n",
              " 'Collective bargaining',\n",
              " 'Federal Labor Relations Act',\n",
              " 'Industrial unionism',\n",
              " 'Trade union',\n",
              " 'Opposition to trade unions']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 44
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "6obikW5A1CV7"
      },
      "source": [
        "#### Article 0 "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "5qa4M84p1CV8",
        "colab": {}
      },
      "source": [
        "with open(articles_dict[articles[0].replace(' ','_')+'.txt']) as article:\n",
        "        doc = article.read()\n",
        "\n",
        "c_doc = text_cleaner(doc)\n",
        "sentences = nltk.sent_tokenize(c_doc)\n",
        "sentences = [[sent, topic, articles[0]] for sent in sentences]\n",
        "\n",
        "ndf = pd.DataFrame(sentences, columns=['text', 'topic', 'article'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "outputId": "97818c6c-f765-414b-8667-870dd7acc0a9",
        "id": "-cU6kM2O1CV9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "cdc_idx_dict = {}\n",
        "cdc_idx_sent = {}\n",
        "cdc_idx_art = {}\n",
        "\n",
        "for i,claim in enumerate(ref_data['clean_Claim']):\n",
        "    check_complete = False\n",
        "    while check_complete == False:\n",
        "        for idx,sentence in enumerate(ndf['text']):\n",
        "            test = claim.lower() in sentence.lower()\n",
        "            if test:\n",
        "                article = ref_data['Article'][i]\n",
        "                cdc_idx_dict[idx] = claim\n",
        "                cdc_idx_sent[idx] = [claim, sentence]\n",
        "                cdc_idx_art[idx] = [claim, article]\n",
        "                check_complete = True\n",
        "            elif idx == (len(ndf['text'])-1):\n",
        "                check_complete = True\n",
        "\n",
        "len(cdc_idx_dict), ref_data.shape[0]"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(1, 1332)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 46
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "outputId": "8c2a6825-3f74-46ef-c1ce-805769823c9e",
        "id": "XjmK04rz1CV_",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "cdc_idx_dict"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{18: 'there is an inherent right to collective bargaining'}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 47
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "mMHbg1Uq1CWA",
        "colab": {}
      },
      "source": [
        "cdc = []\n",
        "\n",
        "for x in range(len(ndf)):\n",
        "    if x in list(cdc_idx_dict.keys()):\n",
        "        cdc.append(cdc_idx_dict.get(x))\n",
        "    else:\n",
        "        cdc.append('---')\n",
        "ndf['cdc'] = cdc\n",
        "\n",
        "df = pd.concat([ndf, df], axis=0, ignore_index=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "atBYQWa71CWC"
      },
      "source": [
        "#### Article 1 "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "7q6j5sWn1CWC",
        "colab": {}
      },
      "source": [
        "with open(articles_dict[articles[1].replace(' ','_')+'.txt']) as article:\n",
        "        doc = article.read()\n",
        "\n",
        "c_doc = text_cleaner(doc)\n",
        "sentences = nltk.sent_tokenize(c_doc)\n",
        "sentences = [[sent, topic, articles[1]] for sent in sentences]\n",
        "\n",
        "ndf = pd.DataFrame(sentences, columns=['text', 'topic', 'article'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "outputId": "c1ce815d-0668-43ed-d264-bf2544ec4ad1",
        "id": "8g9YA3My1CWE",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "cdc_idx_dict = {}\n",
        "cdc_idx_sent = {}\n",
        "cdc_idx_art = {}\n",
        "\n",
        "for i,claim in enumerate(ref_data['clean_Claim']):\n",
        "    check_complete = False\n",
        "    while check_complete == False:\n",
        "        for idx,sentence in enumerate(ndf['text']):\n",
        "            test = claim.lower() in sentence.lower()\n",
        "            if test:\n",
        "                article = ref_data['Article'][i]\n",
        "                cdc_idx_dict[idx] = claim\n",
        "                cdc_idx_sent[idx] = [claim, sentence]\n",
        "                cdc_idx_art[idx] = [claim, article]\n",
        "                check_complete = True\n",
        "            elif idx == (len(ndf['text'])-1):\n",
        "                check_complete = True\n",
        "\n",
        "len(cdc_idx_dict), ref_data.shape[0]"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(5, 1332)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 50
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "outputId": "07bbfe4b-f884-467b-8442-a1746930c3a7",
        "id": "HP71P0511CWG",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "cdc_idx_dict"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{9: 'The right to collectively bargain is recognized through international human rights conventions',\n",
              " 11: 'the \"freedom of association and the effective recognition of the right to collective bargaining\" as an essential right of workers',\n",
              " 12: 'collective bargaining as a human right',\n",
              " 14: 'The right to bargain collectively with an employer enhances the human dignity',\n",
              " 16: 'Collective bargaining permits workers to achieve a form of workplace democracy'}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 51
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "I5Mf7jAt1CWI",
        "colab": {}
      },
      "source": [
        "cdc = []\n",
        "\n",
        "for x in range(len(ndf)):\n",
        "    if x in list(cdc_idx_dict.keys()):\n",
        "        cdc.append(cdc_idx_dict.get(x))\n",
        "    else:\n",
        "        cdc.append('---')\n",
        "ndf['cdc'] = cdc\n",
        "\n",
        "df = pd.concat([df, ndf], axis=0, ignore_index=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "Ug9jtZiT1CWJ"
      },
      "source": [
        "#### Article 2 "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "iANEAirY1CWK",
        "colab": {}
      },
      "source": [
        "with open(articles_dict[articles[2].replace(' ','_')+'.txt']) as article:\n",
        "        doc = article.read()\n",
        "\n",
        "c_doc = text_cleaner(doc)\n",
        "sentences = nltk.sent_tokenize(c_doc)\n",
        "sentences = [[sent, topic, articles[2]] for sent in sentences]\n",
        "\n",
        "ndf = pd.DataFrame(sentences, columns=['text', 'topic', 'article'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "outputId": "3575246a-087f-4198-d455-b7859b91137a",
        "id": "YkewnnUQ1CWL",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "cdc_idx_dict = {}\n",
        "cdc_idx_sent = {}\n",
        "cdc_idx_art = {}\n",
        "\n",
        "for i,claim in enumerate(ref_data['clean_Claim']):\n",
        "    check_complete = False\n",
        "    while check_complete == False:\n",
        "        for idx,sentence in enumerate(ndf['text']):\n",
        "            test = claim.lower() in sentence.lower()\n",
        "            if test:\n",
        "                article = ref_data['Article'][i]\n",
        "                cdc_idx_dict[idx] = claim\n",
        "                cdc_idx_sent[idx] = [claim, sentence]\n",
        "                cdc_idx_art[idx] = [claim, article]\n",
        "                check_complete = True\n",
        "            elif idx == (len(ndf['text'])-1):\n",
        "                check_complete = True\n",
        "\n",
        "len(cdc_idx_dict), ref_data.shape[0]"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(1, 1332)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 54
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "outputId": "00a52044-2565-47fe-93bd-32a117ffdfc8",
        "id": "FSOUFRut1CWN",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "cdc_idx_dict"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{3: 'facilitates and encourages the amicable settlements of disputes between employees and their employers'}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 55
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "rLgBjGzK1CWP",
        "colab": {}
      },
      "source": [
        "cdc = []\n",
        "\n",
        "for x in range(len(ndf)):\n",
        "    if x in list(cdc_idx_dict.keys()):\n",
        "        cdc.append(cdc_idx_dict.get(x))\n",
        "    else:\n",
        "        cdc.append('---')\n",
        "ndf['cdc'] = cdc\n",
        "\n",
        "df = pd.concat([ndf, df], axis=0, ignore_index=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "rU7dd9k-1CWR"
      },
      "source": [
        "#### Article 3 "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "ct6Y8T1f1CWS",
        "colab": {}
      },
      "source": [
        "with open(articles_dict[articles[3].replace(' ','_')+'.txt']) as article:\n",
        "        doc = article.read()\n",
        "\n",
        "c_doc = text_cleaner(doc)\n",
        "sentences = nltk.sent_tokenize(c_doc)\n",
        "sentences = [[sent, topic, articles[3]] for sent in sentences]\n",
        "\n",
        "ndf = pd.DataFrame(sentences, columns=['text', 'topic', 'article'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "outputId": "ae246060-ea38-469f-dcf4-8d9f1bed1d94",
        "id": "ZDOaN7mi1CWU",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "cdc_idx_dict = {}\n",
        "cdc_idx_sent = {}\n",
        "cdc_idx_art = {}\n",
        "\n",
        "for i,claim in enumerate(ref_data['clean_Claim']):\n",
        "    check_complete = False\n",
        "    while check_complete == False:\n",
        "        for idx,sentence in enumerate(ndf['text']):\n",
        "            test = claim.lower() in sentence.lower()\n",
        "            if test:\n",
        "                article = ref_data['Article'][i]\n",
        "                cdc_idx_dict[idx] = claim\n",
        "                cdc_idx_sent[idx] = [claim, sentence]\n",
        "                cdc_idx_art[idx] = [claim, article]\n",
        "                check_complete = True\n",
        "            elif idx == (len(ndf['text'])-1):\n",
        "                check_complete = True\n",
        "\n",
        "len(cdc_idx_dict), ref_data.shape[0]"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(1, 1332)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 58
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "outputId": "ec4c4d14-0b63-4c65-af41-2c7986fcf93b",
        "id": "GMECOd0Z1CWV",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "cdc_idx_dict"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{28: 'an individual cannot stand alone against the power of the company'}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 59
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "5BTmqKR31CWY",
        "colab": {}
      },
      "source": [
        "cdc = []\n",
        "\n",
        "for x in range(len(ndf)):\n",
        "    if x in list(cdc_idx_dict.keys()):\n",
        "        cdc.append(cdc_idx_dict.get(x))\n",
        "    else:\n",
        "        cdc.append('---')\n",
        "ndf['cdc'] = cdc\n",
        "\n",
        "df = pd.concat([ndf, df], axis=0, ignore_index=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "mdgQrEZa1CWb"
      },
      "source": [
        "#### Article 4 "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "9aV0fH-n1CWb",
        "colab": {}
      },
      "source": [
        "with open(articles_dict[articles[4].replace(' ','_')+'.txt']) as article:\n",
        "        doc = article.read()\n",
        "\n",
        "c_doc = text_cleaner(doc)\n",
        "sentences = nltk.sent_tokenize(c_doc)\n",
        "sentences = [[sent, topic, articles[4]] for sent in sentences]\n",
        "\n",
        "ndf = pd.DataFrame(sentences, columns=['text', 'topic', 'article'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "outputId": "442cf3b8-2327-43b5-9d8c-3f74900bab7e",
        "id": "z0oyBRhS1CWc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "cdc_idx_dict = {}\n",
        "cdc_idx_sent = {}\n",
        "cdc_idx_art = {}\n",
        "\n",
        "for i,claim in enumerate(ref_data['clean_Claim']):\n",
        "    check_complete = False\n",
        "    while check_complete == False:\n",
        "        for idx,sentence in enumerate(ndf['text']):\n",
        "            test = claim.lower() in sentence.lower()\n",
        "            if test:\n",
        "                article = ref_data['Article'][i]\n",
        "                cdc_idx_dict[idx] = claim\n",
        "                cdc_idx_sent[idx] = [claim, sentence]\n",
        "                cdc_idx_art[idx] = [claim, article]\n",
        "                check_complete = True\n",
        "            elif idx == (len(ndf['text'])-1):\n",
        "                check_complete = True\n",
        "\n",
        "len(cdc_idx_dict), ref_data.shape[0]"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(1, 1332)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 62
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "outputId": "d047ea45-2a98-4d35-cb71-e5c4c14aab0c",
        "id": "W-7L-sr41CWe",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "cdc_idx_dict"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{318: 'unionisation produces higher wages (for the union members) at the expense of fewer jobs'}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 63
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "EWo7GMtE1CWf",
        "colab": {}
      },
      "source": [
        "cdc = []\n",
        "\n",
        "for x in range(len(ndf)):\n",
        "    if x in list(cdc_idx_dict.keys()):\n",
        "        cdc.append(cdc_idx_dict.get(x))\n",
        "    else:\n",
        "        cdc.append('---')\n",
        "ndf['cdc'] = cdc\n",
        "\n",
        "df = pd.concat([ndf, df], axis=0, ignore_index=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "q6lARy2B3eZ3"
      },
      "source": [
        "#### Article 5 "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "WU1L9tVs3eZ4",
        "colab": {}
      },
      "source": [
        "with open(articles_dict[articles[5].replace(' ','_')+'.txt']) as article:\n",
        "        doc = article.read()\n",
        "\n",
        "c_doc = text_cleaner(doc)\n",
        "sentences = nltk.sent_tokenize(c_doc)\n",
        "sentences = [[sent, topic, articles[5]] for sent in sentences]\n",
        "\n",
        "ndf = pd.DataFrame(sentences, columns=['text', 'topic', 'article'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "outputId": "de8b4532-064e-4bad-a007-c6530b21dff2",
        "id": "W_PlZ9jl3eZ6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "cdc_idx_dict = {}\n",
        "cdc_idx_sent = {}\n",
        "cdc_idx_art = {}\n",
        "\n",
        "for i,claim in enumerate(ref_data['clean_Claim']):\n",
        "    check_complete = False\n",
        "    while check_complete == False:\n",
        "        for idx,sentence in enumerate(ndf['text']):\n",
        "            test = claim.lower() in sentence.lower()\n",
        "            if test:\n",
        "                article = ref_data['Article'][i]\n",
        "                cdc_idx_dict[idx] = claim\n",
        "                cdc_idx_sent[idx] = [claim, sentence]\n",
        "                cdc_idx_art[idx] = [claim, article]\n",
        "                check_complete = True\n",
        "            elif idx == (len(ndf['text'])-1):\n",
        "                check_complete = True\n",
        "\n",
        "len(cdc_idx_dict), ref_data.shape[0]"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(6, 1332)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 66
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "outputId": "acdcc5c3-c3ae-4c2d-dc65-7950bc9aca6d",
        "id": "4Ivy-g-B3eZ8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "cdc_idx_dict"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{3: 'frequently produces higher wages at the expense of fewer jobs',\n",
              " 11: 'unions promote deadweight loss',\n",
              " 18: 'The effect of union activities to influence pricing is potentially very harmful',\n",
              " 36: 'unions never raise productivity to compensate for higher wages',\n",
              " 40: 'unionized workers will spend their higher wages, driving economic growth and creating new jobs',\n",
              " 46: 'Unions may serve the practical purpose of leveling the playing-field between workers and powerful oligopolies'}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 67
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "h6pkpVB53eZ9",
        "colab": {}
      },
      "source": [
        "cdc = []\n",
        "\n",
        "for x in range(len(ndf)):\n",
        "    if x in list(cdc_idx_dict.keys()):\n",
        "        cdc.append(cdc_idx_dict.get(x))\n",
        "    else:\n",
        "        cdc.append('---')\n",
        "ndf['cdc'] = cdc\n",
        "\n",
        "df = pd.concat([ndf, df], axis=0, ignore_index=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c1OKmUnDxun0",
        "colab_type": "text"
      },
      "source": [
        "### 'all nations have a right to nuclear weapons '"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "outputId": "4de46887-9cdc-4727-dd1d-53abb73a68c8",
        "id": "nEFDxNFU1D-r",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "topic = 'all nations have a right to nuclear weapons '\n",
        "\n",
        "articles = topic_article_dict[topic]\n",
        "articles"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['Anti-nuclear movement',\n",
              " 'Nuclear warfare',\n",
              " 'Nuclear proliferation',\n",
              " 'Nuclear holocaust',\n",
              " 'Kenneth Waltz',\n",
              " 'Nuclear weapons debate',\n",
              " 'International Atomic Energy Agency',\n",
              " 'History of nuclear weapons',\n",
              " 'Iran and weapons of mass destruction',\n",
              " 'Deterrence theory',\n",
              " 'Nuclear peace',\n",
              " 'Mutual assured destruction',\n",
              " 'Treaty on the Non-Proliferation of Nuclear Weapons',\n",
              " 'Salted bomb',\n",
              " 'India and weapons of mass destruction',\n",
              " 'UK Trident programme',\n",
              " 'Nuclear weapon',\n",
              " \"Japan's non-nuclear weapons policy\",\n",
              " 'Nuclear disarmament',\n",
              " 'Stability-instability paradox']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 69
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MLKUO6eq5YB4",
        "colab_type": "code",
        "outputId": "9d250329-fba1-4329-93ab-518b38054d64",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "len(articles)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "20"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 70
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "Rptp7U4E1D-t"
      },
      "source": [
        "#### Article 0 "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "ix7nMMUh1D-u",
        "colab": {}
      },
      "source": [
        "with open(articles_dict[articles[0].replace(' ','_')+'.txt']) as article:\n",
        "        doc = article.read()\n",
        "\n",
        "c_doc = text_cleaner(doc)\n",
        "sentences = nltk.sent_tokenize(c_doc)\n",
        "sentences = [[sent, topic, articles[0]] for sent in sentences]\n",
        "\n",
        "ndf = pd.DataFrame(sentences, columns=['text', 'topic', 'article'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "outputId": "7cced632-3607-4840-892d-238918234300",
        "id": "0KYgApMB1D-v",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "cdc_idx_dict = {}\n",
        "cdc_idx_sent = {}\n",
        "cdc_idx_art = {}\n",
        "\n",
        "for i,claim in enumerate(ref_data['clean_Claim']):\n",
        "    check_complete = False\n",
        "    while check_complete == False:\n",
        "        for idx,sentence in enumerate(ndf['text']):\n",
        "            test = claim.lower() in sentence.lower()\n",
        "            if test:\n",
        "                article = ref_data['Article'][i]\n",
        "                cdc_idx_dict[idx] = claim\n",
        "                cdc_idx_sent[idx] = [claim, sentence]\n",
        "                cdc_idx_art[idx] = [claim, article]\n",
        "                check_complete = True\n",
        "            elif idx == (len(ndf['text'])-1):\n",
        "                check_complete = True\n",
        "\n",
        "len(cdc_idx_dict), ref_data.shape[0]"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(1, 1332)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 72
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "outputId": "572b3bfa-2682-493e-fb88-1b96da74d485",
        "id": "enmnd1eo1D-x",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "cdc_idx_dict"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{33: 'nuclear weapons had become a source of extreme risk'}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 73
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "17ZZkEHX1D-y",
        "colab": {}
      },
      "source": [
        "cdc = []\n",
        "\n",
        "for x in range(len(ndf)):\n",
        "    if x in list(cdc_idx_dict.keys()):\n",
        "        cdc.append(cdc_idx_dict.get(x))\n",
        "    else:\n",
        "        cdc.append('---')\n",
        "ndf['cdc'] = cdc\n",
        "\n",
        "df = pd.concat([ndf, df], axis=0, ignore_index=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "vnNDlfen1D-0"
      },
      "source": [
        "#### Article 1 "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "GnYzg_T-1D-0",
        "colab": {}
      },
      "source": [
        "with open(articles_dict[articles[1].replace(' ','_')+'.txt']) as article:\n",
        "        doc = article.read()\n",
        "\n",
        "c_doc = text_cleaner(doc)\n",
        "sentences = nltk.sent_tokenize(c_doc)\n",
        "sentences = [[sent, topic, articles[1]] for sent in sentences]\n",
        "\n",
        "ndf = pd.DataFrame(sentences, columns=['text', 'topic', 'article'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "outputId": "ffcc0a50-6289-45b6-96e9-cd4243d62627",
        "id": "DTsr1smy1D-2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "cdc_idx_dict = {}\n",
        "cdc_idx_sent = {}\n",
        "cdc_idx_art = {}\n",
        "\n",
        "for i,claim in enumerate(ref_data['clean_Claim']):\n",
        "    check_complete = False\n",
        "    while check_complete == False:\n",
        "        for idx,sentence in enumerate(ndf['text']):\n",
        "            test = claim.lower() in sentence.lower()\n",
        "            if test:\n",
        "                article = ref_data['Article'][i]\n",
        "                cdc_idx_dict[idx] = claim\n",
        "                cdc_idx_sent[idx] = [claim, sentence]\n",
        "                cdc_idx_art[idx] = [claim, article]\n",
        "                check_complete = True\n",
        "            elif idx == (len(ndf['text'])-1):\n",
        "                check_complete = True\n",
        "\n",
        "len(cdc_idx_dict), ref_data.shape[0]"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(2, 1332)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 76
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "outputId": "8254fa5f-07d7-483e-ea81-7e9070588dba",
        "id": "iOG3uG-41D-6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "cdc_idx_dict"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{26: 'a full-scale nuclear war could potentially bring about the extinction of the human race',\n",
              " 127: 'a full-scale nuclear war would result in the extinction of the human species'}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 77
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "BDAoNUHF1D-8",
        "colab": {}
      },
      "source": [
        "cdc = []\n",
        "\n",
        "for x in range(len(ndf)):\n",
        "    if x in list(cdc_idx_dict.keys()):\n",
        "        cdc.append(cdc_idx_dict.get(x))\n",
        "    else:\n",
        "        cdc.append('---')\n",
        "ndf['cdc'] = cdc\n",
        "\n",
        "df = pd.concat([df, ndf], axis=0, ignore_index=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "m8j7KW4R1D-9"
      },
      "source": [
        "#### Article 2 "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "KBbpiW5A1D--",
        "colab": {}
      },
      "source": [
        "with open(articles_dict[articles[2].replace(' ','_')+'.txt']) as article:\n",
        "        doc = article.read()\n",
        "\n",
        "c_doc = text_cleaner(doc)\n",
        "sentences = nltk.sent_tokenize(c_doc)\n",
        "sentences = [[sent, topic, articles[2]] for sent in sentences]\n",
        "\n",
        "ndf = pd.DataFrame(sentences, columns=['text', 'topic', 'article'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "outputId": "6b7cb9cb-e002-464d-eb81-453c37dcce51",
        "id": "Td5M7Vul1D-_",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "cdc_idx_dict = {}\n",
        "cdc_idx_sent = {}\n",
        "cdc_idx_art = {}\n",
        "\n",
        "for i,claim in enumerate(ref_data['clean_Claim']):\n",
        "    check_complete = False\n",
        "    while check_complete == False:\n",
        "        for idx,sentence in enumerate(ndf['text']):\n",
        "            test = claim.lower() in sentence.lower()\n",
        "            if test:\n",
        "                article = ref_data['Article'][i]\n",
        "                cdc_idx_dict[idx] = claim\n",
        "                cdc_idx_sent[idx] = [claim, sentence]\n",
        "                cdc_idx_art[idx] = [claim, article]\n",
        "                check_complete = True\n",
        "            elif idx == (len(ndf['text'])-1):\n",
        "                check_complete = True\n",
        "\n",
        "len(cdc_idx_dict), ref_data.shape[0]"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(8, 1332)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 80
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "outputId": "630926bd-1e32-4674-a9d1-1fbf54a941f4",
        "id": "RZ29jvoA1D_A",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "cdc_idx_dict"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{1: 'more countries with nuclear weapons may increase the possibility of nuclear warfare',\n",
              " 38: 'A fundamental goal for American and global security is to minimize the proliferation risks associated with the expansion of nuclear power',\n",
              " 401: 'the spread of nuclear weapons could increase international stability',\n",
              " 403: 'it will decrease the likelihood of war',\n",
              " 407: 'nuclear weapons promote caution in decision-makers',\n",
              " 421: 'weak states will be unable to prevent – or will actively provide for – the disastrous possibility of nuclear terrorism',\n",
              " 431: 'If one state produces a nuclear weapon it creates almost a domino effect within the region',\n",
              " 438: 'prohibition on nuclear proliferation has been characterised as a form of technological apartheid'}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 81
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "2u1yO8ZE1D_C",
        "colab": {}
      },
      "source": [
        "cdc = []\n",
        "\n",
        "for x in range(len(ndf)):\n",
        "    if x in list(cdc_idx_dict.keys()):\n",
        "        cdc.append(cdc_idx_dict.get(x))\n",
        "    else:\n",
        "        cdc.append('---')\n",
        "ndf['cdc'] = cdc\n",
        "\n",
        "df = pd.concat([ndf, df], axis=0, ignore_index=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "gp5Nqeeo1D_D"
      },
      "source": [
        "#### Article 3 "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "LP-s03A21D_E",
        "colab": {}
      },
      "source": [
        "with open(articles_dict[articles[3].replace(' ','_')+'.txt']) as article:\n",
        "        doc = article.read()\n",
        "\n",
        "c_doc = text_cleaner(doc)\n",
        "sentences = nltk.sent_tokenize(c_doc)\n",
        "sentences = [[sent, topic, articles[3]] for sent in sentences]\n",
        "\n",
        "ndf = pd.DataFrame(sentences, columns=['text', 'topic', 'article'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "outputId": "f524812c-9fbf-43c6-faac-ab1ffff4a7fd",
        "id": "A4aYhL301D_F",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "cdc_idx_dict = {}\n",
        "cdc_idx_sent = {}\n",
        "cdc_idx_art = {}\n",
        "\n",
        "for i,claim in enumerate(ref_data['clean_Claim']):\n",
        "    check_complete = False\n",
        "    while check_complete == False:\n",
        "        for idx,sentence in enumerate(ndf['text']):\n",
        "            test = claim.lower() in sentence.lower()\n",
        "            if test:\n",
        "                article = ref_data['Article'][i]\n",
        "                cdc_idx_dict[idx] = claim\n",
        "                cdc_idx_sent[idx] = [claim, sentence]\n",
        "                cdc_idx_art[idx] = [claim, article]\n",
        "                check_complete = True\n",
        "            elif idx == (len(ndf['text'])-1):\n",
        "                check_complete = True\n",
        "\n",
        "len(cdc_idx_dict), ref_data.shape[0]"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(1, 1332)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 84
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "outputId": "f7b97dee-0ce4-44dd-9149-016afdfd3fa0",
        "id": "L7tKgPuN1D_G",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "cdc_idx_dict"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{8: 'nuclear holocaust could result in an end to human life'}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 85
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "qyBGzOKl1D_H",
        "colab": {}
      },
      "source": [
        "cdc = []\n",
        "\n",
        "for x in range(len(ndf)):\n",
        "    if x in list(cdc_idx_dict.keys()):\n",
        "        cdc.append(cdc_idx_dict.get(x))\n",
        "    else:\n",
        "        cdc.append('---')\n",
        "ndf['cdc'] = cdc\n",
        "\n",
        "df = pd.concat([ndf, df], axis=0, ignore_index=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "mKmKXc851D_J"
      },
      "source": [
        "#### Article 4 "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "sqiYmSoC1D_J",
        "colab": {}
      },
      "source": [
        "with open(articles_dict[articles[4].replace(' ','_')+'.txt']) as article:\n",
        "        doc = article.read()\n",
        "\n",
        "c_doc = text_cleaner(doc)\n",
        "sentences = nltk.sent_tokenize(c_doc)\n",
        "sentences = [[sent, topic, articles[4]] for sent in sentences]\n",
        "\n",
        "ndf = pd.DataFrame(sentences, columns=['text', 'topic', 'article'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "outputId": "31ec52bf-d2e0-42d7-9e42-aa91caad2ac0",
        "id": "LE7Tvhki1D_L",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "cdc_idx_dict = {}\n",
        "cdc_idx_sent = {}\n",
        "cdc_idx_art = {}\n",
        "\n",
        "for i,claim in enumerate(ref_data['clean_Claim']):\n",
        "    check_complete = False\n",
        "    while check_complete == False:\n",
        "        for idx,sentence in enumerate(ndf['text']):\n",
        "            test = claim.lower() in sentence.lower()\n",
        "            if test:\n",
        "                article = ref_data['Article'][i]\n",
        "                cdc_idx_dict[idx] = claim\n",
        "                cdc_idx_sent[idx] = [claim, sentence]\n",
        "                cdc_idx_art[idx] = [claim, article]\n",
        "                check_complete = True\n",
        "            elif idx == (len(ndf['text'])-1):\n",
        "                check_complete = True\n",
        "\n",
        "len(cdc_idx_dict), ref_data.shape[0]"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(2, 1332)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 88
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "outputId": "b7fe4bb0-d02f-4240-c7e7-91a437bf36e8",
        "id": "k4ZZsA2r1D_M",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "cdc_idx_dict"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{16: 'states must act in a way that ensures their security above all',\n",
              " 17: 'they cannot count on the good will of others to help them, so they must always be ready to fend for themselves'}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 89
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "e7eW4RWo1D_N",
        "colab": {}
      },
      "source": [
        "cdc = []\n",
        "\n",
        "for x in range(len(ndf)):\n",
        "    if x in list(cdc_idx_dict.keys()):\n",
        "        cdc.append(cdc_idx_dict.get(x))\n",
        "    else:\n",
        "        cdc.append('---')\n",
        "ndf['cdc'] = cdc\n",
        "\n",
        "df = pd.concat([ndf, df], axis=0, ignore_index=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MChxPt7q4RMs",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "6X-mGHnx4ZD2"
      },
      "source": [
        "#### Article 5"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "87RPAc1K4ZD3",
        "colab": {}
      },
      "source": [
        "with open(articles_dict[articles[5].replace(' ','_')+'.txt']) as article:\n",
        "        doc = article.read()\n",
        "\n",
        "c_doc = text_cleaner(doc)\n",
        "sentences = nltk.sent_tokenize(c_doc)\n",
        "sentences = [[sent, topic, articles[5]] for sent in sentences]\n",
        "\n",
        "ndf = pd.DataFrame(sentences, columns=['text', 'topic', 'article'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "outputId": "e8a7d444-99bc-4af9-f362-18926664b344",
        "id": "0rMzdEbK4ZD4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "cdc_idx_dict = {}\n",
        "cdc_idx_sent = {}\n",
        "cdc_idx_art = {}\n",
        "\n",
        "for i,claim in enumerate(ref_data['clean_Claim']):\n",
        "    check_complete = False\n",
        "    while check_complete == False:\n",
        "        for idx,sentence in enumerate(ndf['text']):\n",
        "            test = claim.lower() in sentence.lower()\n",
        "            if test:\n",
        "                article = ref_data['Article'][i]\n",
        "                cdc_idx_dict[idx] = claim\n",
        "                cdc_idx_sent[idx] = [claim, sentence]\n",
        "                cdc_idx_art[idx] = [claim, article]\n",
        "                check_complete = True\n",
        "            elif idx == (len(ndf['text'])-1):\n",
        "                check_complete = True\n",
        "\n",
        "len(cdc_idx_dict), ref_data.shape[0]"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(7, 1332)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 92
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "outputId": "ca86355c-3654-4990-8b9e-792a9f7330d2",
        "id": "UvwLa2W04ZD5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "cdc_idx_dict"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{7: 'it would undermine deterrence',\n",
              " 10: 'no issue carries more importance to the long-term health and security of humanity than the effort to reduce, and perhaps one day, rid the world of nuclear weapons',\n",
              " 29: 'it would undermine deterrence',\n",
              " 31: 'Nuclear weapons are said to have induced \"nuclear peace',\n",
              " 34: 'is obsolete',\n",
              " 41: 'the likelihood that non-state terrorists will get their hands on nuclear weaponry is increasing',\n",
              " 44: 'no issue carries more importance to the long-term health and security of humanity than the effort to reduce, and perhaps one day, rid the world of nuclear weapons'}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 93
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "zHRhtU894ZD6",
        "colab": {}
      },
      "source": [
        "cdc = []\n",
        "\n",
        "for x in range(len(ndf)):\n",
        "    if x in list(cdc_idx_dict.keys()):\n",
        "        cdc.append(cdc_idx_dict.get(x))\n",
        "    else:\n",
        "        cdc.append('---')\n",
        "ndf['cdc'] = cdc\n",
        "\n",
        "df = pd.concat([ndf, df], axis=0, ignore_index=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "BJkxnY_I4Ylc"
      },
      "source": [
        "#### Article 6"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "JGPxjU5M4Yld",
        "colab": {}
      },
      "source": [
        "with open(articles_dict[articles[6].replace(' ','_')+'.txt']) as article:\n",
        "        doc = article.read()\n",
        "\n",
        "c_doc = text_cleaner(doc)\n",
        "sentences = nltk.sent_tokenize(c_doc)\n",
        "sentences = [[sent, topic, articles[6]] for sent in sentences]\n",
        "\n",
        "ndf = pd.DataFrame(sentences, columns=['text', 'topic', 'article'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "outputId": "a1873e88-75c7-49a2-cb77-0375bc5e39c4",
        "id": "-jkwfd0m4Yle",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "cdc_idx_dict = {}\n",
        "cdc_idx_sent = {}\n",
        "cdc_idx_art = {}\n",
        "\n",
        "for i,claim in enumerate(ref_data['clean_Claim']):\n",
        "    check_complete = False\n",
        "    while check_complete == False:\n",
        "        for idx,sentence in enumerate(ndf['text']):\n",
        "            test = claim.lower() in sentence.lower()\n",
        "            if test:\n",
        "                article = ref_data['Article'][i]\n",
        "                cdc_idx_dict[idx] = claim\n",
        "                cdc_idx_sent[idx] = [claim, sentence]\n",
        "                cdc_idx_art[idx] = [claim, article]\n",
        "                check_complete = True\n",
        "            elif idx == (len(ndf['text'])-1):\n",
        "                check_complete = True\n",
        "\n",
        "len(cdc_idx_dict), ref_data.shape[0]"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(1, 1332)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 96
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "outputId": "2837e528-9568-4fd2-9f54-bd9981dccbf7",
        "id": "apyG4LKx4Ylf",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "cdc_idx_dict"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{26: 'if we hope to escape self-destruction, then nuclear weapons should have no place in our collective conscience, and no role in our security'}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 97
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "PfCngCHf4Ylg",
        "colab": {}
      },
      "source": [
        "cdc = []\n",
        "\n",
        "for x in range(len(ndf)):\n",
        "    if x in list(cdc_idx_dict.keys()):\n",
        "        cdc.append(cdc_idx_dict.get(x))\n",
        "    else:\n",
        "        cdc.append('---')\n",
        "ndf['cdc'] = cdc\n",
        "\n",
        "df = pd.concat([ndf, df], axis=0, ignore_index=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "8FbsGBlJ4YFR"
      },
      "source": [
        "#### Article 7"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "W_UEWPrI4YFS",
        "colab": {}
      },
      "source": [
        "with open(articles_dict[articles[7].replace(' ','_')+'.txt']) as article:\n",
        "        doc = article.read()\n",
        "\n",
        "c_doc = text_cleaner(doc)\n",
        "sentences = nltk.sent_tokenize(c_doc)\n",
        "sentences = [[sent, topic, articles[7]] for sent in sentences]\n",
        "\n",
        "ndf = pd.DataFrame(sentences, columns=['text', 'topic', 'article'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "outputId": "d3e1891e-e563-420e-abaf-9923088108ff",
        "id": "cJbg-IzW4YFT",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "cdc_idx_dict = {}\n",
        "cdc_idx_sent = {}\n",
        "cdc_idx_art = {}\n",
        "\n",
        "for i,claim in enumerate(ref_data['clean_Claim']):\n",
        "    check_complete = False\n",
        "    while check_complete == False:\n",
        "        for idx,sentence in enumerate(ndf['text']):\n",
        "            test = claim.lower() in sentence.lower()\n",
        "            if test:\n",
        "                article = ref_data['Article'][i]\n",
        "                cdc_idx_dict[idx] = claim\n",
        "                cdc_idx_sent[idx] = [claim, sentence]\n",
        "                cdc_idx_art[idx] = [claim, article]\n",
        "                check_complete = True\n",
        "            elif idx == (len(ndf['text'])-1):\n",
        "                check_complete = True\n",
        "\n",
        "len(cdc_idx_dict), ref_data.shape[0]"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(1, 1332)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 100
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "outputId": "56073941-1d24-4f61-98c5-75f8c8bf6cf2",
        "id": "VdfjzeHw4YFU",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "cdc_idx_dict"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{217: 'the greater the threat of mutual destruction, the safer the world would be'}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 101
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "6Wi-1ZjB4YFV",
        "colab": {}
      },
      "source": [
        "cdc = []\n",
        "\n",
        "for x in range(len(ndf)):\n",
        "    if x in list(cdc_idx_dict.keys()):\n",
        "        cdc.append(cdc_idx_dict.get(x))\n",
        "    else:\n",
        "        cdc.append('---')\n",
        "ndf['cdc'] = cdc\n",
        "\n",
        "df = pd.concat([ndf, df], axis=0, ignore_index=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "xhKQexSt4Xlo"
      },
      "source": [
        "#### Article 8"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "ZxD_jeTv4Xlp",
        "colab": {}
      },
      "source": [
        "with open(articles_dict[articles[8].replace(' ','_')+'.txt']) as article:\n",
        "        doc = article.read()\n",
        "\n",
        "c_doc = text_cleaner(doc)\n",
        "sentences = nltk.sent_tokenize(c_doc)\n",
        "sentences = [[sent, topic, articles[8]] for sent in sentences]\n",
        "\n",
        "ndf = pd.DataFrame(sentences, columns=['text', 'topic', 'article'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "outputId": "aa0dfa6e-6284-4630-f6fa-ee4191a9f610",
        "id": "_tWb0D8V4Xlq",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "cdc_idx_dict = {}\n",
        "cdc_idx_sent = {}\n",
        "cdc_idx_art = {}\n",
        "\n",
        "for i,claim in enumerate(ref_data['clean_Claim']):\n",
        "    check_complete = False\n",
        "    while check_complete == False:\n",
        "        for idx,sentence in enumerate(ndf['text']):\n",
        "            test = claim.lower() in sentence.lower()\n",
        "            if test:\n",
        "                article = ref_data['Article'][i]\n",
        "                cdc_idx_dict[idx] = claim\n",
        "                cdc_idx_sent[idx] = [claim, sentence]\n",
        "                cdc_idx_art[idx] = [claim, article]\n",
        "                check_complete = True\n",
        "            elif idx == (len(ndf['text'])-1):\n",
        "                check_complete = True\n",
        "\n",
        "len(cdc_idx_dict), ref_data.shape[0]"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(2, 1332)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 104
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "outputId": "2c51825e-7791-428d-8a94-8e76718ca708",
        "id": "DBMcUIev4Xlr",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "cdc_idx_dict"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{165: 'the present situation whereby Nuclear Weapon States monopolise the right to possess nuclear weapons is \"highly discriminatory',\n",
              " 404: 'the present situation whereby Nuclear Weapon States monopolise the right to possess nuclear weapons is \"highly discriminatory'}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 105
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "6pAKPw4z4Xlt",
        "colab": {}
      },
      "source": [
        "cdc = []\n",
        "\n",
        "for x in range(len(ndf)):\n",
        "    if x in list(cdc_idx_dict.keys()):\n",
        "        cdc.append(cdc_idx_dict.get(x))\n",
        "    else:\n",
        "        cdc.append('---')\n",
        "ndf['cdc'] = cdc\n",
        "\n",
        "df = pd.concat([ndf, df], axis=0, ignore_index=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "gslOot1j4XEx"
      },
      "source": [
        "#### Article 9 "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "9pM-YXSx4XEx",
        "colab": {}
      },
      "source": [
        "with open(articles_dict[articles[9].replace(' ','_')+'.txt']) as article:\n",
        "        doc = article.read()\n",
        "\n",
        "c_doc = text_cleaner(doc)\n",
        "sentences = nltk.sent_tokenize(c_doc)\n",
        "sentences = [[sent, topic, articles[9]] for sent in sentences]\n",
        "\n",
        "ndf = pd.DataFrame(sentences, columns=['text', 'topic', 'article'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "outputId": "27c4413d-9af3-416d-d210-3385e1c83747",
        "id": "gfQY6WAP4XEz",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "cdc_idx_dict = {}\n",
        "cdc_idx_sent = {}\n",
        "cdc_idx_art = {}\n",
        "\n",
        "for i,claim in enumerate(ref_data['clean_Claim']):\n",
        "    check_complete = False\n",
        "    while check_complete == False:\n",
        "        for idx,sentence in enumerate(ndf['text']):\n",
        "            test = claim.lower() in sentence.lower()\n",
        "            if test:\n",
        "                article = ref_data['Article'][i]\n",
        "                cdc_idx_dict[idx] = claim\n",
        "                cdc_idx_sent[idx] = [claim, sentence]\n",
        "                cdc_idx_art[idx] = [claim, article]\n",
        "                check_complete = True\n",
        "            elif idx == (len(ndf['text'])-1):\n",
        "                check_complete = True\n",
        "\n",
        "len(cdc_idx_dict), ref_data.shape[0]"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(5, 1332)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 108
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "outputId": "aa31557a-a0dd-4ab7-cfa4-4a00dafef929",
        "id": "IlX0opqv4XE0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "cdc_idx_dict"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{3: 'an inferior nuclear force, by virtue of its extreme destructive power, could deter a more powerful adversary',\n",
              " 16: 'nuclear weapons had become a source of extreme risk',\n",
              " 37: 'nuclear weapons are intended to deter other states from attacking with their nuclear weapons',\n",
              " 98: 'Nuclear weapons give nations the potential to not only destroy their enemies but humanity itself',\n",
              " 127: 'nuclear weapons had become a source of extreme risk'}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 109
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "2JvOZAox4XE1",
        "colab": {}
      },
      "source": [
        "cdc = []\n",
        "\n",
        "for x in range(len(ndf)):\n",
        "    if x in list(cdc_idx_dict.keys()):\n",
        "        cdc.append(cdc_idx_dict.get(x))\n",
        "    else:\n",
        "        cdc.append('---')\n",
        "ndf['cdc'] = cdc\n",
        "\n",
        "df = pd.concat([ndf, df], axis=0, ignore_index=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "4yzgHod54Wj5"
      },
      "source": [
        "#### Article 10 "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "xgr-Yw8u4Wj5",
        "colab": {}
      },
      "source": [
        "with open(articles_dict[articles[10].replace(' ','_')+'.txt']) as article:\n",
        "        doc = article.read()\n",
        "\n",
        "c_doc = text_cleaner(doc)\n",
        "sentences = nltk.sent_tokenize(c_doc)\n",
        "sentences = [[sent, topic, articles[10]] for sent in sentences]\n",
        "\n",
        "ndf = pd.DataFrame(sentences, columns=['text', 'topic', 'article'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "outputId": "232e0d04-f37f-4035-a74a-3b23bd93365f",
        "id": "wyQlyqlC4Wj7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "cdc_idx_dict = {}\n",
        "cdc_idx_sent = {}\n",
        "cdc_idx_art = {}\n",
        "\n",
        "for i,claim in enumerate(ref_data['clean_Claim']):\n",
        "    check_complete = False\n",
        "    while check_complete == False:\n",
        "        for idx,sentence in enumerate(ndf['text']):\n",
        "            test = claim.lower() in sentence.lower()\n",
        "            if test:\n",
        "                article = ref_data['Article'][i]\n",
        "                cdc_idx_dict[idx] = claim\n",
        "                cdc_idx_sent[idx] = [claim, sentence]\n",
        "                cdc_idx_art[idx] = [claim, article]\n",
        "                check_complete = True\n",
        "            elif idx == (len(ndf['text'])-1):\n",
        "                check_complete = True\n",
        "\n",
        "len(cdc_idx_dict), ref_data.shape[0]"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(9, 1332)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 112
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "outputId": "f7171964-2d92-45e9-9476-36e03e19d437",
        "id": "uUoJgSeG4Wj9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "cdc_idx_dict"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{0: 'decrease the chances of crisis escalation',\n",
              " 1: 'nuclear weapons are said to have induced stability',\n",
              " 2: 'nuclear proliferation may be beneficial for inducing stability',\n",
              " 3: 'increases the chances of nuclear material falling into the hands of non-state groups who are free from the threat of nuclear retaliation',\n",
              " 5: 'new nuclear states will use their acquired nuclear capabilities to deter threats and preserve peace',\n",
              " 6: 'new nuclear states often lack adequate organizational controls over their new weapons, which makes for a high risk of either deliberate or accidental nuclear war',\n",
              " 13: \"Nuclear weapons may also lessen a state's reliance on allies for security, thus preventing allies from dragging each other into wars\",\n",
              " 26: 'nuclear weapons induce stability',\n",
              " 27: 'nuclear weapons contribute to stability'}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 113
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "kLBJFlNX4Wj_",
        "colab": {}
      },
      "source": [
        "cdc = []\n",
        "\n",
        "for x in range(len(ndf)):\n",
        "    if x in list(cdc_idx_dict.keys()):\n",
        "        cdc.append(cdc_idx_dict.get(x))\n",
        "    else:\n",
        "        cdc.append('---')\n",
        "ndf['cdc'] = cdc\n",
        "\n",
        "df = pd.concat([ndf, df], axis=0, ignore_index=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "5KYpMUuh4WBy"
      },
      "source": [
        "#### Article 11"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "onaA9Iig4WBz",
        "colab": {}
      },
      "source": [
        "with open(articles_dict[articles[11].replace(' ','_')+'.txt']) as article:\n",
        "        doc = article.read()\n",
        "\n",
        "c_doc = text_cleaner(doc)\n",
        "sentences = nltk.sent_tokenize(c_doc)\n",
        "sentences = [[sent, topic, articles[11]] for sent in sentences]\n",
        "\n",
        "ndf = pd.DataFrame(sentences, columns=['text', 'topic', 'article'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "outputId": "932723aa-880a-49e7-8ee0-3d95724e5b85",
        "id": "D4EV2hHW4WB0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "cdc_idx_dict = {}\n",
        "cdc_idx_sent = {}\n",
        "cdc_idx_art = {}\n",
        "\n",
        "for i,claim in enumerate(ref_data['clean_Claim']):\n",
        "    check_complete = False\n",
        "    while check_complete == False:\n",
        "        for idx,sentence in enumerate(ndf['text']):\n",
        "            test = claim.lower() in sentence.lower()\n",
        "            if test:\n",
        "                article = ref_data['Article'][i]\n",
        "                cdc_idx_dict[idx] = claim\n",
        "                cdc_idx_sent[idx] = [claim, sentence]\n",
        "                cdc_idx_art[idx] = [claim, article]\n",
        "                check_complete = True\n",
        "            elif idx == (len(ndf['text'])-1):\n",
        "                check_complete = True\n",
        "\n",
        "len(cdc_idx_dict), ref_data.shape[0]"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(2, 1332)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 116
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "outputId": "a0d30422-d821-4d8a-c74e-8d011095ed02",
        "id": "PFv580tP4WB2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "cdc_idx_dict"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{1: 'the deployment, and implicit menace of use, of strong weapons is essential to threaten the enemy in order to prevent the use by said-enemy of the same weapons',\n",
              " 75: 'a nuclear nation might be hijacked by a despot or other person or persons who might use nuclear weapons without sane regard for the consequences'}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 117
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "EWrBgUuq4WB3",
        "colab": {}
      },
      "source": [
        "cdc = []\n",
        "\n",
        "for x in range(len(ndf)):\n",
        "    if x in list(cdc_idx_dict.keys()):\n",
        "        cdc.append(cdc_idx_dict.get(x))\n",
        "    else:\n",
        "        cdc.append('---')\n",
        "ndf['cdc'] = cdc\n",
        "\n",
        "df = pd.concat([ndf, df], axis=0, ignore_index=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "XQ9N3Sx24VjY"
      },
      "source": [
        "#### Article 12"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "-6q2XqUI4VjY",
        "colab": {}
      },
      "source": [
        "with open(articles_dict[articles[12].replace(' ','_')+'.txt']) as article:\n",
        "        doc = article.read()\n",
        "\n",
        "c_doc = text_cleaner(doc)\n",
        "sentences = nltk.sent_tokenize(c_doc)\n",
        "sentences = [[sent, topic, articles[12]] for sent in sentences]\n",
        "\n",
        "ndf = pd.DataFrame(sentences, columns=['text', 'topic', 'article'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "outputId": "a6c8dfc4-5f04-4eb2-a87f-efc7ca43ddf2",
        "id": "lhdKmC-y4Vja",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "cdc_idx_dict = {}\n",
        "cdc_idx_sent = {}\n",
        "cdc_idx_art = {}\n",
        "\n",
        "for i,claim in enumerate(ref_data['clean_Claim']):\n",
        "    check_complete = False\n",
        "    while check_complete == False:\n",
        "        for idx,sentence in enumerate(ndf['text']):\n",
        "            test = claim.lower() in sentence.lower()\n",
        "            if test:\n",
        "                article = ref_data['Article'][i]\n",
        "                cdc_idx_dict[idx] = claim\n",
        "                cdc_idx_sent[idx] = [claim, sentence]\n",
        "                cdc_idx_art[idx] = [claim, article]\n",
        "                check_complete = True\n",
        "            elif idx == (len(ndf['text'])-1):\n",
        "                check_complete = True\n",
        "\n",
        "len(cdc_idx_dict), ref_data.shape[0]"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(3, 1332)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 120
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "outputId": "83988624-7bfb-4cb1-fafb-c2df9a1de1ef",
        "id": "5XMY_c7C4Vjb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "cdc_idx_dict"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{16: 'the NPT cannot stop the proliferation of nuclear weapons or the motivation to acquire them',\n",
              " 75: 'Having more nuclear nuclear-weapon states would reduce security for all',\n",
              " 100: 'nuclear forces continue to play an essential role in war prevention'}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 121
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "Hao5vevl4Vjd",
        "colab": {}
      },
      "source": [
        "cdc = []\n",
        "\n",
        "for x in range(len(ndf)):\n",
        "    if x in list(cdc_idx_dict.keys()):\n",
        "        cdc.append(cdc_idx_dict.get(x))\n",
        "    else:\n",
        "        cdc.append('---')\n",
        "ndf['cdc'] = cdc\n",
        "\n",
        "df = pd.concat([ndf, df], axis=0, ignore_index=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "u4y8BOZn4VEn"
      },
      "source": [
        "#### Article 13"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "6UOniaY54VEo",
        "colab": {}
      },
      "source": [
        "with open(articles_dict[articles[13].replace(' ','_')+'.txt']) as article:\n",
        "        doc = article.read()\n",
        "\n",
        "c_doc = text_cleaner(doc)\n",
        "sentences = nltk.sent_tokenize(c_doc)\n",
        "sentences = [[sent, topic, articles[13]] for sent in sentences]\n",
        "\n",
        "ndf = pd.DataFrame(sentences, columns=['text', 'topic', 'article'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "outputId": "c4027a88-482d-499f-b73b-062563a293ac",
        "id": "v1dJqOse4VEp",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "cdc_idx_dict = {}\n",
        "cdc_idx_sent = {}\n",
        "cdc_idx_art = {}\n",
        "\n",
        "for i,claim in enumerate(ref_data['clean_Claim']):\n",
        "    check_complete = False\n",
        "    while check_complete == False:\n",
        "        for idx,sentence in enumerate(ndf['text']):\n",
        "            test = claim.lower() in sentence.lower()\n",
        "            if test:\n",
        "                article = ref_data['Article'][i]\n",
        "                cdc_idx_dict[idx] = claim\n",
        "                cdc_idx_sent[idx] = [claim, sentence]\n",
        "                cdc_idx_art[idx] = [claim, article]\n",
        "                check_complete = True\n",
        "            elif idx == (len(ndf['text'])-1):\n",
        "                check_complete = True\n",
        "\n",
        "len(cdc_idx_dict), ref_data.shape[0]"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(1, 1332)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 124
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "outputId": "585158fd-5c66-45db-aa57-fd93d22257e2",
        "id": "dg4tx1tz4VEq",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "cdc_idx_dict"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{4: 'nuclear weapon technology would soon reach the point where it could end human life on Earth'}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 125
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "jrmQoopd4VEs",
        "colab": {}
      },
      "source": [
        "cdc = []\n",
        "\n",
        "for x in range(len(ndf)):\n",
        "    if x in list(cdc_idx_dict.keys()):\n",
        "        cdc.append(cdc_idx_dict.get(x))\n",
        "    else:\n",
        "        cdc.append('---')\n",
        "ndf['cdc'] = cdc\n",
        "\n",
        "df = pd.concat([ndf, df], axis=0, ignore_index=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "KsgoesMl4Uof"
      },
      "source": [
        "#### Article 14"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "sbwVAp834Uog",
        "colab": {}
      },
      "source": [
        "with open(articles_dict[articles[14].replace(' ','_')+'.txt']) as article:\n",
        "        doc = article.read()\n",
        "\n",
        "c_doc = text_cleaner(doc)\n",
        "sentences = nltk.sent_tokenize(c_doc)\n",
        "sentences = [[sent, topic, articles[14]] for sent in sentences]\n",
        "\n",
        "ndf = pd.DataFrame(sentences, columns=['text', 'topic', 'article'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "outputId": "c9f0ef36-83ff-4e59-9ae5-ea6e2edc83bf",
        "id": "EQ6n6ygj4Uoh",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "cdc_idx_dict = {}\n",
        "cdc_idx_sent = {}\n",
        "cdc_idx_art = {}\n",
        "\n",
        "for i,claim in enumerate(ref_data['clean_Claim']):\n",
        "    check_complete = False\n",
        "    while check_complete == False:\n",
        "        for idx,sentence in enumerate(ndf['text']):\n",
        "            test = claim.lower() in sentence.lower()\n",
        "            if test:\n",
        "                article = ref_data['Article'][i]\n",
        "                cdc_idx_dict[idx] = claim\n",
        "                cdc_idx_sent[idx] = [claim, sentence]\n",
        "                cdc_idx_art[idx] = [claim, article]\n",
        "                check_complete = True\n",
        "            elif idx == (len(ndf['text'])-1):\n",
        "                check_complete = True\n",
        "\n",
        "len(cdc_idx_dict), ref_data.shape[0]"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(1, 1332)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 128
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "outputId": "36b27e84-eef1-4519-a2b2-f6d3d9d5123d",
        "id": "-eloDs1g4Uoj",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "cdc_idx_dict"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{11: 'every country will have to devise and use the latest devices for its protection'}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 129
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "TmU8MO4G4Uok",
        "colab": {}
      },
      "source": [
        "cdc = []\n",
        "\n",
        "for x in range(len(ndf)):\n",
        "    if x in list(cdc_idx_dict.keys()):\n",
        "        cdc.append(cdc_idx_dict.get(x))\n",
        "    else:\n",
        "        cdc.append('---')\n",
        "ndf['cdc'] = cdc\n",
        "\n",
        "df = pd.concat([ndf, df], axis=0, ignore_index=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "MhlHioWP4UC3"
      },
      "source": [
        "#### Article 15"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "7_5DM_Oq4UC4",
        "colab": {}
      },
      "source": [
        "with open(articles_dict[articles[15].replace(' ','_')+'.txt']) as article:\n",
        "        doc = article.read()\n",
        "\n",
        "c_doc = text_cleaner(doc)\n",
        "sentences = nltk.sent_tokenize(c_doc)\n",
        "sentences = [[sent, topic, articles[15]] for sent in sentences]\n",
        "\n",
        "ndf = pd.DataFrame(sentences, columns=['text', 'topic', 'article'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "outputId": "b90a0f3b-4b56-4336-ca59-a7bd63fe2b3f",
        "id": "eM9m7Gcj4UC5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "cdc_idx_dict = {}\n",
        "cdc_idx_sent = {}\n",
        "cdc_idx_art = {}\n",
        "\n",
        "for i,claim in enumerate(ref_data['clean_Claim']):\n",
        "    check_complete = False\n",
        "    while check_complete == False:\n",
        "        for idx,sentence in enumerate(ndf['text']):\n",
        "            test = claim.lower() in sentence.lower()\n",
        "            if test:\n",
        "                article = ref_data['Article'][i]\n",
        "                cdc_idx_dict[idx] = claim\n",
        "                cdc_idx_sent[idx] = [claim, sentence]\n",
        "                cdc_idx_art[idx] = [claim, article]\n",
        "                check_complete = True\n",
        "            elif idx == (len(ndf['text'])-1):\n",
        "                check_complete = True\n",
        "\n",
        "len(cdc_idx_dict), ref_data.shape[0]"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(1, 1332)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 132
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "outputId": "0a08b739-13b5-4a7b-ddb8-b81059036774",
        "id": "eoZInMUc4UC7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "cdc_idx_dict"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{88: 'In certain circumstances, they can play a positive role'}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 133
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "gS8IWQAB4UC9",
        "colab": {}
      },
      "source": [
        "cdc = []\n",
        "\n",
        "for x in range(len(ndf)):\n",
        "    if x in list(cdc_idx_dict.keys()):\n",
        "        cdc.append(cdc_idx_dict.get(x))\n",
        "    else:\n",
        "        cdc.append('---')\n",
        "ndf['cdc'] = cdc\n",
        "\n",
        "df = pd.concat([ndf, df], axis=0, ignore_index=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "h6meM_zh4Ti4"
      },
      "source": [
        "#### Article 16"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "nX6CajQt4Ti5",
        "colab": {}
      },
      "source": [
        "with open(articles_dict[articles[16].replace(' ','_')+'.txt']) as article:\n",
        "        doc = article.read()\n",
        "\n",
        "c_doc = text_cleaner(doc)\n",
        "sentences = nltk.sent_tokenize(c_doc)\n",
        "sentences = [[sent, topic, articles[16]] for sent in sentences]\n",
        "\n",
        "ndf = pd.DataFrame(sentences, columns=['text', 'topic', 'article'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "outputId": "078e50c2-5066-407f-d95d-b618cfa0667a",
        "id": "vj6ofiZ64Ti6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "cdc_idx_dict = {}\n",
        "cdc_idx_sent = {}\n",
        "cdc_idx_art = {}\n",
        "\n",
        "for i,claim in enumerate(ref_data['clean_Claim']):\n",
        "    check_complete = False\n",
        "    while check_complete == False:\n",
        "        for idx,sentence in enumerate(ndf['text']):\n",
        "            test = claim.lower() in sentence.lower()\n",
        "            if test:\n",
        "                article = ref_data['Article'][i]\n",
        "                cdc_idx_dict[idx] = claim\n",
        "                cdc_idx_sent[idx] = [claim, sentence]\n",
        "                cdc_idx_art[idx] = [claim, article]\n",
        "                check_complete = True\n",
        "            elif idx == (len(ndf['text'])-1):\n",
        "                check_complete = True\n",
        "\n",
        "len(cdc_idx_dict), ref_data.shape[0]"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(6, 1332)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 136
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "outputId": "9fb1929d-ec32-41e0-d17d-5539f9be7391",
        "id": "KfbYsi4t4Ti8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "cdc_idx_dict"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{86: 'the significance of nuclear weapons is purely to deter war',\n",
              " 89: 'would generally be contrary to the rules of international law applicable in armed conflict',\n",
              " 90: 'nuclear proliferation would be desirable',\n",
              " 91: 'nuclear weapons successfully deter all-out war between states',\n",
              " 125: 'could lead to increased global instability',\n",
              " 128: 'no issue carries more importance to the long-term health and security of humanity than the effort to reduce, and perhaps one day, rid the world of nuclear weapons'}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 137
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "fDzUDSnG4Ti9",
        "colab": {}
      },
      "source": [
        "cdc = []\n",
        "\n",
        "for x in range(len(ndf)):\n",
        "    if x in list(cdc_idx_dict.keys()):\n",
        "        cdc.append(cdc_idx_dict.get(x))\n",
        "    else:\n",
        "        cdc.append('---')\n",
        "ndf['cdc'] = cdc\n",
        "\n",
        "df = pd.concat([ndf, df], axis=0, ignore_index=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "pk2H4FqF4TCq"
      },
      "source": [
        "#### Article 17"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "NSM_IXvM4TCv",
        "colab": {}
      },
      "source": [
        "with open(articles_dict[articles[17].replace(' ','_')+'.txt']) as article:\n",
        "        doc = article.read()\n",
        "\n",
        "c_doc = text_cleaner(doc)\n",
        "sentences = nltk.sent_tokenize(c_doc)\n",
        "sentences = [[sent, topic, articles[17]] for sent in sentences]\n",
        "\n",
        "ndf = pd.DataFrame(sentences, columns=['text', 'topic', 'article'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "outputId": "b9a9fe0c-cb3e-4049-9eca-d6e4e053ac8e",
        "id": "FPVOS1cV4TDF",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "cdc_idx_dict = {}\n",
        "cdc_idx_sent = {}\n",
        "cdc_idx_art = {}\n",
        "\n",
        "for i,claim in enumerate(ref_data['clean_Claim']):\n",
        "    check_complete = False\n",
        "    while check_complete == False:\n",
        "        for idx,sentence in enumerate(ndf['text']):\n",
        "            test = claim.lower() in sentence.lower()\n",
        "            if test:\n",
        "                article = ref_data['Article'][i]\n",
        "                cdc_idx_dict[idx] = claim\n",
        "                cdc_idx_sent[idx] = [claim, sentence]\n",
        "                cdc_idx_art[idx] = [claim, article]\n",
        "                check_complete = True\n",
        "            elif idx == (len(ndf['text'])-1):\n",
        "                check_complete = True\n",
        "\n",
        "len(cdc_idx_dict), ref_data.shape[0]"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(1, 1332)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 140
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "outputId": "7e75caca-f216-426e-ad23-415348e367b2",
        "id": "kAOSDKno4TDW",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "cdc_idx_dict"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{33: 'public opinion is overwhelmingly opposed to nuclearization'}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 141
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "-qrYGpYQ4TDt",
        "colab": {}
      },
      "source": [
        "cdc = []\n",
        "\n",
        "for x in range(len(ndf)):\n",
        "    if x in list(cdc_idx_dict.keys()):\n",
        "        cdc.append(cdc_idx_dict.get(x))\n",
        "    else:\n",
        "        cdc.append('---')\n",
        "ndf['cdc'] = cdc\n",
        "\n",
        "df = pd.concat([ndf, df], axis=0, ignore_index=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "y3w1Dq1v4Sp8"
      },
      "source": [
        "#### Article 18"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "oHF5Sd184Sp9",
        "colab": {}
      },
      "source": [
        "with open(articles_dict[articles[18].replace(' ','_')+'.txt']) as article:\n",
        "        doc = article.read()\n",
        "\n",
        "c_doc = text_cleaner(doc)\n",
        "sentences = nltk.sent_tokenize(c_doc)\n",
        "sentences = [[sent, topic, articles[18]] for sent in sentences]\n",
        "\n",
        "ndf = pd.DataFrame(sentences, columns=['text', 'topic', 'article'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "outputId": "76a71913-a6de-4caa-b02f-c177520e70a2",
        "id": "gv4t_JmL4Sp-",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "cdc_idx_dict = {}\n",
        "cdc_idx_sent = {}\n",
        "cdc_idx_art = {}\n",
        "\n",
        "for i,claim in enumerate(ref_data['clean_Claim']):\n",
        "    check_complete = False\n",
        "    while check_complete == False:\n",
        "        for idx,sentence in enumerate(ndf['text']):\n",
        "            test = claim.lower() in sentence.lower()\n",
        "            if test:\n",
        "                article = ref_data['Article'][i]\n",
        "                cdc_idx_dict[idx] = claim\n",
        "                cdc_idx_sent[idx] = [claim, sentence]\n",
        "                cdc_idx_art[idx] = [claim, article]\n",
        "                check_complete = True\n",
        "            elif idx == (len(ndf['text'])-1):\n",
        "                check_complete = True\n",
        "\n",
        "len(cdc_idx_dict), ref_data.shape[0]"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(3, 1332)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 144
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "outputId": "3218b50d-17ae-4156-d3dd-ec78723c4c8e",
        "id": "3OO1AhGt4Sp_",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "cdc_idx_dict"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{7: 'it would undermine deterrence',\n",
              " 17: 'extreme danger intrinsic to nuclear war and the possession of nuclear weapons',\n",
              " 71: 'with nuclear weapons more widely available, deterrence is decreasingly effective and increasingly hazardous'}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 145
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "XazZT9HC4SqB",
        "colab": {}
      },
      "source": [
        "cdc = []\n",
        "\n",
        "for x in range(len(ndf)):\n",
        "    if x in list(cdc_idx_dict.keys()):\n",
        "        cdc.append(cdc_idx_dict.get(x))\n",
        "    else:\n",
        "        cdc.append('---')\n",
        "ndf['cdc'] = cdc\n",
        "\n",
        "df = pd.concat([ndf, df], axis=0, ignore_index=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "V9A8jMpE4R6H"
      },
      "source": [
        "#### Article 19 "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "edlnlTDf4R6I",
        "colab": {}
      },
      "source": [
        "with open(articles_dict[articles[19].replace(' ','_')+'.txt']) as article:\n",
        "        doc = article.read()\n",
        "\n",
        "c_doc = text_cleaner(doc)\n",
        "sentences = nltk.sent_tokenize(c_doc)\n",
        "sentences = [[sent, topic, articles[19]] for sent in sentences]\n",
        "\n",
        "ndf = pd.DataFrame(sentences, columns=['text', 'topic', 'article'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "outputId": "8c98e0ef-8ff9-4e87-b22b-5c26839c91e4",
        "id": "T4kIG4Fi4R6K",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "cdc_idx_dict = {}\n",
        "cdc_idx_sent = {}\n",
        "cdc_idx_art = {}\n",
        "\n",
        "for i,claim in enumerate(ref_data['clean_Claim']):\n",
        "    check_complete = False\n",
        "    while check_complete == False:\n",
        "        for idx,sentence in enumerate(ndf['text']):\n",
        "            test = claim.lower() in sentence.lower()\n",
        "            if test:\n",
        "                article = ref_data['Article'][i]\n",
        "                cdc_idx_dict[idx] = claim\n",
        "                cdc_idx_sent[idx] = [claim, sentence]\n",
        "                cdc_idx_art[idx] = [claim, article]\n",
        "                check_complete = True\n",
        "            elif idx == (len(ndf['text'])-1):\n",
        "                check_complete = True\n",
        "\n",
        "len(cdc_idx_dict), ref_data.shape[0]"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(1, 1332)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 148
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "outputId": "287c6aba-65b0-4e77-e7eb-6177ae3f5eb0",
        "id": "PLjQq7VH4R6M",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "cdc_idx_dict"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{1: 'when two countries each have nuclear weapons, the probability of a direct war between them greatly decreases'}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 149
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "Mtl-QPwa4R6O",
        "colab": {}
      },
      "source": [
        "cdc = []\n",
        "\n",
        "for x in range(len(ndf)):\n",
        "    if x in list(cdc_idx_dict.keys()):\n",
        "        cdc.append(cdc_idx_dict.get(x))\n",
        "    else:\n",
        "        cdc.append('---')\n",
        "ndf['cdc'] = cdc\n",
        "\n",
        "df = pd.concat([ndf, df], axis=0, ignore_index=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aV1YoNNQxzq0",
        "colab_type": "text"
      },
      "source": [
        "### 'atheism is the only way '"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "outputId": "5fc00567-87c0-4ff2-d007-cef2a9d0291e",
        "id": "ZdzVoPQ81GOG",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "topic = 'atheism is the only way '\n",
        "\n",
        "articles = topic_article_dict[topic]\n",
        "articles"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['Antitheism',\n",
              " 'Problem of evil',\n",
              " 'The Root of All Evil',\n",
              " 'Quinque viae',\n",
              " 'Cosmological argument',\n",
              " 'Criticism of atheism',\n",
              " 'Argument from morality',\n",
              " 'Criticism of religion',\n",
              " 'Existence of God',\n",
              " 'God Is Not Great',\n",
              " 'Agnosticism',\n",
              " 'Ultimate Boeing 747 gambit',\n",
              " 'The God Delusion',\n",
              " 'Atheism',\n",
              " 'God of the gaps',\n",
              " 'Naturalism (philosophy)',\n",
              " 'God',\n",
              " 'The System of Nature',\n",
              " 'Richard Dawkins']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 151
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_ZZGFK4Y7j5o",
        "colab_type": "code",
        "outputId": "9c4398c8-7dea-441c-fb8a-ce15d2d2ff79",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "len(articles)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "19"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 152
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "jRhIbdKy1GOI"
      },
      "source": [
        "#### Article 0 "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "3brZ82hy1GOI",
        "colab": {}
      },
      "source": [
        "with open(articles_dict[articles[0].replace(' ','_')+'.txt']) as article:\n",
        "        doc = article.read()\n",
        "\n",
        "c_doc = text_cleaner(doc)\n",
        "sentences = nltk.sent_tokenize(c_doc)\n",
        "sentences = [[sent, topic, articles[0]] for sent in sentences]\n",
        "\n",
        "ndf = pd.DataFrame(sentences, columns=['text', 'topic', 'article'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "outputId": "48017b6f-ef8d-422e-efa1-7f3fa29391ea",
        "id": "CBEFlqqb1GOK",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "cdc_idx_dict = {}\n",
        "cdc_idx_sent = {}\n",
        "cdc_idx_art = {}\n",
        "\n",
        "for i,claim in enumerate(ref_data['clean_Claim']):\n",
        "    check_complete = False\n",
        "    while check_complete == False:\n",
        "        for idx,sentence in enumerate(ndf['text']):\n",
        "            test = claim.lower() in sentence.lower()\n",
        "            if test:\n",
        "                article = ref_data['Article'][i]\n",
        "                cdc_idx_dict[idx] = claim\n",
        "                cdc_idx_sent[idx] = [claim, sentence]\n",
        "                cdc_idx_art[idx] = [claim, article]\n",
        "                check_complete = True\n",
        "            elif idx == (len(ndf['text'])-1):\n",
        "                check_complete = True\n",
        "\n",
        "len(cdc_idx_dict), ref_data.shape[0]"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(2, 1332)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 154
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "outputId": "807d2828-026f-4ff7-9197-06ccd987b009",
        "id": "parHI-iC1GOL",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "cdc_idx_dict"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{7: 'the effect of religious belief, is positively harmful',\n",
              " 26: 'there is evidence even for the existence of a God'}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 155
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "CWntRIB71GOO",
        "colab": {}
      },
      "source": [
        "cdc = []\n",
        "\n",
        "for x in range(len(ndf)):\n",
        "    if x in list(cdc_idx_dict.keys()):\n",
        "        cdc.append(cdc_idx_dict.get(x))\n",
        "    else:\n",
        "        cdc.append('---')\n",
        "ndf['cdc'] = cdc\n",
        "\n",
        "df = pd.concat([ndf, df], axis=0, ignore_index=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "zVCnNAOj1GOQ"
      },
      "source": [
        "#### Article 1 "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "Z4pRB1Ti1GOQ",
        "colab": {}
      },
      "source": [
        "with open(articles_dict[articles[1].replace(' ','_')+'.txt']) as article:\n",
        "        doc = article.read()\n",
        "\n",
        "c_doc = text_cleaner(doc)\n",
        "sentences = nltk.sent_tokenize(c_doc)\n",
        "sentences = [[sent, topic, articles[1]] for sent in sentences]\n",
        "\n",
        "ndf = pd.DataFrame(sentences, columns=['text', 'topic', 'article'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "outputId": "93d4963e-f9e1-453c-f072-06fd9c502740",
        "id": "eu9Z-js81GOR",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "cdc_idx_dict = {}\n",
        "cdc_idx_sent = {}\n",
        "cdc_idx_art = {}\n",
        "\n",
        "for i,claim in enumerate(ref_data['clean_Claim']):\n",
        "    check_complete = False\n",
        "    while check_complete == False:\n",
        "        for idx,sentence in enumerate(ndf['text']):\n",
        "            test = claim.lower() in sentence.lower()\n",
        "            if test:\n",
        "                article = ref_data['Article'][i]\n",
        "                cdc_idx_dict[idx] = claim\n",
        "                cdc_idx_sent[idx] = [claim, sentence]\n",
        "                cdc_idx_art[idx] = [claim, article]\n",
        "                check_complete = True\n",
        "            elif idx == (len(ndf['text'])-1):\n",
        "                check_complete = True\n",
        "\n",
        "len(cdc_idx_dict), ref_data.shape[0]"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(4, 1332)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 158
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "outputId": "011405b7-688c-4dde-9082-9a66dfe39124",
        "id": "gPBKOs2K1GOU",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "cdc_idx_dict"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{2: 'the existences of such a god and of evil are logically incompatible',\n",
              " 24: 'God cannot exist with, or would want to prevent, all evils',\n",
              " 29: 'God and evil are logically incompatible',\n",
              " 34: 'An omniscient, wholly good being would prevent the occurrence of any intense suffering'}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 159
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "IdeGUn571GOV",
        "colab": {}
      },
      "source": [
        "cdc = []\n",
        "\n",
        "for x in range(len(ndf)):\n",
        "    if x in list(cdc_idx_dict.keys()):\n",
        "        cdc.append(cdc_idx_dict.get(x))\n",
        "    else:\n",
        "        cdc.append('---')\n",
        "ndf['cdc'] = cdc\n",
        "\n",
        "df = pd.concat([df, ndf], axis=0, ignore_index=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "rcCk_4V31GOX"
      },
      "source": [
        "#### Article 2 "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "8CxxKCUC1GOX",
        "colab": {}
      },
      "source": [
        "with open(articles_dict[articles[2].replace(' ','_')+'.txt']) as article:\n",
        "        doc = article.read()\n",
        "\n",
        "c_doc = text_cleaner(doc)\n",
        "sentences = nltk.sent_tokenize(c_doc)\n",
        "sentences = [[sent, topic, articles[2]] for sent in sentences]\n",
        "\n",
        "ndf = pd.DataFrame(sentences, columns=['text', 'topic', 'article'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "outputId": "8199e95f-aaf0-492a-a91c-e303ac54ef0d",
        "id": "WSx2M01H1GOZ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "cdc_idx_dict = {}\n",
        "cdc_idx_sent = {}\n",
        "cdc_idx_art = {}\n",
        "\n",
        "for i,claim in enumerate(ref_data['clean_Claim']):\n",
        "    check_complete = False\n",
        "    while check_complete == False:\n",
        "        for idx,sentence in enumerate(ndf['text']):\n",
        "            test = claim.lower() in sentence.lower()\n",
        "            if test:\n",
        "                article = ref_data['Article'][i]\n",
        "                cdc_idx_dict[idx] = claim\n",
        "                cdc_idx_sent[idx] = [claim, sentence]\n",
        "                cdc_idx_art[idx] = [claim, article]\n",
        "                check_complete = True\n",
        "            elif idx == (len(ndf['text'])-1):\n",
        "                check_complete = True\n",
        "\n",
        "len(cdc_idx_dict), ref_data.shape[0]"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(5, 1332)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 162
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "outputId": "e3658f95-ac64-4626-fc2d-273f1dca72b4",
        "id": "9EGCUx1P1GOa",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "cdc_idx_dict"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{0: 'humanity would be better off without religion or belief in God',\n",
              " 10: 'is divisive and dangerous',\n",
              " 120: 'atheism is not a recipe for despair but just the opposite',\n",
              " 121: 'is life-affirming in a way that religion can never be',\n",
              " 132: 'religion does more harm than good'}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 163
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "-iMXWjqB1GOc",
        "colab": {}
      },
      "source": [
        "cdc = []\n",
        "\n",
        "for x in range(len(ndf)):\n",
        "    if x in list(cdc_idx_dict.keys()):\n",
        "        cdc.append(cdc_idx_dict.get(x))\n",
        "    else:\n",
        "        cdc.append('---')\n",
        "ndf['cdc'] = cdc\n",
        "\n",
        "df = pd.concat([ndf, df], axis=0, ignore_index=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "_ZJPW45_1GOd"
      },
      "source": [
        "#### Article 3 "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "yFkx42e51GOd",
        "colab": {}
      },
      "source": [
        "with open(articles_dict[articles[3].replace(' ','_')+'.txt']) as article:\n",
        "        doc = article.read()\n",
        "\n",
        "c_doc = text_cleaner(doc)\n",
        "sentences = nltk.sent_tokenize(c_doc)\n",
        "sentences = [[sent, topic, articles[3]] for sent in sentences]\n",
        "\n",
        "ndf = pd.DataFrame(sentences, columns=['text', 'topic', 'article'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "outputId": "4361759b-58dd-4581-ebb5-156a3f65b1c9",
        "id": "b0qDeJBP1GOe",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "cdc_idx_dict = {}\n",
        "cdc_idx_sent = {}\n",
        "cdc_idx_art = {}\n",
        "\n",
        "for i,claim in enumerate(ref_data['clean_Claim']):\n",
        "    check_complete = False\n",
        "    while check_complete == False:\n",
        "        for idx,sentence in enumerate(ndf['text']):\n",
        "            test = claim.lower() in sentence.lower()\n",
        "            if test:\n",
        "                article = ref_data['Article'][i]\n",
        "                cdc_idx_dict[idx] = claim\n",
        "                cdc_idx_sent[idx] = [claim, sentence]\n",
        "                cdc_idx_art[idx] = [claim, article]\n",
        "                check_complete = True\n",
        "            elif idx == (len(ndf['text'])-1):\n",
        "                check_complete = True\n",
        "\n",
        "len(cdc_idx_dict), ref_data.shape[0]"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(2, 1332)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 166
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "outputId": "cd02f590-1fdb-4b43-8861-90b31c0a05fb",
        "id": "Yicg68Lh1GOg",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "cdc_idx_dict"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{35: 'everything in the Universe has a purpose, which must have been caused by God',\n",
              " 40: 'everything in the Universe follows laws, which must have been created by God'}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 167
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "TG55z3ZK1GOh",
        "colab": {}
      },
      "source": [
        "cdc = []\n",
        "\n",
        "for x in range(len(ndf)):\n",
        "    if x in list(cdc_idx_dict.keys()):\n",
        "        cdc.append(cdc_idx_dict.get(x))\n",
        "    else:\n",
        "        cdc.append('---')\n",
        "ndf['cdc'] = cdc\n",
        "\n",
        "df = pd.concat([ndf, df], axis=0, ignore_index=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "T7KNiWBZ1GOj"
      },
      "source": [
        "#### Article 4 "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "PyLZiANu1GOo",
        "colab": {}
      },
      "source": [
        "with open(articles_dict[articles[4].replace(' ','_')+'.txt']) as article:\n",
        "        doc = article.read()\n",
        "\n",
        "c_doc = text_cleaner(doc)\n",
        "sentences = nltk.sent_tokenize(c_doc)\n",
        "sentences = [[sent, topic, articles[4]] for sent in sentences]\n",
        "\n",
        "ndf = pd.DataFrame(sentences, columns=['text', 'topic', 'article'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "outputId": "d760f907-0839-4e84-c623-cd4a93046c55",
        "id": "CIeTmXgC1GOp",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "cdc_idx_dict = {}\n",
        "cdc_idx_sent = {}\n",
        "cdc_idx_art = {}\n",
        "\n",
        "for i,claim in enumerate(ref_data['clean_Claim']):\n",
        "    check_complete = False\n",
        "    while check_complete == False:\n",
        "        for idx,sentence in enumerate(ndf['text']):\n",
        "            test = claim.lower() in sentence.lower()\n",
        "            if test:\n",
        "                article = ref_data['Article'][i]\n",
        "                cdc_idx_dict[idx] = claim\n",
        "                cdc_idx_sent[idx] = [claim, sentence]\n",
        "                cdc_idx_art[idx] = [claim, article]\n",
        "                check_complete = True\n",
        "            elif idx == (len(ndf['text'])-1):\n",
        "                check_complete = True\n",
        "\n",
        "len(cdc_idx_dict), ref_data.shape[0]"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(4, 1332)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 170
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "outputId": "b2cc53b9-2bf2-40a2-9882-db4f6378c3dc",
        "id": "KeV28OhK1GOs",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "cdc_idx_dict"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{3: 'something caused the Universe to exist, and this First Cause must be God',\n",
              " 24: 'existence must be due to an agent cause',\n",
              " 38: 'the existence of the Universe requires an explanation, and the creation of the Universe by a First Cause, generally assumed to be God, is that explanation',\n",
              " 88: 'a god created the Universe'}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 171
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "oQ56OBh31GOv",
        "colab": {}
      },
      "source": [
        "cdc = []\n",
        "\n",
        "for x in range(len(ndf)):\n",
        "    if x in list(cdc_idx_dict.keys()):\n",
        "        cdc.append(cdc_idx_dict.get(x))\n",
        "    else:\n",
        "        cdc.append('---')\n",
        "ndf['cdc'] = cdc\n",
        "\n",
        "df = pd.concat([ndf, df], axis=0, ignore_index=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "Ga07yKv172zS"
      },
      "source": [
        "#### Article 5 "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "IF9TicmD72zS",
        "colab": {}
      },
      "source": [
        "with open(articles_dict[articles[5].replace(' ','_')+'.txt']) as article:\n",
        "        doc = article.read()\n",
        "\n",
        "c_doc = text_cleaner(doc)\n",
        "sentences = nltk.sent_tokenize(c_doc)\n",
        "sentences = [[sent, topic, articles[5]] for sent in sentences]\n",
        "\n",
        "ndf = pd.DataFrame(sentences, columns=['text', 'topic', 'article'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "outputId": "096fcd3f-6d31-4b14-bc84-49c9db3019f9",
        "id": "laq4K5eE72zT",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "cdc_idx_dict = {}\n",
        "cdc_idx_sent = {}\n",
        "cdc_idx_art = {}\n",
        "\n",
        "for i,claim in enumerate(ref_data['clean_Claim']):\n",
        "    check_complete = False\n",
        "    while check_complete == False:\n",
        "        for idx,sentence in enumerate(ndf['text']):\n",
        "            test = claim.lower() in sentence.lower()\n",
        "            if test:\n",
        "                article = ref_data['Article'][i]\n",
        "                cdc_idx_dict[idx] = claim\n",
        "                cdc_idx_sent[idx] = [claim, sentence]\n",
        "                cdc_idx_art[idx] = [claim, article]\n",
        "                check_complete = True\n",
        "            elif idx == (len(ndf['text'])-1):\n",
        "                check_complete = True\n",
        "\n",
        "len(cdc_idx_dict), ref_data.shape[0]"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(4, 1332)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 174
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "outputId": "c0dce9d4-f447-4191-abed-518264ed3e38",
        "id": "dCBl0j_172zU",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "cdc_idx_dict"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{7: 'there are insufficient grounds to assert authoritatively that any supreme being does not exist',\n",
              " 17: 'acknowledgment of God or the gods is a major factor in motivating people towards moral behavior',\n",
              " 40: 'Atheism has been criticized as a faith in itself',\n",
              " 98: 'atheism systematically influences people to do bad things'}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 175
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "y3zJf_EK72zW",
        "colab": {}
      },
      "source": [
        "cdc = []\n",
        "\n",
        "for x in range(len(ndf)):\n",
        "    if x in list(cdc_idx_dict.keys()):\n",
        "        cdc.append(cdc_idx_dict.get(x))\n",
        "    else:\n",
        "        cdc.append('---')\n",
        "ndf['cdc'] = cdc\n",
        "\n",
        "df = pd.concat([ndf, df], axis=0, ignore_index=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "Sks_XDyj72OB"
      },
      "source": [
        "#### Article 6"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "rJV7YIM672OB",
        "colab": {}
      },
      "source": [
        "with open(articles_dict[articles[6].replace(' ','_')+'.txt']) as article:\n",
        "        doc = article.read()\n",
        "\n",
        "c_doc = text_cleaner(doc)\n",
        "sentences = nltk.sent_tokenize(c_doc)\n",
        "sentences = [[sent, topic, articles[6]] for sent in sentences]\n",
        "\n",
        "ndf = pd.DataFrame(sentences, columns=['text', 'topic', 'article'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "outputId": "abed952d-1ff0-433a-80bb-20a95b9a075e",
        "id": "RRTVjEVC72OC",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "cdc_idx_dict = {}\n",
        "cdc_idx_sent = {}\n",
        "cdc_idx_art = {}\n",
        "\n",
        "for i,claim in enumerate(ref_data['clean_Claim']):\n",
        "    check_complete = False\n",
        "    while check_complete == False:\n",
        "        for idx,sentence in enumerate(ndf['text']):\n",
        "            test = claim.lower() in sentence.lower()\n",
        "            if test:\n",
        "                article = ref_data['Article'][i]\n",
        "                cdc_idx_dict[idx] = claim\n",
        "                cdc_idx_sent[idx] = [claim, sentence]\n",
        "                cdc_idx_art[idx] = [claim, article]\n",
        "                check_complete = True\n",
        "            elif idx == (len(ndf['text'])-1):\n",
        "                check_complete = True\n",
        "\n",
        "len(cdc_idx_dict), ref_data.shape[0]"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(8, 1332)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 178
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "outputId": "482b0bba-304a-4556-fc43-6e18c3829705",
        "id": "qVNCBYCF72OD",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "cdc_idx_dict"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{3: 'God must exist to give force to moral obligations',\n",
              " 5: 'objective moral truths and the binding nature of obligations suggests a high power to enforce them, regarded as God',\n",
              " 15: 'only the existence of God as orthodoxly conceived could support the existence of moral order in the world',\n",
              " 19: 'A natural moral order requires the existence of God as orthodoxly conceived, so god must exist',\n",
              " 20: \"there is not good argument for God's existence that arises from pure reason alone\",\n",
              " 22: 'all moral thought requires the assumption that God exists',\n",
              " 26: 'theists are able to offer justification for morality, while atheists are not',\n",
              " 33: 'the natural is all that exists'}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 179
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "Z9aUcEJc72OF",
        "colab": {}
      },
      "source": [
        "cdc = []\n",
        "\n",
        "for x in range(len(ndf)):\n",
        "    if x in list(cdc_idx_dict.keys()):\n",
        "        cdc.append(cdc_idx_dict.get(x))\n",
        "    else:\n",
        "        cdc.append('---')\n",
        "ndf['cdc'] = cdc\n",
        "\n",
        "df = pd.concat([ndf, df], axis=0, ignore_index=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "yUwun7kW71mS"
      },
      "source": [
        "#### Article 7"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "WWQYng1M71mT",
        "colab": {}
      },
      "source": [
        "with open(articles_dict[articles[7].replace(' ','_')+'.txt']) as article:\n",
        "        doc = article.read()\n",
        "\n",
        "c_doc = text_cleaner(doc)\n",
        "sentences = nltk.sent_tokenize(c_doc)\n",
        "sentences = [[sent, topic, articles[7]] for sent in sentences]\n",
        "\n",
        "ndf = pd.DataFrame(sentences, columns=['text', 'topic', 'article'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "outputId": "6bb94d18-bd21-4eaa-c712-a1c2770d814f",
        "id": "6moCU3ZG71mU",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "cdc_idx_dict = {}\n",
        "cdc_idx_sent = {}\n",
        "cdc_idx_art = {}\n",
        "\n",
        "for i,claim in enumerate(ref_data['clean_Claim']):\n",
        "    check_complete = False\n",
        "    while check_complete == False:\n",
        "        for idx,sentence in enumerate(ndf['text']):\n",
        "            test = claim.lower() in sentence.lower()\n",
        "            if test:\n",
        "                article = ref_data['Article'][i]\n",
        "                cdc_idx_dict[idx] = claim\n",
        "                cdc_idx_sent[idx] = [claim, sentence]\n",
        "                cdc_idx_art[idx] = [claim, article]\n",
        "                check_complete = True\n",
        "            elif idx == (len(ndf['text'])-1):\n",
        "                check_complete = True\n",
        "\n",
        "len(cdc_idx_dict), ref_data.shape[0]"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(16, 1332)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 182
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "outputId": "ab2cee99-4c5b-40ab-fc95-044ec1b949f0",
        "id": "dq6ALoED71mV",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "cdc_idx_dict"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{5: 'all phenomena could be understood as resulting from purely natural causes',\n",
              " 6: 'religion was born of fear and ignorance',\n",
              " 14: 'they require beliefs that are irrational',\n",
              " 15: 'religious beliefs and traditions lack scientific or rational foundations',\n",
              " 17: 'Religions often posit facts that are contradicted by scientific evidence',\n",
              " 23: 'their teachings are outdated in comparison with modern Western morals',\n",
              " 26: 'Religions have promoted facts and histories that are contradicted by science',\n",
              " 48: 'theist religions and their holy books are not divinely inspired, but instead are fabrications of non-divine human individuals',\n",
              " 60: 'there are reasonable arguments supporting the existence of God',\n",
              " 90: 'religious belief is a delusion',\n",
              " 94: 'religious belief is a delusion',\n",
              " 95: 'religion is nothing more than a social construct that primitive humans evolved',\n",
              " 103: 'the need for explaining life and death can be met by science and philosophy',\n",
              " 196: 'atheism was responsible for \"some 20th century atrocities',\n",
              " 220: 'theistic religions devalue human compassion and morality',\n",
              " 267: 'religion is a positive civilizing influence on society'}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 183
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "VupMwSY-71mW",
        "colab": {}
      },
      "source": [
        "cdc = []\n",
        "\n",
        "for x in range(len(ndf)):\n",
        "    if x in list(cdc_idx_dict.keys()):\n",
        "        cdc.append(cdc_idx_dict.get(x))\n",
        "    else:\n",
        "        cdc.append('---')\n",
        "ndf['cdc'] = cdc\n",
        "\n",
        "df = pd.concat([ndf, df], axis=0, ignore_index=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "QDnaFm1X70xk"
      },
      "source": [
        "#### Article 8"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "BPpIKiUQ70xl",
        "colab": {}
      },
      "source": [
        "with open(articles_dict[articles[8].replace(' ','_')+'.txt']) as article:\n",
        "        doc = article.read()\n",
        "\n",
        "c_doc = text_cleaner(doc)\n",
        "sentences = nltk.sent_tokenize(c_doc)\n",
        "sentences = [[sent, topic, articles[8]] for sent in sentences]\n",
        "\n",
        "ndf = pd.DataFrame(sentences, columns=['text', 'topic', 'article'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "outputId": "fa731d4d-f251-4da8-88d1-1198f582a779",
        "id": "HiZ08xjR70xo",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "cdc_idx_dict = {}\n",
        "cdc_idx_sent = {}\n",
        "cdc_idx_art = {}\n",
        "\n",
        "for i,claim in enumerate(ref_data['clean_Claim']):\n",
        "    check_complete = False\n",
        "    while check_complete == False:\n",
        "        for idx,sentence in enumerate(ndf['text']):\n",
        "            test = claim.lower() in sentence.lower()\n",
        "            if test:\n",
        "                article = ref_data['Article'][i]\n",
        "                cdc_idx_dict[idx] = claim\n",
        "                cdc_idx_sent[idx] = [claim, sentence]\n",
        "                cdc_idx_art[idx] = [claim, article]\n",
        "                check_complete = True\n",
        "            elif idx == (len(ndf['text'])-1):\n",
        "                check_complete = True\n",
        "\n",
        "len(cdc_idx_dict), ref_data.shape[0]"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(26, 1332)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 186
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "outputId": "db04e6fe-3c11-452e-f4a0-e17c7b037580",
        "id": "UXoS6E0w70xp",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "cdc_idx_dict"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{6: 'arguments for the existence of God show insufficient reason to believe',\n",
              " 54: 'the universe includes \"ideas\" not perceptible to mankind (or not always perceptible), and that there must therefore exist an omniscient superobserver',\n",
              " 62: 'there was a \"first cause\", or \"prime mover\" who is identified as God',\n",
              " 64: \"the universe's order and complexity are best explained by reference to a creator God\",\n",
              " 68: 'certain features of the universe and of living things are the product of an intelligent cause',\n",
              " 74: \"basic facts, such as humanity's existence, are best explained by the existence of God\",\n",
              " 76: 'atheistic arguments must ultimately refute themselves if pressed with rigorous consistency',\n",
              " 115: \"the theism of people throughout most of recorded history and in many different places provides prima facie demonstration of God's existence\",\n",
              " 127: \"when a person's understanding ponders over the existence of God it encounters nothing but contradictions\",\n",
              " 146: 'natural (non-supernatural) theories adequately explain the development of religion and belief in gods',\n",
              " 155: 'The argument for the existence of god is then a logical fallacy',\n",
              " 158: 'the concept of an omnipotent entity is logically contradictory',\n",
              " 167: 'things cannot exist without creators',\n",
              " 176: 'an omnipotent and omniscient being would not have any reason to act in any way, specifically by creating the universe',\n",
              " 189: 'if, when asked for, there is no visible help from God, there is no reason to believe that there is a God',\n",
              " 194: 'an unchanging God cannot be the source of an ever changing world',\n",
              " 196: 'the idea of God is inconceivable and self-contradictory',\n",
              " 197: 'a perfect God can have no need to create a world',\n",
              " 198: 'a benevolent deity ought to create only happy creatures, not an imperfect world like the real world',\n",
              " 199: 'the evidence allegedly proving the existence of God was insufficient',\n",
              " 208: 'God\\'s existence \"can be known with certainty from the created world by the natural light of human reason',\n",
              " 209: \"God's existence can be demonstrated\",\n",
              " 225: 'all human experience and action (even the condition of unbelief, itself) is a proof for the existence of God',\n",
              " 242: 'there is insufficient reason to believe that any gods exist',\n",
              " 245: 'are logically contradictory',\n",
              " 253: 'there are no good reasons and no credible grounds for believing that gods exist'}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 187
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "kGLU13Vg70xr",
        "colab": {}
      },
      "source": [
        "cdc = []\n",
        "\n",
        "for x in range(len(ndf)):\n",
        "    if x in list(cdc_idx_dict.keys()):\n",
        "        cdc.append(cdc_idx_dict.get(x))\n",
        "    else:\n",
        "        cdc.append('---')\n",
        "ndf['cdc'] = cdc\n",
        "\n",
        "df = pd.concat([ndf, df], axis=0, ignore_index=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "j0bV5KAm7z-k"
      },
      "source": [
        "#### Article 9"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "ez2Bb0o57z-l",
        "colab": {}
      },
      "source": [
        "with open(articles_dict[articles[9].replace(' ','_')+'.txt']) as article:\n",
        "        doc = article.read()\n",
        "\n",
        "c_doc = text_cleaner(doc)\n",
        "sentences = nltk.sent_tokenize(c_doc)\n",
        "sentences = [[sent, topic, articles[9]] for sent in sentences]\n",
        "\n",
        "ndf = pd.DataFrame(sentences, columns=['text', 'topic', 'article'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "outputId": "0a347f5f-cd59-4e04-e3aa-ff676764d53a",
        "id": "UGMaDOnH7z-m",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "cdc_idx_dict = {}\n",
        "cdc_idx_sent = {}\n",
        "cdc_idx_art = {}\n",
        "\n",
        "for i,claim in enumerate(ref_data['clean_Claim']):\n",
        "    check_complete = False\n",
        "    while check_complete == False:\n",
        "        for idx,sentence in enumerate(ndf['text']):\n",
        "            test = claim.lower() in sentence.lower()\n",
        "            if test:\n",
        "                article = ref_data['Article'][i]\n",
        "                cdc_idx_dict[idx] = claim\n",
        "                cdc_idx_sent[idx] = [claim, sentence]\n",
        "                cdc_idx_art[idx] = [claim, article]\n",
        "                check_complete = True\n",
        "            elif idx == (len(ndf['text'])-1):\n",
        "                check_complete = True\n",
        "\n",
        "len(cdc_idx_dict), ref_data.shape[0]"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(4, 1332)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 190
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "outputId": "983bfeeb-93f4-4961-cb13-e2c9afddf753",
        "id": "9o5I6hk57z-n",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "cdc_idx_dict"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{32: 'we do not need God to explain things',\n",
              " 81: 'the most immoral acts in human history were performed by atheists',\n",
              " 88: 'the human race no longer needs religion',\n",
              " 97: 'all attempts to reconcile faith with science and reason are consigned to failure'}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 191
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "szKGTkRg7z-p",
        "colab": {}
      },
      "source": [
        "cdc = []\n",
        "\n",
        "for x in range(len(ndf)):\n",
        "    if x in list(cdc_idx_dict.keys()):\n",
        "        cdc.append(cdc_idx_dict.get(x))\n",
        "    else:\n",
        "        cdc.append('---')\n",
        "ndf['cdc'] = cdc\n",
        "\n",
        "df = pd.concat([ndf, df], axis=0, ignore_index=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "4qgUGVsP7zTD"
      },
      "source": [
        "#### Article 10"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "aYk79QYC7zTM",
        "colab": {}
      },
      "source": [
        "with open(articles_dict[articles[10].replace(' ','_')+'.txt']) as article:\n",
        "        doc = article.read()\n",
        "\n",
        "c_doc = text_cleaner(doc)\n",
        "sentences = nltk.sent_tokenize(c_doc)\n",
        "sentences = [[sent, topic, articles[10]] for sent in sentences]\n",
        "\n",
        "ndf = pd.DataFrame(sentences, columns=['text', 'topic', 'article'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "outputId": "d518a843-983b-4396-d633-655479242a55",
        "id": "mQdTWLWm7zTg",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "cdc_idx_dict = {}\n",
        "cdc_idx_sent = {}\n",
        "cdc_idx_art = {}\n",
        "\n",
        "for i,claim in enumerate(ref_data['clean_Claim']):\n",
        "    check_complete = False\n",
        "    while check_complete == False:\n",
        "        for idx,sentence in enumerate(ndf['text']):\n",
        "            test = claim.lower() in sentence.lower()\n",
        "            if test:\n",
        "                article = ref_data['Article'][i]\n",
        "                cdc_idx_dict[idx] = claim\n",
        "                cdc_idx_sent[idx] = [claim, sentence]\n",
        "                cdc_idx_art[idx] = [claim, article]\n",
        "                check_complete = True\n",
        "            elif idx == (len(ndf['text'])-1):\n",
        "                check_complete = True\n",
        "\n",
        "len(cdc_idx_dict), ref_data.shape[0]"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(2, 1332)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 194
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "outputId": "4f98ce57-270a-4687-805f-7690e6e7dfc6",
        "id": "dgEmAbf97zT2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "cdc_idx_dict"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{5: 'human reason is incapable of providing sufficient rational grounds to justify the belief that deities either do or do not exist',\n",
              " 30: 'God, the beginning and end of all, can, by the natural light of human reason, be known with certainty from the works of creation'}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 195
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "Td_hPWGw7zUI",
        "colab": {}
      },
      "source": [
        "cdc = []\n",
        "\n",
        "for x in range(len(ndf)):\n",
        "    if x in list(cdc_idx_dict.keys()):\n",
        "        cdc.append(cdc_idx_dict.get(x))\n",
        "    else:\n",
        "        cdc.append('---')\n",
        "ndf['cdc'] = cdc\n",
        "\n",
        "df = pd.concat([ndf, df], axis=0, ignore_index=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "hRT5t_WC7ykR"
      },
      "source": [
        "#### Article 11 "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "ubs2oNtK7ykX",
        "colab": {}
      },
      "source": [
        "with open(articles_dict[articles[11].replace(' ','_')+'.txt']) as article:\n",
        "        doc = article.read()\n",
        "\n",
        "c_doc = text_cleaner(doc)\n",
        "sentences = nltk.sent_tokenize(c_doc)\n",
        "sentences = [[sent, topic, articles[11]] for sent in sentences]\n",
        "\n",
        "ndf = pd.DataFrame(sentences, columns=['text', 'topic', 'article'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "outputId": "0d53c036-3b72-4210-8264-3290c490c426",
        "id": "YyssxMeg7ykr",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "cdc_idx_dict = {}\n",
        "cdc_idx_sent = {}\n",
        "cdc_idx_art = {}\n",
        "\n",
        "for i,claim in enumerate(ref_data['clean_Claim']):\n",
        "    check_complete = False\n",
        "    while check_complete == False:\n",
        "        for idx,sentence in enumerate(ndf['text']):\n",
        "            test = claim.lower() in sentence.lower()\n",
        "            if test:\n",
        "                article = ref_data['Article'][i]\n",
        "                cdc_idx_dict[idx] = claim\n",
        "                cdc_idx_sent[idx] = [claim, sentence]\n",
        "                cdc_idx_art[idx] = [claim, article]\n",
        "                check_complete = True\n",
        "            elif idx == (len(ndf['text'])-1):\n",
        "                check_complete = True\n",
        "\n",
        "len(cdc_idx_dict), ref_data.shape[0]"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(6, 1332)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 198
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "outputId": "a2c44b8a-bcfd-458b-cb2f-b36d09af9a96",
        "id": "rGFSXWrg7yk9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "cdc_idx_dict"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{6: 'the God hypothesis inferior to evolution by natural selection as explanations for the complexity of life',\n",
              " 12: 'where design fails to explain complexity, evolution by natural selection succeeds',\n",
              " 20: 'The theory of natural selection is much simpler than the theory of the existence of such a complex being, and thus preferable',\n",
              " 58: 'God is improbable',\n",
              " 60: 'a creator of a universe with such complexity would have to be complex and improbable',\n",
              " 64: 'there must be a first cause, which can be given the name God'}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 199
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "o0YEqlKQ7ylU",
        "colab": {}
      },
      "source": [
        "cdc = []\n",
        "\n",
        "for x in range(len(ndf)):\n",
        "    if x in list(cdc_idx_dict.keys()):\n",
        "        cdc.append(cdc_idx_dict.get(x))\n",
        "    else:\n",
        "        cdc.append('---')\n",
        "ndf['cdc'] = cdc\n",
        "\n",
        "df = pd.concat([ndf, df], axis=0, ignore_index=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "kFcX8sMA7yDX"
      },
      "source": [
        "#### Article 12"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "7ER_r5ts7yDX",
        "colab": {}
      },
      "source": [
        "with open(articles_dict[articles[12].replace(' ','_')+'.txt']) as article:\n",
        "        doc = article.read()\n",
        "\n",
        "c_doc = text_cleaner(doc)\n",
        "sentences = nltk.sent_tokenize(c_doc)\n",
        "sentences = [[sent, topic, articles[12]] for sent in sentences]\n",
        "\n",
        "ndf = pd.DataFrame(sentences, columns=['text', 'topic', 'article'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "outputId": "ee81180e-702c-42db-8fd2-c51a92b7caca",
        "id": "Q4NONoZE7yDZ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "cdc_idx_dict = {}\n",
        "cdc_idx_sent = {}\n",
        "cdc_idx_art = {}\n",
        "\n",
        "for i,claim in enumerate(ref_data['clean_Claim']):\n",
        "    check_complete = False\n",
        "    while check_complete == False:\n",
        "        for idx,sentence in enumerate(ndf['text']):\n",
        "            test = claim.lower() in sentence.lower()\n",
        "            if test:\n",
        "                article = ref_data['Article'][i]\n",
        "                cdc_idx_dict[idx] = claim\n",
        "                cdc_idx_sent[idx] = [claim, sentence]\n",
        "                cdc_idx_art[idx] = [claim, article]\n",
        "                check_complete = True\n",
        "            elif idx == (len(ndf['text'])-1):\n",
        "                check_complete = True\n",
        "\n",
        "len(cdc_idx_dict), ref_data.shape[0]"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(9, 1332)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 202
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "outputId": "6655ec60-307c-4c9e-cae6-ba884faa1a3c",
        "id": "O22OIxhU7yDa",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "cdc_idx_dict"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{11: 'evolution can explain the apparent design in nature',\n",
              " 23: 'Natural selection and similar scientific theories are superior to a \"God hypothesis\"—the illusion of intelligent design—in explaining the living world and the cosmos',\n",
              " 26: 'atheism is evidence of a healthy, independent mind',\n",
              " 33: 'evolution by natural selection can explain apparent design in nature',\n",
              " 37: 'the designer hypothesis immediately raises the larger problem of who designed the designer',\n",
              " 43: 'the theory of a universe without a God is preferable to the theory of a universe with a God',\n",
              " 50: 'religion is needed to make us behave morally',\n",
              " 59: 'fills a \"much needed gap',\n",
              " 72: 'religion is socially dangerous'}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 203
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "s723-P3r7yDb",
        "colab": {}
      },
      "source": [
        "cdc = []\n",
        "\n",
        "for x in range(len(ndf)):\n",
        "    if x in list(cdc_idx_dict.keys()):\n",
        "        cdc.append(cdc_idx_dict.get(x))\n",
        "    else:\n",
        "        cdc.append('---')\n",
        "ndf['cdc'] = cdc\n",
        "\n",
        "df = pd.concat([ndf, df], axis=0, ignore_index=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "Q0aD4BJs7xi1"
      },
      "source": [
        "#### Article 13"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "WntllVm77xi1",
        "colab": {}
      },
      "source": [
        "with open(articles_dict[articles[13].replace(' ','_')+'.txt']) as article:\n",
        "        doc = article.read()\n",
        "\n",
        "c_doc = text_cleaner(doc)\n",
        "sentences = nltk.sent_tokenize(c_doc)\n",
        "sentences = [[sent, topic, articles[13]] for sent in sentences]\n",
        "\n",
        "ndf = pd.DataFrame(sentences, columns=['text', 'topic', 'article'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "outputId": "039aac58-2fe0-4bf8-e7bd-4a70cd36c624",
        "id": "RcqSU0P67xi3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "cdc_idx_dict = {}\n",
        "cdc_idx_sent = {}\n",
        "cdc_idx_art = {}\n",
        "\n",
        "for i,claim in enumerate(ref_data['clean_Claim']):\n",
        "    check_complete = False\n",
        "    while check_complete == False:\n",
        "        for idx,sentence in enumerate(ndf['text']):\n",
        "            test = claim.lower() in sentence.lower()\n",
        "            if test:\n",
        "                article = ref_data['Article'][i]\n",
        "                cdc_idx_dict[idx] = claim\n",
        "                cdc_idx_sent[idx] = [claim, sentence]\n",
        "                cdc_idx_art[idx] = [claim, article]\n",
        "                check_complete = True\n",
        "            elif idx == (len(ndf['text'])-1):\n",
        "                check_complete = True\n",
        "\n",
        "len(cdc_idx_dict), ref_data.shape[0]"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(10, 1332)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 206
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "outputId": "2774d019-8dfd-46e1-949f-7183eee23604",
        "id": "4QC5zQdo7xi4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "cdc_idx_dict"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{76: 'unproven religious propositions deserve as much disbelief as all other unproven propositions',\n",
              " 81: 'atheists are quick to believe in God in times of crisis',\n",
              " 107: 'God and other religious beliefs are human inventions',\n",
              " 109: 'belief in God and religion are social functions, used by those in power to oppress the working class',\n",
              " 110: 'necessarily ends in the enslavement of mankind',\n",
              " 115: 'renders life meaningless and miserable',\n",
              " 139: 'religion as a human invention used to frighten people into following moral order',\n",
              " 261: 'atheism is a superior basis for ethics',\n",
              " 265: 'religions provide a net benefit to individuals and society',\n",
              " 266: 'reliance on divine authority lends itself to authoritarianism and dogmatism'}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 207
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "93LyeV2X7xi5",
        "colab": {}
      },
      "source": [
        "cdc = []\n",
        "\n",
        "for x in range(len(ndf)):\n",
        "    if x in list(cdc_idx_dict.keys()):\n",
        "        cdc.append(cdc_idx_dict.get(x))\n",
        "    else:\n",
        "        cdc.append('---')\n",
        "ndf['cdc'] = cdc\n",
        "\n",
        "df = pd.concat([ndf, df], axis=0, ignore_index=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "GORl16do7xDi"
      },
      "source": [
        "#### Article 14 "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "-UjDLNzL7xDj",
        "colab": {}
      },
      "source": [
        "with open(articles_dict[articles[14].replace(' ','_')+'.txt']) as article:\n",
        "        doc = article.read()\n",
        "\n",
        "c_doc = text_cleaner(doc)\n",
        "sentences = nltk.sent_tokenize(c_doc)\n",
        "sentences = [[sent, topic, articles[14]] for sent in sentences]\n",
        "\n",
        "ndf = pd.DataFrame(sentences, columns=['text', 'topic', 'article'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "outputId": "71ea479c-943a-4162-e5c7-2a05d611f7d1",
        "id": "OH7FXX0k7xDk",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "cdc_idx_dict = {}\n",
        "cdc_idx_sent = {}\n",
        "cdc_idx_art = {}\n",
        "\n",
        "for i,claim in enumerate(ref_data['clean_Claim']):\n",
        "    check_complete = False\n",
        "    while check_complete == False:\n",
        "        for idx,sentence in enumerate(ndf['text']):\n",
        "            test = claim.lower() in sentence.lower()\n",
        "            if test:\n",
        "                article = ref_data['Article'][i]\n",
        "                cdc_idx_dict[idx] = claim\n",
        "                cdc_idx_sent[idx] = [claim, sentence]\n",
        "                cdc_idx_art[idx] = [claim, article]\n",
        "                check_complete = True\n",
        "            elif idx == (len(ndf['text'])-1):\n",
        "                check_complete = True\n",
        "\n",
        "len(cdc_idx_dict), ref_data.shape[0]"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(1, 1332)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 210
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "outputId": "1251d3b4-5cdd-4c53-c150-30b1de8c0486",
        "id": "-_DIGPAC7xDl",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "cdc_idx_dict"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{27: \"Because current science can't figure out exactly how life started, it must be God who caused life to start\"}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 211
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "x87gb3WT7xDm",
        "colab": {}
      },
      "source": [
        "cdc = []\n",
        "\n",
        "for x in range(len(ndf)):\n",
        "    if x in list(cdc_idx_dict.keys()):\n",
        "        cdc.append(cdc_idx_dict.get(x))\n",
        "    else:\n",
        "        cdc.append('---')\n",
        "ndf['cdc'] = cdc\n",
        "\n",
        "df = pd.concat([ndf, df], axis=0, ignore_index=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "7SGPvwS17whR"
      },
      "source": [
        "#### Article 15"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "nWRVO4K-7whS",
        "colab": {}
      },
      "source": [
        "with open(articles_dict[articles[15].replace(' ','_')+'.txt']) as article:\n",
        "        doc = article.read()\n",
        "\n",
        "c_doc = text_cleaner(doc)\n",
        "sentences = nltk.sent_tokenize(c_doc)\n",
        "sentences = [[sent, topic, articles[15]] for sent in sentences]\n",
        "\n",
        "ndf = pd.DataFrame(sentences, columns=['text', 'topic', 'article'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "outputId": "8cd5229e-1851-4860-f842-ccab66ac460f",
        "id": "qq4IS4l57whU",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "cdc_idx_dict = {}\n",
        "cdc_idx_sent = {}\n",
        "cdc_idx_art = {}\n",
        "\n",
        "for i,claim in enumerate(ref_data['clean_Claim']):\n",
        "    check_complete = False\n",
        "    while check_complete == False:\n",
        "        for idx,sentence in enumerate(ndf['text']):\n",
        "            test = claim.lower() in sentence.lower()\n",
        "            if test:\n",
        "                article = ref_data['Article'][i]\n",
        "                cdc_idx_dict[idx] = claim\n",
        "                cdc_idx_sent[idx] = [claim, sentence]\n",
        "                cdc_idx_art[idx] = [claim, article]\n",
        "                check_complete = True\n",
        "            elif idx == (len(ndf['text'])-1):\n",
        "                check_complete = True\n",
        "\n",
        "len(cdc_idx_dict), ref_data.shape[0]"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(2, 1332)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 214
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "outputId": "2a0295c5-b0de-4176-efa9-4887085b6060",
        "id": "cEn2LSr97whV",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "cdc_idx_dict"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{1: 'nothing exists beyond the natural universe', 8: 'nature is all there is'}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 215
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "fNBhJflE7whW",
        "colab": {}
      },
      "source": [
        "cdc = []\n",
        "\n",
        "for x in range(len(ndf)):\n",
        "    if x in list(cdc_idx_dict.keys()):\n",
        "        cdc.append(cdc_idx_dict.get(x))\n",
        "    else:\n",
        "        cdc.append('---')\n",
        "ndf['cdc'] = cdc\n",
        "\n",
        "df = pd.concat([ndf, df], axis=0, ignore_index=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "t4s8XdGV7wEF"
      },
      "source": [
        "#### Article 16"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "2ShGquA47wEG",
        "colab": {}
      },
      "source": [
        "with open(articles_dict[articles[16].replace(' ','_')+'.txt']) as article:\n",
        "        doc = article.read()\n",
        "\n",
        "c_doc = text_cleaner(doc)\n",
        "sentences = nltk.sent_tokenize(c_doc)\n",
        "sentences = [[sent, topic, articles[16]] for sent in sentences]\n",
        "\n",
        "ndf = pd.DataFrame(sentences, columns=['text', 'topic', 'article'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "outputId": "34464426-dc5a-4049-fb12-d6d00d7a21f6",
        "id": "sdUl45177wEH",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "cdc_idx_dict = {}\n",
        "cdc_idx_sent = {}\n",
        "cdc_idx_art = {}\n",
        "\n",
        "for i,claim in enumerate(ref_data['clean_Claim']):\n",
        "    check_complete = False\n",
        "    while check_complete == False:\n",
        "        for idx,sentence in enumerate(ndf['text']):\n",
        "            test = claim.lower() in sentence.lower()\n",
        "            if test:\n",
        "                article = ref_data['Article'][i]\n",
        "                cdc_idx_dict[idx] = claim\n",
        "                cdc_idx_sent[idx] = [claim, sentence]\n",
        "                cdc_idx_art[idx] = [claim, article]\n",
        "                check_complete = True\n",
        "            elif idx == (len(ndf['text'])-1):\n",
        "                check_complete = True\n",
        "\n",
        "len(cdc_idx_dict), ref_data.shape[0]"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(3, 1332)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 218
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "outputId": "d1f9f6c8-3b9b-455f-becb-b297e9aa83d8",
        "id": "RAakFLmf7wEI",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "cdc_idx_dict"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{49: 'the universe can be explained without any reference to the supernatural',\n",
              " 60: 'God exists and this can be proven',\n",
              " 102: \"none of the arguments for God's existence are compelling\"}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 219
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "ornwfBXK7wEJ",
        "colab": {}
      },
      "source": [
        "cdc = []\n",
        "\n",
        "for x in range(len(ndf)):\n",
        "    if x in list(cdc_idx_dict.keys()):\n",
        "        cdc.append(cdc_idx_dict.get(x))\n",
        "    else:\n",
        "        cdc.append('---')\n",
        "ndf['cdc'] = cdc\n",
        "\n",
        "df = pd.concat([ndf, df], axis=0, ignore_index=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "-Uk097KK7vjk"
      },
      "source": [
        "#### Article 17"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "XCBw4HiN7vjl",
        "colab": {}
      },
      "source": [
        "with open(articles_dict[articles[17].replace(' ','_')+'.txt']) as article:\n",
        "        doc = article.read()\n",
        "\n",
        "c_doc = text_cleaner(doc)\n",
        "sentences = nltk.sent_tokenize(c_doc)\n",
        "sentences = [[sent, topic, articles[17]] for sent in sentences]\n",
        "\n",
        "ndf = pd.DataFrame(sentences, columns=['text', 'topic', 'article'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "outputId": "503569bb-46fd-4a07-9d6a-d73eef919308",
        "id": "z56HGmH07vjm",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "cdc_idx_dict = {}\n",
        "cdc_idx_sent = {}\n",
        "cdc_idx_art = {}\n",
        "\n",
        "for i,claim in enumerate(ref_data['clean_Claim']):\n",
        "    check_complete = False\n",
        "    while check_complete == False:\n",
        "        for idx,sentence in enumerate(ndf['text']):\n",
        "            test = claim.lower() in sentence.lower()\n",
        "            if test:\n",
        "                article = ref_data['Article'][i]\n",
        "                cdc_idx_dict[idx] = claim\n",
        "                cdc_idx_sent[idx] = [claim, sentence]\n",
        "                cdc_idx_art[idx] = [claim, article]\n",
        "                check_complete = True\n",
        "            elif idx == (len(ndf['text'])-1):\n",
        "                check_complete = True\n",
        "\n",
        "len(cdc_idx_dict), ref_data.shape[0]"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(1, 1332)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 222
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "outputId": "b66abf48-a7bb-4c58-cfd4-aadc937ba6b9",
        "id": "gMvzajxB7vjp",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "cdc_idx_dict"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{3: 'belief in a higher being is the product of fear'}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 223
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "WX3zLvek7vjq",
        "colab": {}
      },
      "source": [
        "cdc = []\n",
        "\n",
        "for x in range(len(ndf)):\n",
        "    if x in list(cdc_idx_dict.keys()):\n",
        "        cdc.append(cdc_idx_dict.get(x))\n",
        "    else:\n",
        "        cdc.append('---')\n",
        "ndf['cdc'] = cdc\n",
        "\n",
        "df = pd.concat([ndf, df], axis=0, ignore_index=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "MdKShyTI7u1n"
      },
      "source": [
        "#### Article 18 "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "PZ9p0BgD7u1p",
        "colab": {}
      },
      "source": [
        "with open(articles_dict[articles[18].replace(' ','_')+'.txt']) as article:\n",
        "        doc = article.read()\n",
        "\n",
        "c_doc = text_cleaner(doc)\n",
        "sentences = nltk.sent_tokenize(c_doc)\n",
        "sentences = [[sent, topic, articles[18]] for sent in sentences]\n",
        "\n",
        "ndf = pd.DataFrame(sentences, columns=['text', 'topic', 'article'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "outputId": "e89595bd-11fa-44d2-db10-39ac6e83607c",
        "id": "dvnkqDRT7u1r",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "cdc_idx_dict = {}\n",
        "cdc_idx_sent = {}\n",
        "cdc_idx_art = {}\n",
        "\n",
        "for i,claim in enumerate(ref_data['clean_Claim']):\n",
        "    check_complete = False\n",
        "    while check_complete == False:\n",
        "        for idx,sentence in enumerate(ndf['text']):\n",
        "            test = claim.lower() in sentence.lower()\n",
        "            if test:\n",
        "                article = ref_data['Article'][i]\n",
        "                cdc_idx_dict[idx] = claim\n",
        "                cdc_idx_sent[idx] = [claim, sentence]\n",
        "                cdc_idx_art[idx] = [claim, article]\n",
        "                check_complete = True\n",
        "            elif idx == (len(ndf['text'])-1):\n",
        "                check_complete = True\n",
        "\n",
        "len(cdc_idx_dict), ref_data.shape[0]"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(2, 1332)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 226
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "outputId": "daadf01d-e9bd-43d7-a847-970b96ddd121",
        "id": "onJiaNIo7u1s",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "cdc_idx_dict"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{85: 'life and the universe were created by a deity',\n",
              " 123: 'atheism is evidence of a healthy, independent mind'}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 227
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "c1VsTqaC7u1y",
        "colab": {}
      },
      "source": [
        "cdc = []\n",
        "\n",
        "for x in range(len(ndf)):\n",
        "    if x in list(cdc_idx_dict.keys()):\n",
        "        cdc.append(cdc_idx_dict.get(x))\n",
        "    else:\n",
        "        cdc.append('---')\n",
        "ndf['cdc'] = cdc\n",
        "\n",
        "df = pd.concat([ndf, df], axis=0, ignore_index=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lHs2iY0Tx_bk",
        "colab_type": "text"
      },
      "source": [
        "### 'boxing '"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "outputId": "bf823417-d3be-4fda-d5b5-107d153d9ca9",
        "id": "BlXcddlc1IO8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "topic = 'boxing '\n",
        "\n",
        "articles = topic_article_dict[topic]\n",
        "articles"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['Boxing styles and technique',\n",
              " 'Knockout',\n",
              " 'Boxing',\n",
              " 'Concussion',\n",
              " 'Combat sport',\n",
              " 'Dementia pugilistica',\n",
              " 'Contact sport',\n",
              " 'Boxing in China',\n",
              " 'The distance (boxing)',\n",
              " 'Amateur boxing']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 229
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_OETQfff1H89",
        "colab_type": "code",
        "outputId": "1e7611cc-85d3-4c39-c288-d2bfd60cb1b3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "len(articles)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "10"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 230
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "Lr3ktpo11IO-"
      },
      "source": [
        "#### Article 0 "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "rNLEjQpA1IO-",
        "colab": {}
      },
      "source": [
        "with open(articles_dict[articles[0].replace(' ','_')+'.txt']) as article:\n",
        "        doc = article.read()\n",
        "\n",
        "c_doc = text_cleaner(doc)\n",
        "sentences = nltk.sent_tokenize(c_doc)\n",
        "sentences = [[sent, topic, articles[0]] for sent in sentences]\n",
        "\n",
        "ndf = pd.DataFrame(sentences, columns=['text', 'topic', 'article'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "outputId": "90931f0f-55fb-4db7-8419-8fe752f5d186",
        "id": "ZfugmOyq1IPA",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "cdc_idx_dict = {}\n",
        "cdc_idx_sent = {}\n",
        "cdc_idx_art = {}\n",
        "\n",
        "for i,claim in enumerate(ref_data['clean_Claim']):\n",
        "    check_complete = False\n",
        "    while check_complete == False:\n",
        "        for idx,sentence in enumerate(ndf['text']):\n",
        "            test = claim.lower() in sentence.lower()\n",
        "            if test:\n",
        "                article = ref_data['Article'][i]\n",
        "                cdc_idx_dict[idx] = claim\n",
        "                cdc_idx_sent[idx] = [claim, sentence]\n",
        "                cdc_idx_art[idx] = [claim, article]\n",
        "                check_complete = True\n",
        "            elif idx == (len(ndf['text'])-1):\n",
        "                check_complete = True\n",
        "\n",
        "len(cdc_idx_dict), ref_data.shape[0]"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(1, 1332)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 232
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "outputId": "a3c9e7d1-a5c0-4970-a810-0fdedf7d1ab1",
        "id": "HqHDGP3Q1IPB",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "cdc_idx_dict"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{65: 'a powerpunch can do a lot of damage to a boxer'}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 233
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "G7dLPr-y1IPC",
        "colab": {}
      },
      "source": [
        "cdc = []\n",
        "\n",
        "for x in range(len(ndf)):\n",
        "    if x in list(cdc_idx_dict.keys()):\n",
        "        cdc.append(cdc_idx_dict.get(x))\n",
        "    else:\n",
        "        cdc.append('---')\n",
        "ndf['cdc'] = cdc\n",
        "\n",
        "df = pd.concat([ndf, df], axis=0, ignore_index=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "bMkPFKIO1IPD"
      },
      "source": [
        "#### Article 1 "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "0G3UVH2u1IPD",
        "colab": {}
      },
      "source": [
        "with open(articles_dict[articles[1].replace(' ','_')+'.txt']) as article:\n",
        "        doc = article.read()\n",
        "\n",
        "c_doc = text_cleaner(doc)\n",
        "sentences = nltk.sent_tokenize(c_doc)\n",
        "sentences = [[sent, topic, articles[1]] for sent in sentences]\n",
        "\n",
        "ndf = pd.DataFrame(sentences, columns=['text', 'topic', 'article'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "outputId": "a36099f8-cb7b-41c0-dfc4-667bac89279c",
        "id": "sSM4p6rF1IPE",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "cdc_idx_dict = {}\n",
        "cdc_idx_sent = {}\n",
        "cdc_idx_art = {}\n",
        "\n",
        "for i,claim in enumerate(ref_data['clean_Claim']):\n",
        "    check_complete = False\n",
        "    while check_complete == False:\n",
        "        for idx,sentence in enumerate(ndf['text']):\n",
        "            test = claim.lower() in sentence.lower()\n",
        "            if test:\n",
        "                article = ref_data['Article'][i]\n",
        "                cdc_idx_dict[idx] = claim\n",
        "                cdc_idx_sent[idx] = [claim, sentence]\n",
        "                cdc_idx_art[idx] = [claim, article]\n",
        "                check_complete = True\n",
        "            elif idx == (len(ndf['text'])-1):\n",
        "                check_complete = True\n",
        "\n",
        "len(cdc_idx_dict), ref_data.shape[0]"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(5, 1332)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 236
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "outputId": "55944ea0-bd1b-4370-be33-0f7b4c833353",
        "id": "D7jqd7mJ1IPG",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "cdc_idx_dict"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{25: 'The referee intervenes to avoid unnecessary damage or potential injury',\n",
              " 29: 'the typical knock out which results in a sustained loss of consciousness',\n",
              " 33: 'Repeated blows to the head are known to gradually cause permanent brain damage',\n",
              " 34: 'In severe cases may cause strokes or paralysis',\n",
              " 36: 'many physicians advise against sports involving knockouts'}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 237
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "lrCeU7c81IPH",
        "colab": {}
      },
      "source": [
        "cdc = []\n",
        "\n",
        "for x in range(len(ndf)):\n",
        "    if x in list(cdc_idx_dict.keys()):\n",
        "        cdc.append(cdc_idx_dict.get(x))\n",
        "    else:\n",
        "        cdc.append('---')\n",
        "ndf['cdc'] = cdc\n",
        "\n",
        "df = pd.concat([df, ndf], axis=0, ignore_index=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "i4PdPqrs1IPI"
      },
      "source": [
        "#### Article 2 "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "gNqnnOAF1IPI",
        "colab": {}
      },
      "source": [
        "with open(articles_dict[articles[2].replace(' ','_')+'.txt']) as article:\n",
        "        doc = article.read()\n",
        "\n",
        "c_doc = text_cleaner(doc)\n",
        "sentences = nltk.sent_tokenize(c_doc)\n",
        "sentences = [[sent, topic, articles[2]] for sent in sentences]\n",
        "\n",
        "ndf = pd.DataFrame(sentences, columns=['text', 'topic', 'article'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "outputId": "85afc4f9-62d9-442d-a39e-1a68e1c156ff",
        "id": "LP2XiXUU1IPJ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "cdc_idx_dict = {}\n",
        "cdc_idx_sent = {}\n",
        "cdc_idx_art = {}\n",
        "\n",
        "for i,claim in enumerate(ref_data['clean_Claim']):\n",
        "    check_complete = False\n",
        "    while check_complete == False:\n",
        "        for idx,sentence in enumerate(ndf['text']):\n",
        "            test = claim.lower() in sentence.lower()\n",
        "            if test:\n",
        "                article = ref_data['Article'][i]\n",
        "                cdc_idx_dict[idx] = claim\n",
        "                cdc_idx_sent[idx] = [claim, sentence]\n",
        "                cdc_idx_art[idx] = [claim, article]\n",
        "                check_complete = True\n",
        "            elif idx == (len(ndf['text'])-1):\n",
        "                check_complete = True\n",
        "\n",
        "len(cdc_idx_dict), ref_data.shape[0]"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(14, 1332)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 240
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "outputId": "f29a46bd-e504-4f47-9402-e81dd39def97",
        "id": "CNzPLlOf1IPK",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "cdc_idx_dict"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{59: 'boxing commissions and other sanctioning bodies were established to regulate the sport',\n",
              " 101: 'fighters wear protective headgear, reducing the number of injuries, knockdowns, and knockouts',\n",
              " 111: 'A referee monitors the fight to ensure that competitors use only legal blows',\n",
              " 116: 'Referees will stop the bout if a boxer is seriously injured',\n",
              " 122: 'Headgear is not permitted in professional bouts, and boxers are generally allowed to take much more damage before a fight is halted',\n",
              " 123: 'the referee may stop the contest if he believes that one participant cannot defend himself due to injury',\n",
              " 381: 'Knocking a person unconscious or even causing concussion may cause permanent brain damage',\n",
              " 382: 'There is no clear division between the force required to knock a person out and the force likely to kill a person',\n",
              " 383: 'amateur boxers, professional boxers and Toughman fighters have died as the result of ring or training injuries',\n",
              " 385: 'boxing an \"obscenity\" that \"should not be sanctioned by any civilized society',\n",
              " 386: 'Medical Associations also have called for bans on boxing',\n",
              " 387: 'boxing is the only sport where hurting the other athlete is the goal',\n",
              " 388: 'It is the only sport where the intention is to inflict serious injury on your opponent',\n",
              " 389: 'amateur boxers faced a high risk of brain damage'}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 241
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "Up6pM4CI1IPM",
        "colab": {}
      },
      "source": [
        "cdc = []\n",
        "\n",
        "for x in range(len(ndf)):\n",
        "    if x in list(cdc_idx_dict.keys()):\n",
        "        cdc.append(cdc_idx_dict.get(x))\n",
        "    else:\n",
        "        cdc.append('---')\n",
        "ndf['cdc'] = cdc\n",
        "\n",
        "df = pd.concat([ndf, df], axis=0, ignore_index=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "nT0DQtJf1IPN"
      },
      "source": [
        "#### Article 3 "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "11W0NftU1IPN",
        "colab": {}
      },
      "source": [
        "with open(articles_dict[articles[3].replace(' ','_')+'.txt']) as article:\n",
        "        doc = article.read()\n",
        "\n",
        "c_doc = text_cleaner(doc)\n",
        "sentences = nltk.sent_tokenize(c_doc)\n",
        "sentences = [[sent, topic, articles[3]] for sent in sentences]\n",
        "\n",
        "ndf = pd.DataFrame(sentences, columns=['text', 'topic', 'article'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "outputId": "16371e23-b62e-404d-b891-dad6c010db5d",
        "id": "qTYt72KB1IPO",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "cdc_idx_dict = {}\n",
        "cdc_idx_sent = {}\n",
        "cdc_idx_art = {}\n",
        "\n",
        "for i,claim in enumerate(ref_data['clean_Claim']):\n",
        "    check_complete = False\n",
        "    while check_complete == False:\n",
        "        for idx,sentence in enumerate(ndf['text']):\n",
        "            test = claim.lower() in sentence.lower()\n",
        "            if test:\n",
        "                article = ref_data['Article'][i]\n",
        "                cdc_idx_dict[idx] = claim\n",
        "                cdc_idx_sent[idx] = [claim, sentence]\n",
        "                cdc_idx_art[idx] = [claim, article]\n",
        "                check_complete = True\n",
        "            elif idx == (len(ndf['text'])-1):\n",
        "                check_complete = True\n",
        "\n",
        "len(cdc_idx_dict), ref_data.shape[0]"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(1, 1332)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 244
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "outputId": "cb1d2d69-8f79-4318-af45-003bb97f5240",
        "id": "nf0g9tCD1IPQ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "cdc_idx_dict"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{200: 'medical groups have called for a ban on the sport'}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 245
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "VT3kkqoF1IPR",
        "colab": {}
      },
      "source": [
        "cdc = []\n",
        "\n",
        "for x in range(len(ndf)):\n",
        "    if x in list(cdc_idx_dict.keys()):\n",
        "        cdc.append(cdc_idx_dict.get(x))\n",
        "    else:\n",
        "        cdc.append('---')\n",
        "ndf['cdc'] = cdc\n",
        "\n",
        "df = pd.concat([ndf, df], axis=0, ignore_index=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "L4oQjbxC1IPS"
      },
      "source": [
        "#### Article 4 "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "dSsW4pxh1IPS",
        "colab": {}
      },
      "source": [
        "with open(articles_dict[articles[4].replace(' ','_')+'.txt']) as article:\n",
        "        doc = article.read()\n",
        "\n",
        "c_doc = text_cleaner(doc)\n",
        "sentences = nltk.sent_tokenize(c_doc)\n",
        "sentences = [[sent, topic, articles[4]] for sent in sentences]\n",
        "\n",
        "ndf = pd.DataFrame(sentences, columns=['text', 'topic', 'article'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "outputId": "45050a8e-4478-49a2-f9e0-0ac42c44691e",
        "id": "n7NIPLfa1IPU",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "cdc_idx_dict = {}\n",
        "cdc_idx_sent = {}\n",
        "cdc_idx_art = {}\n",
        "\n",
        "for i,claim in enumerate(ref_data['clean_Claim']):\n",
        "    check_complete = False\n",
        "    while check_complete == False:\n",
        "        for idx,sentence in enumerate(ndf['text']):\n",
        "            test = claim.lower() in sentence.lower()\n",
        "            if test:\n",
        "                article = ref_data['Article'][i]\n",
        "                cdc_idx_dict[idx] = claim\n",
        "                cdc_idx_sent[idx] = [claim, sentence]\n",
        "                cdc_idx_art[idx] = [claim, article]\n",
        "                check_complete = True\n",
        "            elif idx == (len(ndf['text'])-1):\n",
        "                check_complete = True\n",
        "\n",
        "len(cdc_idx_dict), ref_data.shape[0]"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(1, 1332)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 248
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "outputId": "f9dbe462-3a6e-43a2-a84a-7e6d64da5eca",
        "id": "YdRLisH21IPV",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "cdc_idx_dict"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{3: 'Sports related to combat skills have been a part of human culture for thousands of years'}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 249
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "SWIiAPkq1IPW",
        "colab": {}
      },
      "source": [
        "cdc = []\n",
        "\n",
        "for x in range(len(ndf)):\n",
        "    if x in list(cdc_idx_dict.keys()):\n",
        "        cdc.append(cdc_idx_dict.get(x))\n",
        "    else:\n",
        "        cdc.append('---')\n",
        "ndf['cdc'] = cdc\n",
        "\n",
        "df = pd.concat([ndf, df], axis=0, ignore_index=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ghhyl83V9hef",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "aEsvDEfp9iFt"
      },
      "source": [
        "#### Article 5 "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "5wAh2DhH9iFv",
        "colab": {}
      },
      "source": [
        "with open(articles_dict[articles[5].replace(' ','_')+'.txt']) as article:\n",
        "        doc = article.read()\n",
        "\n",
        "c_doc = text_cleaner(doc)\n",
        "sentences = nltk.sent_tokenize(c_doc)\n",
        "sentences = [[sent, topic, articles[5]] for sent in sentences]\n",
        "\n",
        "ndf = pd.DataFrame(sentences, columns=['text', 'topic', 'article'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "outputId": "11983d76-16b2-4175-f7ef-4e7694954904",
        "id": "_EijVLb99iFx",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "cdc_idx_dict = {}\n",
        "cdc_idx_sent = {}\n",
        "cdc_idx_art = {}\n",
        "\n",
        "for i,claim in enumerate(ref_data['clean_Claim']):\n",
        "    check_complete = False\n",
        "    while check_complete == False:\n",
        "        for idx,sentence in enumerate(ndf['text']):\n",
        "            test = claim.lower() in sentence.lower()\n",
        "            if test:\n",
        "                article = ref_data['Article'][i]\n",
        "                cdc_idx_dict[idx] = claim\n",
        "                cdc_idx_sent[idx] = [claim, sentence]\n",
        "                cdc_idx_art[idx] = [claim, article]\n",
        "                check_complete = True\n",
        "            elif idx == (len(ndf['text'])-1):\n",
        "                check_complete = True\n",
        "\n",
        "len(cdc_idx_dict), ref_data.shape[0]"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(1, 1332)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 252
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "outputId": "b79f8707-85eb-4943-e291-19dfc9bee397",
        "id": "2diuQezj9iF0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "cdc_idx_dict"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{6: 'boxing may cause DP'}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 253
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "vrbL8Jz89iF1",
        "colab": {}
      },
      "source": [
        "cdc = []\n",
        "\n",
        "for x in range(len(ndf)):\n",
        "    if x in list(cdc_idx_dict.keys()):\n",
        "        cdc.append(cdc_idx_dict.get(x))\n",
        "    else:\n",
        "        cdc.append('---')\n",
        "ndf['cdc'] = cdc\n",
        "\n",
        "df = pd.concat([ndf, df], axis=0, ignore_index=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "BqCSpw7T9iF3"
      },
      "source": [
        "#### Article 6"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "rEXZeVQm9iF3",
        "colab": {}
      },
      "source": [
        "with open(articles_dict[articles[6].replace(' ','_')+'.txt']) as article:\n",
        "        doc = article.read()\n",
        "\n",
        "c_doc = text_cleaner(doc)\n",
        "sentences = nltk.sent_tokenize(c_doc)\n",
        "sentences = [[sent, topic, articles[6]] for sent in sentences]\n",
        "\n",
        "ndf = pd.DataFrame(sentences, columns=['text', 'topic', 'article'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "outputId": "d8bff030-2e3a-4464-8d3e-5cb7aa00cf92",
        "id": "2EvlzlnU9iF5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "cdc_idx_dict = {}\n",
        "cdc_idx_sent = {}\n",
        "cdc_idx_art = {}\n",
        "\n",
        "for i,claim in enumerate(ref_data['clean_Claim']):\n",
        "    check_complete = False\n",
        "    while check_complete == False:\n",
        "        for idx,sentence in enumerate(ndf['text']):\n",
        "            test = claim.lower() in sentence.lower()\n",
        "            if test:\n",
        "                article = ref_data['Article'][i]\n",
        "                cdc_idx_dict[idx] = claim\n",
        "                cdc_idx_sent[idx] = [claim, sentence]\n",
        "                cdc_idx_art[idx] = [claim, article]\n",
        "                check_complete = True\n",
        "            elif idx == (len(ndf['text'])-1):\n",
        "                check_complete = True\n",
        "\n",
        "len(cdc_idx_dict), ref_data.shape[0]"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(2, 1332)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 256
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "outputId": "aaa7daae-da1d-4dea-a22b-378fa100982d",
        "id": "MVZzSwPQ9iF7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "cdc_idx_dict"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{8: 'Contact sports have a higher risk of transmission of blood-borne disease between players',\n",
              " 16: 'tend to cause injuries'}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 257
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "WK4wztps9iF8",
        "colab": {}
      },
      "source": [
        "cdc = []\n",
        "\n",
        "for x in range(len(ndf)):\n",
        "    if x in list(cdc_idx_dict.keys()):\n",
        "        cdc.append(cdc_idx_dict.get(x))\n",
        "    else:\n",
        "        cdc.append('---')\n",
        "ndf['cdc'] = cdc\n",
        "\n",
        "df = pd.concat([ndf, df], axis=0, ignore_index=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "9H_RVRQx9iF-"
      },
      "source": [
        "#### Article 7"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "zZiEn4JB9iF-",
        "colab": {}
      },
      "source": [
        "with open(articles_dict[articles[7].replace(' ','_')+'.txt']) as article:\n",
        "        doc = article.read()\n",
        "\n",
        "c_doc = text_cleaner(doc)\n",
        "sentences = nltk.sent_tokenize(c_doc)\n",
        "sentences = [[sent, topic, articles[7]] for sent in sentences]\n",
        "\n",
        "ndf = pd.DataFrame(sentences, columns=['text', 'topic', 'article'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "outputId": "fb36a904-3fc3-4d27-9c96-bf0da09eb24d",
        "id": "p_iBoB6S9iGA",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "cdc_idx_dict = {}\n",
        "cdc_idx_sent = {}\n",
        "cdc_idx_art = {}\n",
        "\n",
        "for i,claim in enumerate(ref_data['clean_Claim']):\n",
        "    check_complete = False\n",
        "    while check_complete == False:\n",
        "        for idx,sentence in enumerate(ndf['text']):\n",
        "            test = claim.lower() in sentence.lower()\n",
        "            if test:\n",
        "                article = ref_data['Article'][i]\n",
        "                cdc_idx_dict[idx] = claim\n",
        "                cdc_idx_sent[idx] = [claim, sentence]\n",
        "                cdc_idx_art[idx] = [claim, article]\n",
        "                check_complete = True\n",
        "            elif idx == (len(ndf['text'])-1):\n",
        "                check_complete = True\n",
        "\n",
        "len(cdc_idx_dict), ref_data.shape[0]"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(1, 1332)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 260
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "outputId": "2067f9cb-f8ac-4529-eba9-8e62c098dbbf",
        "id": "Y0UcDIUI9iGB",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "cdc_idx_dict"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{5: 'boxing was very brutal'}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 261
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "WhwB35m39iGD",
        "colab": {}
      },
      "source": [
        "cdc = []\n",
        "\n",
        "for x in range(len(ndf)):\n",
        "    if x in list(cdc_idx_dict.keys()):\n",
        "        cdc.append(cdc_idx_dict.get(x))\n",
        "    else:\n",
        "        cdc.append('---')\n",
        "ndf['cdc'] = cdc\n",
        "\n",
        "df = pd.concat([ndf, df], axis=0, ignore_index=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "qnpdgP9N9iGG"
      },
      "source": [
        "#### Article 8"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "aEAhDvLM9iGG",
        "colab": {}
      },
      "source": [
        "with open(articles_dict[articles[8].replace(' ','_')+'.txt']) as article:\n",
        "        doc = article.read()\n",
        "\n",
        "c_doc = text_cleaner(doc)\n",
        "sentences = nltk.sent_tokenize(c_doc)\n",
        "sentences = [[sent, topic, articles[8]] for sent in sentences]\n",
        "\n",
        "ndf = pd.DataFrame(sentences, columns=['text', 'topic', 'article'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "outputId": "5899ef40-6273-4dad-cea6-1c3702ff218b",
        "id": "1-r54eB19iGI",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "cdc_idx_dict = {}\n",
        "cdc_idx_sent = {}\n",
        "cdc_idx_art = {}\n",
        "\n",
        "for i,claim in enumerate(ref_data['clean_Claim']):\n",
        "    check_complete = False\n",
        "    while check_complete == False:\n",
        "        for idx,sentence in enumerate(ndf['text']):\n",
        "            test = claim.lower() in sentence.lower()\n",
        "            if test:\n",
        "                article = ref_data['Article'][i]\n",
        "                cdc_idx_dict[idx] = claim\n",
        "                cdc_idx_sent[idx] = [claim, sentence]\n",
        "                cdc_idx_art[idx] = [claim, article]\n",
        "                check_complete = True\n",
        "            elif idx == (len(ndf['text'])-1):\n",
        "                check_complete = True\n",
        "\n",
        "len(cdc_idx_dict), ref_data.shape[0]"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(2, 1332)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 264
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "outputId": "873d748a-4423-44c1-944d-29385663d2d6",
        "id": "DS72WLHP9iGJ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "cdc_idx_dict"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{32: 'fatalities are rare in heavyweight matches',\n",
              " 35: 'boxing remains the 8th most deadly sport'}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 265
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "XHDfZk6z9iGL",
        "colab": {}
      },
      "source": [
        "cdc = []\n",
        "\n",
        "for x in range(len(ndf)):\n",
        "    if x in list(cdc_idx_dict.keys()):\n",
        "        cdc.append(cdc_idx_dict.get(x))\n",
        "    else:\n",
        "        cdc.append('---')\n",
        "ndf['cdc'] = cdc\n",
        "\n",
        "df = pd.concat([ndf, df], axis=0, ignore_index=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "GBGTpXfz9iGM"
      },
      "source": [
        "#### Article 9"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "W-E3WvWD9iGM",
        "colab": {}
      },
      "source": [
        "with open(articles_dict[articles[9].replace(' ','_')+'.txt']) as article:\n",
        "        doc = article.read()\n",
        "\n",
        "c_doc = text_cleaner(doc)\n",
        "sentences = nltk.sent_tokenize(c_doc)\n",
        "sentences = [[sent, topic, articles[9]] for sent in sentences]\n",
        "\n",
        "ndf = pd.DataFrame(sentences, columns=['text', 'topic', 'article'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "outputId": "ba85011b-cbb0-4e6f-de5a-3c8905f675d0",
        "id": "jLCUBidK9iGO",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "cdc_idx_dict = {}\n",
        "cdc_idx_sent = {}\n",
        "cdc_idx_art = {}\n",
        "\n",
        "for i,claim in enumerate(ref_data['clean_Claim']):\n",
        "    check_complete = False\n",
        "    while check_complete == False:\n",
        "        for idx,sentence in enumerate(ndf['text']):\n",
        "            test = claim.lower() in sentence.lower()\n",
        "            if test:\n",
        "                article = ref_data['Article'][i]\n",
        "                cdc_idx_dict[idx] = claim\n",
        "                cdc_idx_sent[idx] = [claim, sentence]\n",
        "                cdc_idx_art[idx] = [claim, article]\n",
        "                check_complete = True\n",
        "            elif idx == (len(ndf['text'])-1):\n",
        "                check_complete = True\n",
        "\n",
        "len(cdc_idx_dict), ref_data.shape[0]"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(2, 1332)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 268
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "outputId": "b53335df-34c2-43d4-e307-415ebe7c44db",
        "id": "Cq3wcc-c9iGP",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "cdc_idx_dict"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{7: 'A referee monitors the fight to ensure that competitors use only legal blows',\n",
              " 10: 'Referees will stop the bout if a boxer is seriously injured'}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 269
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "I0SdKYcI9iGQ",
        "colab": {}
      },
      "source": [
        "cdc = []\n",
        "\n",
        "for x in range(len(ndf)):\n",
        "    if x in list(cdc_idx_dict.keys()):\n",
        "        cdc.append(cdc_idx_dict.get(x))\n",
        "    else:\n",
        "        cdc.append('---')\n",
        "ndf['cdc'] = cdc\n",
        "\n",
        "df = pd.concat([ndf, df], axis=0, ignore_index=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "outputId": "e966764a-7f33-452c-c2ff-66272983d659",
        "id": "rlDPrAWJ9iGU",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "cdc_idx_dict = {}\n",
        "cdc_idx_sent = {}\n",
        "cdc_idx_art = {}\n",
        "\n",
        "for i,claim in enumerate(ref_data['clean_Claim']):\n",
        "    check_complete = False\n",
        "    while check_complete == False:\n",
        "        for idx,sentence in enumerate(ndf['text']):\n",
        "            test = claim.lower() in sentence.lower()\n",
        "            if test:\n",
        "                article = ref_data['Article'][i]\n",
        "                cdc_idx_dict[idx] = claim\n",
        "                cdc_idx_sent[idx] = [claim, sentence]\n",
        "                cdc_idx_art[idx] = [claim, article]\n",
        "                check_complete = True\n",
        "            elif idx == (len(ndf['text'])-1):\n",
        "                check_complete = True\n",
        "\n",
        "len(cdc_idx_dict), ref_data.shape[0]"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(2, 1332)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 271
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "outputId": "e8d5bd18-fe03-4a7f-84ca-e031542aa5d9",
        "id": "LdQVZAWq9iGV",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "cdc_idx_dict"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{7: 'A referee monitors the fight to ensure that competitors use only legal blows',\n",
              " 10: 'Referees will stop the bout if a boxer is seriously injured'}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 272
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "BaquEk4D9iGW",
        "colab": {}
      },
      "source": [
        "cdc = []\n",
        "\n",
        "for x in range(len(ndf)):\n",
        "    if x in list(cdc_idx_dict.keys()):\n",
        "        cdc.append(cdc_idx_dict.get(x))\n",
        "    else:\n",
        "        cdc.append('---')\n",
        "ndf['cdc'] = cdc\n",
        "\n",
        "df = pd.concat([ndf, df], axis=0, ignore_index=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Uer3brO_yFCI",
        "colab_type": "text"
      },
      "source": [
        "### 'bribery is sometimes acceptable '"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gcQG56BE1Jjk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "outputId": "ebfcf8f7-7217-4ee1-ebdd-6e1b1913769f",
        "id": "T8ORloxU1J3u",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "topic = 'bribery is sometimes acceptable '\n",
        "\n",
        "articles = topic_article_dict[topic]\n",
        "articles"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['Bribery',\n",
              " 'United Nations Convention against Corruption',\n",
              " 'Political corruption',\n",
              " \"Corruption in the People's Republic of China\"]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 274
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "jk-AADWS1J3v"
      },
      "source": [
        "#### Article 0 "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "N80qcKej1J3v",
        "colab": {}
      },
      "source": [
        "with open(articles_dict[articles[0].replace(' ','_')+'.txt']) as article:\n",
        "        doc = article.read()\n",
        "\n",
        "c_doc = text_cleaner(doc)\n",
        "sentences = nltk.sent_tokenize(c_doc)\n",
        "sentences = [[sent, topic, articles[0]] for sent in sentences]\n",
        "\n",
        "ndf = pd.DataFrame(sentences, columns=['text', 'topic', 'article'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "outputId": "42cfce1e-7b8c-4b17-c159-9422f055b570",
        "id": "8YuzSilT1J3x",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "cdc_idx_dict = {}\n",
        "cdc_idx_sent = {}\n",
        "cdc_idx_art = {}\n",
        "\n",
        "for i,claim in enumerate(ref_data['clean_Claim']):\n",
        "    check_complete = False\n",
        "    while check_complete == False:\n",
        "        for idx,sentence in enumerate(ndf['text']):\n",
        "            test = claim.lower() in sentence.lower()\n",
        "            if test:\n",
        "                article = ref_data['Article'][i]\n",
        "                cdc_idx_dict[idx] = claim\n",
        "                cdc_idx_sent[idx] = [claim, sentence]\n",
        "                cdc_idx_art[idx] = [claim, article]\n",
        "                check_complete = True\n",
        "            elif idx == (len(ndf['text'])-1):\n",
        "                check_complete = True\n",
        "\n",
        "len(cdc_idx_dict), ref_data.shape[0]"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(5, 1332)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 276
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "outputId": "397a6600-eb2b-47ce-df83-06b2c2ba35f8",
        "id": "oz2r_CZm1J3y",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "cdc_idx_dict"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{5: 'Bribery in bureaucracy has been viewed as a reason for higher cost of production of goods and services',\n",
              " 8: 'Expectations of when a monetary transaction is appropriate can differ from place to place',\n",
              " 34: 'it encourages rent seeking behaviour',\n",
              " 36: 'may interfere with good government',\n",
              " 53: 'In some cases where the system of law is not well-implemented, bribes may be a way for companies to continue their businesses'}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 277
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "OZks_P0P1J3z",
        "colab": {}
      },
      "source": [
        "cdc = []\n",
        "\n",
        "for x in range(len(ndf)):\n",
        "    if x in list(cdc_idx_dict.keys()):\n",
        "        cdc.append(cdc_idx_dict.get(x))\n",
        "    else:\n",
        "        cdc.append('---')\n",
        "ndf['cdc'] = cdc\n",
        "\n",
        "df = pd.concat([ndf, df], axis=0, ignore_index=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "LHVCctT11J30"
      },
      "source": [
        "#### Article 1 "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "4J-2INRY1J30",
        "colab": {}
      },
      "source": [
        "with open(articles_dict[articles[1].replace(' ','_')+'.txt']) as article:\n",
        "        doc = article.read()\n",
        "\n",
        "c_doc = text_cleaner(doc)\n",
        "sentences = nltk.sent_tokenize(c_doc)\n",
        "sentences = [[sent, topic, articles[1]] for sent in sentences]\n",
        "\n",
        "ndf = pd.DataFrame(sentences, columns=['text', 'topic', 'article'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "outputId": "dcae41bf-0caf-4d40-8419-89de25cdbbd6",
        "id": "mSDs3Cj51J32",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "cdc_idx_dict = {}\n",
        "cdc_idx_sent = {}\n",
        "cdc_idx_art = {}\n",
        "\n",
        "for i,claim in enumerate(ref_data['clean_Claim']):\n",
        "    check_complete = False\n",
        "    while check_complete == False:\n",
        "        for idx,sentence in enumerate(ndf['text']):\n",
        "            test = claim.lower() in sentence.lower()\n",
        "            if test:\n",
        "                article = ref_data['Article'][i]\n",
        "                cdc_idx_dict[idx] = claim\n",
        "                cdc_idx_sent[idx] = [claim, sentence]\n",
        "                cdc_idx_art[idx] = [claim, article]\n",
        "                check_complete = True\n",
        "            elif idx == (len(ndf['text'])-1):\n",
        "                check_complete = True\n",
        "\n",
        "len(cdc_idx_dict), ref_data.shape[0]"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(1, 1332)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 280
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "outputId": "4efd578a-658d-4e44-bd86-08e95e936977",
        "id": "ufvedJJ21J34",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "cdc_idx_dict"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{23: 'undermine the value of democracy'}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 281
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "szFJqogr1J36",
        "colab": {}
      },
      "source": [
        "cdc = []\n",
        "\n",
        "for x in range(len(ndf)):\n",
        "    if x in list(cdc_idx_dict.keys()):\n",
        "        cdc.append(cdc_idx_dict.get(x))\n",
        "    else:\n",
        "        cdc.append('---')\n",
        "ndf['cdc'] = cdc\n",
        "\n",
        "df = pd.concat([df, ndf], axis=0, ignore_index=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "EJsQy-My1J37"
      },
      "source": [
        "#### Article 2 "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "bcQsXcYx1J38",
        "colab": {}
      },
      "source": [
        "with open(articles_dict[articles[2].replace(' ','_')+'.txt']) as article:\n",
        "        doc = article.read()\n",
        "\n",
        "c_doc = text_cleaner(doc)\n",
        "sentences = nltk.sent_tokenize(c_doc)\n",
        "sentences = [[sent, topic, articles[2]] for sent in sentences]\n",
        "\n",
        "ndf = pd.DataFrame(sentences, columns=['text', 'topic', 'article'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "outputId": "dbd1511e-e48c-4c82-9e41-56ff2bd0d8c5",
        "id": "Z9eBtM5M1J39",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "cdc_idx_dict = {}\n",
        "cdc_idx_sent = {}\n",
        "cdc_idx_art = {}\n",
        "\n",
        "for i,claim in enumerate(ref_data['clean_Claim']):\n",
        "    check_complete = False\n",
        "    while check_complete == False:\n",
        "        for idx,sentence in enumerate(ndf['text']):\n",
        "            test = claim.lower() in sentence.lower()\n",
        "            if test:\n",
        "                article = ref_data['Article'][i]\n",
        "                cdc_idx_dict[idx] = claim\n",
        "                cdc_idx_sent[idx] = [claim, sentence]\n",
        "                cdc_idx_art[idx] = [claim, article]\n",
        "                check_complete = True\n",
        "            elif idx == (len(ndf['text'])-1):\n",
        "                check_complete = True\n",
        "\n",
        "len(cdc_idx_dict), ref_data.shape[0]"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(7, 1332)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 284
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "outputId": "33dab7ce-8f33-4154-f81d-48c88b67dc96",
        "id": "O725V5ve1J3-",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "cdc_idx_dict"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{12: 'Corruption poses a serious development challenge',\n",
              " 13: 'it undermines democracy and good governance',\n",
              " 18: 'corruption increases the cost of business',\n",
              " 19: 'corruption reduces costs by cutting bureaucracy',\n",
              " 21: 'distorts the playing field',\n",
              " 22: 'Corruption also generates economic distortions',\n",
              " 24: 'reduces the quality of government services and infrastructure'}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 285
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "2PJ-_76j1J3_",
        "colab": {}
      },
      "source": [
        "cdc = []\n",
        "\n",
        "for x in range(len(ndf)):\n",
        "    if x in list(cdc_idx_dict.keys()):\n",
        "        cdc.append(cdc_idx_dict.get(x))\n",
        "    else:\n",
        "        cdc.append('---')\n",
        "ndf['cdc'] = cdc\n",
        "\n",
        "df = pd.concat([ndf, df], axis=0, ignore_index=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "YUgHKIID1J4A"
      },
      "source": [
        "#### Article 3 "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "lJipC9YR1J4A",
        "colab": {}
      },
      "source": [
        "with open(articles_dict[articles[3].replace(' ','_')+'.txt']) as article:\n",
        "        doc = article.read()\n",
        "\n",
        "c_doc = text_cleaner(doc)\n",
        "sentences = nltk.sent_tokenize(c_doc)\n",
        "sentences = [[sent, topic, articles[3]] for sent in sentences]\n",
        "\n",
        "ndf = pd.DataFrame(sentences, columns=['text', 'topic', 'article'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "outputId": "39634288-3965-4550-8147-789ce57d6cf7",
        "id": "urqezSVT1J4C",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "cdc_idx_dict = {}\n",
        "cdc_idx_sent = {}\n",
        "cdc_idx_art = {}\n",
        "\n",
        "for i,claim in enumerate(ref_data['clean_Claim']):\n",
        "    check_complete = False\n",
        "    while check_complete == False:\n",
        "        for idx,sentence in enumerate(ndf['text']):\n",
        "            test = claim.lower() in sentence.lower()\n",
        "            if test:\n",
        "                article = ref_data['Article'][i]\n",
        "                cdc_idx_dict[idx] = claim\n",
        "                cdc_idx_sent[idx] = [claim, sentence]\n",
        "                cdc_idx_art[idx] = [claim, article]\n",
        "                check_complete = True\n",
        "            elif idx == (len(ndf['text'])-1):\n",
        "                check_complete = True\n",
        "\n",
        "len(cdc_idx_dict), ref_data.shape[0]"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(5, 1332)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 288
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "outputId": "7b87e5fe-8dff-47ce-dd4c-e55b5c74ae3e",
        "id": "gfMlQZ1A1J4D",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "cdc_idx_dict"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{7: 'adds to economic inequality',\n",
              " 93: 'Corruption favors the most connected and unscrupulous, rather than the efficient',\n",
              " 95: 'Bribes also lead to a misdirection of resources',\n",
              " 101: 'it distorts and retards development',\n",
              " 102: 'corruption is a necessary trade-off'}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 289
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "Bhtja-Ct1J4F",
        "colab": {}
      },
      "source": [
        "cdc = []\n",
        "\n",
        "for x in range(len(ndf)):\n",
        "    if x in list(cdc_idx_dict.keys()):\n",
        "        cdc.append(cdc_idx_dict.get(x))\n",
        "    else:\n",
        "        cdc.append('---')\n",
        "ndf['cdc'] = cdc\n",
        "\n",
        "df = pd.concat([ndf, df], axis=0, ignore_index=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wN7UCkMcyJs5",
        "colab_type": "text"
      },
      "source": [
        "### 'countries with an imbalanced male female ratio skewed towards males should encourage parents to produce girls '"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "outputId": "02335b98-7a2a-4884-bdd7-2624b9c334c9",
        "id": "VwTVQ_Y_1LnK",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "topic = 'countries with an imbalanced male female ratio skewed towards males should encourage parents to produce girls '\n",
        "\n",
        "articles = topic_article_dict[topic]\n",
        "articles"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['Human sex ratio',\n",
              " 'Sex selection',\n",
              " 'Sex-selective abortion',\n",
              " 'One-child policy']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 291
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "ab8a7AAb1LnM"
      },
      "source": [
        "#### Article 0 "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "H1lNxe3s1LnM",
        "colab": {}
      },
      "source": [
        "with open(articles_dict[articles[0].replace(' ','_')+'.txt']) as article:\n",
        "        doc = article.read()\n",
        "\n",
        "c_doc = text_cleaner(doc)\n",
        "sentences = nltk.sent_tokenize(c_doc)\n",
        "sentences = [[sent, topic, articles[0]] for sent in sentences]\n",
        "\n",
        "ndf = pd.DataFrame(sentences, columns=['text', 'topic', 'article'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "outputId": "eb159540-b7aa-429f-8b61-877f219c2b25",
        "id": "QAoAW9jZ1LnN",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "cdc_idx_dict = {}\n",
        "cdc_idx_sent = {}\n",
        "cdc_idx_art = {}\n",
        "\n",
        "for i,claim in enumerate(ref_data['clean_Claim']):\n",
        "    check_complete = False\n",
        "    while check_complete == False:\n",
        "        for idx,sentence in enumerate(ndf['text']):\n",
        "            test = claim.lower() in sentence.lower()\n",
        "            if test:\n",
        "                article = ref_data['Article'][i]\n",
        "                cdc_idx_dict[idx] = claim\n",
        "                cdc_idx_sent[idx] = [claim, sentence]\n",
        "                cdc_idx_art[idx] = [claim, article]\n",
        "                check_complete = True\n",
        "            elif idx == (len(ndf['text'])-1):\n",
        "                check_complete = True\n",
        "\n",
        "len(cdc_idx_dict), ref_data.shape[0]"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(1, 1332)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 293
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "outputId": "acf3fd83-0acd-485c-83c1-27016abcf5bd",
        "id": "WkuoL6Sm1LnO",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "cdc_idx_dict"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{143: 'Gender imbalance may result in the threat of social unrest, especially in the case of an excess of low-status young males unable to find spouses'}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 294
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "9g4Js3_y1LnP",
        "colab": {}
      },
      "source": [
        "cdc = []\n",
        "\n",
        "for x in range(len(ndf)):\n",
        "    if x in list(cdc_idx_dict.keys()):\n",
        "        cdc.append(cdc_idx_dict.get(x))\n",
        "    else:\n",
        "        cdc.append('---')\n",
        "ndf['cdc'] = cdc\n",
        "\n",
        "df = pd.concat([ndf, df], axis=0, ignore_index=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "I-x2Sc7s1LnQ"
      },
      "source": [
        "#### Article 1 "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "k-TkhJz81LnQ",
        "colab": {}
      },
      "source": [
        "with open(articles_dict[articles[1].replace(' ','_')+'.txt']) as article:\n",
        "        doc = article.read()\n",
        "\n",
        "c_doc = text_cleaner(doc)\n",
        "sentences = nltk.sent_tokenize(c_doc)\n",
        "sentences = [[sent, topic, articles[1]] for sent in sentences]\n",
        "\n",
        "ndf = pd.DataFrame(sentences, columns=['text', 'topic', 'article'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "outputId": "b9c1fcd4-597e-4a37-9e36-08b728aa4ee4",
        "id": "HMkhCMxO1LnR",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "cdc_idx_dict = {}\n",
        "cdc_idx_sent = {}\n",
        "cdc_idx_art = {}\n",
        "\n",
        "for i,claim in enumerate(ref_data['clean_Claim']):\n",
        "    check_complete = False\n",
        "    while check_complete == False:\n",
        "        for idx,sentence in enumerate(ndf['text']):\n",
        "            test = claim.lower() in sentence.lower()\n",
        "            if test:\n",
        "                article = ref_data['Article'][i]\n",
        "                cdc_idx_dict[idx] = claim\n",
        "                cdc_idx_sent[idx] = [claim, sentence]\n",
        "                cdc_idx_art[idx] = [claim, article]\n",
        "                check_complete = True\n",
        "            elif idx == (len(ndf['text'])-1):\n",
        "                check_complete = True\n",
        "\n",
        "len(cdc_idx_dict), ref_data.shape[0]"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(4, 1332)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 297
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "outputId": "396ac995-6491-46ed-fa8e-d61a921ff79a",
        "id": "8yg1gz261LnS",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "cdc_idx_dict"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{52: 'sex selection is an expression of reproductive rights',\n",
              " 61: \"China's gender imbalance is further increased by the One Child Policy\",\n",
              " 62: 'a lack of opportunity for many men to marry is believed to be producing increases in crime',\n",
              " 68: 'if female babies worth their weight in rupees and yuan, economic and educational opportunities for girls would soon follow'}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 298
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "F92OtBYW1LnT",
        "colab": {}
      },
      "source": [
        "cdc = []\n",
        "\n",
        "for x in range(len(ndf)):\n",
        "    if x in list(cdc_idx_dict.keys()):\n",
        "        cdc.append(cdc_idx_dict.get(x))\n",
        "    else:\n",
        "        cdc.append('---')\n",
        "ndf['cdc'] = cdc\n",
        "\n",
        "df = pd.concat([df, ndf], axis=0, ignore_index=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "63o5uKOS1LnU"
      },
      "source": [
        "#### Article 2 "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "-BPthavU1LnV",
        "colab": {}
      },
      "source": [
        "with open(articles_dict[articles[2].replace(' ','_')+'.txt']) as article:\n",
        "        doc = article.read()\n",
        "\n",
        "c_doc = text_cleaner(doc)\n",
        "sentences = nltk.sent_tokenize(c_doc)\n",
        "sentences = [[sent, topic, articles[2]] for sent in sentences]\n",
        "\n",
        "ndf = pd.DataFrame(sentences, columns=['text', 'topic', 'article'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "outputId": "0cd31414-333b-4ef5-f03f-f7fcc0ee7506",
        "id": "uejfBexK1LnW",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "cdc_idx_dict = {}\n",
        "cdc_idx_sent = {}\n",
        "cdc_idx_art = {}\n",
        "\n",
        "for i,claim in enumerate(ref_data['clean_Claim']):\n",
        "    check_complete = False\n",
        "    while check_complete == False:\n",
        "        for idx,sentence in enumerate(ndf['text']):\n",
        "            test = claim.lower() in sentence.lower()\n",
        "            if test:\n",
        "                article = ref_data['Article'][i]\n",
        "                cdc_idx_dict[idx] = claim\n",
        "                cdc_idx_sent[idx] = [claim, sentence]\n",
        "                cdc_idx_art[idx] = [claim, article]\n",
        "                check_complete = True\n",
        "            elif idx == (len(ndf['text'])-1):\n",
        "                check_complete = True\n",
        "\n",
        "len(cdc_idx_dict), ref_data.shape[0]"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(2, 1332)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 301
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "outputId": "61d97e2b-ed19-4282-d12a-68bc34f6e6cc",
        "id": "9T9vLK4K1LnX",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "cdc_idx_dict"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{58: 'Shortage of females has the effect of driving human trafficking',\n",
              " 61: 'son preference, which results in harmful and unethical practices'}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 302
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "6dQL7xUm1LnY",
        "colab": {}
      },
      "source": [
        "cdc = []\n",
        "\n",
        "for x in range(len(ndf)):\n",
        "    if x in list(cdc_idx_dict.keys()):\n",
        "        cdc.append(cdc_idx_dict.get(x))\n",
        "    else:\n",
        "        cdc.append('---')\n",
        "ndf['cdc'] = cdc\n",
        "\n",
        "df = pd.concat([ndf, df], axis=0, ignore_index=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "ggLU_vZJ1LnZ"
      },
      "source": [
        "#### Article 3 "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "vw4V-NdP1LnZ",
        "colab": {}
      },
      "source": [
        "with open(articles_dict[articles[3].replace(' ','_')+'.txt']) as article:\n",
        "        doc = article.read()\n",
        "\n",
        "c_doc = text_cleaner(doc)\n",
        "sentences = nltk.sent_tokenize(c_doc)\n",
        "sentences = [[sent, topic, articles[3]] for sent in sentences]\n",
        "\n",
        "ndf = pd.DataFrame(sentences, columns=['text', 'topic', 'article'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "outputId": "f8e1b504-48ea-4566-f42e-86abc37563a1",
        "id": "d7g9WQeF1Lnb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "cdc_idx_dict = {}\n",
        "cdc_idx_sent = {}\n",
        "cdc_idx_art = {}\n",
        "\n",
        "for i,claim in enumerate(ref_data['clean_Claim']):\n",
        "    check_complete = False\n",
        "    while check_complete == False:\n",
        "        for idx,sentence in enumerate(ndf['text']):\n",
        "            test = claim.lower() in sentence.lower()\n",
        "            if test:\n",
        "                article = ref_data['Article'][i]\n",
        "                cdc_idx_dict[idx] = claim\n",
        "                cdc_idx_sent[idx] = [claim, sentence]\n",
        "                cdc_idx_art[idx] = [claim, article]\n",
        "                check_complete = True\n",
        "            elif idx == (len(ndf['text'])-1):\n",
        "                check_complete = True\n",
        "\n",
        "len(cdc_idx_dict), ref_data.shape[0]"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(17, 1332)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 305
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "outputId": "c9a47ba8-abf9-48ad-abe7-583878b524e3",
        "id": "CFwoHK2j1Lnc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "cdc_idx_dict"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{8: 'The policy is controversial both within and outside China because of the manner in which the policy has been implemented, and because of concerns about negative social consequences',\n",
              " 9: \"possible cause behind China's gender imbalance\",\n",
              " 55: 'it had proved \"remarkably effective',\n",
              " 62: \"great success in helping to implement China's current economic growth\",\n",
              " 63: 'The reduction in the fertility rate and thus population growth has reduced the severity of problems that come with overpopulation',\n",
              " 65: 'the focus of China on population control helps provide a better health service for women',\n",
              " 67: 'The individual savings rate has increased since the one-child policy was introduced',\n",
              " 72: 'less intrusive options, including those that emphasized delay and spacing of births, could have achieved the same results over an extended period of time',\n",
              " 83: 'China could have expected a continued reduction in its fertility rate just from continued economic development, had it kept to the previous policy',\n",
              " 84: \"The one-child policy is challenged in principle and in practice for violating a human right to determine the size of one's own family\",\n",
              " 97: 'leaves the older generations with increased chances of dependency on retirement funds or charity in order to receive support',\n",
              " 99: 'If, for any reason, the single child is unable to care for their older adult relatives, the oldest generations would face a lack of resources and necessities',\n",
              " 102: 'Some parents may over-indulge their only child',\n",
              " 108: 'social problems and personality disorders in young people',\n",
              " 160: 'Only if equality of males and females is strongly promoted.. will the harmonious and sustainable development of society be possible',\n",
              " 161: 'The social pressure exerted by the one-child policy has affected the rate at which parents abandon undesirable children',\n",
              " 176: \"China's family planning programs contribute to infanticide\"}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 306
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "yqmkgYwE1Lnd",
        "colab": {}
      },
      "source": [
        "cdc = []\n",
        "\n",
        "for x in range(len(ndf)):\n",
        "    if x in list(cdc_idx_dict.keys()):\n",
        "        cdc.append(cdc_idx_dict.get(x))\n",
        "    else:\n",
        "        cdc.append('---')\n",
        "ndf['cdc'] = cdc\n",
        "\n",
        "df = pd.concat([ndf, df], axis=0, ignore_index=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ae9nMQS1yL7o",
        "colab_type": "text"
      },
      "source": [
        "### 'democratic governments should require voters to present photo identification at the polling station '"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I0dnd5ar1M7a",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "outputId": "1fc9b1f9-95a7-49c1-f23b-842ef4997ecb",
        "id": "RxMs5NZa1NNH",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "topic = 'democratic governments should require voters to present photo identification at the polling station '\n",
        "\n",
        "articles = topic_article_dict[topic]\n",
        "articles"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['Crawford v Marion County Election Board',\n",
              " 'Voter suppression',\n",
              " 'Help America Vote Act']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 308
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "s0kQ6ago1NNI"
      },
      "source": [
        "#### Article 0 "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "U3WjAoEl1NNK",
        "colab": {}
      },
      "source": [
        "with open(articles_dict[articles[0].replace(' ','_')+'.txt']) as article:\n",
        "        doc = article.read()\n",
        "\n",
        "c_doc = text_cleaner(doc)\n",
        "sentences = nltk.sent_tokenize(c_doc)\n",
        "sentences = [[sent, topic, articles[0]] for sent in sentences]\n",
        "\n",
        "ndf = pd.DataFrame(sentences, columns=['text', 'topic', 'article'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "outputId": "76f05a37-11c9-4a88-ccc1-d0b4ef2e3065",
        "id": "s2ZkrvIc1NNM",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "cdc_idx_dict = {}\n",
        "cdc_idx_sent = {}\n",
        "cdc_idx_art = {}\n",
        "\n",
        "for i,claim in enumerate(ref_data['clean_Claim']):\n",
        "    check_complete = False\n",
        "    while check_complete == False:\n",
        "        for idx,sentence in enumerate(ndf['text']):\n",
        "            test = claim.lower() in sentence.lower()\n",
        "            if test:\n",
        "                article = ref_data['Article'][i]\n",
        "                cdc_idx_dict[idx] = claim\n",
        "                cdc_idx_sent[idx] = [claim, sentence]\n",
        "                cdc_idx_art[idx] = [claim, article]\n",
        "                check_complete = True\n",
        "            elif idx == (len(ndf['text'])-1):\n",
        "                check_complete = True\n",
        "\n",
        "len(cdc_idx_dict), ref_data.shape[0]"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(1, 1332)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 310
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "outputId": "0dcd60bd-8f9a-4428-e224-21e7c7b4a38a",
        "id": "fIU3mWED1NNN",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "cdc_idx_dict"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{20: 'procedures for acquiring an ID were too burdensome and costly for some low income or elderly voters'}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 311
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "FdTCizg61NNP",
        "colab": {}
      },
      "source": [
        "cdc = []\n",
        "\n",
        "for x in range(len(ndf)):\n",
        "    if x in list(cdc_idx_dict.keys()):\n",
        "        cdc.append(cdc_idx_dict.get(x))\n",
        "    else:\n",
        "        cdc.append('---')\n",
        "ndf['cdc'] = cdc\n",
        "\n",
        "df = pd.concat([ndf, df], axis=0, ignore_index=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "J5WZG9tj1NNR"
      },
      "source": [
        "#### Article 1 "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "F57qFntg1NNR",
        "colab": {}
      },
      "source": [
        "with open(articles_dict[articles[1].replace(' ','_')+'.txt']) as article:\n",
        "        doc = article.read()\n",
        "\n",
        "c_doc = text_cleaner(doc)\n",
        "sentences = nltk.sent_tokenize(c_doc)\n",
        "sentences = [[sent, topic, articles[1]] for sent in sentences]\n",
        "\n",
        "ndf = pd.DataFrame(sentences, columns=['text', 'topic', 'article'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "outputId": "372377d4-58ae-4406-ff2f-7ff69f40b55c",
        "id": "jvjhKKps1NNS",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "cdc_idx_dict = {}\n",
        "cdc_idx_sent = {}\n",
        "cdc_idx_art = {}\n",
        "\n",
        "for i,claim in enumerate(ref_data['clean_Claim']):\n",
        "    check_complete = False\n",
        "    while check_complete == False:\n",
        "        for idx,sentence in enumerate(ndf['text']):\n",
        "            test = claim.lower() in sentence.lower()\n",
        "            if test:\n",
        "                article = ref_data['Article'][i]\n",
        "                cdc_idx_dict[idx] = claim\n",
        "                cdc_idx_sent[idx] = [claim, sentence]\n",
        "                cdc_idx_art[idx] = [claim, article]\n",
        "                check_complete = True\n",
        "            elif idx == (len(ndf['text'])-1):\n",
        "                check_complete = True\n",
        "\n",
        "len(cdc_idx_dict), ref_data.shape[0]"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(6, 1332)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 314
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "outputId": "c6faa517-01c0-4d28-e277-ec96fad40d72",
        "id": "MxZSOZCM1NNT",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "cdc_idx_dict"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{12: 'presenting them is a minor inconvenience when weighed against the possibility of ineligible voters affecting elections',\n",
              " 13: 'photo ID requirements disproportionately affect minority and elderly voters',\n",
              " 17: 'photo identification was necessary to prevent widespread voter fraud',\n",
              " 18: 'would decrease voting',\n",
              " 22: 'The danger of voter fraud threatens the integrity of the entire electoral process',\n",
              " 28: 'it \"has the potential to block millions of eligible American voters, and thus suppress the right to vote'}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 315
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "o6mRQoMA1NNU",
        "colab": {}
      },
      "source": [
        "cdc = []\n",
        "\n",
        "for x in range(len(ndf)):\n",
        "    if x in list(cdc_idx_dict.keys()):\n",
        "        cdc.append(cdc_idx_dict.get(x))\n",
        "    else:\n",
        "        cdc.append('---')\n",
        "ndf['cdc'] = cdc\n",
        "\n",
        "df = pd.concat([df, ndf], axis=0, ignore_index=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "OMVMprbM1NNV"
      },
      "source": [
        "#### Article 2 "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "AblNV9n11NNV",
        "colab": {}
      },
      "source": [
        "with open(articles_dict[articles[2].replace(' ','_')+'.txt']) as article:\n",
        "        doc = article.read()\n",
        "\n",
        "c_doc = text_cleaner(doc)\n",
        "sentences = nltk.sent_tokenize(c_doc)\n",
        "sentences = [[sent, topic, articles[2]] for sent in sentences]\n",
        "\n",
        "ndf = pd.DataFrame(sentences, columns=['text', 'topic', 'article'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "outputId": "8e6e2141-08d0-49f7-e7c0-4853e1bad47e",
        "id": "NMEzmpxv1NNW",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "cdc_idx_dict = {}\n",
        "cdc_idx_sent = {}\n",
        "cdc_idx_art = {}\n",
        "\n",
        "for i,claim in enumerate(ref_data['clean_Claim']):\n",
        "    check_complete = False\n",
        "    while check_complete == False:\n",
        "        for idx,sentence in enumerate(ndf['text']):\n",
        "            test = claim.lower() in sentence.lower()\n",
        "            if test:\n",
        "                article = ref_data['Article'][i]\n",
        "                cdc_idx_dict[idx] = claim\n",
        "                cdc_idx_sent[idx] = [claim, sentence]\n",
        "                cdc_idx_art[idx] = [claim, article]\n",
        "                check_complete = True\n",
        "            elif idx == (len(ndf['text'])-1):\n",
        "                check_complete = True\n",
        "\n",
        "len(cdc_idx_dict), ref_data.shape[0]"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(2, 1332)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 318
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "outputId": "aaf8daf6-126c-4a53-a444-786c34b944a6",
        "id": "6oA2lTxj1NNX",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "cdc_idx_dict"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{59: 'may reduce rather than expand the electorate',\n",
              " 63: 'voter identification laws that could suppress the turnout by voters'}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 319
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "bGlH6QM51NNY",
        "colab": {}
      },
      "source": [
        "cdc = []\n",
        "\n",
        "for x in range(len(ndf)):\n",
        "    if x in list(cdc_idx_dict.keys()):\n",
        "        cdc.append(cdc_idx_dict.get(x))\n",
        "    else:\n",
        "        cdc.append('---')\n",
        "ndf['cdc'] = cdc\n",
        "\n",
        "df = pd.concat([ndf, df], axis=0, ignore_index=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DH3hxSysySaD",
        "colab_type": "text"
      },
      "source": [
        "### 'endangered species should be protected '"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "outputId": "93afa5e7-8a11-4b42-8c10-105cbe91698f",
        "id": "AUjACxbu1Ox2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "topic = 'endangered species should be protected '\n",
        "\n",
        "articles = topic_article_dict[topic]\n",
        "articles"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['Habitat conservation',\n",
              " 'Conservation biology',\n",
              " 'Biodiversity',\n",
              " 'Habitat destruction',\n",
              " 'Conservation in Australia',\n",
              " 'Deep ecology',\n",
              " 'Biocentrism (ethics)',\n",
              " 'Extinction',\n",
              " 'Melbourne Principles',\n",
              " 'Environmental ethics',\n",
              " 'Ecological effects of biodiversity',\n",
              " 'Economics of biodiversity',\n",
              " 'Convention on Biological Diversity']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 321
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y0BB1qpK1Ohy",
        "colab_type": "code",
        "outputId": "d0fedfee-e90a-46d0-be82-7a623ac30eb2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "len(articles)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "13"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 322
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "Kwcphfn_1Ox3"
      },
      "source": [
        "#### Article 0 "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "eXK-KCPO1Ox3",
        "colab": {}
      },
      "source": [
        "with open(articles_dict[articles[0].replace(' ','_')+'.txt']) as article:\n",
        "        doc = article.read()\n",
        "\n",
        "c_doc = text_cleaner(doc)\n",
        "sentences = nltk.sent_tokenize(c_doc)\n",
        "sentences = [[sent, topic, articles[0]] for sent in sentences]\n",
        "\n",
        "ndf = pd.DataFrame(sentences, columns=['text', 'topic', 'article'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "outputId": "e0e7bb61-0a21-4245-f31b-1c6f8ed51b40",
        "id": "2g7Y6fPR1Ox4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "cdc_idx_dict = {}\n",
        "cdc_idx_sent = {}\n",
        "cdc_idx_art = {}\n",
        "\n",
        "for i,claim in enumerate(ref_data['clean_Claim']):\n",
        "    check_complete = False\n",
        "    while check_complete == False:\n",
        "        for idx,sentence in enumerate(ndf['text']):\n",
        "            test = claim.lower() in sentence.lower()\n",
        "            if test:\n",
        "                article = ref_data['Article'][i]\n",
        "                cdc_idx_dict[idx] = claim\n",
        "                cdc_idx_sent[idx] = [claim, sentence]\n",
        "                cdc_idx_art[idx] = [claim, article]\n",
        "                check_complete = True\n",
        "            elif idx == (len(ndf['text'])-1):\n",
        "                check_complete = True\n",
        "\n",
        "len(cdc_idx_dict), ref_data.shape[0]"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(1, 1332)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 324
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "outputId": "f299ff0d-0774-419c-c12b-d0d128f83513",
        "id": "0h0eDJIH1Ox5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "cdc_idx_dict"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{9: 'The cost of repairing damaged ecosystems is considered to be much higher than the cost of conserving natural ecosystems'}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 325
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "9ebT8Fuv1Ox6",
        "colab": {}
      },
      "source": [
        "cdc = []\n",
        "\n",
        "for x in range(len(ndf)):\n",
        "    if x in list(cdc_idx_dict.keys()):\n",
        "        cdc.append(cdc_idx_dict.get(x))\n",
        "    else:\n",
        "        cdc.append('---')\n",
        "ndf['cdc'] = cdc\n",
        "\n",
        "df = pd.concat([ndf, df], axis=0, ignore_index=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "QRHAwuTp1Ox7"
      },
      "source": [
        "#### Article 1 "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "H7w7qUF11Ox7",
        "colab": {}
      },
      "source": [
        "with open(articles_dict[articles[1].replace(' ','_')+'.txt']) as article:\n",
        "        doc = article.read()\n",
        "\n",
        "c_doc = text_cleaner(doc)\n",
        "sentences = nltk.sent_tokenize(c_doc)\n",
        "sentences = [[sent, topic, articles[1]] for sent in sentences]\n",
        "\n",
        "ndf = pd.DataFrame(sentences, columns=['text', 'topic', 'article'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "outputId": "a8ecec75-8e2c-48fa-a7dd-2c16bbb79eeb",
        "id": "E1JyCsjl1Ox9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "cdc_idx_dict = {}\n",
        "cdc_idx_sent = {}\n",
        "cdc_idx_art = {}\n",
        "\n",
        "for i,claim in enumerate(ref_data['clean_Claim']):\n",
        "    check_complete = False\n",
        "    while check_complete == False:\n",
        "        for idx,sentence in enumerate(ndf['text']):\n",
        "            test = claim.lower() in sentence.lower()\n",
        "            if test:\n",
        "                article = ref_data['Article'][i]\n",
        "                cdc_idx_dict[idx] = claim\n",
        "                cdc_idx_sent[idx] = [claim, sentence]\n",
        "                cdc_idx_art[idx] = [claim, article]\n",
        "                check_complete = True\n",
        "            elif idx == (len(ndf['text'])-1):\n",
        "                check_complete = True\n",
        "\n",
        "len(cdc_idx_dict), ref_data.shape[0]"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(2, 1332)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 328
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "outputId": "dae8b5dd-abec-4def-850a-a7050290e7a7",
        "id": "hoaTfhho1Ox-",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "cdc_idx_dict"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{124: 'rapid rates of biodiversity loss threatens the sustained well-being of humanity',\n",
              " 144: 'species are irreplaceable components of the global ecosystem'}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 329
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "y_e7XVBf1OyA",
        "colab": {}
      },
      "source": [
        "cdc = []\n",
        "\n",
        "for x in range(len(ndf)):\n",
        "    if x in list(cdc_idx_dict.keys()):\n",
        "        cdc.append(cdc_idx_dict.get(x))\n",
        "    else:\n",
        "        cdc.append('---')\n",
        "ndf['cdc'] = cdc\n",
        "\n",
        "df = pd.concat([df, ndf], axis=0, ignore_index=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "KGzJbwCF1OyB"
      },
      "source": [
        "#### Article 2 "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "XT_LsKDN1OyC",
        "colab": {}
      },
      "source": [
        "with open(articles_dict[articles[2].replace(' ','_')+'.txt']) as article:\n",
        "        doc = article.read()\n",
        "\n",
        "c_doc = text_cleaner(doc)\n",
        "sentences = nltk.sent_tokenize(c_doc)\n",
        "sentences = [[sent, topic, articles[2]] for sent in sentences]\n",
        "\n",
        "ndf = pd.DataFrame(sentences, columns=['text', 'topic', 'article'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "outputId": "a62c8e28-9c17-4a89-e38e-236bc74bd040",
        "id": "F2eFkcmH1OyE",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "cdc_idx_dict = {}\n",
        "cdc_idx_sent = {}\n",
        "cdc_idx_art = {}\n",
        "\n",
        "for i,claim in enumerate(ref_data['clean_Claim']):\n",
        "    check_complete = False\n",
        "    while check_complete == False:\n",
        "        for idx,sentence in enumerate(ndf['text']):\n",
        "            test = claim.lower() in sentence.lower()\n",
        "            if test:\n",
        "                article = ref_data['Article'][i]\n",
        "                cdc_idx_dict[idx] = claim\n",
        "                cdc_idx_sent[idx] = [claim, sentence]\n",
        "                cdc_idx_art[idx] = [claim, article]\n",
        "                check_complete = True\n",
        "            elif idx == (len(ndf['text'])-1):\n",
        "                check_complete = True\n",
        "\n",
        "len(cdc_idx_dict), ref_data.shape[0]"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(10, 1332)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 332
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "outputId": "34f46e67-f848-4c2d-c6be-510f0ced369d",
        "id": "J07dhIfj1OyF",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "cdc_idx_dict"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{114: \"Earth's surviving biodiversity provides resources for increasing the range of food and other products suitable for human use\",\n",
              " 124: 'Biodiversity is also known to have an important role in reducing disaster risk, and in post-disaster relief',\n",
              " 125: 'Biodiversity provides critical support for drug discovery and the availability of medicinal resources',\n",
              " 128: 'Biodiversity has been critical to advances throughout the field of bionics',\n",
              " 133: 'Biodiversity is also important to the security of resources',\n",
              " 135: 'Biodiversity enriches leisure activities',\n",
              " 142: 'biodiversity has intrinsic aesthetic and spiritual value to mankind',\n",
              " 144: 'Biodiversity supports many ecosystem services',\n",
              " 146: 'Biodiversity is directly involved in water purification',\n",
              " 218: 'Loss of biodiversity results in the loss of natural capital that supplies ecosystem goods and services'}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 333
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "hb2XiXxg1OyG",
        "colab": {}
      },
      "source": [
        "cdc = []\n",
        "\n",
        "for x in range(len(ndf)):\n",
        "    if x in list(cdc_idx_dict.keys()):\n",
        "        cdc.append(cdc_idx_dict.get(x))\n",
        "    else:\n",
        "        cdc.append('---')\n",
        "ndf['cdc'] = cdc\n",
        "\n",
        "df = pd.concat([ndf, df], axis=0, ignore_index=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "y5luGPuT1OyH"
      },
      "source": [
        "#### Article 3 "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "gPw2FnAT1OyH",
        "colab": {}
      },
      "source": [
        "with open(articles_dict[articles[3].replace(' ','_')+'.txt']) as article:\n",
        "        doc = article.read()\n",
        "\n",
        "c_doc = text_cleaner(doc)\n",
        "sentences = nltk.sent_tokenize(c_doc)\n",
        "sentences = [[sent, topic, articles[3]] for sent in sentences]\n",
        "\n",
        "ndf = pd.DataFrame(sentences, columns=['text', 'topic', 'article'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "outputId": "81016e96-2cdc-4213-e394-b6333ab7ced9",
        "id": "NU_smS441OyJ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "cdc_idx_dict = {}\n",
        "cdc_idx_sent = {}\n",
        "cdc_idx_art = {}\n",
        "\n",
        "for i,claim in enumerate(ref_data['clean_Claim']):\n",
        "    check_complete = False\n",
        "    while check_complete == False:\n",
        "        for idx,sentence in enumerate(ndf['text']):\n",
        "            test = claim.lower() in sentence.lower()\n",
        "            if test:\n",
        "                article = ref_data['Article'][i]\n",
        "                cdc_idx_dict[idx] = claim\n",
        "                cdc_idx_sent[idx] = [claim, sentence]\n",
        "                cdc_idx_art[idx] = [claim, article]\n",
        "                check_complete = True\n",
        "            elif idx == (len(ndf['text'])-1):\n",
        "                check_complete = True\n",
        "\n",
        "len(cdc_idx_dict), ref_data.shape[0]"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(3, 1332)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 336
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "outputId": "da9de017-286f-4e62-da19-2e36289b87b7",
        "id": "onsghH3x1OyK",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "cdc_idx_dict"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{94: 'When biodiversity is lost, the environment loses many species that provide valuable and unique roles to the ecosystem',\n",
              " 95: 'The environment and all its inhabitants rely on biodiversity',\n",
              " 97: 'humans are losing animals that could have served as biological control agents'}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 337
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "jThrG3RP1OyL",
        "colab": {}
      },
      "source": [
        "cdc = []\n",
        "\n",
        "for x in range(len(ndf)):\n",
        "    if x in list(cdc_idx_dict.keys()):\n",
        "        cdc.append(cdc_idx_dict.get(x))\n",
        "    else:\n",
        "        cdc.append('---')\n",
        "ndf['cdc'] = cdc\n",
        "\n",
        "df = pd.concat([ndf, df], axis=0, ignore_index=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "r68Rhusv1OyM"
      },
      "source": [
        "#### Article 4 "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "D8U01wmq1OyM",
        "colab": {}
      },
      "source": [
        "with open(articles_dict[articles[4].replace(' ','_')+'.txt']) as article:\n",
        "        doc = article.read()\n",
        "\n",
        "c_doc = text_cleaner(doc)\n",
        "sentences = nltk.sent_tokenize(c_doc)\n",
        "sentences = [[sent, topic, articles[4]] for sent in sentences]\n",
        "\n",
        "ndf = pd.DataFrame(sentences, columns=['text', 'topic', 'article'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "outputId": "12b8f2c0-46bd-4372-948d-943d0b72b4db",
        "id": "nbuK83X61OyP",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "cdc_idx_dict = {}\n",
        "cdc_idx_sent = {}\n",
        "cdc_idx_art = {}\n",
        "\n",
        "for i,claim in enumerate(ref_data['clean_Claim']):\n",
        "    check_complete = False\n",
        "    while check_complete == False:\n",
        "        for idx,sentence in enumerate(ndf['text']):\n",
        "            test = claim.lower() in sentence.lower()\n",
        "            if test:\n",
        "                article = ref_data['Article'][i]\n",
        "                cdc_idx_dict[idx] = claim\n",
        "                cdc_idx_sent[idx] = [claim, sentence]\n",
        "                cdc_idx_art[idx] = [claim, article]\n",
        "                check_complete = True\n",
        "            elif idx == (len(ndf['text'])-1):\n",
        "                check_complete = True\n",
        "\n",
        "len(cdc_idx_dict), ref_data.shape[0]"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(3, 1332)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 340
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "outputId": "21a72206-561d-48ff-aad2-fa2804366f15",
        "id": "AXVF0kVT1OyQ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "cdc_idx_dict"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{2: 'wealth of biodiversity is important for future generations',\n",
              " 4: 'biological richness is an unmeasurable aesthetic that may be developed into commercial recreational attractions',\n",
              " 6: 'Research on natural processes can only occur if habitat is preserved and organisms continue to thrive'}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 341
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "SuXw7jtK1OyR",
        "colab": {}
      },
      "source": [
        "cdc = []\n",
        "\n",
        "for x in range(len(ndf)):\n",
        "    if x in list(cdc_idx_dict.keys()):\n",
        "        cdc.append(cdc_idx_dict.get(x))\n",
        "    else:\n",
        "        cdc.append('---')\n",
        "ndf['cdc'] = cdc\n",
        "\n",
        "df = pd.concat([ndf, df], axis=0, ignore_index=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "gc9sFBoi-BSF"
      },
      "source": [
        "#### Article 5 "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "s75UX9ip-BSG",
        "colab": {}
      },
      "source": [
        "with open(articles_dict[articles[5].replace(' ','_')+'.txt']) as article:\n",
        "        doc = article.read()\n",
        "\n",
        "c_doc = text_cleaner(doc)\n",
        "sentences = nltk.sent_tokenize(c_doc)\n",
        "sentences = [[sent, topic, articles[5]] for sent in sentences]\n",
        "\n",
        "ndf = pd.DataFrame(sentences, columns=['text', 'topic', 'article'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "outputId": "d0c2fec5-d533-48b0-f06a-81bad27735f7",
        "id": "gOpvVVQa-BSI",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "cdc_idx_dict = {}\n",
        "cdc_idx_sent = {}\n",
        "cdc_idx_art = {}\n",
        "\n",
        "for i,claim in enumerate(ref_data['clean_Claim']):\n",
        "    check_complete = False\n",
        "    while check_complete == False:\n",
        "        for idx,sentence in enumerate(ndf['text']):\n",
        "            test = claim.lower() in sentence.lower()\n",
        "            if test:\n",
        "                article = ref_data['Article'][i]\n",
        "                cdc_idx_dict[idx] = claim\n",
        "                cdc_idx_sent[idx] = [claim, sentence]\n",
        "                cdc_idx_art[idx] = [claim, article]\n",
        "                check_complete = True\n",
        "            elif idx == (len(ndf['text'])-1):\n",
        "                check_complete = True\n",
        "\n",
        "len(cdc_idx_dict), ref_data.shape[0]"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(5, 1332)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 344
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "outputId": "0af13744-2117-420c-da56-7273fe5a6e26",
        "id": "vM7UTyW2-BSK",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "cdc_idx_dict"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{4: 'like humanity, the living environment as a whole has the same right to live and flourish',\n",
              " 15: 'the right of all forms to live is a universal right',\n",
              " 42: 'Human life is dependent on the harmonious balance of interdependent relationships between organisms',\n",
              " 71: 'the world does not exist as a resource to be freely exploited by humans',\n",
              " 118: 'All life has intrinsic value'}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 345
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "x9ebBoQ3-BSM",
        "colab": {}
      },
      "source": [
        "cdc = []\n",
        "\n",
        "for x in range(len(ndf)):\n",
        "    if x in list(cdc_idx_dict.keys()):\n",
        "        cdc.append(cdc_idx_dict.get(x))\n",
        "    else:\n",
        "        cdc.append('---')\n",
        "ndf['cdc'] = cdc\n",
        "\n",
        "df = pd.concat([ndf, df], axis=0, ignore_index=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "al-XqSTy-BSN"
      },
      "source": [
        "#### Article 6"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "KhvWxkc0-BSO",
        "colab": {}
      },
      "source": [
        "with open(articles_dict[articles[6].replace(' ','_')+'.txt']) as article:\n",
        "        doc = article.read()\n",
        "\n",
        "c_doc = text_cleaner(doc)\n",
        "sentences = nltk.sent_tokenize(c_doc)\n",
        "sentences = [[sent, topic, articles[6]] for sent in sentences]\n",
        "\n",
        "ndf = pd.DataFrame(sentences, columns=['text', 'topic', 'article'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "outputId": "624fcaf6-9d5a-4fd0-8617-67740b9a36f9",
        "id": "xzky4DJP-BSP",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "cdc_idx_dict = {}\n",
        "cdc_idx_sent = {}\n",
        "cdc_idx_art = {}\n",
        "\n",
        "for i,claim in enumerate(ref_data['clean_Claim']):\n",
        "    check_complete = False\n",
        "    while check_complete == False:\n",
        "        for idx,sentence in enumerate(ndf['text']):\n",
        "            test = claim.lower() in sentence.lower()\n",
        "            if test:\n",
        "                article = ref_data['Article'][i]\n",
        "                cdc_idx_dict[idx] = claim\n",
        "                cdc_idx_sent[idx] = [claim, sentence]\n",
        "                cdc_idx_art[idx] = [claim, article]\n",
        "                check_complete = True\n",
        "            elif idx == (len(ndf['text'])-1):\n",
        "                check_complete = True\n",
        "\n",
        "len(cdc_idx_dict), ref_data.shape[0]"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(3, 1332)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 348
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "outputId": "9d9ea227-3a16-4126-cfa6-0e9831171bef",
        "id": "zfFNzOcm-BSR",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "cdc_idx_dict"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{3: 'any actions which negatively affect the living systems of which we are a part, adversely affect us as well',\n",
              " 4: 'all species have inherent value',\n",
              " 8: 'each organism has a purpose and a reason for being'}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 349
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "69IddY-T-BSS",
        "colab": {}
      },
      "source": [
        "cdc = []\n",
        "\n",
        "for x in range(len(ndf)):\n",
        "    if x in list(cdc_idx_dict.keys()):\n",
        "        cdc.append(cdc_idx_dict.get(x))\n",
        "    else:\n",
        "        cdc.append('---')\n",
        "ndf['cdc'] = cdc\n",
        "\n",
        "df = pd.concat([ndf, df], axis=0, ignore_index=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "pLIU-Qt8-BSU"
      },
      "source": [
        "#### Article 7"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "gGZpXmSz-BSV",
        "colab": {}
      },
      "source": [
        "with open(articles_dict[articles[7].replace(' ','_')+'.txt']) as article:\n",
        "        doc = article.read()\n",
        "\n",
        "c_doc = text_cleaner(doc)\n",
        "sentences = nltk.sent_tokenize(c_doc)\n",
        "sentences = [[sent, topic, articles[7]] for sent in sentences]\n",
        "\n",
        "ndf = pd.DataFrame(sentences, columns=['text', 'topic', 'article'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "outputId": "7e8518d8-3eac-4d6e-ea09-a9e9c2642c27",
        "id": "aV2rl_JB-BSW",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "cdc_idx_dict = {}\n",
        "cdc_idx_sent = {}\n",
        "cdc_idx_art = {}\n",
        "\n",
        "for i,claim in enumerate(ref_data['clean_Claim']):\n",
        "    check_complete = False\n",
        "    while check_complete == False:\n",
        "        for idx,sentence in enumerate(ndf['text']):\n",
        "            test = claim.lower() in sentence.lower()\n",
        "            if test:\n",
        "                article = ref_data['Article'][i]\n",
        "                cdc_idx_dict[idx] = claim\n",
        "                cdc_idx_sent[idx] = [claim, sentence]\n",
        "                cdc_idx_art[idx] = [claim, article]\n",
        "                check_complete = True\n",
        "            elif idx == (len(ndf['text'])-1):\n",
        "                check_complete = True\n",
        "\n",
        "len(cdc_idx_dict), ref_data.shape[0]"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(5, 1332)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 352
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "outputId": "d67e2ef1-d82e-4c3f-b6c1-d0a309aed9ca",
        "id": "2jMPg-0H-BSX",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "cdc_idx_dict"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{40: 'As long as species have been evolving, species have been going extinct',\n",
              " 136: 'the loss of native species as a loss to ecotourism',\n",
              " 140: 'People who live close to nature can be dependent on the survival of all the species in their environment',\n",
              " 142: 'The very fact that a species is near extinction implies that its final demise will have negligible impact',\n",
              " 150: 'since species become extinct \"all the time\" the disappearance of a few more will not destroy the ecosystem'}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 353
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "UQjLbYVo-BSY",
        "colab": {}
      },
      "source": [
        "cdc = []\n",
        "\n",
        "for x in range(len(ndf)):\n",
        "    if x in list(cdc_idx_dict.keys()):\n",
        "        cdc.append(cdc_idx_dict.get(x))\n",
        "    else:\n",
        "        cdc.append('---')\n",
        "ndf['cdc'] = cdc\n",
        "\n",
        "df = pd.concat([ndf, df], axis=0, ignore_index=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "PvGz07zS-BSa"
      },
      "source": [
        "#### Article 8"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "1LJmF6yY-BSb",
        "colab": {}
      },
      "source": [
        "with open(articles_dict[articles[8].replace(' ','_')+'.txt']) as article:\n",
        "        doc = article.read()\n",
        "\n",
        "c_doc = text_cleaner(doc)\n",
        "sentences = nltk.sent_tokenize(c_doc)\n",
        "sentences = [[sent, topic, articles[8]] for sent in sentences]\n",
        "\n",
        "ndf = pd.DataFrame(sentences, columns=['text', 'topic', 'article'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "outputId": "5ad1b62b-8de3-41ba-df7c-8776aa4b43e7",
        "id": "NogtXT2V-BSc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "cdc_idx_dict = {}\n",
        "cdc_idx_sent = {}\n",
        "cdc_idx_art = {}\n",
        "\n",
        "for i,claim in enumerate(ref_data['clean_Claim']):\n",
        "    check_complete = False\n",
        "    while check_complete == False:\n",
        "        for idx,sentence in enumerate(ndf['text']):\n",
        "            test = claim.lower() in sentence.lower()\n",
        "            if test:\n",
        "                article = ref_data['Article'][i]\n",
        "                cdc_idx_dict[idx] = claim\n",
        "                cdc_idx_sent[idx] = [claim, sentence]\n",
        "                cdc_idx_art[idx] = [claim, article]\n",
        "                check_complete = True\n",
        "            elif idx == (len(ndf['text'])-1):\n",
        "                check_complete = True\n",
        "\n",
        "len(cdc_idx_dict), ref_data.shape[0]"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(3, 1332)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 356
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "outputId": "251c54d1-9094-4cd1-fee9-48b1cbe12c12",
        "id": "QS9Kmt83-BSd",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "cdc_idx_dict"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{20: 'Nature is more than a commodity for the benefit of humans',\n",
              " 22: 'They warrant our respect, whether or not they are of immediate benefit to us',\n",
              " 26: 'we have a responsibility to act as custodians for nature'}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 357
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "AXV3D6pu-BSf",
        "colab": {}
      },
      "source": [
        "cdc = []\n",
        "\n",
        "for x in range(len(ndf)):\n",
        "    if x in list(cdc_idx_dict.keys()):\n",
        "        cdc.append(cdc_idx_dict.get(x))\n",
        "    else:\n",
        "        cdc.append('---')\n",
        "ndf['cdc'] = cdc\n",
        "\n",
        "df = pd.concat([ndf, df], axis=0, ignore_index=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "ngBdRk0--BSg"
      },
      "source": [
        "#### Article 9"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "fY9vgKBy-BSh",
        "colab": {}
      },
      "source": [
        "with open(articles_dict[articles[9].replace(' ','_')+'.txt']) as article:\n",
        "        doc = article.read()\n",
        "\n",
        "c_doc = text_cleaner(doc)\n",
        "sentences = nltk.sent_tokenize(c_doc)\n",
        "sentences = [[sent, topic, articles[9]] for sent in sentences]\n",
        "\n",
        "ndf = pd.DataFrame(sentences, columns=['text', 'topic', 'article'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "outputId": "464f480a-df97-4f5c-8703-a2e23bfe5164",
        "id": "UK4x_Yoe-BSj",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "cdc_idx_dict = {}\n",
        "cdc_idx_sent = {}\n",
        "cdc_idx_art = {}\n",
        "\n",
        "for i,claim in enumerate(ref_data['clean_Claim']):\n",
        "    check_complete = False\n",
        "    while check_complete == False:\n",
        "        for idx,sentence in enumerate(ndf['text']):\n",
        "            test = claim.lower() in sentence.lower()\n",
        "            if test:\n",
        "                article = ref_data['Article'][i]\n",
        "                cdc_idx_dict[idx] = claim\n",
        "                cdc_idx_sent[idx] = [claim, sentence]\n",
        "                cdc_idx_art[idx] = [claim, article]\n",
        "                check_complete = True\n",
        "            elif idx == (len(ndf['text'])-1):\n",
        "                check_complete = True\n",
        "\n",
        "len(cdc_idx_dict), ref_data.shape[0]"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(1, 1332)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 360
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "outputId": "20c01a51-4c66-43fd-a5f0-2c6864abc1df",
        "id": "TyWwZmBE-BSl",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "cdc_idx_dict"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{39: 'it has extrinsic value – instrumental to the welfare of human beings'}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 361
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "063X9PCf-BSm",
        "colab": {}
      },
      "source": [
        "cdc = []\n",
        "\n",
        "for x in range(len(ndf)):\n",
        "    if x in list(cdc_idx_dict.keys()):\n",
        "        cdc.append(cdc_idx_dict.get(x))\n",
        "    else:\n",
        "        cdc.append('---')\n",
        "ndf['cdc'] = cdc\n",
        "\n",
        "df = pd.concat([ndf, df], axis=0, ignore_index=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "TcSlJNlQ-BSo"
      },
      "source": [
        "#### Article 10"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "YmEEpF_Z-BSp",
        "colab": {}
      },
      "source": [
        "with open(articles_dict[articles[10].replace(' ','_')+'.txt']) as article:\n",
        "        doc = article.read()\n",
        "\n",
        "c_doc = text_cleaner(doc)\n",
        "sentences = nltk.sent_tokenize(c_doc)\n",
        "sentences = [[sent, topic, articles[10]] for sent in sentences]\n",
        "\n",
        "ndf = pd.DataFrame(sentences, columns=['text', 'topic', 'article'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "outputId": "c747d434-dcfb-4787-bed7-46dae1fd76c6",
        "id": "O0QQdp8W-BSq",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "cdc_idx_dict = {}\n",
        "cdc_idx_sent = {}\n",
        "cdc_idx_art = {}\n",
        "\n",
        "for i,claim in enumerate(ref_data['clean_Claim']):\n",
        "    check_complete = False\n",
        "    while check_complete == False:\n",
        "        for idx,sentence in enumerate(ndf['text']):\n",
        "            test = claim.lower() in sentence.lower()\n",
        "            if test:\n",
        "                article = ref_data['Article'][i]\n",
        "                cdc_idx_dict[idx] = claim\n",
        "                cdc_idx_sent[idx] = [claim, sentence]\n",
        "                cdc_idx_art[idx] = [claim, article]\n",
        "                check_complete = True\n",
        "            elif idx == (len(ndf['text'])-1):\n",
        "                check_complete = True\n",
        "\n",
        "len(cdc_idx_dict), ref_data.shape[0]"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(4, 1332)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 364
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "outputId": "db225b57-5e73-4db1-8f9b-ceddad04279e",
        "id": "zq5H0w47-BSs",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "cdc_idx_dict"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{4: 'they appear to be more stable',\n",
              " 22: 'there are direct economic consequences of losing diversity in certain ecosystems and in the world as a whole',\n",
              " 23: 'Losing species means losing potential foods',\n",
              " 70: 'diverse ecosystems actually resist invasion and disease better than their less diverse equivalents'}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 365
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "rL4otMdf-BSt",
        "colab": {}
      },
      "source": [
        "cdc = []\n",
        "\n",
        "for x in range(len(ndf)):\n",
        "    if x in list(cdc_idx_dict.keys()):\n",
        "        cdc.append(cdc_idx_dict.get(x))\n",
        "    else:\n",
        "        cdc.append('---')\n",
        "ndf['cdc'] = cdc\n",
        "\n",
        "df = pd.concat([ndf, df], axis=0, ignore_index=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "ciTqG53_-BSu"
      },
      "source": [
        "#### Article 11 "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "Nxgzo3H1-BSu",
        "colab": {}
      },
      "source": [
        "with open(articles_dict[articles[11].replace(' ','_')+'.txt']) as article:\n",
        "        doc = article.read()\n",
        "\n",
        "c_doc = text_cleaner(doc)\n",
        "sentences = nltk.sent_tokenize(c_doc)\n",
        "sentences = [[sent, topic, articles[11]] for sent in sentences]\n",
        "\n",
        "ndf = pd.DataFrame(sentences, columns=['text', 'topic', 'article'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "outputId": "37c5517b-d9bb-4d92-8529-44632fd9d102",
        "id": "uLWzYfbh-BSx",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "cdc_idx_dict = {}\n",
        "cdc_idx_sent = {}\n",
        "cdc_idx_art = {}\n",
        "\n",
        "for i,claim in enumerate(ref_data['clean_Claim']):\n",
        "    check_complete = False\n",
        "    while check_complete == False:\n",
        "        for idx,sentence in enumerate(ndf['text']):\n",
        "            test = claim.lower() in sentence.lower()\n",
        "            if test:\n",
        "                article = ref_data['Article'][i]\n",
        "                cdc_idx_dict[idx] = claim\n",
        "                cdc_idx_sent[idx] = [claim, sentence]\n",
        "                cdc_idx_art[idx] = [claim, article]\n",
        "                check_complete = True\n",
        "            elif idx == (len(ndf['text'])-1):\n",
        "                check_complete = True\n",
        "\n",
        "len(cdc_idx_dict), ref_data.shape[0]"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(4, 1332)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 368
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "outputId": "09558cdf-5890-4be8-9031-ab9e995ffca8",
        "id": "2nHnTRt1-BSy",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "cdc_idx_dict"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{1: 'biodiversity is inherently valuable',\n",
              " 2: 'Diverse ecosystems are typically more productive than non-diverse ones',\n",
              " 3: \"human economic productivity is largely reliant on Earth's ecosystems\",\n",
              " 44: 'Biodiversity is a source of economic wealth'}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 369
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "cykAdZMw-BS-",
        "colab": {}
      },
      "source": [
        "cdc = []\n",
        "\n",
        "for x in range(len(ndf)):\n",
        "    if x in list(cdc_idx_dict.keys()):\n",
        "        cdc.append(cdc_idx_dict.get(x))\n",
        "    else:\n",
        "        cdc.append('---')\n",
        "ndf['cdc'] = cdc\n",
        "\n",
        "df = pd.concat([ndf, df], axis=0, ignore_index=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "TRq7paWg-BS_"
      },
      "source": [
        "#### Article 12"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "gxQy1QR6-BS_",
        "colab": {}
      },
      "source": [
        "with open(articles_dict[articles[12].replace(' ','_')+'.txt']) as article:\n",
        "        doc = article.read()\n",
        "\n",
        "c_doc = text_cleaner(doc)\n",
        "sentences = nltk.sent_tokenize(c_doc)\n",
        "sentences = [[sent, topic, articles[12]] for sent in sentences]\n",
        "\n",
        "ndf = pd.DataFrame(sentences, columns=['text', 'topic', 'article'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "outputId": "a2713948-c99a-422f-ab8a-75ec53d67829",
        "id": "KwsS3_oV-BTA",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "cdc_idx_dict = {}\n",
        "cdc_idx_sent = {}\n",
        "cdc_idx_art = {}\n",
        "\n",
        "for i,claim in enumerate(ref_data['clean_Claim']):\n",
        "    check_complete = False\n",
        "    while check_complete == False:\n",
        "        for idx,sentence in enumerate(ndf['text']):\n",
        "            test = claim.lower() in sentence.lower()\n",
        "            if test:\n",
        "                article = ref_data['Article'][i]\n",
        "                cdc_idx_dict[idx] = claim\n",
        "                cdc_idx_sent[idx] = [claim, sentence]\n",
        "                cdc_idx_art[idx] = [claim, article]\n",
        "                check_complete = True\n",
        "            elif idx == (len(ndf['text'])-1):\n",
        "                check_complete = True\n",
        "\n",
        "len(cdc_idx_dict), ref_data.shape[0]"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(3, 1332)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 372
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "outputId": "8ba28a79-51db-43e3-ac12-1b3e9e291220",
        "id": "JTFrPGs8-BTC",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "cdc_idx_dict"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{12: 'is an integral part of the development process',\n",
              " 21: 'there is a threat of significant reduction or loss of biological diversity',\n",
              " 23: 'conservation will bring us significant environmental, economic and social benefits in return'}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 373
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "sTSOS7_4-BTE",
        "colab": {}
      },
      "source": [
        "cdc = []\n",
        "\n",
        "for x in range(len(ndf)):\n",
        "    if x in list(cdc_idx_dict.keys()):\n",
        "        cdc.append(cdc_idx_dict.get(x))\n",
        "    else:\n",
        "        cdc.append('---')\n",
        "ndf['cdc'] = cdc\n",
        "\n",
        "df = pd.concat([ndf, df], axis=0, ignore_index=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CL6k7PP9yWZJ",
        "colab_type": "text"
      },
      "source": [
        "### 'gambling '"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "outputId": "ce1c2296-b377-4c8b-fda0-964ff8197a6c",
        "id": "XKPraPef1QWx",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "topic = 'gambling '\n",
        "\n",
        "articles = topic_article_dict[topic]\n",
        "articles"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['Problem gambling',\n",
              " 'Charity gambling',\n",
              " 'Gambling',\n",
              " 'Gambling in the United States',\n",
              " 'Lottery',\n",
              " 'Economics of gambling',\n",
              " 'Southern District of New York action against online poker players',\n",
              " 'Gamblers Anonymous',\n",
              " 'Unlawful Internet Gambling Enforcement Act of 2006',\n",
              " 'Online gambling',\n",
              " 'Casino']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 375
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oqaj1sxL1QE5",
        "colab_type": "code",
        "outputId": "91171852-5fa8-45ae-afd6-86a260cf360c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "len(articles)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "11"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 376
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "bEfQ3OOu1QWz"
      },
      "source": [
        "#### Article 0 "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "Z0JyHfh41QWz",
        "colab": {}
      },
      "source": [
        "with open(articles_dict[articles[0].replace(' ','_')+'.txt']) as article:\n",
        "        doc = article.read()\n",
        "\n",
        "c_doc = text_cleaner(doc)\n",
        "sentences = nltk.sent_tokenize(c_doc)\n",
        "sentences = [[sent, topic, articles[0]] for sent in sentences]\n",
        "\n",
        "ndf = pd.DataFrame(sentences, columns=['text', 'topic', 'article'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "outputId": "630e91f2-e167-49f5-f97e-b2fb73064026",
        "id": "lBmTAQhy1QW0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "cdc_idx_dict = {}\n",
        "cdc_idx_sent = {}\n",
        "cdc_idx_art = {}\n",
        "\n",
        "for i,claim in enumerate(ref_data['clean_Claim']):\n",
        "    check_complete = False\n",
        "    while check_complete == False:\n",
        "        for idx,sentence in enumerate(ndf['text']):\n",
        "            test = claim.lower() in sentence.lower()\n",
        "            if test:\n",
        "                article = ref_data['Article'][i]\n",
        "                cdc_idx_dict[idx] = claim\n",
        "                cdc_idx_sent[idx] = [claim, sentence]\n",
        "                cdc_idx_art[idx] = [claim, article]\n",
        "                check_complete = True\n",
        "            elif idx == (len(ndf['text'])-1):\n",
        "                check_complete = True\n",
        "\n",
        "len(cdc_idx_dict), ref_data.shape[0]"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(10, 1332)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 378
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "outputId": "90f36762-96c8-475e-9a34-ea7feb941841",
        "id": "gG8sCqPG1QW1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "cdc_idx_dict"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{3: 'Pathological gambling is a common disorder that is associated with social costs',\n",
              " 7: 'leads to adverse consequences for the gambler, others, or for the community',\n",
              " 35: 'pathological gambling is an addiction similar to chemical addiction',\n",
              " 46: 'Problem gamblers have the erroneous belief that if they keep playing, they will eventually win',\n",
              " 60: 'Pathological gambling is similar to many other impulse control disorders',\n",
              " 63: 'As debts build up people turn to other sources of money such as theft',\n",
              " 67: 'Compulsive gambling is often very detrimental to personal relationships',\n",
              " 70: 'Abuse is also common in homes where pathological gambling is present',\n",
              " 73: 'Problem gambling is often associated with increased suicidal ideation',\n",
              " 74: 'problem gambling increases the lifetime risk of suicide'}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 379
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "u_SpgZ3A1QW2",
        "colab": {}
      },
      "source": [
        "cdc = []\n",
        "\n",
        "for x in range(len(ndf)):\n",
        "    if x in list(cdc_idx_dict.keys()):\n",
        "        cdc.append(cdc_idx_dict.get(x))\n",
        "    else:\n",
        "        cdc.append('---')\n",
        "ndf['cdc'] = cdc\n",
        "\n",
        "df = pd.concat([ndf, df], axis=0, ignore_index=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "GRS6AxzN1QW2"
      },
      "source": [
        "#### Article 1 "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "U3JrNRiP1QW4",
        "colab": {}
      },
      "source": [
        "with open(articles_dict[articles[1].replace(' ','_')+'.txt']) as article:\n",
        "        doc = article.read()\n",
        "\n",
        "c_doc = text_cleaner(doc)\n",
        "sentences = nltk.sent_tokenize(c_doc)\n",
        "sentences = [[sent, topic, articles[1]] for sent in sentences]\n",
        "\n",
        "ndf = pd.DataFrame(sentences, columns=['text', 'topic', 'article'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "outputId": "f1837383-d3bc-4ef2-8773-6f3c69e470fd",
        "id": "6zBIwJLW1QW5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "cdc_idx_dict = {}\n",
        "cdc_idx_sent = {}\n",
        "cdc_idx_art = {}\n",
        "\n",
        "for i,claim in enumerate(ref_data['clean_Claim']):\n",
        "    check_complete = False\n",
        "    while check_complete == False:\n",
        "        for idx,sentence in enumerate(ndf['text']):\n",
        "            test = claim.lower() in sentence.lower()\n",
        "            if test:\n",
        "                article = ref_data['Article'][i]\n",
        "                cdc_idx_dict[idx] = claim\n",
        "                cdc_idx_sent[idx] = [claim, sentence]\n",
        "                cdc_idx_art[idx] = [claim, article]\n",
        "                check_complete = True\n",
        "            elif idx == (len(ndf['text'])-1):\n",
        "                check_complete = True\n",
        "\n",
        "len(cdc_idx_dict), ref_data.shape[0]"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(1, 1332)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 382
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "outputId": "413fe5c0-df51-4bae-9c63-5c2ad6614ffb",
        "id": "BDzpqZ811QW6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "cdc_idx_dict"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{2: 'profits from the venture go to the charity or group of charities, rather than to a municipality or private casino'}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 383
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "O3P_OUyv1QW8",
        "colab": {}
      },
      "source": [
        "cdc = []\n",
        "\n",
        "for x in range(len(ndf)):\n",
        "    if x in list(cdc_idx_dict.keys()):\n",
        "        cdc.append(cdc_idx_dict.get(x))\n",
        "    else:\n",
        "        cdc.append('---')\n",
        "ndf['cdc'] = cdc\n",
        "\n",
        "df = pd.concat([df, ndf], axis=0, ignore_index=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "ruN-7eBS1QW9"
      },
      "source": [
        "#### Article 2 "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "1gbGLAFh1QW9",
        "colab": {}
      },
      "source": [
        "with open(articles_dict[articles[2].replace(' ','_')+'.txt']) as article:\n",
        "        doc = article.read()\n",
        "\n",
        "c_doc = text_cleaner(doc)\n",
        "sentences = nltk.sent_tokenize(c_doc)\n",
        "sentences = [[sent, topic, articles[2]] for sent in sentences]\n",
        "\n",
        "ndf = pd.DataFrame(sentences, columns=['text', 'topic', 'article'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "outputId": "53144f01-bbe9-43fa-fe76-d50311beabae",
        "id": "gNXsMMtE1QW-",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "cdc_idx_dict = {}\n",
        "cdc_idx_sent = {}\n",
        "cdc_idx_art = {}\n",
        "\n",
        "for i,claim in enumerate(ref_data['clean_Claim']):\n",
        "    check_complete = False\n",
        "    while check_complete == False:\n",
        "        for idx,sentence in enumerate(ndf['text']):\n",
        "            test = claim.lower() in sentence.lower()\n",
        "            if test:\n",
        "                article = ref_data['Article'][i]\n",
        "                cdc_idx_dict[idx] = claim\n",
        "                cdc_idx_sent[idx] = [claim, sentence]\n",
        "                cdc_idx_art[idx] = [claim, article]\n",
        "                check_complete = True\n",
        "            elif idx == (len(ndf['text'])-1):\n",
        "                check_complete = True\n",
        "\n",
        "len(cdc_idx_dict), ref_data.shape[0]"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(11, 1332)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 386
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "outputId": "a1d77afc-483c-4eff-8193-b2bc67ffdc18",
        "id": "079YLP6_1QW_",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "cdc_idx_dict"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{7: 'Gambling is also a major international commercial activity',\n",
              " 10: 'religious authorities generally disapprove of gambling',\n",
              " 12: 'there is no moral impediment to gambling',\n",
              " 13: 'most legal jurisdictions limit gambling',\n",
              " 19: 'Many jurisdictions, local as well as national, either ban gambling or heavily control it by licensing',\n",
              " 20: 'regulation generally leads to gambling tourism and illegal gambling',\n",
              " 21: 'legal gambling provides significant government revenue',\n",
              " 33: 'high-payoffs have very low probability, a house bias can quite easily be missed',\n",
              " 46: 'Betting on team sports has become an important service industry in many countries',\n",
              " 79: 'gambling, like any behavior which involves variation in brain chemistry, can become a psychologically addictive and harmful behavior',\n",
              " 80: 'gamblers persist in gambling even after repeated losses'}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 387
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "LM6mo0GV1QXA",
        "colab": {}
      },
      "source": [
        "cdc = []\n",
        "\n",
        "for x in range(len(ndf)):\n",
        "    if x in list(cdc_idx_dict.keys()):\n",
        "        cdc.append(cdc_idx_dict.get(x))\n",
        "    else:\n",
        "        cdc.append('---')\n",
        "ndf['cdc'] = cdc\n",
        "\n",
        "df = pd.concat([ndf, df], axis=0, ignore_index=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "W5RFmB2u1QXB"
      },
      "source": [
        "#### Article 3 "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "kIT_zvyg1QXC",
        "colab": {}
      },
      "source": [
        "with open(articles_dict[articles[3].replace(' ','_')+'.txt']) as article:\n",
        "        doc = article.read()\n",
        "\n",
        "c_doc = text_cleaner(doc)\n",
        "sentences = nltk.sent_tokenize(c_doc)\n",
        "sentences = [[sent, topic, articles[3]] for sent in sentences]\n",
        "\n",
        "ndf = pd.DataFrame(sentences, columns=['text', 'topic', 'article'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "outputId": "1cea20ef-37f1-48e4-dc2e-3c04b6520401",
        "id": "wbIGbLze1QXD",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "cdc_idx_dict = {}\n",
        "cdc_idx_sent = {}\n",
        "cdc_idx_art = {}\n",
        "\n",
        "for i,claim in enumerate(ref_data['clean_Claim']):\n",
        "    check_complete = False\n",
        "    while check_complete == False:\n",
        "        for idx,sentence in enumerate(ndf['text']):\n",
        "            test = claim.lower() in sentence.lower()\n",
        "            if test:\n",
        "                article = ref_data['Article'][i]\n",
        "                cdc_idx_dict[idx] = claim\n",
        "                cdc_idx_sent[idx] = [claim, sentence]\n",
        "                cdc_idx_art[idx] = [claim, article]\n",
        "                check_complete = True\n",
        "            elif idx == (len(ndf['text'])-1):\n",
        "                check_complete = True\n",
        "\n",
        "len(cdc_idx_dict), ref_data.shape[0]"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(4, 1332)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 390
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "outputId": "31482690-40cd-4b18-881f-e0dfe615077a",
        "id": "4Fi_xPWc1QXE",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "cdc_idx_dict"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{3: 'it leads to increased political corruption, compulsive gambling and higher crime rates',\n",
              " 4: 'gambling is a type of regressive tax on the individuals',\n",
              " 25: \"nearly all the western states' governments outlawed gambling\",\n",
              " 50: 'the majority of the states run some type of lottery to raise funds for state operations'}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 391
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "TrZo4zLf1QXF",
        "colab": {}
      },
      "source": [
        "cdc = []\n",
        "\n",
        "for x in range(len(ndf)):\n",
        "    if x in list(cdc_idx_dict.keys()):\n",
        "        cdc.append(cdc_idx_dict.get(x))\n",
        "    else:\n",
        "        cdc.append('---')\n",
        "ndf['cdc'] = cdc\n",
        "\n",
        "df = pd.concat([ndf, df], axis=0, ignore_index=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "LlKfC7f_1QXG"
      },
      "source": [
        "#### Article 4 "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "3BP-lrA81QXG",
        "colab": {}
      },
      "source": [
        "with open(articles_dict[articles[4].replace(' ','_')+'.txt']) as article:\n",
        "        doc = article.read()\n",
        "\n",
        "c_doc = text_cleaner(doc)\n",
        "sentences = nltk.sent_tokenize(c_doc)\n",
        "sentences = [[sent, topic, articles[4]] for sent in sentences]\n",
        "\n",
        "ndf = pd.DataFrame(sentences, columns=['text', 'topic', 'article'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "outputId": "9380185f-5c93-4f4e-9f08-5a93c06f5421",
        "id": "myxaEdPB1QXH",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "cdc_idx_dict = {}\n",
        "cdc_idx_sent = {}\n",
        "cdc_idx_art = {}\n",
        "\n",
        "for i,claim in enumerate(ref_data['clean_Claim']):\n",
        "    check_complete = False\n",
        "    while check_complete == False:\n",
        "        for idx,sentence in enumerate(ndf['text']):\n",
        "            test = claim.lower() in sentence.lower()\n",
        "            if test:\n",
        "                article = ref_data['Article'][i]\n",
        "                cdc_idx_dict[idx] = claim\n",
        "                cdc_idx_sent[idx] = [claim, sentence]\n",
        "                cdc_idx_art[idx] = [claim, article]\n",
        "                check_complete = True\n",
        "            elif idx == (len(ndf['text'])-1):\n",
        "                check_complete = True\n",
        "\n",
        "len(cdc_idx_dict), ref_data.shape[0]"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(6, 1332)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 394
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "outputId": "e17a7fd2-3027-44a5-edce-b97970221c7d",
        "id": "fX_fOyN71QXI",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "cdc_idx_dict"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{37: 'The lotteries proved very popular and were hailed as a painless form of taxation',\n",
              " 128: 'There can be some problems associated with winning a lottery jackpot',\n",
              " 130: 'Winners sometimes feel anomie from the dramatic change of lifestyles',\n",
              " 131: 'lotteries facilitate a higher degree of inequality than a society should have',\n",
              " 136: 'any social system that allocates resources based on chance is one that is corrupt',\n",
              " 137: 'any form of gambling, is susceptible to fraud'}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 395
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "A181k7Bk1QXI",
        "colab": {}
      },
      "source": [
        "cdc = []\n",
        "\n",
        "for x in range(len(ndf)):\n",
        "    if x in list(cdc_idx_dict.keys()):\n",
        "        cdc.append(cdc_idx_dict.get(x))\n",
        "    else:\n",
        "        cdc.append('---')\n",
        "ndf['cdc'] = cdc\n",
        "\n",
        "df = pd.concat([ndf, df], axis=0, ignore_index=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "ZqyGuQTo-G-h"
      },
      "source": [
        "#### Article 5 "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "XaN6iPZh-G-i",
        "colab": {}
      },
      "source": [
        "with open(articles_dict[articles[5].replace(' ','_')+'.txt']) as article:\n",
        "        doc = article.read()\n",
        "\n",
        "c_doc = text_cleaner(doc)\n",
        "sentences = nltk.sent_tokenize(c_doc)\n",
        "sentences = [[sent, topic, articles[5]] for sent in sentences]\n",
        "\n",
        "ndf = pd.DataFrame(sentences, columns=['text', 'topic', 'article'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "outputId": "a4b1658d-92c1-43aa-e936-564500e1bce4",
        "id": "Yz48lW7S-G-j",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "cdc_idx_dict = {}\n",
        "cdc_idx_sent = {}\n",
        "cdc_idx_art = {}\n",
        "\n",
        "for i,claim in enumerate(ref_data['clean_Claim']):\n",
        "    check_complete = False\n",
        "    while check_complete == False:\n",
        "        for idx,sentence in enumerate(ndf['text']):\n",
        "            test = claim.lower() in sentence.lower()\n",
        "            if test:\n",
        "                article = ref_data['Article'][i]\n",
        "                cdc_idx_dict[idx] = claim\n",
        "                cdc_idx_sent[idx] = [claim, sentence]\n",
        "                cdc_idx_art[idx] = [claim, article]\n",
        "                check_complete = True\n",
        "            elif idx == (len(ndf['text'])-1):\n",
        "                check_complete = True\n",
        "\n",
        "len(cdc_idx_dict), ref_data.shape[0]"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(9, 1332)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 398
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "outputId": "30086949-690b-4be9-877c-0533e226edf1",
        "id": "NzxKRiwy-G-y",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "cdc_idx_dict"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{5: 'As a result of gambling, some are driven to extreme lengths to cover debt',\n",
              " 7: 'addicted gamblers spend most of their energy following their addiction',\n",
              " 8: 'They cost companies loss of productivity and profit',\n",
              " 9: 'Gamblers themselves may suffer from depression and bankruptcy',\n",
              " 11: 'The social costs to society are varied',\n",
              " 16: 'Gambling provides jobs',\n",
              " 24: 'gambling increases aggregate demand for goods and services in the economy',\n",
              " 26: 'money goes directly towards stimulating the economy',\n",
              " 41: 'it is economically beneficial for a state to allow and support gambling institutions'}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 399
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "_wwu4XPL-G-z",
        "colab": {}
      },
      "source": [
        "cdc = []\n",
        "\n",
        "for x in range(len(ndf)):\n",
        "    if x in list(cdc_idx_dict.keys()):\n",
        "        cdc.append(cdc_idx_dict.get(x))\n",
        "    else:\n",
        "        cdc.append('---')\n",
        "ndf['cdc'] = cdc\n",
        "\n",
        "df = pd.concat([ndf, df], axis=0, ignore_index=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "wboyXxUq-G-0"
      },
      "source": [
        "#### Article 6"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "kyAmfZyt-G-0",
        "colab": {}
      },
      "source": [
        "with open(articles_dict[articles[6].replace(' ','_')+'.txt']) as article:\n",
        "        doc = article.read()\n",
        "\n",
        "c_doc = text_cleaner(doc)\n",
        "sentences = nltk.sent_tokenize(c_doc)\n",
        "sentences = [[sent, topic, articles[6]] for sent in sentences]\n",
        "\n",
        "ndf = pd.DataFrame(sentences, columns=['text', 'topic', 'article'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "outputId": "99c64c3a-39bc-4e6d-8dcf-0b76b4bee369",
        "id": "Yb7sMGtS-G-1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "cdc_idx_dict = {}\n",
        "cdc_idx_sent = {}\n",
        "cdc_idx_art = {}\n",
        "\n",
        "for i,claim in enumerate(ref_data['clean_Claim']):\n",
        "    check_complete = False\n",
        "    while check_complete == False:\n",
        "        for idx,sentence in enumerate(ndf['text']):\n",
        "            test = claim.lower() in sentence.lower()\n",
        "            if test:\n",
        "                article = ref_data['Article'][i]\n",
        "                cdc_idx_dict[idx] = claim\n",
        "                cdc_idx_sent[idx] = [claim, sentence]\n",
        "                cdc_idx_art[idx] = [claim, article]\n",
        "                check_complete = True\n",
        "            elif idx == (len(ndf['text'])-1):\n",
        "                check_complete = True\n",
        "\n",
        "len(cdc_idx_dict), ref_data.shape[0]"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(1, 1332)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 402
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "outputId": "fff556fc-285d-4c0e-84ad-a0087c5903d0",
        "id": "iJa4tYnh-G-2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "cdc_idx_dict"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{28: 'internet gambling as a legitimate activity that citizens have the right to engage in'}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 403
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "sjNKCz0C-G-3",
        "colab": {}
      },
      "source": [
        "cdc = []\n",
        "\n",
        "for x in range(len(ndf)):\n",
        "    if x in list(cdc_idx_dict.keys()):\n",
        "        cdc.append(cdc_idx_dict.get(x))\n",
        "    else:\n",
        "        cdc.append('---')\n",
        "ndf['cdc'] = cdc\n",
        "\n",
        "df = pd.concat([ndf, df], axis=0, ignore_index=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "nmblLOiU-G-5"
      },
      "source": [
        "#### Article 7"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "fABeVZL2-G-5",
        "colab": {}
      },
      "source": [
        "with open(articles_dict[articles[7].replace(' ','_')+'.txt']) as article:\n",
        "        doc = article.read()\n",
        "\n",
        "c_doc = text_cleaner(doc)\n",
        "sentences = nltk.sent_tokenize(c_doc)\n",
        "sentences = [[sent, topic, articles[7]] for sent in sentences]\n",
        "\n",
        "ndf = pd.DataFrame(sentences, columns=['text', 'topic', 'article'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "outputId": "0f1622e0-fe83-41a8-a34b-7de3cda26dc6",
        "id": "G7OCInVd-G-6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "cdc_idx_dict = {}\n",
        "cdc_idx_sent = {}\n",
        "cdc_idx_art = {}\n",
        "\n",
        "for i,claim in enumerate(ref_data['clean_Claim']):\n",
        "    check_complete = False\n",
        "    while check_complete == False:\n",
        "        for idx,sentence in enumerate(ndf['text']):\n",
        "            test = claim.lower() in sentence.lower()\n",
        "            if test:\n",
        "                article = ref_data['Article'][i]\n",
        "                cdc_idx_dict[idx] = claim\n",
        "                cdc_idx_sent[idx] = [claim, sentence]\n",
        "                cdc_idx_art[idx] = [claim, article]\n",
        "                check_complete = True\n",
        "            elif idx == (len(ndf['text'])-1):\n",
        "                check_complete = True\n",
        "\n",
        "len(cdc_idx_dict), ref_data.shape[0]"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(1, 1332)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 406
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "outputId": "0d4ad233-e1ac-4fad-c0e9-13e2debf1e14",
        "id": "s0pIsU6i-G-7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "cdc_idx_dict"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{4: 'problem gambling has been shown to cause dysfunctional families'}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 407
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "x6KPnSEn-G-9",
        "colab": {}
      },
      "source": [
        "cdc = []\n",
        "\n",
        "for x in range(len(ndf)):\n",
        "    if x in list(cdc_idx_dict.keys()):\n",
        "        cdc.append(cdc_idx_dict.get(x))\n",
        "    else:\n",
        "        cdc.append('---')\n",
        "ndf['cdc'] = cdc\n",
        "\n",
        "df = pd.concat([ndf, df], axis=0, ignore_index=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "oayTA2QC-G-_"
      },
      "source": [
        "#### Article 8"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "JREVvYsX-G_A",
        "colab": {}
      },
      "source": [
        "with open(articles_dict[articles[8].replace(' ','_')+'.txt']) as article:\n",
        "        doc = article.read()\n",
        "\n",
        "c_doc = text_cleaner(doc)\n",
        "sentences = nltk.sent_tokenize(c_doc)\n",
        "sentences = [[sent, topic, articles[8]] for sent in sentences]\n",
        "\n",
        "ndf = pd.DataFrame(sentences, columns=['text', 'topic', 'article'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "outputId": "2987dc21-9c86-49f5-8036-07b8b223ddbb",
        "id": "J_mUucJg-G_B",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "cdc_idx_dict = {}\n",
        "cdc_idx_sent = {}\n",
        "cdc_idx_art = {}\n",
        "\n",
        "for i,claim in enumerate(ref_data['clean_Claim']):\n",
        "    check_complete = False\n",
        "    while check_complete == False:\n",
        "        for idx,sentence in enumerate(ndf['text']):\n",
        "            test = claim.lower() in sentence.lower()\n",
        "            if test:\n",
        "                article = ref_data['Article'][i]\n",
        "                cdc_idx_dict[idx] = claim\n",
        "                cdc_idx_sent[idx] = [claim, sentence]\n",
        "                cdc_idx_art[idx] = [claim, article]\n",
        "                check_complete = True\n",
        "            elif idx == (len(ndf['text'])-1):\n",
        "                check_complete = True\n",
        "\n",
        "len(cdc_idx_dict), ref_data.shape[0]"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(2, 1332)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 410
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "outputId": "76d7affd-5ecd-4ee5-8c79-83ea5ece8562",
        "id": "OoofcGjp-G_F",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "cdc_idx_dict"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{36: 'Internet gambling is a growing problem for banks and credit card companies',\n",
              " 86: 'regulation of online gambling is a better alternative'}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 411
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "-fmJLtC1-G_G",
        "colab": {}
      },
      "source": [
        "cdc = []\n",
        "\n",
        "for x in range(len(ndf)):\n",
        "    if x in list(cdc_idx_dict.keys()):\n",
        "        cdc.append(cdc_idx_dict.get(x))\n",
        "    else:\n",
        "        cdc.append('---')\n",
        "ndf['cdc'] = cdc\n",
        "\n",
        "df = pd.concat([ndf, df], axis=0, ignore_index=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "nSM3Vae2-G_I"
      },
      "source": [
        "#### Article 9"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "wM82wsCx-G_I",
        "colab": {}
      },
      "source": [
        "with open(articles_dict[articles[9].replace(' ','_')+'.txt']) as article:\n",
        "        doc = article.read()\n",
        "\n",
        "c_doc = text_cleaner(doc)\n",
        "sentences = nltk.sent_tokenize(c_doc)\n",
        "sentences = [[sent, topic, articles[9]] for sent in sentences]\n",
        "\n",
        "ndf = pd.DataFrame(sentences, columns=['text', 'topic', 'article'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "outputId": "0c2f3d87-b8cc-4589-8fe0-ae9378dea3e2",
        "id": "2WcmjV8B-G_J",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "cdc_idx_dict = {}\n",
        "cdc_idx_sent = {}\n",
        "cdc_idx_art = {}\n",
        "\n",
        "for i,claim in enumerate(ref_data['clean_Claim']):\n",
        "    check_complete = False\n",
        "    while check_complete == False:\n",
        "        for idx,sentence in enumerate(ndf['text']):\n",
        "            test = claim.lower() in sentence.lower()\n",
        "            if test:\n",
        "                article = ref_data['Article'][i]\n",
        "                cdc_idx_dict[idx] = claim\n",
        "                cdc_idx_sent[idx] = [claim, sentence]\n",
        "                cdc_idx_art[idx] = [claim, article]\n",
        "                check_complete = True\n",
        "            elif idx == (len(ndf['text'])-1):\n",
        "                check_complete = True\n",
        "\n",
        "len(cdc_idx_dict), ref_data.shape[0]"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(5, 1332)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 414
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "outputId": "f193ee0b-09d4-46e1-d031-60b9459a5c2b",
        "id": "nPVgnNpC-G_K",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "cdc_idx_dict"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{20: 'Internet gambling has become one of the most popular and lucrative business present on the Internet',\n",
              " 132: 'a popular leisure activity enjoyed in many forms by millions of people',\n",
              " 147: 'Various forms of online gambling are legal and regulated in many countries',\n",
              " 161: 'the high-speed instant gratification of Internet games and the high level of privacy they offer may exacerbate problem and pathological gambling',\n",
              " 168: 'electronic funds transfers inherent in online gambling are being exploited by criminal interests'}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 415
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "KV4zZ077-G_L",
        "colab": {}
      },
      "source": [
        "cdc = []\n",
        "\n",
        "for x in range(len(ndf)):\n",
        "    if x in list(cdc_idx_dict.keys()):\n",
        "        cdc.append(cdc_idx_dict.get(x))\n",
        "    else:\n",
        "        cdc.append('---')\n",
        "ndf['cdc'] = cdc\n",
        "\n",
        "df = pd.concat([ndf, df], axis=0, ignore_index=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "6NlibAUM-G_M"
      },
      "source": [
        "#### Article 10"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "8dClQqa5-G_M",
        "colab": {}
      },
      "source": [
        "with open(articles_dict[articles[10].replace(' ','_')+'.txt']) as article:\n",
        "        doc = article.read()\n",
        "\n",
        "c_doc = text_cleaner(doc)\n",
        "sentences = nltk.sent_tokenize(c_doc)\n",
        "sentences = [[sent, topic, articles[10]] for sent in sentences]\n",
        "\n",
        "ndf = pd.DataFrame(sentences, columns=['text', 'topic', 'article'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "outputId": "86901341-9357-46d2-96a6-c82478813d9e",
        "id": "vLzQJ59z-G_N",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "cdc_idx_dict = {}\n",
        "cdc_idx_sent = {}\n",
        "cdc_idx_art = {}\n",
        "\n",
        "for i,claim in enumerate(ref_data['clean_Claim']):\n",
        "    check_complete = False\n",
        "    while check_complete == False:\n",
        "        for idx,sentence in enumerate(ndf['text']):\n",
        "            test = claim.lower() in sentence.lower()\n",
        "            if test:\n",
        "                article = ref_data['Article'][i]\n",
        "                cdc_idx_dict[idx] = claim\n",
        "                cdc_idx_sent[idx] = [claim, sentence]\n",
        "                cdc_idx_art[idx] = [claim, article]\n",
        "                check_complete = True\n",
        "            elif idx == (len(ndf['text'])-1):\n",
        "                check_complete = True\n",
        "\n",
        "len(cdc_idx_dict), ref_data.shape[0]"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(7, 1332)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 418
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "outputId": "39b1094f-2732-453d-c025-afec37e03f55",
        "id": "MlaTPjGs-G_O",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "cdc_idx_dict"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{3: 'the social and economic consequences of casino gambling outweigh the initial revenue that may be generated',\n",
              " 22: 'gambling in some form or another has been seen in almost every society in history',\n",
              " 35: 'Most games played have mathematically-determined odds that ensure the house has at all times an advantage over the players',\n",
              " 43: 'the modern day slot machine is addictive',\n",
              " 97: 'Given the large amounts of currency handled within a casino, both patrons and staff may be tempted to cheat and steal',\n",
              " 108: 'One area of controversy surrounding casinos is their relationship to crime rates',\n",
              " 109: 'a positive relationship between casinos and crime'}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 419
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "jjQRQMfR-G_Q",
        "colab": {}
      },
      "source": [
        "cdc = []\n",
        "\n",
        "for x in range(len(ndf)):\n",
        "    if x in list(cdc_idx_dict.keys()):\n",
        "        cdc.append(cdc_idx_dict.get(x))\n",
        "    else:\n",
        "        cdc.append('---')\n",
        "ndf['cdc'] = cdc\n",
        "\n",
        "df = pd.concat([ndf, df], axis=0, ignore_index=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a2SKfO3sybWG",
        "colab_type": "text"
      },
      "source": [
        "### 'housewives should be paid for their work '"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "63NZNGWr1Rh7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "outputId": "da476c1a-73ec-487c-de15-5393e6c44bfd",
        "id": "bcOWkNH_1R97",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "topic = 'housewives should be paid for their work '\n",
        "articles = topic_article_dict[topic]\n",
        "articles"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['Care work', 'Feminist economics']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 421
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "NMU4iOcC1R98"
      },
      "source": [
        "#### Article 0 "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "UNckA3Rq1R99",
        "colab": {}
      },
      "source": [
        "with open(articles_dict[articles[0].replace(' ','_')+'.txt']) as article:\n",
        "        doc = article.read()\n",
        "\n",
        "c_doc = text_cleaner(doc)\n",
        "sentences = nltk.sent_tokenize(c_doc)\n",
        "sentences = [[sent, topic, articles[0]] for sent in sentences]\n",
        "\n",
        "ndf = pd.DataFrame(sentences, columns=['text', 'topic', 'article'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "outputId": "91eb1c34-ecd4-4196-de8b-80acbb18e3e8",
        "id": "uhIVMgg31R99",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "cdc_idx_dict = {}\n",
        "cdc_idx_sent = {}\n",
        "cdc_idx_art = {}\n",
        "\n",
        "for i,claim in enumerate(ref_data['clean_Claim']):\n",
        "    check_complete = False\n",
        "    while check_complete == False:\n",
        "        for idx,sentence in enumerate(ndf['text']):\n",
        "            test = claim.lower() in sentence.lower()\n",
        "            if test:\n",
        "                article = ref_data['Article'][i]\n",
        "                cdc_idx_dict[idx] = claim\n",
        "                cdc_idx_sent[idx] = [claim, sentence]\n",
        "                cdc_idx_art[idx] = [claim, article]\n",
        "                check_complete = True\n",
        "            elif idx == (len(ndf['text'])-1):\n",
        "                check_complete = True\n",
        "\n",
        "len(cdc_idx_dict), ref_data.shape[0]"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(9, 1332)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 423
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "outputId": "2cd3189d-0fda-4634-8cce-295bfcef95fe",
        "id": "KI-lbvVb1R9_",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "cdc_idx_dict"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{12: 'Care work is essential to human well-being',\n",
              " 16: 'care work is directly related to the health of a society as well as to the economic development of that society',\n",
              " 30: 'the household sector is a wealth spender, and not a wealth creator',\n",
              " 31: 'the household sector plays a very important role in wealth creation',\n",
              " 42: \"women's jobs in the home were not part of any market\",\n",
              " 102: 'the household does not form wealth',\n",
              " 106: 'the quality of care may decrease in response to the call for profit-making and efficiency',\n",
              " 133: 'care work should not be done for pay because pay will undermine the intrinsic motivations for this work',\n",
              " 136: 'care work should be better compensated by the market'}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 424
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "VcEAud4-1R-A",
        "colab": {}
      },
      "source": [
        "cdc = []\n",
        "\n",
        "for x in range(len(ndf)):\n",
        "    if x in list(cdc_idx_dict.keys()):\n",
        "        cdc.append(cdc_idx_dict.get(x))\n",
        "    else:\n",
        "        cdc.append('---')\n",
        "ndf['cdc'] = cdc\n",
        "\n",
        "df = pd.concat([ndf, df], axis=0, ignore_index=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "kkQNePvv1R-B"
      },
      "source": [
        "#### Article 1 "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "OOhXHBEF1R-B",
        "colab": {}
      },
      "source": [
        "with open(articles_dict[articles[1].replace(' ','_')+'.txt']) as article:\n",
        "        doc = article.read()\n",
        "\n",
        "c_doc = text_cleaner(doc)\n",
        "sentences = nltk.sent_tokenize(c_doc)\n",
        "sentences = [[sent, topic, articles[1]] for sent in sentences]\n",
        "\n",
        "ndf = pd.DataFrame(sentences, columns=['text', 'topic', 'article'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "outputId": "1aa708da-6173-4460-ac1d-42e4021b5702",
        "id": "TxAnGCt41R-C",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "cdc_idx_dict = {}\n",
        "cdc_idx_sent = {}\n",
        "cdc_idx_art = {}\n",
        "\n",
        "for i,claim in enumerate(ref_data['clean_Claim']):\n",
        "    check_complete = False\n",
        "    while check_complete == False:\n",
        "        for idx,sentence in enumerate(ndf['text']):\n",
        "            test = claim.lower() in sentence.lower()\n",
        "            if test:\n",
        "                article = ref_data['Article'][i]\n",
        "                cdc_idx_dict[idx] = claim\n",
        "                cdc_idx_sent[idx] = [claim, sentence]\n",
        "                cdc_idx_art[idx] = [claim, article]\n",
        "                check_complete = True\n",
        "            elif idx == (len(ndf['text'])-1):\n",
        "                check_complete = True\n",
        "\n",
        "len(cdc_idx_dict), ref_data.shape[0]"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(3, 1332)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 427
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "outputId": "0886dedd-aadd-402d-c506-116eb17df622",
        "id": "cX1pBkyT1R-D",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "cdc_idx_dict"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{111: 'care work as central to economic development and human well-being',\n",
              " 114: 'unpaid domestic work is just as valuable as paid work',\n",
              " 161: 'domestic labor is work'}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 428
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "fbEnzw6w1R-E",
        "colab": {}
      },
      "source": [
        "cdc = []\n",
        "\n",
        "for x in range(len(ndf)):\n",
        "    if x in list(cdc_idx_dict.keys()):\n",
        "        cdc.append(cdc_idx_dict.get(x))\n",
        "    else:\n",
        "        cdc.append('---')\n",
        "ndf['cdc'] = cdc\n",
        "\n",
        "df = pd.concat([df, ndf], axis=0, ignore_index=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d5V9YdNZyfkH",
        "colab_type": "text"
      },
      "source": [
        "### 'institute a mandatory retirement age '"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6NuOuNmZ1Tc9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "outputId": "468f9017-1502-4cb7-e6c7-a7109ebca574",
        "id": "kU3-LD0S1TwA",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        }
      },
      "source": [
        "topic = 'institute a mandatory retirement age '\n",
        "\n",
        "articles = topic_article_dict[topic]\n",
        "articles"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['Ageing', 'Memory and aging', 'US age discrimination', 'Mandatory retirement']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 430
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "OJkfp-5P1TwB"
      },
      "source": [
        "#### Article 0 "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "tD4ze20U1TwC",
        "colab": {}
      },
      "source": [
        "with open(articles_dict[articles[0].replace(' ','_')+'.txt']) as article:\n",
        "        doc = article.read()\n",
        "\n",
        "c_doc = text_cleaner(doc)\n",
        "sentences = nltk.sent_tokenize(c_doc)\n",
        "sentences = [[sent, topic, articles[0]] for sent in sentences]\n",
        "\n",
        "ndf = pd.DataFrame(sentences, columns=['text', 'topic', 'article'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "outputId": "57ccb2f9-9d50-4074-a839-7869726385be",
        "id": "sHD5DHUz1TwC",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "cdc_idx_dict = {}\n",
        "cdc_idx_sent = {}\n",
        "cdc_idx_art = {}\n",
        "\n",
        "for i,claim in enumerate(ref_data['clean_Claim']):\n",
        "    check_complete = False\n",
        "    while check_complete == False:\n",
        "        for idx,sentence in enumerate(ndf['text']):\n",
        "            test = claim.lower() in sentence.lower()\n",
        "            if test:\n",
        "                article = ref_data['Article'][i]\n",
        "                cdc_idx_dict[idx] = claim\n",
        "                cdc_idx_sent[idx] = [claim, sentence]\n",
        "                cdc_idx_art[idx] = [claim, article]\n",
        "                check_complete = True\n",
        "            elif idx == (len(ndf['text'])-1):\n",
        "                check_complete = True\n",
        "\n",
        "len(cdc_idx_dict), ref_data.shape[0]"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(2, 1332)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 432
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "outputId": "e2b5c95f-f65e-4eb5-8f70-fd072be94baf",
        "id": "rfdLq2_O1TwD",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "cdc_idx_dict"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{224: 'benefits both society and older individuals',\n",
              " 228: 'the more active elderly people are, the more likely they are to be satisfied with life'}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 433
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "-0omXKCd1TwE",
        "colab": {}
      },
      "source": [
        "cdc = []\n",
        "\n",
        "for x in range(len(ndf)):\n",
        "    if x in list(cdc_idx_dict.keys()):\n",
        "        cdc.append(cdc_idx_dict.get(x))\n",
        "    else:\n",
        "        cdc.append('---')\n",
        "ndf['cdc'] = cdc\n",
        "\n",
        "df = pd.concat([ndf, df], axis=0, ignore_index=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "K8ko1I4L1TwF"
      },
      "source": [
        "#### Article 1 "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "V8kF8aR21TwF",
        "colab": {}
      },
      "source": [
        "with open(articles_dict[articles[1].replace(' ','_')+'.txt']) as article:\n",
        "        doc = article.read()\n",
        "\n",
        "c_doc = text_cleaner(doc)\n",
        "sentences = nltk.sent_tokenize(c_doc)\n",
        "sentences = [[sent, topic, articles[1]] for sent in sentences]\n",
        "\n",
        "ndf = pd.DataFrame(sentences, columns=['text', 'topic', 'article'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "outputId": "b15fa264-2360-47b6-8603-1e3fa7fad404",
        "id": "tpAECEHI1TwG",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "cdc_idx_dict = {}\n",
        "cdc_idx_sent = {}\n",
        "cdc_idx_art = {}\n",
        "\n",
        "for i,claim in enumerate(ref_data['clean_Claim']):\n",
        "    check_complete = False\n",
        "    while check_complete == False:\n",
        "        for idx,sentence in enumerate(ndf['text']):\n",
        "            test = claim.lower() in sentence.lower()\n",
        "            if test:\n",
        "                article = ref_data['Article'][i]\n",
        "                cdc_idx_dict[idx] = claim\n",
        "                cdc_idx_sent[idx] = [claim, sentence]\n",
        "                cdc_idx_art[idx] = [claim, article]\n",
        "                check_complete = True\n",
        "            elif idx == (len(ndf['text'])-1):\n",
        "                check_complete = True\n",
        "\n",
        "len(cdc_idx_dict), ref_data.shape[0]"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(1, 1332)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 436
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "outputId": "30dd30b4-db7b-4a35-de8b-6c731381c1e1",
        "id": "ExmkQtZC1TwH",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "cdc_idx_dict"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{14: 'Normal aging is associated with a decline in various memory abilities in many cognitive tasks'}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 437
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "PmfLI7f41TwJ",
        "colab": {}
      },
      "source": [
        "cdc = []\n",
        "\n",
        "for x in range(len(ndf)):\n",
        "    if x in list(cdc_idx_dict.keys()):\n",
        "        cdc.append(cdc_idx_dict.get(x))\n",
        "    else:\n",
        "        cdc.append('---')\n",
        "ndf['cdc'] = cdc\n",
        "\n",
        "df = pd.concat([df, ndf], axis=0, ignore_index=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "LukM-b-g1TwK"
      },
      "source": [
        "#### Article 2 "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "zKiI4vQK1TwK",
        "colab": {}
      },
      "source": [
        "with open(articles_dict[articles[2].replace(' ','_')+'.txt']) as article:\n",
        "        doc = article.read()\n",
        "\n",
        "c_doc = text_cleaner(doc)\n",
        "sentences = nltk.sent_tokenize(c_doc)\n",
        "sentences = [[sent, topic, articles[2]] for sent in sentences]\n",
        "\n",
        "ndf = pd.DataFrame(sentences, columns=['text', 'topic', 'article'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "outputId": "d0c11d07-8d80-4ae8-bdda-5f8d5c643748",
        "id": "ZXW_CaW51TwL",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "cdc_idx_dict = {}\n",
        "cdc_idx_sent = {}\n",
        "cdc_idx_art = {}\n",
        "\n",
        "for i,claim in enumerate(ref_data['clean_Claim']):\n",
        "    check_complete = False\n",
        "    while check_complete == False:\n",
        "        for idx,sentence in enumerate(ndf['text']):\n",
        "            test = claim.lower() in sentence.lower()\n",
        "            if test:\n",
        "                article = ref_data['Article'][i]\n",
        "                cdc_idx_dict[idx] = claim\n",
        "                cdc_idx_sent[idx] = [claim, sentence]\n",
        "                cdc_idx_art[idx] = [claim, article]\n",
        "                check_complete = True\n",
        "            elif idx == (len(ndf['text'])-1):\n",
        "                check_complete = True\n",
        "\n",
        "len(cdc_idx_dict), ref_data.shape[0]"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(3, 1332)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 440
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "outputId": "24884b44-6407-4087-f690-811c1d5e8b4d",
        "id": "0DHEDPQC1TwL",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "cdc_idx_dict"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{7: 'they lack up-to-date skills',\n",
              " 15: 'older people as a group that acts as more of a cost than an asset to the company',\n",
              " 17: 'The older generation workers often require more benefits from the company due to their age'}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 441
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "WXGtQzbu1TwM",
        "colab": {}
      },
      "source": [
        "cdc = []\n",
        "\n",
        "for x in range(len(ndf)):\n",
        "    if x in list(cdc_idx_dict.keys()):\n",
        "        cdc.append(cdc_idx_dict.get(x))\n",
        "    else:\n",
        "        cdc.append('---')\n",
        "ndf['cdc'] = cdc\n",
        "\n",
        "df = pd.concat([ndf, df], axis=0, ignore_index=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "pGjQKnMn1TwN"
      },
      "source": [
        "#### Article 3 "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "549BUONk1TwN",
        "colab": {}
      },
      "source": [
        "with open(articles_dict[articles[3].replace(' ','_')+'.txt']) as article:\n",
        "        doc = article.read()\n",
        "\n",
        "c_doc = text_cleaner(doc)\n",
        "sentences = nltk.sent_tokenize(c_doc)\n",
        "sentences = [[sent, topic, articles[3]] for sent in sentences]\n",
        "\n",
        "ndf = pd.DataFrame(sentences, columns=['text', 'topic', 'article'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "outputId": "b7cc432c-4799-486b-a69f-5377ae5c157e",
        "id": "LTId4HEq1TwO",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "cdc_idx_dict = {}\n",
        "cdc_idx_sent = {}\n",
        "cdc_idx_art = {}\n",
        "\n",
        "for i,claim in enumerate(ref_data['clean_Claim']):\n",
        "    check_complete = False\n",
        "    while check_complete == False:\n",
        "        for idx,sentence in enumerate(ndf['text']):\n",
        "            test = claim.lower() in sentence.lower()\n",
        "            if test:\n",
        "                article = ref_data['Article'][i]\n",
        "                cdc_idx_dict[idx] = claim\n",
        "                cdc_idx_sent[idx] = [claim, sentence]\n",
        "                cdc_idx_art[idx] = [claim, article]\n",
        "                check_complete = True\n",
        "            elif idx == (len(ndf['text'])-1):\n",
        "                check_complete = True\n",
        "\n",
        "len(cdc_idx_dict), ref_data.shape[0]"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(2, 1332)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 444
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "outputId": "849c4e3a-b97b-4e69-995b-7b8feb164fb3",
        "id": "x3Z2u7jb1TwP",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "cdc_idx_dict"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{2: 'the practice as a form of age discrimination, or ageism',\n",
              " 7: 'it is unlawful to discriminate against a person because of hisher age'}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 445
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "QxThdUlc1TwP",
        "colab": {}
      },
      "source": [
        "cdc = []\n",
        "\n",
        "for x in range(len(ndf)):\n",
        "    if x in list(cdc_idx_dict.keys()):\n",
        "        cdc.append(cdc_idx_dict.get(x))\n",
        "    else:\n",
        "        cdc.append('---')\n",
        "ndf['cdc'] = cdc\n",
        "\n",
        "df = pd.concat([ndf, df], axis=0, ignore_index=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3LUPKCa6yjFZ",
        "colab_type": "text"
      },
      "source": [
        "### 'intellectual property rights '"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "outputId": "ce289996-e75f-4b2c-8e1b-aa1bab1d9cbd",
        "id": "2XwNdOwT1Vc_",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 170
        }
      },
      "source": [
        "topic = 'intellectual property rights '\n",
        "\n",
        "articles = topic_article_dict[topic]\n",
        "articles"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['Property',\n",
              " 'Patent',\n",
              " 'Intellectual property',\n",
              " 'Societal views on patents',\n",
              " 'Libertarian perspectives on intellectual property',\n",
              " 'Missionary Church of Kopimism',\n",
              " 'Philosophy of copyright',\n",
              " 'Anti-copyright',\n",
              " 'Copyright']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 447
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "znmGQHgj1VNh",
        "colab_type": "code",
        "outputId": "4409a3f2-4a59-4f81-e31c-857e3b6abb6a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "len(articles)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "9"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 448
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "55g4PnVF1VdB"
      },
      "source": [
        "#### Article 0 "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "kfQbIRQG1VdB",
        "colab": {}
      },
      "source": [
        "with open(articles_dict[articles[0].replace(' ','_')+'.txt']) as article:\n",
        "        doc = article.read()\n",
        "\n",
        "c_doc = text_cleaner(doc)\n",
        "sentences = nltk.sent_tokenize(c_doc)\n",
        "sentences = [[sent, topic, articles[0]] for sent in sentences]\n",
        "\n",
        "ndf = pd.DataFrame(sentences, columns=['text', 'topic', 'article'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "outputId": "0276951d-828a-403d-a748-7bc0105f6d3f",
        "id": "xfiAxVkk1VdC",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "cdc_idx_dict = {}\n",
        "cdc_idx_sent = {}\n",
        "cdc_idx_art = {}\n",
        "\n",
        "for i,claim in enumerate(ref_data['clean_Claim']):\n",
        "    check_complete = False\n",
        "    while check_complete == False:\n",
        "        for idx,sentence in enumerate(ndf['text']):\n",
        "            test = claim.lower() in sentence.lower()\n",
        "            if test:\n",
        "                article = ref_data['Article'][i]\n",
        "                cdc_idx_dict[idx] = claim\n",
        "                cdc_idx_sent[idx] = [claim, sentence]\n",
        "                cdc_idx_art[idx] = [claim, article]\n",
        "                check_complete = True\n",
        "            elif idx == (len(ndf['text'])-1):\n",
        "                check_complete = True\n",
        "\n",
        "len(cdc_idx_dict), ref_data.shape[0]"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(3, 1332)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 450
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "outputId": "52b5ea69-6b69-4345-d703-2048caedd94a",
        "id": "nkPikiRQ1VdD",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "cdc_idx_dict"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{34: 'property rights encourage their holders to develop the property',\n",
              " 53: 'property rights encourage their holders to develop their property or generate wealth',\n",
              " 193: 'interference by the state over the centuries in property ownership has had dire consequences for justice as well as for economic productivity'}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 451
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "SiT8sPZA1VdD",
        "colab": {}
      },
      "source": [
        "cdc = []\n",
        "\n",
        "for x in range(len(ndf)):\n",
        "    if x in list(cdc_idx_dict.keys()):\n",
        "        cdc.append(cdc_idx_dict.get(x))\n",
        "    else:\n",
        "        cdc.append('---')\n",
        "ndf['cdc'] = cdc\n",
        "\n",
        "df = pd.concat([ndf, df], axis=0, ignore_index=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "CeOI_JJ61VdE"
      },
      "source": [
        "#### Article 1 "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "2HvLKG4j1VdE",
        "colab": {}
      },
      "source": [
        "with open(articles_dict[articles[1].replace(' ','_')+'.txt']) as article:\n",
        "        doc = article.read()\n",
        "\n",
        "c_doc = text_cleaner(doc)\n",
        "sentences = nltk.sent_tokenize(c_doc)\n",
        "sentences = [[sent, topic, articles[1]] for sent in sentences]\n",
        "\n",
        "ndf = pd.DataFrame(sentences, columns=['text', 'topic', 'article'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "outputId": "9305cedf-2993-492e-ce0d-e2f359093a7c",
        "id": "LeikYYlP1VdF",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "cdc_idx_dict = {}\n",
        "cdc_idx_sent = {}\n",
        "cdc_idx_art = {}\n",
        "\n",
        "for i,claim in enumerate(ref_data['clean_Claim']):\n",
        "    check_complete = False\n",
        "    while check_complete == False:\n",
        "        for idx,sentence in enumerate(ndf['text']):\n",
        "            test = claim.lower() in sentence.lower()\n",
        "            if test:\n",
        "                article = ref_data['Article'][i]\n",
        "                cdc_idx_dict[idx] = claim\n",
        "                cdc_idx_sent[idx] = [claim, sentence]\n",
        "                cdc_idx_art[idx] = [claim, article]\n",
        "                check_complete = True\n",
        "            elif idx == (len(ndf['text'])-1):\n",
        "                check_complete = True\n",
        "\n",
        "len(cdc_idx_dict), ref_data.shape[0]"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(6, 1332)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 454
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "outputId": "78703561-b126-4ecf-a4cd-db72d97441c4",
        "id": "7pW7nKp81VdG",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "cdc_idx_dict"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{117: 'Patents provide incentives for economically efficient research and development',\n",
              " 124: 'patents facilitate and encourage disclosure of innovations into the public domain for the common good',\n",
              " 125: 'If inventors did not have the legal protection of patents, in many cases, they would prefer or tend to keep their inventions secret',\n",
              " 126: 'Awarding patents generally makes the details of new technology publicly available',\n",
              " 127: \"when a patent's term has expired, the public record ensures that the patentee's idea is not lost to humanity\",\n",
              " 138: 'patents have been criticized as inconsistent with free trade'}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 455
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "S3OvkRSG1VdH",
        "colab": {}
      },
      "source": [
        "cdc = []\n",
        "\n",
        "for x in range(len(ndf)):\n",
        "    if x in list(cdc_idx_dict.keys()):\n",
        "        cdc.append(cdc_idx_dict.get(x))\n",
        "    else:\n",
        "        cdc.append('---')\n",
        "ndf['cdc'] = cdc\n",
        "\n",
        "df = pd.concat([df, ndf], axis=0, ignore_index=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "PrzF3IhH1VdH"
      },
      "source": [
        "#### Article 2 "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "4nDuiMwk1VdI",
        "colab": {}
      },
      "source": [
        "with open(articles_dict[articles[2].replace(' ','_')+'.txt']) as article:\n",
        "        doc = article.read()\n",
        "\n",
        "c_doc = text_cleaner(doc)\n",
        "sentences = nltk.sent_tokenize(c_doc)\n",
        "sentences = [[sent, topic, articles[2]] for sent in sentences]\n",
        "\n",
        "ndf = pd.DataFrame(sentences, columns=['text', 'topic', 'article'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "outputId": "90d51d3f-3703-4255-e112-6841a7e99fc4",
        "id": "V6tDfnAX1VdI",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "cdc_idx_dict = {}\n",
        "cdc_idx_sent = {}\n",
        "cdc_idx_art = {}\n",
        "\n",
        "for i,claim in enumerate(ref_data['clean_Claim']):\n",
        "    check_complete = False\n",
        "    while check_complete == False:\n",
        "        for idx,sentence in enumerate(ndf['text']):\n",
        "            test = claim.lower() in sentence.lower()\n",
        "            if test:\n",
        "                article = ref_data['Article'][i]\n",
        "                cdc_idx_dict[idx] = claim\n",
        "                cdc_idx_sent[idx] = [claim, sentence]\n",
        "                cdc_idx_art[idx] = [claim, article]\n",
        "                check_complete = True\n",
        "            elif idx == (len(ndf['text'])-1):\n",
        "                check_complete = True\n",
        "\n",
        "len(cdc_idx_dict), ref_data.shape[0]"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(11, 1332)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 458
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "outputId": "8a140d3d-040f-4900-e2ec-e41e516550cb",
        "id": "dHh6g3bv1VdJ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "cdc_idx_dict"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{23: 'intellectual property is desirable because it encourages innovation',\n",
              " 24: 'creators will not have sufficient incentive to invent unless they are legally entitled to capture the full social value of their inventions',\n",
              " 28: 'intellectual property rights are essential to maintaining economic growth',\n",
              " 29: 'give statutory expression to the moral and economic rights of creators in their creations',\n",
              " 30: 'encourage fair trading which would contribute to economic and social development',\n",
              " 31: 'effective enforcement of intellectual property rights is critical to sustaining economic growth',\n",
              " 34: 'a positive correlation between the strengthening of the IP system and subsequent economic growth',\n",
              " 35: 'IP can be a disincentive to innovation',\n",
              " 49: 'they promote public welfare',\n",
              " 54: 'To violate intellectual property is therefore no different morally than violating other property rights',\n",
              " 64: 'infringes on the right to own tangible property'}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 459
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "oHk_BRCa1VdK",
        "colab": {}
      },
      "source": [
        "cdc = []\n",
        "\n",
        "for x in range(len(ndf)):\n",
        "    if x in list(cdc_idx_dict.keys()):\n",
        "        cdc.append(cdc_idx_dict.get(x))\n",
        "    else:\n",
        "        cdc.append('---')\n",
        "ndf['cdc'] = cdc\n",
        "\n",
        "df = pd.concat([ndf, df], axis=0, ignore_index=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "PzqIMl6q1VdL"
      },
      "source": [
        "#### Article 3 "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "koJIzURL1VdL",
        "colab": {}
      },
      "source": [
        "with open(articles_dict[articles[3].replace(' ','_')+'.txt']) as article:\n",
        "        doc = article.read()\n",
        "\n",
        "c_doc = text_cleaner(doc)\n",
        "sentences = nltk.sent_tokenize(c_doc)\n",
        "sentences = [[sent, topic, articles[3]] for sent in sentences]\n",
        "\n",
        "ndf = pd.DataFrame(sentences, columns=['text', 'topic', 'article'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "outputId": "2c659a32-f5aa-4c06-8f01-a1ba37cbb53f",
        "id": "EY37djDD1VdM",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "cdc_idx_dict = {}\n",
        "cdc_idx_sent = {}\n",
        "cdc_idx_art = {}\n",
        "\n",
        "for i,claim in enumerate(ref_data['clean_Claim']):\n",
        "    check_complete = False\n",
        "    while check_complete == False:\n",
        "        for idx,sentence in enumerate(ndf['text']):\n",
        "            test = claim.lower() in sentence.lower()\n",
        "            if test:\n",
        "                article = ref_data['Article'][i]\n",
        "                cdc_idx_dict[idx] = claim\n",
        "                cdc_idx_sent[idx] = [claim, sentence]\n",
        "                cdc_idx_art[idx] = [claim, article]\n",
        "                check_complete = True\n",
        "            elif idx == (len(ndf['text'])-1):\n",
        "                check_complete = True\n",
        "\n",
        "len(cdc_idx_dict), ref_data.shape[0]"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(4, 1332)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 462
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "outputId": "317cb22e-3211-428e-ae9b-96362bb6b8fd",
        "id": "44ckRBax1VdN",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "cdc_idx_dict"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{4: 'patents were obstructing research',\n",
              " 8: 'patents as state-granted monopolies inconsistent with free trade',\n",
              " 10: 'give rise to \"troll\" entities',\n",
              " 27: 'intellectual property rights may become so fragmented that, effectively, no one can take advantage of them'}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 463
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "1aU1TBYT1VdO",
        "colab": {}
      },
      "source": [
        "cdc = []\n",
        "\n",
        "for x in range(len(ndf)):\n",
        "    if x in list(cdc_idx_dict.keys()):\n",
        "        cdc.append(cdc_idx_dict.get(x))\n",
        "    else:\n",
        "        cdc.append('---')\n",
        "ndf['cdc'] = cdc\n",
        "\n",
        "df = pd.concat([ndf, df], axis=0, ignore_index=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "FWwxCZoA1VdO"
      },
      "source": [
        "#### Article 4 "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "xlLJkWmc1VdP",
        "colab": {}
      },
      "source": [
        "with open(articles_dict[articles[4].replace(' ','_')+'.txt']) as article:\n",
        "        doc = article.read()\n",
        "\n",
        "c_doc = text_cleaner(doc)\n",
        "sentences = nltk.sent_tokenize(c_doc)\n",
        "sentences = [[sent, topic, articles[4]] for sent in sentences]\n",
        "\n",
        "ndf = pd.DataFrame(sentences, columns=['text', 'topic', 'article'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "outputId": "bab8394a-58e2-4e11-e894-bd387293d957",
        "id": "qxHuxzlK1VdP",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "cdc_idx_dict = {}\n",
        "cdc_idx_sent = {}\n",
        "cdc_idx_art = {}\n",
        "\n",
        "for i,claim in enumerate(ref_data['clean_Claim']):\n",
        "    check_complete = False\n",
        "    while check_complete == False:\n",
        "        for idx,sentence in enumerate(ndf['text']):\n",
        "            test = claim.lower() in sentence.lower()\n",
        "            if test:\n",
        "                article = ref_data['Article'][i]\n",
        "                cdc_idx_dict[idx] = claim\n",
        "                cdc_idx_sent[idx] = [claim, sentence]\n",
        "                cdc_idx_art[idx] = [claim, article]\n",
        "                check_complete = True\n",
        "            elif idx == (len(ndf['text'])-1):\n",
        "                check_complete = True\n",
        "\n",
        "len(cdc_idx_dict), ref_data.shape[0]"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(8, 1332)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 466
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "outputId": "23a0e5ce-dc25-49b2-e195-27b75cd6797a",
        "id": "RJN0er3S1VdQ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "cdc_idx_dict"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{3: \"Patents and copyrights are the legal implementation of the base of all property rights: a man's right to the product of his mind\",\n",
              " 18: 'intellectual property laws can actually hinder innovation',\n",
              " 22: 'they divert resources from research and development to patent filing and lawsuits',\n",
              " 24: 'are not a legitimate subject of property rights',\n",
              " 25: \"the only way that intellectual property rights can be implemented is by limiting others' physical property rights\",\n",
              " 29: 'one cannot own information without owning other people',\n",
              " 31: 'the patent monopoly..consists in protecting inventors..against competition for a period long enough to extort from the people a reward enormously in excess of the labor measure of their services',\n",
              " 35: 'have hindered the ability of consumers to buy the products they want'}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 467
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "HpgQZf211VdR",
        "colab": {}
      },
      "source": [
        "cdc = []\n",
        "\n",
        "for x in range(len(ndf)):\n",
        "    if x in list(cdc_idx_dict.keys()):\n",
        "        cdc.append(cdc_idx_dict.get(x))\n",
        "    else:\n",
        "        cdc.append('---')\n",
        "ndf['cdc'] = cdc\n",
        "\n",
        "df = pd.concat([ndf, df], axis=0, ignore_index=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "ksdsdNwn-a7p"
      },
      "source": [
        "#### Article 5 "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "9UlUnXet-a7q",
        "colab": {}
      },
      "source": [
        "with open(articles_dict[articles[5].replace(' ','_')+'.txt']) as article:\n",
        "        doc = article.read()\n",
        "\n",
        "c_doc = text_cleaner(doc)\n",
        "sentences = nltk.sent_tokenize(c_doc)\n",
        "sentences = [[sent, topic, articles[5]] for sent in sentences]\n",
        "\n",
        "ndf = pd.DataFrame(sentences, columns=['text', 'topic', 'article'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "outputId": "720e330c-789f-47e5-eaab-23ecb449e601",
        "id": "WSRiYbeD-a7r",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "cdc_idx_dict = {}\n",
        "cdc_idx_sent = {}\n",
        "cdc_idx_art = {}\n",
        "\n",
        "for i,claim in enumerate(ref_data['clean_Claim']):\n",
        "    check_complete = False\n",
        "    while check_complete == False:\n",
        "        for idx,sentence in enumerate(ndf['text']):\n",
        "            test = claim.lower() in sentence.lower()\n",
        "            if test:\n",
        "                article = ref_data['Article'][i]\n",
        "                cdc_idx_dict[idx] = claim\n",
        "                cdc_idx_sent[idx] = [claim, sentence]\n",
        "                cdc_idx_art[idx] = [claim, article]\n",
        "                check_complete = True\n",
        "            elif idx == (len(ndf['text'])-1):\n",
        "                check_complete = True\n",
        "\n",
        "len(cdc_idx_dict), ref_data.shape[0]"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(1, 1332)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 470
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "outputId": "9b68df0b-d5ef-4d8c-96aa-6a4e5fc75593",
        "id": "AzQ_5Qi3-a7s",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "cdc_idx_dict"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{4: 'all information should be freely distributed and unrestricted'}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 471
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "tj8Bwf9b-a7t",
        "colab": {}
      },
      "source": [
        "cdc = []\n",
        "\n",
        "for x in range(len(ndf)):\n",
        "    if x in list(cdc_idx_dict.keys()):\n",
        "        cdc.append(cdc_idx_dict.get(x))\n",
        "    else:\n",
        "        cdc.append('---')\n",
        "ndf['cdc'] = cdc\n",
        "\n",
        "df = pd.concat([ndf, df], axis=0, ignore_index=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "AU85H94k-a7u"
      },
      "source": [
        "#### Article 6"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "5bvWgXlV-a7u",
        "colab": {}
      },
      "source": [
        "with open(articles_dict[articles[6].replace(' ','_')+'.txt']) as article:\n",
        "        doc = article.read()\n",
        "\n",
        "c_doc = text_cleaner(doc)\n",
        "sentences = nltk.sent_tokenize(c_doc)\n",
        "sentences = [[sent, topic, articles[6]] for sent in sentences]\n",
        "\n",
        "ndf = pd.DataFrame(sentences, columns=['text', 'topic', 'article'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "outputId": "a58cbf91-fd9e-4203-84fc-7fb64639ceb8",
        "id": "FWoYzr14-a7w",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "cdc_idx_dict = {}\n",
        "cdc_idx_sent = {}\n",
        "cdc_idx_art = {}\n",
        "\n",
        "for i,claim in enumerate(ref_data['clean_Claim']):\n",
        "    check_complete = False\n",
        "    while check_complete == False:\n",
        "        for idx,sentence in enumerate(ndf['text']):\n",
        "            test = claim.lower() in sentence.lower()\n",
        "            if test:\n",
        "                article = ref_data['Article'][i]\n",
        "                cdc_idx_dict[idx] = claim\n",
        "                cdc_idx_sent[idx] = [claim, sentence]\n",
        "                cdc_idx_art[idx] = [claim, article]\n",
        "                check_complete = True\n",
        "            elif idx == (len(ndf['text'])-1):\n",
        "                check_complete = True\n",
        "\n",
        "len(cdc_idx_dict), ref_data.shape[0]"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(10, 1332)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 474
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "outputId": "3bd6797d-3ff3-4c57-8ea3-4010dd6a4daf",
        "id": "EysgXApA-a7x",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "cdc_idx_dict"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{16: 'intellectual property as a necessary way of incentivising the creation of new creative works',\n",
              " 22: 'in the absence of intellectual property protections such as copyright and patents, various types of intangible assets would be under-produced',\n",
              " 28: 'without a significant period of legal protection of their future income, many valuable books and artworks would not be created',\n",
              " 32: 'Without a feasible way to recoup investments of creative time through copyright, there would be little economic incentive to produce',\n",
              " 35: 'it has been largely successful in financing the creation and distribution of a wide variety of works',\n",
              " 45: 'has always served simply to enrich a few at the expense of creativity',\n",
              " 50: 'the current (international) copyright system undermines its own goal',\n",
              " 59: 'quality works can be created even in the absence of a copyright-enforced monopoly rent',\n",
              " 63: 'Copyright can also be used to stifle political criticism',\n",
              " 69: 'has made and continues to make a valuable even essential contribution to the creation and dissemination of works'}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 475
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "zgGwlD8F-a7z",
        "colab": {}
      },
      "source": [
        "cdc = []\n",
        "\n",
        "for x in range(len(ndf)):\n",
        "    if x in list(cdc_idx_dict.keys()):\n",
        "        cdc.append(cdc_idx_dict.get(x))\n",
        "    else:\n",
        "        cdc.append('---')\n",
        "ndf['cdc'] = cdc\n",
        "\n",
        "df = pd.concat([ndf, df], axis=0, ignore_index=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "arO9AiS0-a70"
      },
      "source": [
        "#### Article 7"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "WDKjGHMB-a70",
        "colab": {}
      },
      "source": [
        "with open(articles_dict[articles[7].replace(' ','_')+'.txt']) as article:\n",
        "        doc = article.read()\n",
        "\n",
        "c_doc = text_cleaner(doc)\n",
        "sentences = nltk.sent_tokenize(c_doc)\n",
        "sentences = [[sent, topic, articles[7]] for sent in sentences]\n",
        "\n",
        "ndf = pd.DataFrame(sentences, columns=['text', 'topic', 'article'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "outputId": "f178145b-1d51-4b60-c10a-7242c835f612",
        "id": "9uR7TMuC-a71",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "cdc_idx_dict = {}\n",
        "cdc_idx_sent = {}\n",
        "cdc_idx_art = {}\n",
        "\n",
        "for i,claim in enumerate(ref_data['clean_Claim']):\n",
        "    check_complete = False\n",
        "    while check_complete == False:\n",
        "        for idx,sentence in enumerate(ndf['text']):\n",
        "            test = claim.lower() in sentence.lower()\n",
        "            if test:\n",
        "                article = ref_data['Article'][i]\n",
        "                cdc_idx_dict[idx] = claim\n",
        "                cdc_idx_sent[idx] = [claim, sentence]\n",
        "                cdc_idx_art[idx] = [claim, article]\n",
        "                check_complete = True\n",
        "            elif idx == (len(ndf['text'])-1):\n",
        "                check_complete = True\n",
        "\n",
        "len(cdc_idx_dict), ref_data.shape[0]"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(10, 1332)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 478
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "outputId": "e02a3aae-43a0-42c2-cc91-b92bed9e0b66",
        "id": "4ftDvtHu-a72",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "cdc_idx_dict"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{2: 'granting developers temporary monopolies over their works encourages further development and creativity',\n",
              " 3: 'serves to enrich a few at the expense of creativity',\n",
              " 28: 'copyright is invalid because, unlike physical property, intellectual property is not scarce',\n",
              " 32: 'is obsolete',\n",
              " 38: 'the cost of trying to enforce it is unreasonable',\n",
              " 39: 'knowledge should be \"shared in solidarity',\n",
              " 42: 'copyright law as preventing or slowing human progress',\n",
              " 51: 'artists cannot produce new works without an economic incentive',\n",
              " 56: 'is a fundamental right for both creators and consumers',\n",
              " 57: 'content creators would not have incentive to produce their products if they cannot be guaranteed payment'}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 479
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "yf_2YJEh-a72",
        "colab": {}
      },
      "source": [
        "cdc = []\n",
        "\n",
        "for x in range(len(ndf)):\n",
        "    if x in list(cdc_idx_dict.keys()):\n",
        "        cdc.append(cdc_idx_dict.get(x))\n",
        "    else:\n",
        "        cdc.append('---')\n",
        "ndf['cdc'] = cdc\n",
        "\n",
        "df = pd.concat([ndf, df], axis=0, ignore_index=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "55iVgWbO-a73"
      },
      "source": [
        "#### Article 8"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "-YDoueUo-a74",
        "colab": {}
      },
      "source": [
        "with open(articles_dict[articles[8].replace(' ','_')+'.txt']) as article:\n",
        "        doc = article.read()\n",
        "\n",
        "c_doc = text_cleaner(doc)\n",
        "sentences = nltk.sent_tokenize(c_doc)\n",
        "sentences = [[sent, topic, articles[8]] for sent in sentences]\n",
        "\n",
        "ndf = pd.DataFrame(sentences, columns=['text', 'topic', 'article'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "outputId": "1fa06a17-6394-4da7-8f10-e26d9325b241",
        "id": "fWkiWW28-a75",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "cdc_idx_dict = {}\n",
        "cdc_idx_sent = {}\n",
        "cdc_idx_art = {}\n",
        "\n",
        "for i,claim in enumerate(ref_data['clean_Claim']):\n",
        "    check_complete = False\n",
        "    while check_complete == False:\n",
        "        for idx,sentence in enumerate(ndf['text']):\n",
        "            test = claim.lower() in sentence.lower()\n",
        "            if test:\n",
        "                article = ref_data['Article'][i]\n",
        "                cdc_idx_dict[idx] = claim\n",
        "                cdc_idx_sent[idx] = [claim, sentence]\n",
        "                cdc_idx_art[idx] = [claim, article]\n",
        "                check_complete = True\n",
        "            elif idx == (len(ndf['text'])-1):\n",
        "                check_complete = True\n",
        "\n",
        "len(cdc_idx_dict), ref_data.shape[0]"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(2, 1332)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 482
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "outputId": "68a0b8a4-761b-4595-b66e-380a676930d3",
        "id": "wjNNsvSP-a76",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "cdc_idx_dict"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{20: 'the law is fair and just',\n",
              " 32: 'patent and copyright laws support in fundamental and thoroughgoing ways the expansion of the range of creative human activities that can be commodified'}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 483
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "yaffLb9v-a77",
        "colab": {}
      },
      "source": [
        "cdc = []\n",
        "\n",
        "for x in range(len(ndf)):\n",
        "    if x in list(cdc_idx_dict.keys()):\n",
        "        cdc.append(cdc_idx_dict.get(x))\n",
        "    else:\n",
        "        cdc.append('---')\n",
        "ndf['cdc'] = cdc\n",
        "\n",
        "df = pd.concat([ndf, df], axis=0, ignore_index=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ck3B3fvPynOg",
        "colab_type": "text"
      },
      "source": [
        "### 'limit the right to bear arms '"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "outputId": "b2ff0bbd-3348-4b70-f790-88035710248d",
        "id": "UK9jjDJB1Xag",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 187
        }
      },
      "source": [
        "topic = 'limit the right to bear arms '\n",
        "\n",
        "articles = topic_article_dict[topic]\n",
        "articles"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['Gun violence in the United States',\n",
              " 'Gun culture',\n",
              " 'National Rifle Association',\n",
              " 'Second Amendment to the United States Constitution',\n",
              " 'Gun politics in the United States',\n",
              " 'Political arguments of gun politics in the United States',\n",
              " 'Gun politics in Brazil',\n",
              " 'Gun politics',\n",
              " 'Gun violence and gun control in Texas',\n",
              " 'Gun control']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 485
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yPdFfuR-1XE_",
        "colab_type": "code",
        "outputId": "2f10784f-b1a4-4d9b-e728-0f47c171fc12",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "len(articles)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "10"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 486
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "7qPcP1SB1Xah"
      },
      "source": [
        "#### Article 0 "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "REW7NhxW1Xah",
        "colab": {}
      },
      "source": [
        "with open(articles_dict[articles[0].replace(' ','_')+'.txt']) as article:\n",
        "        doc = article.read()\n",
        "\n",
        "c_doc = text_cleaner(doc)\n",
        "sentences = nltk.sent_tokenize(c_doc)\n",
        "sentences = [[sent, topic, articles[0]] for sent in sentences]\n",
        "\n",
        "ndf = pd.DataFrame(sentences, columns=['text', 'topic', 'article'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "outputId": "54985165-5232-48e6-a325-4c87c821a873",
        "id": "xE_uy2s41Xaj",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "cdc_idx_dict = {}\n",
        "cdc_idx_sent = {}\n",
        "cdc_idx_art = {}\n",
        "\n",
        "for i,claim in enumerate(ref_data['clean_Claim']):\n",
        "    check_complete = False\n",
        "    while check_complete == False:\n",
        "        for idx,sentence in enumerate(ndf['text']):\n",
        "            test = claim.lower() in sentence.lower()\n",
        "            if test:\n",
        "                article = ref_data['Article'][i]\n",
        "                cdc_idx_dict[idx] = claim\n",
        "                cdc_idx_sent[idx] = [claim, sentence]\n",
        "                cdc_idx_art[idx] = [claim, article]\n",
        "                check_complete = True\n",
        "            elif idx == (len(ndf['text'])-1):\n",
        "                check_complete = True\n",
        "\n",
        "len(cdc_idx_dict), ref_data.shape[0]"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(6, 1332)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 488
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "outputId": "ee723710-add7-4a58-8dff-f80d75cb7273",
        "id": "hvpoKO-n1Xak",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "cdc_idx_dict"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{43: 'the likelihood that a death will result is significantly increased when either the victim or the attacker has a firearm',\n",
              " 59: 'if guns were less available, criminals may likely commit the crime anyway',\n",
              " 89: 'criminal use of guns is far more common than self-defense use of guns',\n",
              " 99: 'more guns can reduce crime',\n",
              " 100: 'limiting access to guns by law-abiding people makes them more vulnerable to armed criminals',\n",
              " 171: 'potential crime victims might be carrying firearms, and thus serve as a deterrent against crime'}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 489
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "qfzh03VU1Xal",
        "colab": {}
      },
      "source": [
        "cdc = []\n",
        "\n",
        "for x in range(len(ndf)):\n",
        "    if x in list(cdc_idx_dict.keys()):\n",
        "        cdc.append(cdc_idx_dict.get(x))\n",
        "    else:\n",
        "        cdc.append('---')\n",
        "ndf['cdc'] = cdc\n",
        "\n",
        "df = pd.concat([ndf, df], axis=0, ignore_index=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "ZqaSBlDJ1Xal"
      },
      "source": [
        "#### Article 1 "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "2ngLuiMp1Xam",
        "colab": {}
      },
      "source": [
        "with open(articles_dict[articles[1].replace(' ','_')+'.txt']) as article:\n",
        "        doc = article.read()\n",
        "\n",
        "c_doc = text_cleaner(doc)\n",
        "sentences = nltk.sent_tokenize(c_doc)\n",
        "sentences = [[sent, topic, articles[1]] for sent in sentences]\n",
        "\n",
        "ndf = pd.DataFrame(sentences, columns=['text', 'topic', 'article'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "outputId": "bfee8aba-6b15-41da-f019-00f91da528aa",
        "id": "ED14EV3y1Xam",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "cdc_idx_dict = {}\n",
        "cdc_idx_sent = {}\n",
        "cdc_idx_art = {}\n",
        "\n",
        "for i,claim in enumerate(ref_data['clean_Claim']):\n",
        "    check_complete = False\n",
        "    while check_complete == False:\n",
        "        for idx,sentence in enumerate(ndf['text']):\n",
        "            test = claim.lower() in sentence.lower()\n",
        "            if test:\n",
        "                article = ref_data['Article'][i]\n",
        "                cdc_idx_dict[idx] = claim\n",
        "                cdc_idx_sent[idx] = [claim, sentence]\n",
        "                cdc_idx_art[idx] = [claim, article]\n",
        "                check_complete = True\n",
        "            elif idx == (len(ndf['text'])-1):\n",
        "                check_complete = True\n",
        "\n",
        "len(cdc_idx_dict), ref_data.shape[0]"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(3, 1332)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 492
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "outputId": "c89af931-f824-45e1-dae5-bbaa02a9342f",
        "id": "xgrxY65U1Xan",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "cdc_idx_dict"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{21: 'citizens should not be prevented from having guns unless they have done something to show that they are not to be trusted with them',\n",
              " 22: 'guns provide some level of protection against criminality and tyranny',\n",
              " 23: 'widespread gun ownership is protection against tyranny'}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 493
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "2JQVo5q_1Xao",
        "colab": {}
      },
      "source": [
        "cdc = []\n",
        "\n",
        "for x in range(len(ndf)):\n",
        "    if x in list(cdc_idx_dict.keys()):\n",
        "        cdc.append(cdc_idx_dict.get(x))\n",
        "    else:\n",
        "        cdc.append('---')\n",
        "ndf['cdc'] = cdc\n",
        "\n",
        "df = pd.concat([df, ndf], axis=0, ignore_index=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "q9-url7_1Xap"
      },
      "source": [
        "#### Article 2 "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "Og8oGzhq1Xaq",
        "colab": {}
      },
      "source": [
        "with open(articles_dict[articles[2].replace(' ','_')+'.txt']) as article:\n",
        "        doc = article.read()\n",
        "\n",
        "c_doc = text_cleaner(doc)\n",
        "sentences = nltk.sent_tokenize(c_doc)\n",
        "sentences = [[sent, topic, articles[2]] for sent in sentences]\n",
        "\n",
        "ndf = pd.DataFrame(sentences, columns=['text', 'topic', 'article'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "outputId": "917ad0e9-48c2-4205-8ecc-353e96d71c14",
        "id": "ZcwxIQ1x1Xar",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "cdc_idx_dict = {}\n",
        "cdc_idx_sent = {}\n",
        "cdc_idx_art = {}\n",
        "\n",
        "for i,claim in enumerate(ref_data['clean_Claim']):\n",
        "    check_complete = False\n",
        "    while check_complete == False:\n",
        "        for idx,sentence in enumerate(ndf['text']):\n",
        "            test = claim.lower() in sentence.lower()\n",
        "            if test:\n",
        "                article = ref_data['Article'][i]\n",
        "                cdc_idx_dict[idx] = claim\n",
        "                cdc_idx_sent[idx] = [claim, sentence]\n",
        "                cdc_idx_art[idx] = [claim, article]\n",
        "                check_complete = True\n",
        "            elif idx == (len(ndf['text'])-1):\n",
        "                check_complete = True\n",
        "\n",
        "len(cdc_idx_dict), ref_data.shape[0]"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(2, 1332)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 496
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "outputId": "4ef50dce-af91-4b1f-d695-c281d0501b8a",
        "id": "jbhbniwn1Xar",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "cdc_idx_dict"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{4: 'gun ownership is a civil liberty',\n",
              " 204: 'citizens need to arm themselves to safeguard political liberties against threats by the government'}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 497
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "wjd8Ye6M1Xas",
        "colab": {}
      },
      "source": [
        "cdc = []\n",
        "\n",
        "for x in range(len(ndf)):\n",
        "    if x in list(cdc_idx_dict.keys()):\n",
        "        cdc.append(cdc_idx_dict.get(x))\n",
        "    else:\n",
        "        cdc.append('---')\n",
        "ndf['cdc'] = cdc\n",
        "\n",
        "df = pd.concat([ndf, df], axis=0, ignore_index=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "o3Wj3Y9C1Xat"
      },
      "source": [
        "#### Article 3 "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "CxgnwBpj1Xat",
        "colab": {}
      },
      "source": [
        "with open(articles_dict[articles[3].replace(' ','_')+'.txt']) as article:\n",
        "        doc = article.read()\n",
        "\n",
        "c_doc = text_cleaner(doc)\n",
        "sentences = nltk.sent_tokenize(c_doc)\n",
        "sentences = [[sent, topic, articles[3]] for sent in sentences]\n",
        "\n",
        "ndf = pd.DataFrame(sentences, columns=['text', 'topic', 'article'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "outputId": "215985e6-e742-424c-c2c8-fc1f604e8d89",
        "id": "LCXztlgo1Xau",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "cdc_idx_dict = {}\n",
        "cdc_idx_sent = {}\n",
        "cdc_idx_art = {}\n",
        "\n",
        "for i,claim in enumerate(ref_data['clean_Claim']):\n",
        "    check_complete = False\n",
        "    while check_complete == False:\n",
        "        for idx,sentence in enumerate(ndf['text']):\n",
        "            test = claim.lower() in sentence.lower()\n",
        "            if test:\n",
        "                article = ref_data['Article'][i]\n",
        "                cdc_idx_dict[idx] = claim\n",
        "                cdc_idx_sent[idx] = [claim, sentence]\n",
        "                cdc_idx_art[idx] = [claim, article]\n",
        "                check_complete = True\n",
        "            elif idx == (len(ndf['text'])-1):\n",
        "                check_complete = True\n",
        "\n",
        "len(cdc_idx_dict), ref_data.shape[0]"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(1, 1332)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 500
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "outputId": "92f7201c-60f1-4851-ae48-caf63d785a51",
        "id": "sExUjet31Xav",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "cdc_idx_dict"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{41: 'people have a right to bear arms for the defence of themselves and the state'}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 501
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "a_wNpx9h1Xaw",
        "colab": {}
      },
      "source": [
        "cdc = []\n",
        "\n",
        "for x in range(len(ndf)):\n",
        "    if x in list(cdc_idx_dict.keys()):\n",
        "        cdc.append(cdc_idx_dict.get(x))\n",
        "    else:\n",
        "        cdc.append('---')\n",
        "ndf['cdc'] = cdc\n",
        "\n",
        "df = pd.concat([ndf, df], axis=0, ignore_index=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "L1hyaIRx1Xax"
      },
      "source": [
        "#### Article 4 "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "2H4NmCK51Xax",
        "colab": {}
      },
      "source": [
        "with open(articles_dict[articles[4].replace(' ','_')+'.txt']) as article:\n",
        "        doc = article.read()\n",
        "\n",
        "c_doc = text_cleaner(doc)\n",
        "sentences = nltk.sent_tokenize(c_doc)\n",
        "sentences = [[sent, topic, articles[4]] for sent in sentences]\n",
        "\n",
        "ndf = pd.DataFrame(sentences, columns=['text', 'topic', 'article'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "outputId": "1bd530f4-5717-4bff-b62a-15bfd679918c",
        "id": "AbnjnzRQ1Xay",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "cdc_idx_dict = {}\n",
        "cdc_idx_sent = {}\n",
        "cdc_idx_art = {}\n",
        "\n",
        "for i,claim in enumerate(ref_data['clean_Claim']):\n",
        "    check_complete = False\n",
        "    while check_complete == False:\n",
        "        for idx,sentence in enumerate(ndf['text']):\n",
        "            test = claim.lower() in sentence.lower()\n",
        "            if test:\n",
        "                article = ref_data['Article'][i]\n",
        "                cdc_idx_dict[idx] = claim\n",
        "                cdc_idx_sent[idx] = [claim, sentence]\n",
        "                cdc_idx_art[idx] = [claim, article]\n",
        "                check_complete = True\n",
        "            elif idx == (len(ndf['text'])-1):\n",
        "                check_complete = True\n",
        "\n",
        "len(cdc_idx_dict), ref_data.shape[0]"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(3, 1332)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 504
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "outputId": "1a145b3d-b2c8-42c6-80b7-2889592ede56",
        "id": "VZRV5fHe1Xaz",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "cdc_idx_dict"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{18: 'most guns are in the hands of people who are unlikely to misuse them',\n",
              " 68: 'the right to bear arms is absolute and unqualified',\n",
              " 119: 'Americans have an individual right described in the Second Amendment to possess firearms'}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 505
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "tbvbe2Ia1Xa0",
        "colab": {}
      },
      "source": [
        "cdc = []\n",
        "\n",
        "for x in range(len(ndf)):\n",
        "    if x in list(cdc_idx_dict.keys()):\n",
        "        cdc.append(cdc_idx_dict.get(x))\n",
        "    else:\n",
        "        cdc.append('---')\n",
        "ndf['cdc'] = cdc\n",
        "\n",
        "df = pd.concat([ndf, df], axis=0, ignore_index=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "ee3--AGl-gym"
      },
      "source": [
        "#### Article 5 "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "_gujQTSV-gyn",
        "colab": {}
      },
      "source": [
        "with open(articles_dict[articles[5].replace(' ','_')+'.txt']) as article:\n",
        "        doc = article.read()\n",
        "\n",
        "c_doc = text_cleaner(doc)\n",
        "sentences = nltk.sent_tokenize(c_doc)\n",
        "sentences = [[sent, topic, articles[5]] for sent in sentences]\n",
        "\n",
        "ndf = pd.DataFrame(sentences, columns=['text', 'topic', 'article'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "outputId": "723709b5-642e-4cb4-85a0-36d5439dc973",
        "id": "vNPRvvJy-gyo",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "cdc_idx_dict = {}\n",
        "cdc_idx_sent = {}\n",
        "cdc_idx_art = {}\n",
        "\n",
        "for i,claim in enumerate(ref_data['clean_Claim']):\n",
        "    check_complete = False\n",
        "    while check_complete == False:\n",
        "        for idx,sentence in enumerate(ndf['text']):\n",
        "            test = claim.lower() in sentence.lower()\n",
        "            if test:\n",
        "                article = ref_data['Article'][i]\n",
        "                cdc_idx_dict[idx] = claim\n",
        "                cdc_idx_sent[idx] = [claim, sentence]\n",
        "                cdc_idx_art[idx] = [claim, article]\n",
        "                check_complete = True\n",
        "            elif idx == (len(ndf['text'])-1):\n",
        "                check_complete = True\n",
        "\n",
        "len(cdc_idx_dict), ref_data.shape[0]"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(10, 1332)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 508
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "outputId": "4211d626-1aa4-4199-a123-1dd39eb950ab",
        "id": "6X3nPqCJ-gyo",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "cdc_idx_dict"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{4: 'gun possession is a fundamental civil right',\n",
              " 41: 'the people have a right to \"keep and bear arms\" as a protection from the government',\n",
              " 43: 'the right to bear arms is necessary for the citizens to protect themselves from the \"tyranny in government',\n",
              " 44: \"an armed citizenry is the population's last line of defense against tyranny by their own government\",\n",
              " 86: 'making civilian ownership of firearms illegal would increase the crime rate',\n",
              " 88: 'increased gun ownership leads to higher levels of crime',\n",
              " 129: 'are effectively deterred by armed intended victims',\n",
              " 149: 'people who keep a gun at home increase their risk of homicide',\n",
              " 158: 'allowing law-abiding citizens to carry concealed firearms, deters crime',\n",
              " 159: 'The possibility of getting shot by an armed victim is a substantial deterrent to crime'}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 509
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "XfMtOJWq-gyp",
        "colab": {}
      },
      "source": [
        "cdc = []\n",
        "\n",
        "for x in range(len(ndf)):\n",
        "    if x in list(cdc_idx_dict.keys()):\n",
        "        cdc.append(cdc_idx_dict.get(x))\n",
        "    else:\n",
        "        cdc.append('---')\n",
        "ndf['cdc'] = cdc\n",
        "\n",
        "df = pd.concat([ndf, df], axis=0, ignore_index=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "3_nNQyxD-gyq"
      },
      "source": [
        "#### Article 6"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "vfPTB-nW-gyq",
        "colab": {}
      },
      "source": [
        "with open(articles_dict[articles[6].replace(' ','_')+'.txt']) as article:\n",
        "        doc = article.read()\n",
        "\n",
        "c_doc = text_cleaner(doc)\n",
        "sentences = nltk.sent_tokenize(c_doc)\n",
        "sentences = [[sent, topic, articles[6]] for sent in sentences]\n",
        "\n",
        "ndf = pd.DataFrame(sentences, columns=['text', 'topic', 'article'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "outputId": "807a138c-fcea-45e9-9315-ff0afbb57c57",
        "id": "FzF_u5u9-gyr",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "cdc_idx_dict = {}\n",
        "cdc_idx_sent = {}\n",
        "cdc_idx_art = {}\n",
        "\n",
        "for i,claim in enumerate(ref_data['clean_Claim']):\n",
        "    check_complete = False\n",
        "    while check_complete == False:\n",
        "        for idx,sentence in enumerate(ndf['text']):\n",
        "            test = claim.lower() in sentence.lower()\n",
        "            if test:\n",
        "                article = ref_data['Article'][i]\n",
        "                cdc_idx_dict[idx] = claim\n",
        "                cdc_idx_sent[idx] = [claim, sentence]\n",
        "                cdc_idx_art[idx] = [claim, article]\n",
        "                check_complete = True\n",
        "            elif idx == (len(ndf['text'])-1):\n",
        "                check_complete = True\n",
        "\n",
        "len(cdc_idx_dict), ref_data.shape[0]"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(5, 1332)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 512
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "outputId": "108b3dae-fb98-4b9c-fdb8-c1f7f60ff29b",
        "id": "InK3liqE-gys",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "cdc_idx_dict"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{16: 'no rights should ever be allowed to be taken away by the government',\n",
              " 18: 'it would be of no use to forbid law-abiding citizens to own legal registered guns in accordance to the law',\n",
              " 19: 'regions where gun ownership is widespread were the ones with the smallest number of gun-related deaths',\n",
              " 21: 'their only reason to exist is to harm others',\n",
              " 24: 'guns are needed for personal security'}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 513
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "IscuooSE-gyt",
        "colab": {}
      },
      "source": [
        "cdc = []\n",
        "\n",
        "for x in range(len(ndf)):\n",
        "    if x in list(cdc_idx_dict.keys()):\n",
        "        cdc.append(cdc_idx_dict.get(x))\n",
        "    else:\n",
        "        cdc.append('---')\n",
        "ndf['cdc'] = cdc\n",
        "\n",
        "df = pd.concat([ndf, df], axis=0, ignore_index=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "-rlgLR1Y-gyt"
      },
      "source": [
        "#### Article 7"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "zmVv0JAj-gyu",
        "colab": {}
      },
      "source": [
        "with open(articles_dict[articles[7].replace(' ','_')+'.txt']) as article:\n",
        "        doc = article.read()\n",
        "\n",
        "c_doc = text_cleaner(doc)\n",
        "sentences = nltk.sent_tokenize(c_doc)\n",
        "sentences = [[sent, topic, articles[7]] for sent in sentences]\n",
        "\n",
        "ndf = pd.DataFrame(sentences, columns=['text', 'topic', 'article'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "outputId": "a67dd74b-98e2-414f-97bd-aea56ca13102",
        "id": "0XWZJmq2-gyu",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "cdc_idx_dict = {}\n",
        "cdc_idx_sent = {}\n",
        "cdc_idx_art = {}\n",
        "\n",
        "for i,claim in enumerate(ref_data['clean_Claim']):\n",
        "    check_complete = False\n",
        "    while check_complete == False:\n",
        "        for idx,sentence in enumerate(ndf['text']):\n",
        "            test = claim.lower() in sentence.lower()\n",
        "            if test:\n",
        "                article = ref_data['Article'][i]\n",
        "                cdc_idx_dict[idx] = claim\n",
        "                cdc_idx_sent[idx] = [claim, sentence]\n",
        "                cdc_idx_art[idx] = [claim, article]\n",
        "                check_complete = True\n",
        "            elif idx == (len(ndf['text'])-1):\n",
        "                check_complete = True\n",
        "\n",
        "len(cdc_idx_dict), ref_data.shape[0]"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(9, 1332)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 516
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "outputId": "5e9eee71-dfdc-4f70-d214-69386bba1b3d",
        "id": "Ih1JoJXs-gyv",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "cdc_idx_dict"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{364: 'there were substantial correlations between gun ownership and gun-related suicide and homicide rates',\n",
              " 368: 'easier access to guns lead to more violence',\n",
              " 390: 'laws which make it easier for law-abiding citizens to get a permit to carry a gun in public places, cause reductions in crime',\n",
              " 391: 'allowing law-abiding citizens to carry concealed firearms deters crime',\n",
              " 394: 'gun laws generally had no significant effect on violent crime rates or suicide rates',\n",
              " 407: 'laws that forbid the carrying of arms.. disarm only those who are neither inclined nor determined to commit crimes',\n",
              " 408: 'they serve rather to encourage than to prevent homicides',\n",
              " 428: 'gun possession is a civil right',\n",
              " 447: \"an armed citizens' militia can help deter crime and tyranny\"}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 517
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "DG2cOoxj-gyv",
        "colab": {}
      },
      "source": [
        "cdc = []\n",
        "\n",
        "for x in range(len(ndf)):\n",
        "    if x in list(cdc_idx_dict.keys()):\n",
        "        cdc.append(cdc_idx_dict.get(x))\n",
        "    else:\n",
        "        cdc.append('---')\n",
        "ndf['cdc'] = cdc\n",
        "\n",
        "df = pd.concat([ndf, df], axis=0, ignore_index=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "oblL-bjL-gyw"
      },
      "source": [
        "#### Article 8"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "7MyYzEUe-gyw",
        "colab": {}
      },
      "source": [
        "with open(articles_dict[articles[8].replace(' ','_')+'.txt']) as article:\n",
        "        doc = article.read()\n",
        "\n",
        "c_doc = text_cleaner(doc)\n",
        "sentences = nltk.sent_tokenize(c_doc)\n",
        "sentences = [[sent, topic, articles[8]] for sent in sentences]\n",
        "\n",
        "ndf = pd.DataFrame(sentences, columns=['text', 'topic', 'article'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "outputId": "d4cd3f89-8f43-4dd4-c2f7-0186680d8804",
        "id": "osmlFVey-gyx",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "cdc_idx_dict = {}\n",
        "cdc_idx_sent = {}\n",
        "cdc_idx_art = {}\n",
        "\n",
        "for i,claim in enumerate(ref_data['clean_Claim']):\n",
        "    check_complete = False\n",
        "    while check_complete == False:\n",
        "        for idx,sentence in enumerate(ndf['text']):\n",
        "            test = claim.lower() in sentence.lower()\n",
        "            if test:\n",
        "                article = ref_data['Article'][i]\n",
        "                cdc_idx_dict[idx] = claim\n",
        "                cdc_idx_sent[idx] = [claim, sentence]\n",
        "                cdc_idx_art[idx] = [claim, article]\n",
        "                check_complete = True\n",
        "            elif idx == (len(ndf['text'])-1):\n",
        "                check_complete = True\n",
        "\n",
        "len(cdc_idx_dict), ref_data.shape[0]"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(6, 1332)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 520
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "outputId": "c2a6c385-ba20-4d5f-c65e-770346e10731",
        "id": "uSbdWKFj-gyy",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "cdc_idx_dict"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{3: 'gun control laws are effective in reducing gun-related accidents and crime',\n",
              " 4: 'gun control laws are ineffective in reducing gun-related accidents and crime',\n",
              " 6: \"the Second Amendment guarantees an individual's right to own a firearm\",\n",
              " 71: 'fewer restrictions on handguns will result in increasing numbers of injuries and deaths',\n",
              " 78: 'Defensive use of guns is both common and effective in preventing injury and property loss',\n",
              " 85: 'gun bans would increase injuries and deaths'}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 521
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "1oZ0dU22-gyz",
        "colab": {}
      },
      "source": [
        "cdc = []\n",
        "\n",
        "for x in range(len(ndf)):\n",
        "    if x in list(cdc_idx_dict.keys()):\n",
        "        cdc.append(cdc_idx_dict.get(x))\n",
        "    else:\n",
        "        cdc.append('---')\n",
        "ndf['cdc'] = cdc\n",
        "\n",
        "df = pd.concat([ndf, df], axis=0, ignore_index=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "P-v3E5wE-gy1"
      },
      "source": [
        "#### Article 9"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "PhxtF8Gc-gy1",
        "colab": {}
      },
      "source": [
        "with open(articles_dict[articles[9].replace(' ','_')+'.txt']) as article:\n",
        "        doc = article.read()\n",
        "\n",
        "c_doc = text_cleaner(doc)\n",
        "sentences = nltk.sent_tokenize(c_doc)\n",
        "sentences = [[sent, topic, articles[9]] for sent in sentences]\n",
        "\n",
        "ndf = pd.DataFrame(sentences, columns=['text', 'topic', 'article'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "outputId": "b0927001-906b-4235-e5b8-52709ffd0248",
        "id": "bdJllaHa-gy3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "cdc_idx_dict = {}\n",
        "cdc_idx_sent = {}\n",
        "cdc_idx_art = {}\n",
        "\n",
        "for i,claim in enumerate(ref_data['clean_Claim']):\n",
        "    check_complete = False\n",
        "    while check_complete == False:\n",
        "        for idx,sentence in enumerate(ndf['text']):\n",
        "            test = claim.lower() in sentence.lower()\n",
        "            if test:\n",
        "                article = ref_data['Article'][i]\n",
        "                cdc_idx_dict[idx] = claim\n",
        "                cdc_idx_sent[idx] = [claim, sentence]\n",
        "                cdc_idx_art[idx] = [claim, article]\n",
        "                check_complete = True\n",
        "            elif idx == (len(ndf['text'])-1):\n",
        "                check_complete = True\n",
        "\n",
        "len(cdc_idx_dict), ref_data.shape[0]"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(11, 1332)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 524
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "outputId": "fc1e5eaf-7f0d-41fb-c92d-9fe9344b1d6e",
        "id": "yammTfsT-gy4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "cdc_idx_dict"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{5: 'there were significant correlations between gun ownership and gun-related suicide and homicide rates',\n",
              " 9: 'the access to guns leads to more violence',\n",
              " 38: 'laws which make it easier for law-abiding citizens to get a permit to carry a gun in public places, cause reductions in crime',\n",
              " 39: 'allowing law-abiding citizens to carry concealed firearms deters crime',\n",
              " 45: 'gun laws generally had no significant effect on violent crime rates or suicide rates',\n",
              " 56: 'laws that forbid the carrying of arms.. disarm only those who are neither inclined nor determined to commit crimes',\n",
              " 57: 'they serve rather to encourage than to prevent homicides',\n",
              " 78: 'gun ownership as a civil right',\n",
              " 81: 'gun possession is a civil right',\n",
              " 105: \"an armed citizens' militia can help deter crime and tyranny\",\n",
              " 172: 'gun control works'}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 525
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "FwOQWzuZ-gy5",
        "colab": {}
      },
      "source": [
        "cdc = []\n",
        "\n",
        "for x in range(len(ndf)):\n",
        "    if x in list(cdc_idx_dict.keys()):\n",
        "        cdc.append(cdc_idx_dict.get(x))\n",
        "    else:\n",
        "        cdc.append('---')\n",
        "ndf['cdc'] = cdc\n",
        "\n",
        "df = pd.concat([ndf, df], axis=0, ignore_index=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J8BPtbO2ytJt",
        "colab_type": "text"
      },
      "source": [
        "### 'make physical education compulsory '"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "outputId": "acf55abe-d9ed-447d-fc7b-675fdfc6220b",
        "id": "Leh3vKXO1Ysa",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 238
        }
      },
      "source": [
        "topic = 'make physical education compulsory '\n",
        "\n",
        "articles = topic_article_dict[topic]\n",
        "articles"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['Physical exercise',\n",
              " 'Physical fitness',\n",
              " 'Overweight',\n",
              " 'Active Living',\n",
              " 'Exercise trends',\n",
              " 'Health',\n",
              " 'Physical education',\n",
              " 'Democratic education',\n",
              " 'Obesity',\n",
              " 'Recess (break)',\n",
              " 'Childhood obesity',\n",
              " 'Summerhill School',\n",
              " 'Sedentary lifestyle']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 527
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4FWuGFZS1Yc6",
        "colab_type": "code",
        "outputId": "d64c05fd-d509-4343-8d39-bf12b637da32",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "len(articles)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "13"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 528
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "EWgv7pz61Ysc"
      },
      "source": [
        "#### Article 0 "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "SddRp6WC1Ysc",
        "colab": {}
      },
      "source": [
        "with open(articles_dict[articles[0].replace(' ','_')+'.txt']) as article:\n",
        "        doc = article.read()\n",
        "\n",
        "c_doc = text_cleaner(doc)\n",
        "sentences = nltk.sent_tokenize(c_doc)\n",
        "sentences = [[sent, topic, articles[0]] for sent in sentences]\n",
        "\n",
        "ndf = pd.DataFrame(sentences, columns=['text', 'topic', 'article'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "outputId": "ae4cbd45-f215-4d73-a6a8-ae7786ed24b7",
        "id": "RTcr4bhW1Ysd",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "cdc_idx_dict = {}\n",
        "cdc_idx_sent = {}\n",
        "cdc_idx_art = {}\n",
        "\n",
        "for i,claim in enumerate(ref_data['clean_Claim']):\n",
        "    check_complete = False\n",
        "    while check_complete == False:\n",
        "        for idx,sentence in enumerate(ndf['text']):\n",
        "            test = claim.lower() in sentence.lower()\n",
        "            if test:\n",
        "                article = ref_data['Article'][i]\n",
        "                cdc_idx_dict[idx] = claim\n",
        "                cdc_idx_sent[idx] = [claim, sentence]\n",
        "                cdc_idx_art[idx] = [claim, article]\n",
        "                check_complete = True\n",
        "            elif idx == (len(ndf['text'])-1):\n",
        "                check_complete = True\n",
        "\n",
        "len(cdc_idx_dict), ref_data.shape[0]"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(10, 1332)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 530
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "outputId": "9c5af4db-9b22-4270-b3be-9a19c514dfe5",
        "id": "JHxaZnwN1Yse",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "cdc_idx_dict"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{3: 'helps prevent the \"diseases of affluence',\n",
              " 4: 'It also improves mental health',\n",
              " 5: 'physical exercise may help decrease some of the effects of childhood and adult obesity',\n",
              " 21: 'strengthening the immune system',\n",
              " 23: 'Frequent and regular aerobic exercise has been shown to help prevent or treat serious and life-threatening chronic conditions',\n",
              " 33: 'Not everyone benefits equally from exercise',\n",
              " 45: 'moderate exercise has a beneficial effect on the human immune system',\n",
              " 68: 'Exercise alone is a potential prevention method andor treatment for mild forms of depression',\n",
              " 76: 'Too much exercise can be harmful',\n",
              " 79: 'Inappropriate exercise can do more harm than good'}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 531
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "f9j1wE1N1Yse",
        "colab": {}
      },
      "source": [
        "cdc = []\n",
        "\n",
        "for x in range(len(ndf)):\n",
        "    if x in list(cdc_idx_dict.keys()):\n",
        "        cdc.append(cdc_idx_dict.get(x))\n",
        "    else:\n",
        "        cdc.append('---')\n",
        "ndf['cdc'] = cdc\n",
        "\n",
        "df = pd.concat([ndf, df], axis=0, ignore_index=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "qoFwcgIr1Ysf"
      },
      "source": [
        "#### Article 1 "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "8gJzTILs1Ysf",
        "colab": {}
      },
      "source": [
        "with open(articles_dict[articles[1].replace(' ','_')+'.txt']) as article:\n",
        "        doc = article.read()\n",
        "\n",
        "c_doc = text_cleaner(doc)\n",
        "sentences = nltk.sent_tokenize(c_doc)\n",
        "sentences = [[sent, topic, articles[1]] for sent in sentences]\n",
        "\n",
        "ndf = pd.DataFrame(sentences, columns=['text', 'topic', 'article'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "outputId": "4a35255e-7c7b-4a61-a76f-e8921b8fe3f5",
        "id": "M5h24ikO1Ysg",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "cdc_idx_dict = {}\n",
        "cdc_idx_sent = {}\n",
        "cdc_idx_art = {}\n",
        "\n",
        "for i,claim in enumerate(ref_data['clean_Claim']):\n",
        "    check_complete = False\n",
        "    while check_complete == False:\n",
        "        for idx,sentence in enumerate(ndf['text']):\n",
        "            test = claim.lower() in sentence.lower()\n",
        "            if test:\n",
        "                article = ref_data['Article'][i]\n",
        "                cdc_idx_dict[idx] = claim\n",
        "                cdc_idx_sent[idx] = [claim, sentence]\n",
        "                cdc_idx_art[idx] = [claim, article]\n",
        "                check_complete = True\n",
        "            elif idx == (len(ndf['text'])-1):\n",
        "                check_complete = True\n",
        "\n",
        "len(cdc_idx_dict), ref_data.shape[0]"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(2, 1332)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 534
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "outputId": "79bc3e6b-ee4c-46dd-b2d9-f86a971e4f8b",
        "id": "4Ha-JP031Ysi",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "cdc_idx_dict"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{11: 'Physical fitness can also prevent or treat many chronic health conditions',\n",
              " 13: 'To stay healthy it is important to engage in physical activity'}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 535
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "8WiXp6iM1Ysj",
        "colab": {}
      },
      "source": [
        "cdc = []\n",
        "\n",
        "for x in range(len(ndf)):\n",
        "    if x in list(cdc_idx_dict.keys()):\n",
        "        cdc.append(cdc_idx_dict.get(x))\n",
        "    else:\n",
        "        cdc.append('---')\n",
        "ndf['cdc'] = cdc\n",
        "\n",
        "df = pd.concat([df, ndf], axis=0, ignore_index=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "cJlmp3Et1Ysl"
      },
      "source": [
        "#### Article 2 "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "MSycf4RJ1Ysm",
        "colab": {}
      },
      "source": [
        "with open(articles_dict[articles[2].replace(' ','_')+'.txt']) as article:\n",
        "        doc = article.read()\n",
        "\n",
        "c_doc = text_cleaner(doc)\n",
        "sentences = nltk.sent_tokenize(c_doc)\n",
        "sentences = [[sent, topic, articles[2]] for sent in sentences]\n",
        "\n",
        "ndf = pd.DataFrame(sentences, columns=['text', 'topic', 'article'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "outputId": "6a569292-9393-40fc-c751-acd477255192",
        "id": "YMKuqAPI1Ysm",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "cdc_idx_dict = {}\n",
        "cdc_idx_sent = {}\n",
        "cdc_idx_art = {}\n",
        "\n",
        "for i,claim in enumerate(ref_data['clean_Claim']):\n",
        "    check_complete = False\n",
        "    while check_complete == False:\n",
        "        for idx,sentence in enumerate(ndf['text']):\n",
        "            test = claim.lower() in sentence.lower()\n",
        "            if test:\n",
        "                article = ref_data['Article'][i]\n",
        "                cdc_idx_dict[idx] = claim\n",
        "                cdc_idx_sent[idx] = [claim, sentence]\n",
        "                cdc_idx_art[idx] = [claim, article]\n",
        "                check_complete = True\n",
        "            elif idx == (len(ndf['text'])-1):\n",
        "                check_complete = True\n",
        "\n",
        "len(cdc_idx_dict), ref_data.shape[0]"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(1, 1332)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 538
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "outputId": "5a5588e7-a572-4913-a531-27de82727282",
        "id": "r2fErmp61Yso",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "cdc_idx_dict"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{3: 'Excess weight has reached epidemic proportions globally'}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 539
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "vpA0ipax1Ysp",
        "colab": {}
      },
      "source": [
        "cdc = []\n",
        "\n",
        "for x in range(len(ndf)):\n",
        "    if x in list(cdc_idx_dict.keys()):\n",
        "        cdc.append(cdc_idx_dict.get(x))\n",
        "    else:\n",
        "        cdc.append('---')\n",
        "ndf['cdc'] = cdc\n",
        "\n",
        "df = pd.concat([ndf, df], axis=0, ignore_index=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "SMRCnUv_1Ysq"
      },
      "source": [
        "#### Article 3 "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "8yk-TS5w1Ysq",
        "colab": {}
      },
      "source": [
        "with open(articles_dict[articles[3].replace(' ','_')+'.txt']) as article:\n",
        "        doc = article.read()\n",
        "\n",
        "c_doc = text_cleaner(doc)\n",
        "sentences = nltk.sent_tokenize(c_doc)\n",
        "sentences = [[sent, topic, articles[3]] for sent in sentences]\n",
        "\n",
        "ndf = pd.DataFrame(sentences, columns=['text', 'topic', 'article'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "outputId": "438107b1-725b-452c-aea5-9addcc9df1ba",
        "id": "TKnR_UiE1Yss",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "cdc_idx_dict = {}\n",
        "cdc_idx_sent = {}\n",
        "cdc_idx_art = {}\n",
        "\n",
        "for i,claim in enumerate(ref_data['clean_Claim']):\n",
        "    check_complete = False\n",
        "    while check_complete == False:\n",
        "        for idx,sentence in enumerate(ndf['text']):\n",
        "            test = claim.lower() in sentence.lower()\n",
        "            if test:\n",
        "                article = ref_data['Article'][i]\n",
        "                cdc_idx_dict[idx] = claim\n",
        "                cdc_idx_sent[idx] = [claim, sentence]\n",
        "                cdc_idx_art[idx] = [claim, article]\n",
        "                check_complete = True\n",
        "            elif idx == (len(ndf['text'])-1):\n",
        "                check_complete = True\n",
        "\n",
        "len(cdc_idx_dict), ref_data.shape[0]"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(1, 1332)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 542
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "outputId": "c0b76b65-2253-49e1-9891-e44f71c4864c",
        "id": "jq1Klj1Y1Yst",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "cdc_idx_dict"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{12: 'There are many health related benefits to being physically active'}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 543
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "HCyzdpKB1Ysu",
        "colab": {}
      },
      "source": [
        "cdc = []\n",
        "\n",
        "for x in range(len(ndf)):\n",
        "    if x in list(cdc_idx_dict.keys()):\n",
        "        cdc.append(cdc_idx_dict.get(x))\n",
        "    else:\n",
        "        cdc.append('---')\n",
        "ndf['cdc'] = cdc\n",
        "\n",
        "df = pd.concat([ndf, df], axis=0, ignore_index=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "ztGdoL5z1Ysv"
      },
      "source": [
        "#### Article 4 "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "I6Y2zITk1Ysv",
        "colab": {}
      },
      "source": [
        "with open(articles_dict[articles[4].replace(' ','_')+'.txt']) as article:\n",
        "        doc = article.read()\n",
        "\n",
        "c_doc = text_cleaner(doc)\n",
        "sentences = nltk.sent_tokenize(c_doc)\n",
        "sentences = [[sent, topic, articles[4]] for sent in sentences]\n",
        "\n",
        "ndf = pd.DataFrame(sentences, columns=['text', 'topic', 'article'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "outputId": "31b9e1c3-51ff-4664-a735-f499d604a2ea",
        "id": "auQHZERT1Ysw",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "cdc_idx_dict = {}\n",
        "cdc_idx_sent = {}\n",
        "cdc_idx_art = {}\n",
        "\n",
        "for i,claim in enumerate(ref_data['clean_Claim']):\n",
        "    check_complete = False\n",
        "    while check_complete == False:\n",
        "        for idx,sentence in enumerate(ndf['text']):\n",
        "            test = claim.lower() in sentence.lower()\n",
        "            if test:\n",
        "                article = ref_data['Article'][i]\n",
        "                cdc_idx_dict[idx] = claim\n",
        "                cdc_idx_sent[idx] = [claim, sentence]\n",
        "                cdc_idx_art[idx] = [claim, article]\n",
        "                check_complete = True\n",
        "            elif idx == (len(ndf['text'])-1):\n",
        "                check_complete = True\n",
        "\n",
        "len(cdc_idx_dict), ref_data.shape[0]"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(2, 1332)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 546
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "outputId": "d68fd2e6-e820-412f-ad53-724ebf99e57b",
        "id": "bucxlkNy1Ysw",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "cdc_idx_dict"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{10: 'Physical inactivity is increasing or high among many groups in the population',\n",
              " 15: 'inactivity one of the leading preventable causes of death worldwide'}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 547
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "QCKtMdng1Ysx",
        "colab": {}
      },
      "source": [
        "cdc = []\n",
        "\n",
        "for x in range(len(ndf)):\n",
        "    if x in list(cdc_idx_dict.keys()):\n",
        "        cdc.append(cdc_idx_dict.get(x))\n",
        "    else:\n",
        "        cdc.append('---')\n",
        "ndf['cdc'] = cdc\n",
        "\n",
        "df = pd.concat([ndf, df], axis=0, ignore_index=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "OdooBGyS-nPf"
      },
      "source": [
        "#### Article 5 "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "46OU8xNN-nPf",
        "colab": {}
      },
      "source": [
        "with open(articles_dict[articles[5].replace(' ','_')+'.txt']) as article:\n",
        "        doc = article.read()\n",
        "\n",
        "c_doc = text_cleaner(doc)\n",
        "sentences = nltk.sent_tokenize(c_doc)\n",
        "sentences = [[sent, topic, articles[5]] for sent in sentences]\n",
        "\n",
        "ndf = pd.DataFrame(sentences, columns=['text', 'topic', 'article'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "outputId": "f62c3698-3b85-4fbb-b4f2-c49cf4fe4132",
        "id": "PXNha41C-nPg",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "cdc_idx_dict = {}\n",
        "cdc_idx_sent = {}\n",
        "cdc_idx_art = {}\n",
        "\n",
        "for i,claim in enumerate(ref_data['clean_Claim']):\n",
        "    check_complete = False\n",
        "    while check_complete == False:\n",
        "        for idx,sentence in enumerate(ndf['text']):\n",
        "            test = claim.lower() in sentence.lower()\n",
        "            if test:\n",
        "                article = ref_data['Article'][i]\n",
        "                cdc_idx_dict[idx] = claim\n",
        "                cdc_idx_sent[idx] = [claim, sentence]\n",
        "                cdc_idx_art[idx] = [claim, article]\n",
        "                check_complete = True\n",
        "            elif idx == (len(ndf['text'])-1):\n",
        "                check_complete = True\n",
        "\n",
        "len(cdc_idx_dict), ref_data.shape[0]"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(1, 1332)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 550
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "outputId": "bba58376-e6f7-40f8-fe26-abb274e3b4e7",
        "id": "7pHxv3kM-nPh",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "cdc_idx_dict"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{21: 'people can improve their health via exercise'}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 551
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "5YXD4F7N-nPi",
        "colab": {}
      },
      "source": [
        "cdc = []\n",
        "\n",
        "for x in range(len(ndf)):\n",
        "    if x in list(cdc_idx_dict.keys()):\n",
        "        cdc.append(cdc_idx_dict.get(x))\n",
        "    else:\n",
        "        cdc.append('---')\n",
        "ndf['cdc'] = cdc\n",
        "\n",
        "df = pd.concat([ndf, df], axis=0, ignore_index=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "3lf61eK--nPj"
      },
      "source": [
        "#### Article 6"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "upv95Oyp-nPj",
        "colab": {}
      },
      "source": [
        "with open(articles_dict[articles[6].replace(' ','_')+'.txt']) as article:\n",
        "        doc = article.read()\n",
        "\n",
        "c_doc = text_cleaner(doc)\n",
        "sentences = nltk.sent_tokenize(c_doc)\n",
        "sentences = [[sent, topic, articles[6]] for sent in sentences]\n",
        "\n",
        "ndf = pd.DataFrame(sentences, columns=['text', 'topic', 'article'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "outputId": "19e88975-032e-48ff-9613-aee86dc7371f",
        "id": "CEGbdGKx-nPk",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "cdc_idx_dict = {}\n",
        "cdc_idx_sent = {}\n",
        "cdc_idx_art = {}\n",
        "\n",
        "for i,claim in enumerate(ref_data['clean_Claim']):\n",
        "    check_complete = False\n",
        "    while check_complete == False:\n",
        "        for idx,sentence in enumerate(ndf['text']):\n",
        "            test = claim.lower() in sentence.lower()\n",
        "            if test:\n",
        "                article = ref_data['Article'][i]\n",
        "                cdc_idx_dict[idx] = claim\n",
        "                cdc_idx_sent[idx] = [claim, sentence]\n",
        "                cdc_idx_art[idx] = [claim, article]\n",
        "                check_complete = True\n",
        "            elif idx == (len(ndf['text'])-1):\n",
        "                check_complete = True\n",
        "\n",
        "len(cdc_idx_dict), ref_data.shape[0]"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(2, 1332)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 554
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "outputId": "95f59388-4549-40c8-e6f7-c7eb10bc9883",
        "id": "7DoVcULa-nPk",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "cdc_idx_dict"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{5: 'Introducing students to activities like bowling, walkinghiking, or Frisbee at an early age can help students develop good activity habits that will carry over into adulthood',\n",
              " 7: 'Teaching non-traditional sports to students may also provide the necessary motivation for students to increase their activity, and can help students learn about different cultures'}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 555
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "h3UOfq2s-nPl",
        "colab": {}
      },
      "source": [
        "cdc = []\n",
        "\n",
        "for x in range(len(ndf)):\n",
        "    if x in list(cdc_idx_dict.keys()):\n",
        "        cdc.append(cdc_idx_dict.get(x))\n",
        "    else:\n",
        "        cdc.append('---')\n",
        "ndf['cdc'] = cdc\n",
        "\n",
        "df = pd.concat([ndf, df], axis=0, ignore_index=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "FBN5hCnm-nPm"
      },
      "source": [
        "#### Article 7"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "Pdms1__m-nPm",
        "colab": {}
      },
      "source": [
        "with open(articles_dict[articles[7].replace(' ','_')+'.txt']) as article:\n",
        "        doc = article.read()\n",
        "\n",
        "c_doc = text_cleaner(doc)\n",
        "sentences = nltk.sent_tokenize(c_doc)\n",
        "sentences = [[sent, topic, articles[7]] for sent in sentences]\n",
        "\n",
        "ndf = pd.DataFrame(sentences, columns=['text', 'topic', 'article'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "outputId": "1f4069df-88e2-4fce-bcdc-0c15d49c03c7",
        "id": "aGgCzeeT-nPn",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "cdc_idx_dict = {}\n",
        "cdc_idx_sent = {}\n",
        "cdc_idx_art = {}\n",
        "\n",
        "for i,claim in enumerate(ref_data['clean_Claim']):\n",
        "    check_complete = False\n",
        "    while check_complete == False:\n",
        "        for idx,sentence in enumerate(ndf['text']):\n",
        "            test = claim.lower() in sentence.lower()\n",
        "            if test:\n",
        "                article = ref_data['Article'][i]\n",
        "                cdc_idx_dict[idx] = claim\n",
        "                cdc_idx_sent[idx] = [claim, sentence]\n",
        "                cdc_idx_art[idx] = [claim, article]\n",
        "                check_complete = True\n",
        "            elif idx == (len(ndf['text'])-1):\n",
        "                check_complete = True\n",
        "\n",
        "len(cdc_idx_dict), ref_data.shape[0]"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(1, 1332)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 558
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "outputId": "34c3d758-187d-4234-97ed-b9f91a2131e3",
        "id": "6ZUeGEHQ-nPo",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "cdc_idx_dict"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{91: 'the model of ideal education is that which occurs when people go on their own initiative to discover things'}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 559
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "D6Rh_2YF-nPp",
        "colab": {}
      },
      "source": [
        "cdc = []\n",
        "\n",
        "for x in range(len(ndf)):\n",
        "    if x in list(cdc_idx_dict.keys()):\n",
        "        cdc.append(cdc_idx_dict.get(x))\n",
        "    else:\n",
        "        cdc.append('---')\n",
        "ndf['cdc'] = cdc\n",
        "\n",
        "df = pd.concat([ndf, df], axis=0, ignore_index=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "d_psEZwu-nPq"
      },
      "source": [
        "#### Article 8"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "PWeIchKt-nPq",
        "colab": {}
      },
      "source": [
        "with open(articles_dict[articles[8].replace(' ','_')+'.txt']) as article:\n",
        "        doc = article.read()\n",
        "\n",
        "c_doc = text_cleaner(doc)\n",
        "sentences = nltk.sent_tokenize(c_doc)\n",
        "sentences = [[sent, topic, articles[8]] for sent in sentences]\n",
        "\n",
        "ndf = pd.DataFrame(sentences, columns=['text', 'topic', 'article'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "outputId": "6f7ae82c-6d5e-4215-c976-218e8e07a21e",
        "id": "fY3XV3-J-nPr",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "cdc_idx_dict = {}\n",
        "cdc_idx_sent = {}\n",
        "cdc_idx_art = {}\n",
        "\n",
        "for i,claim in enumerate(ref_data['clean_Claim']):\n",
        "    check_complete = False\n",
        "    while check_complete == False:\n",
        "        for idx,sentence in enumerate(ndf['text']):\n",
        "            test = claim.lower() in sentence.lower()\n",
        "            if test:\n",
        "                article = ref_data['Article'][i]\n",
        "                cdc_idx_dict[idx] = claim\n",
        "                cdc_idx_sent[idx] = [claim, sentence]\n",
        "                cdc_idx_art[idx] = [claim, article]\n",
        "                check_complete = True\n",
        "            elif idx == (len(ndf['text'])-1):\n",
        "                check_complete = True\n",
        "\n",
        "len(cdc_idx_dict), ref_data.shape[0]"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(1, 1332)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 562
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "outputId": "a19f5b29-6784-4a5f-a904-b8041a71a682",
        "id": "IoshIe6H-nPs",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "cdc_idx_dict"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{65: 'a lack of physical activity is thought to explain most cases of obesity'}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 563
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "XDteXceO-nPt",
        "colab": {}
      },
      "source": [
        "cdc = []\n",
        "\n",
        "for x in range(len(ndf)):\n",
        "    if x in list(cdc_idx_dict.keys()):\n",
        "        cdc.append(cdc_idx_dict.get(x))\n",
        "    else:\n",
        "        cdc.append('---')\n",
        "ndf['cdc'] = cdc\n",
        "\n",
        "df = pd.concat([ndf, df], axis=0, ignore_index=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "GQ6m5xY_-nPt"
      },
      "source": [
        "#### Article 9"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "xywH0D_K-nPu",
        "colab": {}
      },
      "source": [
        "with open(articles_dict[articles[9].replace(' ','_')+'.txt']) as article:\n",
        "        doc = article.read()\n",
        "\n",
        "c_doc = text_cleaner(doc)\n",
        "sentences = nltk.sent_tokenize(c_doc)\n",
        "sentences = [[sent, topic, articles[9]] for sent in sentences]\n",
        "\n",
        "ndf = pd.DataFrame(sentences, columns=['text', 'topic', 'article'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "outputId": "fdb6376f-9388-41da-c8aa-3a83f58280b5",
        "id": "B4IE8dub-nPv",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "cdc_idx_dict = {}\n",
        "cdc_idx_sent = {}\n",
        "cdc_idx_art = {}\n",
        "\n",
        "for i,claim in enumerate(ref_data['clean_Claim']):\n",
        "    check_complete = False\n",
        "    while check_complete == False:\n",
        "        for idx,sentence in enumerate(ndf['text']):\n",
        "            test = claim.lower() in sentence.lower()\n",
        "            if test:\n",
        "                article = ref_data['Article'][i]\n",
        "                cdc_idx_dict[idx] = claim\n",
        "                cdc_idx_sent[idx] = [claim, sentence]\n",
        "                cdc_idx_art[idx] = [claim, article]\n",
        "                check_complete = True\n",
        "            elif idx == (len(ndf['text'])-1):\n",
        "                check_complete = True\n",
        "\n",
        "len(cdc_idx_dict), ref_data.shape[0]"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(1, 1332)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 566
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "outputId": "905ca503-784f-4215-d7b0-1466af20ac99",
        "id": "JAx8IdlV-nPv",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "cdc_idx_dict"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{17: 'youth do not get the physical outlet needed not only for their cognitive development but for their physical health'}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 567
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "CuryqoyF-nPw",
        "colab": {}
      },
      "source": [
        "cdc = []\n",
        "\n",
        "for x in range(len(ndf)):\n",
        "    if x in list(cdc_idx_dict.keys()):\n",
        "        cdc.append(cdc_idx_dict.get(x))\n",
        "    else:\n",
        "        cdc.append('---')\n",
        "ndf['cdc'] = cdc\n",
        "\n",
        "df = pd.concat([ndf, df], axis=0, ignore_index=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "sGS0b0hb-nPx"
      },
      "source": [
        "#### Article 10"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "uFOlz5hT-nPx",
        "colab": {}
      },
      "source": [
        "with open(articles_dict[articles[10].replace(' ','_')+'.txt']) as article:\n",
        "        doc = article.read()\n",
        "\n",
        "c_doc = text_cleaner(doc)\n",
        "sentences = nltk.sent_tokenize(c_doc)\n",
        "sentences = [[sent, topic, articles[10]] for sent in sentences]\n",
        "\n",
        "ndf = pd.DataFrame(sentences, columns=['text', 'topic', 'article'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "outputId": "159a2cb5-069c-48f4-c580-3815ca017168",
        "id": "YAjJAuyx-nPy",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "cdc_idx_dict = {}\n",
        "cdc_idx_sent = {}\n",
        "cdc_idx_art = {}\n",
        "\n",
        "for i,claim in enumerate(ref_data['clean_Claim']):\n",
        "    check_complete = False\n",
        "    while check_complete == False:\n",
        "        for idx,sentence in enumerate(ndf['text']):\n",
        "            test = claim.lower() in sentence.lower()\n",
        "            if test:\n",
        "                article = ref_data['Article'][i]\n",
        "                cdc_idx_dict[idx] = claim\n",
        "                cdc_idx_sent[idx] = [claim, sentence]\n",
        "                cdc_idx_art[idx] = [claim, article]\n",
        "                check_complete = True\n",
        "            elif idx == (len(ndf['text'])-1):\n",
        "                check_complete = True\n",
        "\n",
        "len(cdc_idx_dict), ref_data.shape[0]"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(3, 1332)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 570
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "outputId": "1b0c9f71-7c54-49f6-8e21-f75f4544ffdd",
        "id": "_dwcDK9t-nPz",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "cdc_idx_dict"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{56: 'children who fail to engage in regular physical activity are at greater risk of obesity',\n",
              " 59: 'Physical inactivity as a child could result in physical inactivity as an adult',\n",
              " 73: 'Childhood inactivity is linked to obesity'}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 571
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "5zftmAX_-nP0",
        "colab": {}
      },
      "source": [
        "cdc = []\n",
        "\n",
        "for x in range(len(ndf)):\n",
        "    if x in list(cdc_idx_dict.keys()):\n",
        "        cdc.append(cdc_idx_dict.get(x))\n",
        "    else:\n",
        "        cdc.append('---')\n",
        "ndf['cdc'] = cdc\n",
        "\n",
        "df = pd.concat([ndf, df], axis=0, ignore_index=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "nUyyhUe8-nP1"
      },
      "source": [
        "#### Article 11 "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "rArYDbAj-nP1",
        "colab": {}
      },
      "source": [
        "with open(articles_dict[articles[11].replace(' ','_')+'.txt']) as article:\n",
        "        doc = article.read()\n",
        "\n",
        "c_doc = text_cleaner(doc)\n",
        "sentences = nltk.sent_tokenize(c_doc)\n",
        "sentences = [[sent, topic, articles[11]] for sent in sentences]\n",
        "\n",
        "ndf = pd.DataFrame(sentences, columns=['text', 'topic', 'article'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "outputId": "45b263cd-7998-430d-ee4b-d5eba5096df9",
        "id": "weakAhGf-nP2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "cdc_idx_dict = {}\n",
        "cdc_idx_sent = {}\n",
        "cdc_idx_art = {}\n",
        "\n",
        "for i,claim in enumerate(ref_data['clean_Claim']):\n",
        "    check_complete = False\n",
        "    while check_complete == False:\n",
        "        for idx,sentence in enumerate(ndf['text']):\n",
        "            test = claim.lower() in sentence.lower()\n",
        "            if test:\n",
        "                article = ref_data['Article'][i]\n",
        "                cdc_idx_dict[idx] = claim\n",
        "                cdc_idx_sent[idx] = [claim, sentence]\n",
        "                cdc_idx_art[idx] = [claim, article]\n",
        "                check_complete = True\n",
        "            elif idx == (len(ndf['text'])-1):\n",
        "                check_complete = True\n",
        "\n",
        "len(cdc_idx_dict), ref_data.shape[0]"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(2, 1332)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 574
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "outputId": "b5cf0ab7-1f84-4199-d895-6e17277343d8",
        "id": "CblYeLE_-nP3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "cdc_idx_dict"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{0: 'school should be made to fit the child, rather than the other way around',\n",
              " 16: 'children learn best with freedom from coercion'}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 575
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "A58uDXRM-nP6",
        "colab": {}
      },
      "source": [
        "cdc = []\n",
        "\n",
        "for x in range(len(ndf)):\n",
        "    if x in list(cdc_idx_dict.keys()):\n",
        "        cdc.append(cdc_idx_dict.get(x))\n",
        "    else:\n",
        "        cdc.append('---')\n",
        "ndf['cdc'] = cdc\n",
        "\n",
        "df = pd.concat([ndf, df], axis=0, ignore_index=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "9aSIBUXC-nP8"
      },
      "source": [
        "#### Article 12"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "pdyKlbkG-nP9",
        "colab": {}
      },
      "source": [
        "with open(articles_dict[articles[12].replace(' ','_')+'.txt']) as article:\n",
        "        doc = article.read()\n",
        "\n",
        "c_doc = text_cleaner(doc)\n",
        "sentences = nltk.sent_tokenize(c_doc)\n",
        "sentences = [[sent, topic, articles[12]] for sent in sentences]\n",
        "\n",
        "ndf = pd.DataFrame(sentences, columns=['text', 'topic', 'article'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "outputId": "94489e00-4fed-4eab-e56d-e21c52464fc8",
        "id": "OnxWYUTm-nP-",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "cdc_idx_dict = {}\n",
        "cdc_idx_sent = {}\n",
        "cdc_idx_art = {}\n",
        "\n",
        "for i,claim in enumerate(ref_data['clean_Claim']):\n",
        "    check_complete = False\n",
        "    while check_complete == False:\n",
        "        for idx,sentence in enumerate(ndf['text']):\n",
        "            test = claim.lower() in sentence.lower()\n",
        "            if test:\n",
        "                article = ref_data['Article'][i]\n",
        "                cdc_idx_dict[idx] = claim\n",
        "                cdc_idx_sent[idx] = [claim, sentence]\n",
        "                cdc_idx_art[idx] = [claim, article]\n",
        "                check_complete = True\n",
        "            elif idx == (len(ndf['text'])-1):\n",
        "                check_complete = True\n",
        "\n",
        "len(cdc_idx_dict), ref_data.shape[0]"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(1, 1332)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 578
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "outputId": "b62eb204-a884-4bfc-840d-a721538c8460",
        "id": "rhohwnao-nP_",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "cdc_idx_dict"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{22: 'many children lead a relatively sedentary lifestyle'}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 579
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "Xs3h2ggb-nQA",
        "colab": {}
      },
      "source": [
        "cdc = []\n",
        "\n",
        "for x in range(len(ndf)):\n",
        "    if x in list(cdc_idx_dict.keys()):\n",
        "        cdc.append(cdc_idx_dict.get(x))\n",
        "    else:\n",
        "        cdc.append('---')\n",
        "ndf['cdc'] = cdc\n",
        "\n",
        "df = pd.concat([ndf, df], axis=0, ignore_index=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HWEBdPT4yxou",
        "colab_type": "text"
      },
      "source": [
        "### 'multiculturalism '"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "outputId": "f70fdf66-88a9-408b-d9dd-647d561883ae",
        "id": "Spu46lrE1aTE",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 445
        }
      },
      "source": [
        "topic = 'multiculturalism '\n",
        "\n",
        "articles = topic_article_dict[topic]\n",
        "articles"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['Multiculturalism',\n",
              " 'Multiculturalism in Canada',\n",
              " 'Multiculturalism in Australia',\n",
              " 'Multiculturalism in the Netherlands',\n",
              " 'Cultural diversity',\n",
              " 'All for Australia',\n",
              " 'Muscular liberalism',\n",
              " 'Melting pot',\n",
              " 'Convention on the Protection and Promotion of the Diversity of Cultural Expressions',\n",
              " 'Cultural imperialism',\n",
              " 'Declaration on the Rights of Indigenous Peoples',\n",
              " 'Universal Declaration on Cultural Diversity',\n",
              " 'Canadian identity',\n",
              " 'Nationalism',\n",
              " 'Multicultural education',\n",
              " 'Minority group',\n",
              " 'Criticism of multiculturalism',\n",
              " 'Cultural competence',\n",
              " 'Alliance of Civilizations',\n",
              " 'Acculturation',\n",
              " 'Cosmopolitanism',\n",
              " 'Interminority racism',\n",
              " 'Leitkultur',\n",
              " 'Interculturalism']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 581
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ENmP63i91aEA",
        "colab_type": "code",
        "outputId": "00390608-0a0a-4c84-ceba-ee696343f27e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "len(articles)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "24"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 582
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "e63O3_MN1aTG"
      },
      "source": [
        "#### Article 0 "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "eNjrbdb21aTG",
        "colab": {}
      },
      "source": [
        "with open(articles_dict[articles[0].replace(' ','_')+'.txt']) as article:\n",
        "        doc = article.read()\n",
        "\n",
        "c_doc = text_cleaner(doc)\n",
        "sentences = nltk.sent_tokenize(c_doc)\n",
        "sentences = [[sent, topic, articles[0]] for sent in sentences]\n",
        "\n",
        "ndf = pd.DataFrame(sentences, columns=['text', 'topic', 'article'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "outputId": "88f58bb5-b4e3-4e40-f969-7ad27d21b077",
        "id": "bLUvUY-R1aTH",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "cdc_idx_dict = {}\n",
        "cdc_idx_sent = {}\n",
        "cdc_idx_art = {}\n",
        "\n",
        "for i,claim in enumerate(ref_data['clean_Claim']):\n",
        "    check_complete = False\n",
        "    while check_complete == False:\n",
        "        for idx,sentence in enumerate(ndf['text']):\n",
        "            test = claim.lower() in sentence.lower()\n",
        "            if test:\n",
        "                article = ref_data['Article'][i]\n",
        "                cdc_idx_dict[idx] = claim\n",
        "                cdc_idx_sent[idx] = [claim, sentence]\n",
        "                cdc_idx_art[idx] = [claim, article]\n",
        "                check_complete = True\n",
        "            elif idx == (len(ndf['text'])-1):\n",
        "                check_complete = True\n",
        "\n",
        "len(cdc_idx_dict), ref_data.shape[0]"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(7, 1332)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 584
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "outputId": "bb2465c4-dd3f-46f5-8991-1678b9f2e8ec",
        "id": "pVtwqLfq1aTI",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "cdc_idx_dict"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{78: 'state multiculturalism has failed',\n",
              " 82: 'is seen as an essential feature of the nation and the nation-state',\n",
              " 200: 'allows people to truly express who they are within a society',\n",
              " 204: 'promotes respect for the dignity of the lives and voices of the forgotten',\n",
              " 205: 'multiculturalism tries to restore a sense of wholeness in a postmodern era that fragments human life and thought',\n",
              " 210: \"ultimately erodes the host nations' distinct culture\",\n",
              " 212: 'the more racially diverse a community is, the greater the loss of trust'}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 585
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "nK3N11-51aTJ",
        "colab": {}
      },
      "source": [
        "cdc = []\n",
        "\n",
        "for x in range(len(ndf)):\n",
        "    if x in list(cdc_idx_dict.keys()):\n",
        "        cdc.append(cdc_idx_dict.get(x))\n",
        "    else:\n",
        "        cdc.append('---')\n",
        "ndf['cdc'] = cdc\n",
        "\n",
        "df = pd.concat([ndf, df], axis=0, ignore_index=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "PuBex5e51aTK"
      },
      "source": [
        "#### Article 1 "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "KaOgENqz1aTK",
        "colab": {}
      },
      "source": [
        "with open(articles_dict[articles[1].replace(' ','_')+'.txt']) as article:\n",
        "        doc = article.read()\n",
        "\n",
        "c_doc = text_cleaner(doc)\n",
        "sentences = nltk.sent_tokenize(c_doc)\n",
        "sentences = [[sent, topic, articles[1]] for sent in sentences]\n",
        "\n",
        "ndf = pd.DataFrame(sentences, columns=['text', 'topic', 'article'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "outputId": "19cdaab8-7694-4d07-e737-b20db0d2a24a",
        "id": "Frdcwmz21aTL",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "cdc_idx_dict = {}\n",
        "cdc_idx_sent = {}\n",
        "cdc_idx_art = {}\n",
        "\n",
        "for i,claim in enumerate(ref_data['clean_Claim']):\n",
        "    check_complete = False\n",
        "    while check_complete == False:\n",
        "        for idx,sentence in enumerate(ndf['text']):\n",
        "            test = claim.lower() in sentence.lower()\n",
        "            if test:\n",
        "                article = ref_data['Article'][i]\n",
        "                cdc_idx_dict[idx] = claim\n",
        "                cdc_idx_sent[idx] = [claim, sentence]\n",
        "                cdc_idx_art[idx] = [claim, article]\n",
        "                check_complete = True\n",
        "            elif idx == (len(ndf['text'])-1):\n",
        "                check_complete = True\n",
        "\n",
        "len(cdc_idx_dict), ref_data.shape[0]"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(5, 1332)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 588
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "outputId": "cbd28c53-5991-41f8-e1fc-0f1a6db95269",
        "id": "V0cttpf-1aTM",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "cdc_idx_dict"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{61: 'the strongest nations are those that are made up of different racial elements',\n",
              " 135: 'multiculturalism helps in bringing together immigrants and minorities in the country',\n",
              " 147: 'official multiculturalism limits the freedom of minority members',\n",
              " 153: 'multiculturalism works better in theory than in practice',\n",
              " 154: 'it hinders equity and equality in society'}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 589
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "DsHwvntF1aTM",
        "colab": {}
      },
      "source": [
        "cdc = []\n",
        "\n",
        "for x in range(len(ndf)):\n",
        "    if x in list(cdc_idx_dict.keys()):\n",
        "        cdc.append(cdc_idx_dict.get(x))\n",
        "    else:\n",
        "        cdc.append('---')\n",
        "ndf['cdc'] = cdc\n",
        "\n",
        "df = pd.concat([df, ndf], axis=0, ignore_index=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "jx5ik_vz1aTN"
      },
      "source": [
        "#### Article 2 "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "0P7HbXKH1aTN",
        "colab": {}
      },
      "source": [
        "with open(articles_dict[articles[2].replace(' ','_')+'.txt']) as article:\n",
        "        doc = article.read()\n",
        "\n",
        "c_doc = text_cleaner(doc)\n",
        "sentences = nltk.sent_tokenize(c_doc)\n",
        "sentences = [[sent, topic, articles[2]] for sent in sentences]\n",
        "\n",
        "ndf = pd.DataFrame(sentences, columns=['text', 'topic', 'article'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "outputId": "05913dde-3caf-476e-9b43-e6b25687847c",
        "id": "dBgPBxM41aTO",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "cdc_idx_dict = {}\n",
        "cdc_idx_sent = {}\n",
        "cdc_idx_art = {}\n",
        "\n",
        "for i,claim in enumerate(ref_data['clean_Claim']):\n",
        "    check_complete = False\n",
        "    while check_complete == False:\n",
        "        for idx,sentence in enumerate(ndf['text']):\n",
        "            test = claim.lower() in sentence.lower()\n",
        "            if test:\n",
        "                article = ref_data['Article'][i]\n",
        "                cdc_idx_dict[idx] = claim\n",
        "                cdc_idx_sent[idx] = [claim, sentence]\n",
        "                cdc_idx_art[idx] = [claim, article]\n",
        "                check_complete = True\n",
        "            elif idx == (len(ndf['text'])-1):\n",
        "                check_complete = True\n",
        "\n",
        "len(cdc_idx_dict), ref_data.shape[0]"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(4, 1332)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 592
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "outputId": "09573446-aa2f-4924-9ca3-f0e61eb425f9",
        "id": "QNhAkhko1aTP",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "cdc_idx_dict"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{38: 'a multicultural society could never be strong',\n",
              " 49: 'many multicultural societies have failed',\n",
              " 51: 'it is a perilous concept on which to found policy',\n",
              " 58: 'multiculturalism has resulted in political corruption'}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 593
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "dw8Iii_Z1aTQ",
        "colab": {}
      },
      "source": [
        "cdc = []\n",
        "\n",
        "for x in range(len(ndf)):\n",
        "    if x in list(cdc_idx_dict.keys()):\n",
        "        cdc.append(cdc_idx_dict.get(x))\n",
        "    else:\n",
        "        cdc.append('---')\n",
        "ndf['cdc'] = cdc\n",
        "\n",
        "df = pd.concat([ndf, df], axis=0, ignore_index=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "01N9h5lU1aTR"
      },
      "source": [
        "#### Article 3 "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "kzTQ5c0J1aTR",
        "colab": {}
      },
      "source": [
        "with open(articles_dict[articles[3].replace(' ','_')+'.txt']) as article:\n",
        "        doc = article.read()\n",
        "\n",
        "c_doc = text_cleaner(doc)\n",
        "sentences = nltk.sent_tokenize(c_doc)\n",
        "sentences = [[sent, topic, articles[3]] for sent in sentences]\n",
        "\n",
        "ndf = pd.DataFrame(sentences, columns=['text', 'topic', 'article'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "outputId": "0527f2af-93cd-48c7-8782-077b56d8d8a2",
        "id": "4UztwFCb1aTR",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "cdc_idx_dict = {}\n",
        "cdc_idx_sent = {}\n",
        "cdc_idx_art = {}\n",
        "\n",
        "for i,claim in enumerate(ref_data['clean_Claim']):\n",
        "    check_complete = False\n",
        "    while check_complete == False:\n",
        "        for idx,sentence in enumerate(ndf['text']):\n",
        "            test = claim.lower() in sentence.lower()\n",
        "            if test:\n",
        "                article = ref_data['Article'][i]\n",
        "                cdc_idx_dict[idx] = claim\n",
        "                cdc_idx_sent[idx] = [claim, sentence]\n",
        "                cdc_idx_art[idx] = [claim, article]\n",
        "                check_complete = True\n",
        "            elif idx == (len(ndf['text'])-1):\n",
        "                check_complete = True\n",
        "\n",
        "len(cdc_idx_dict), ref_data.shape[0]"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(9, 1332)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 596
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "outputId": "f6ea8bb6-3573-490b-f164-727ef139151a",
        "id": "tM4aPiru1aTS",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "cdc_idx_dict"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{26: 'would lead to acceptance of barbaric practices',\n",
              " 32: 'homogeneity and integration are necessary for a society',\n",
              " 36: 'multiculturalism and immigration led to adaptation problems',\n",
              " 40: 'immigrants must always lose their own culture - that is the price of immigration',\n",
              " 43: 'lack of integration threatened society',\n",
              " 47: 'A liberal democracy cannot be multicultural',\n",
              " 52: 'Democracy and the rule of law could only be restored by abolishing multiculturalism',\n",
              " 61: 'the emphasis on group identity and group rights diminished individual liberty for those within the minorities',\n",
              " 69: 'Human beings are equal; cultures are not'}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 597
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "CjuBakxq1aTT",
        "colab": {}
      },
      "source": [
        "cdc = []\n",
        "\n",
        "for x in range(len(ndf)):\n",
        "    if x in list(cdc_idx_dict.keys()):\n",
        "        cdc.append(cdc_idx_dict.get(x))\n",
        "    else:\n",
        "        cdc.append('---')\n",
        "ndf['cdc'] = cdc\n",
        "\n",
        "df = pd.concat([ndf, df], axis=0, ignore_index=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "oJHWP5XN1aTU"
      },
      "source": [
        "#### Article 4 "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "8OTfq_Eb1aTU",
        "colab": {}
      },
      "source": [
        "with open(articles_dict[articles[4].replace(' ','_')+'.txt']) as article:\n",
        "        doc = article.read()\n",
        "\n",
        "c_doc = text_cleaner(doc)\n",
        "sentences = nltk.sent_tokenize(c_doc)\n",
        "sentences = [[sent, topic, articles[4]] for sent in sentences]\n",
        "\n",
        "ndf = pd.DataFrame(sentences, columns=['text', 'topic', 'article'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "outputId": "fcd6200a-529f-40b5-a37c-30b3ad002900",
        "id": "sNs6P7uu1aTV",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "cdc_idx_dict = {}\n",
        "cdc_idx_sent = {}\n",
        "cdc_idx_art = {}\n",
        "\n",
        "for i,claim in enumerate(ref_data['clean_Claim']):\n",
        "    check_complete = False\n",
        "    while check_complete == False:\n",
        "        for idx,sentence in enumerate(ndf['text']):\n",
        "            test = claim.lower() in sentence.lower()\n",
        "            if test:\n",
        "                article = ref_data['Article'][i]\n",
        "                cdc_idx_dict[idx] = claim\n",
        "                cdc_idx_sent[idx] = [claim, sentence]\n",
        "                cdc_idx_art[idx] = [claim, article]\n",
        "                check_complete = True\n",
        "            elif idx == (len(ndf['text'])-1):\n",
        "                check_complete = True\n",
        "\n",
        "len(cdc_idx_dict), ref_data.shape[0]"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(4, 1332)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 600
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "outputId": "92012424-11bb-4054-8136-719bd2af7b58",
        "id": "yjsFoUzH1aTW",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "cdc_idx_dict"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{9: 'cultural diversity may be vital for the long-term survival of humanity',\n",
              " 10: 'cultural diversity is as necessary for humankind as biodiversity is for nature',\n",
              " 13: 'it is unethical deliberately to conserve \"less developed\" societies',\n",
              " 23: 'it is in the best interests of individuals and of humanity as a whole that all people adhere to a specific model for society'}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 601
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "KtYAEUSz1aTW",
        "colab": {}
      },
      "source": [
        "cdc = []\n",
        "\n",
        "for x in range(len(ndf)):\n",
        "    if x in list(cdc_idx_dict.keys()):\n",
        "        cdc.append(cdc_idx_dict.get(x))\n",
        "    else:\n",
        "        cdc.append('---')\n",
        "ndf['cdc'] = cdc\n",
        "\n",
        "df = pd.concat([ndf, df], axis=0, ignore_index=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "fFmdXbJR-uBV"
      },
      "source": [
        "#### Article 5 "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "SSl0gEeb-uBW",
        "colab": {}
      },
      "source": [
        "with open(articles_dict[articles[5].replace(' ','_')+'.txt']) as article:\n",
        "        doc = article.read()\n",
        "\n",
        "c_doc = text_cleaner(doc)\n",
        "sentences = nltk.sent_tokenize(c_doc)\n",
        "sentences = [[sent, topic, articles[5]] for sent in sentences]\n",
        "\n",
        "ndf = pd.DataFrame(sentences, columns=['text', 'topic', 'article'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "outputId": "defdd2e4-e0e9-4dfc-a3f7-b492015489d0",
        "id": "MAk_qbFU-uBW",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "cdc_idx_dict = {}\n",
        "cdc_idx_sent = {}\n",
        "cdc_idx_art = {}\n",
        "\n",
        "for i,claim in enumerate(ref_data['clean_Claim']):\n",
        "    check_complete = False\n",
        "    while check_complete == False:\n",
        "        for idx,sentence in enumerate(ndf['text']):\n",
        "            test = claim.lower() in sentence.lower()\n",
        "            if test:\n",
        "                article = ref_data['Article'][i]\n",
        "                cdc_idx_dict[idx] = claim\n",
        "                cdc_idx_sent[idx] = [claim, sentence]\n",
        "                cdc_idx_art[idx] = [claim, article]\n",
        "                check_complete = True\n",
        "            elif idx == (len(ndf['text'])-1):\n",
        "                check_complete = True\n",
        "\n",
        "len(cdc_idx_dict), ref_data.shape[0]"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(1, 1332)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 604
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "outputId": "fa08d2b4-445b-49ac-abc7-b4ef28718811",
        "id": "OTh_ovFP-uBX",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "cdc_idx_dict"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{10: 'Multiculturalism tends to emphasize the rights of ethnic minorities at the expense of the majority'}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 605
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "pW7EgvT9-uBY",
        "colab": {}
      },
      "source": [
        "cdc = []\n",
        "\n",
        "for x in range(len(ndf)):\n",
        "    if x in list(cdc_idx_dict.keys()):\n",
        "        cdc.append(cdc_idx_dict.get(x))\n",
        "    else:\n",
        "        cdc.append('---')\n",
        "ndf['cdc'] = cdc\n",
        "\n",
        "df = pd.concat([ndf, df], axis=0, ignore_index=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "IfzeVrst-uBZ"
      },
      "source": [
        "#### Article 6"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "qJEL_2na-uBZ",
        "colab": {}
      },
      "source": [
        "with open(articles_dict[articles[6].replace(' ','_')+'.txt']) as article:\n",
        "        doc = article.read()\n",
        "\n",
        "c_doc = text_cleaner(doc)\n",
        "sentences = nltk.sent_tokenize(c_doc)\n",
        "sentences = [[sent, topic, articles[6]] for sent in sentences]\n",
        "\n",
        "ndf = pd.DataFrame(sentences, columns=['text', 'topic', 'article'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "outputId": "4fbb118c-06da-46ca-9d4e-8ec3fba25423",
        "id": "khpZlarx-uBa",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "cdc_idx_dict = {}\n",
        "cdc_idx_sent = {}\n",
        "cdc_idx_art = {}\n",
        "\n",
        "for i,claim in enumerate(ref_data['clean_Claim']):\n",
        "    check_complete = False\n",
        "    while check_complete == False:\n",
        "        for idx,sentence in enumerate(ndf['text']):\n",
        "            test = claim.lower() in sentence.lower()\n",
        "            if test:\n",
        "                article = ref_data['Article'][i]\n",
        "                cdc_idx_dict[idx] = claim\n",
        "                cdc_idx_sent[idx] = [claim, sentence]\n",
        "                cdc_idx_art[idx] = [claim, article]\n",
        "                check_complete = True\n",
        "            elif idx == (len(ndf['text'])-1):\n",
        "                check_complete = True\n",
        "\n",
        "len(cdc_idx_dict), ref_data.shape[0]"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(1, 1332)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 608
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "outputId": "aafdeda3-4dda-4b46-e1d4-1a1c40409afc",
        "id": "Oc8cECnO-uBa",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "cdc_idx_dict"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{5: 'multiculturalism has shifted from tolerating multiple cultures to tolerating multiple value systems, which can be hostile to liberalism'}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 609
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "OVco14Gy-uBb",
        "colab": {}
      },
      "source": [
        "cdc = []\n",
        "\n",
        "for x in range(len(ndf)):\n",
        "    if x in list(cdc_idx_dict.keys()):\n",
        "        cdc.append(cdc_idx_dict.get(x))\n",
        "    else:\n",
        "        cdc.append('---')\n",
        "ndf['cdc'] = cdc\n",
        "\n",
        "df = pd.concat([ndf, df], axis=0, ignore_index=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "uItSIFLx-uBc"
      },
      "source": [
        "#### Article 7"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "4MZee8Zh-uBc",
        "colab": {}
      },
      "source": [
        "with open(articles_dict[articles[7].replace(' ','_')+'.txt']) as article:\n",
        "        doc = article.read()\n",
        "\n",
        "c_doc = text_cleaner(doc)\n",
        "sentences = nltk.sent_tokenize(c_doc)\n",
        "sentences = [[sent, topic, articles[7]] for sent in sentences]\n",
        "\n",
        "ndf = pd.DataFrame(sentences, columns=['text', 'topic', 'article'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "outputId": "4a1a6950-8155-4365-d553-f4269f3ae2b0",
        "id": "zJ8J14t3-uBc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "cdc_idx_dict = {}\n",
        "cdc_idx_sent = {}\n",
        "cdc_idx_art = {}\n",
        "\n",
        "for i,claim in enumerate(ref_data['clean_Claim']):\n",
        "    check_complete = False\n",
        "    while check_complete == False:\n",
        "        for idx,sentence in enumerate(ndf['text']):\n",
        "            test = claim.lower() in sentence.lower()\n",
        "            if test:\n",
        "                article = ref_data['Article'][i]\n",
        "                cdc_idx_dict[idx] = claim\n",
        "                cdc_idx_sent[idx] = [claim, sentence]\n",
        "                cdc_idx_art[idx] = [claim, article]\n",
        "                check_complete = True\n",
        "            elif idx == (len(ndf['text'])-1):\n",
        "                check_complete = True\n",
        "\n",
        "len(cdc_idx_dict), ref_data.shape[0]"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(5, 1332)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 612
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "outputId": "173a6630-eb63-4b2f-8f30-b59f3619da25",
        "id": "ox69GAcU-uBd",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "cdc_idx_dict"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{2: 'cultural differences within society are valuable and should be preserved',\n",
              " 120: \"one does not need to assimilate or abandon one's heritage in order to blend in\",\n",
              " 128: 'assimilation can hurt minority cultures by stripping away their distinctive features',\n",
              " 141: 'separating citizens by ethnicity or race and providing immigrant groups \"special privileges\" can harm the very groups they are intended to help',\n",
              " 145: 'the multiculturalist policy of freer immigration is unworkable in an era in which the supply of immigrants from third world countries seems limitless'}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 613
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "SsEK7FSf-uBe",
        "colab": {}
      },
      "source": [
        "cdc = []\n",
        "\n",
        "for x in range(len(ndf)):\n",
        "    if x in list(cdc_idx_dict.keys()):\n",
        "        cdc.append(cdc_idx_dict.get(x))\n",
        "    else:\n",
        "        cdc.append('---')\n",
        "ndf['cdc'] = cdc\n",
        "\n",
        "df = pd.concat([ndf, df], axis=0, ignore_index=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "JEy-oIlB-uBe"
      },
      "source": [
        "#### Article 8"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "XGeUFGab-uBe",
        "colab": {}
      },
      "source": [
        "with open(articles_dict[articles[8].replace(' ','_')+'.txt']) as article:\n",
        "        doc = article.read()\n",
        "\n",
        "c_doc = text_cleaner(doc)\n",
        "sentences = nltk.sent_tokenize(c_doc)\n",
        "sentences = [[sent, topic, articles[8]] for sent in sentences]\n",
        "\n",
        "ndf = pd.DataFrame(sentences, columns=['text', 'topic', 'article'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "outputId": "3dcbfcc0-f035-44e8-9ce0-fbebfbe0ad8b",
        "id": "Lb44RNrP-uBf",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "cdc_idx_dict = {}\n",
        "cdc_idx_sent = {}\n",
        "cdc_idx_art = {}\n",
        "\n",
        "for i,claim in enumerate(ref_data['clean_Claim']):\n",
        "    check_complete = False\n",
        "    while check_complete == False:\n",
        "        for idx,sentence in enumerate(ndf['text']):\n",
        "            test = claim.lower() in sentence.lower()\n",
        "            if test:\n",
        "                article = ref_data['Article'][i]\n",
        "                cdc_idx_dict[idx] = claim\n",
        "                cdc_idx_sent[idx] = [claim, sentence]\n",
        "                cdc_idx_art[idx] = [claim, article]\n",
        "                check_complete = True\n",
        "            elif idx == (len(ndf['text'])-1):\n",
        "                check_complete = True\n",
        "\n",
        "len(cdc_idx_dict), ref_data.shape[0]"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(1, 1332)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 616
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "outputId": "7704a564-04cb-4ddb-c57b-b95533da8954",
        "id": "1ALPc2mQ-uBf",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "cdc_idx_dict"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{6: 'promotion and maintenance of cultural diversity are an essential requirement for sustainable development'}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 617
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "BFmgVBXJ-uBg",
        "colab": {}
      },
      "source": [
        "cdc = []\n",
        "\n",
        "for x in range(len(ndf)):\n",
        "    if x in list(cdc_idx_dict.keys()):\n",
        "        cdc.append(cdc_idx_dict.get(x))\n",
        "    else:\n",
        "        cdc.append('---')\n",
        "ndf['cdc'] = cdc\n",
        "\n",
        "df = pd.concat([ndf, df], axis=0, ignore_index=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "3xquuCJp-uBh"
      },
      "source": [
        "#### Article 9"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "jFM67ohn-uBh",
        "colab": {}
      },
      "source": [
        "with open(articles_dict[articles[9].replace(' ','_')+'.txt']) as article:\n",
        "        doc = article.read()\n",
        "\n",
        "c_doc = text_cleaner(doc)\n",
        "sentences = nltk.sent_tokenize(c_doc)\n",
        "sentences = [[sent, topic, articles[9]] for sent in sentences]\n",
        "\n",
        "ndf = pd.DataFrame(sentences, columns=['text', 'topic', 'article'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "outputId": "ca661594-5ac5-4d83-ad3b-2028d6f71bcf",
        "id": "IGVs7q3v-uBh",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "cdc_idx_dict = {}\n",
        "cdc_idx_sent = {}\n",
        "cdc_idx_art = {}\n",
        "\n",
        "for i,claim in enumerate(ref_data['clean_Claim']):\n",
        "    check_complete = False\n",
        "    while check_complete == False:\n",
        "        for idx,sentence in enumerate(ndf['text']):\n",
        "            test = claim.lower() in sentence.lower()\n",
        "            if test:\n",
        "                article = ref_data['Article'][i]\n",
        "                cdc_idx_dict[idx] = claim\n",
        "                cdc_idx_sent[idx] = [claim, sentence]\n",
        "                cdc_idx_art[idx] = [claim, article]\n",
        "                check_complete = True\n",
        "            elif idx == (len(ndf['text'])-1):\n",
        "                check_complete = True\n",
        "\n",
        "len(cdc_idx_dict), ref_data.shape[0]"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(2, 1332)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 620
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "outputId": "5d08db78-6be2-441b-cc73-b782660aa1f2",
        "id": "qmzSSZYh-uBi",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "cdc_idx_dict"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{63: 'it makes available more ways of solving problems and responding to catastrophes',\n",
              " 108: 'The greater public good warrants eliminating those cultural characteristics that promote conflict or prevent harmony'}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 621
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "2ulpZZHf-uBj",
        "colab": {}
      },
      "source": [
        "cdc = []\n",
        "\n",
        "for x in range(len(ndf)):\n",
        "    if x in list(cdc_idx_dict.keys()):\n",
        "        cdc.append(cdc_idx_dict.get(x))\n",
        "    else:\n",
        "        cdc.append('---')\n",
        "ndf['cdc'] = cdc\n",
        "\n",
        "df = pd.concat([ndf, df], axis=0, ignore_index=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "MjFRv5YO-uBj"
      },
      "source": [
        "#### Article 10"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "wpzhUCm_-uBj",
        "colab": {}
      },
      "source": [
        "with open(articles_dict[articles[10].replace(' ','_')+'.txt']) as article:\n",
        "        doc = article.read()\n",
        "\n",
        "c_doc = text_cleaner(doc)\n",
        "sentences = nltk.sent_tokenize(c_doc)\n",
        "sentences = [[sent, topic, articles[10]] for sent in sentences]\n",
        "\n",
        "ndf = pd.DataFrame(sentences, columns=['text', 'topic', 'article'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "outputId": "58018a59-7aff-46fe-c33a-99ceeddc8bad",
        "id": "FVlBH_S3-uBk",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "cdc_idx_dict = {}\n",
        "cdc_idx_sent = {}\n",
        "cdc_idx_art = {}\n",
        "\n",
        "for i,claim in enumerate(ref_data['clean_Claim']):\n",
        "    check_complete = False\n",
        "    while check_complete == False:\n",
        "        for idx,sentence in enumerate(ndf['text']):\n",
        "            test = claim.lower() in sentence.lower()\n",
        "            if test:\n",
        "                article = ref_data['Article'][i]\n",
        "                cdc_idx_dict[idx] = claim\n",
        "                cdc_idx_sent[idx] = [claim, sentence]\n",
        "                cdc_idx_art[idx] = [claim, article]\n",
        "                check_complete = True\n",
        "            elif idx == (len(ndf['text'])-1):\n",
        "                check_complete = True\n",
        "\n",
        "len(cdc_idx_dict), ref_data.shape[0]"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(2, 1332)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 624
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "outputId": "ff786555-349c-440d-af92-0f270b1517a6",
        "id": "7TN036YI-uBk",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "cdc_idx_dict"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{35: 'Indigenous peoples have the right to the dignity and diversity of their cultures',\n",
              " 84: \"the distinctiveness of people's identity and their rights to preserve their heritage should be acknowledged\"}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 625
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "SIOrgumz-uBl",
        "colab": {}
      },
      "source": [
        "cdc = []\n",
        "\n",
        "for x in range(len(ndf)):\n",
        "    if x in list(cdc_idx_dict.keys()):\n",
        "        cdc.append(cdc_idx_dict.get(x))\n",
        "    else:\n",
        "        cdc.append('---')\n",
        "ndf['cdc'] = cdc\n",
        "\n",
        "df = pd.concat([ndf, df], axis=0, ignore_index=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "AzUJeStZ-uBl"
      },
      "source": [
        "#### Article 11 "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "z_AXCh_2-uBm",
        "colab": {}
      },
      "source": [
        "with open(articles_dict[articles[11].replace(' ','_')+'.txt']) as article:\n",
        "        doc = article.read()\n",
        "\n",
        "c_doc = text_cleaner(doc)\n",
        "sentences = nltk.sent_tokenize(c_doc)\n",
        "sentences = [[sent, topic, articles[11]] for sent in sentences]\n",
        "\n",
        "ndf = pd.DataFrame(sentences, columns=['text', 'topic', 'article'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "outputId": "729a93e2-0d2a-444a-fef1-326b495a715f",
        "id": "kQxtk2xs-uBm",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "cdc_idx_dict = {}\n",
        "cdc_idx_sent = {}\n",
        "cdc_idx_art = {}\n",
        "\n",
        "for i,claim in enumerate(ref_data['clean_Claim']):\n",
        "    check_complete = False\n",
        "    while check_complete == False:\n",
        "        for idx,sentence in enumerate(ndf['text']):\n",
        "            test = claim.lower() in sentence.lower()\n",
        "            if test:\n",
        "                article = ref_data['Article'][i]\n",
        "                cdc_idx_dict[idx] = claim\n",
        "                cdc_idx_sent[idx] = [claim, sentence]\n",
        "                cdc_idx_art[idx] = [claim, article]\n",
        "                check_complete = True\n",
        "            elif idx == (len(ndf['text'])-1):\n",
        "                check_complete = True\n",
        "\n",
        "len(cdc_idx_dict), ref_data.shape[0]"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(2, 1332)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 628
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "outputId": "b35c94fe-9286-4836-aee2-2adf0965ed41",
        "id": "ozegL2mP-uBn",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "cdc_idx_dict"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{2: 'cultural diversity is as necessary for humankind as biodiversity is for the nature',\n",
              " 3: 'it is the common heritage of humanity'}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 629
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "EA4a2VhQ-uBo",
        "colab": {}
      },
      "source": [
        "cdc = []\n",
        "\n",
        "for x in range(len(ndf)):\n",
        "    if x in list(cdc_idx_dict.keys()):\n",
        "        cdc.append(cdc_idx_dict.get(x))\n",
        "    else:\n",
        "        cdc.append('---')\n",
        "ndf['cdc'] = cdc\n",
        "\n",
        "df = pd.concat([ndf, df], axis=0, ignore_index=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "aMNN_GFc-uBo"
      },
      "source": [
        "#### Article 12"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "CsBq8ef2-uBp",
        "colab": {}
      },
      "source": [
        "with open(articles_dict[articles[12].replace(' ','_')+'.txt']) as article:\n",
        "        doc = article.read()\n",
        "\n",
        "c_doc = text_cleaner(doc)\n",
        "sentences = nltk.sent_tokenize(c_doc)\n",
        "sentences = [[sent, topic, articles[12]] for sent in sentences]\n",
        "\n",
        "ndf = pd.DataFrame(sentences, columns=['text', 'topic', 'article'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "outputId": "3b693f91-debc-42ed-f120-4e94af0a3525",
        "id": "_puDYkHK-uBp",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "cdc_idx_dict = {}\n",
        "cdc_idx_sent = {}\n",
        "cdc_idx_art = {}\n",
        "\n",
        "for i,claim in enumerate(ref_data['clean_Claim']):\n",
        "    check_complete = False\n",
        "    while check_complete == False:\n",
        "        for idx,sentence in enumerate(ndf['text']):\n",
        "            test = claim.lower() in sentence.lower()\n",
        "            if test:\n",
        "                article = ref_data['Article'][i]\n",
        "                cdc_idx_dict[idx] = claim\n",
        "                cdc_idx_sent[idx] = [claim, sentence]\n",
        "                cdc_idx_art[idx] = [claim, article]\n",
        "                check_complete = True\n",
        "            elif idx == (len(ndf['text'])-1):\n",
        "                check_complete = True\n",
        "\n",
        "len(cdc_idx_dict), ref_data.shape[0]"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(1, 1332)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 632
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "outputId": "d04abfda-5fd5-43ab-b9b7-7ee01ae29568",
        "id": "peZKafey-uBq",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "cdc_idx_dict"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{203: 'cultural appreciation of ethnic and religious diversity promotes a greater willingness to tolerate political differences'}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 633
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "hiJm1DGZ-uBr",
        "colab": {}
      },
      "source": [
        "cdc = []\n",
        "\n",
        "for x in range(len(ndf)):\n",
        "    if x in list(cdc_idx_dict.keys()):\n",
        "        cdc.append(cdc_idx_dict.get(x))\n",
        "    else:\n",
        "        cdc.append('---')\n",
        "ndf['cdc'] = cdc\n",
        "\n",
        "df = pd.concat([ndf, df], axis=0, ignore_index=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "nSfJD5pC-uBr"
      },
      "source": [
        "#### Article 13"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "RzvLdDTh-uBs",
        "colab": {}
      },
      "source": [
        "with open(articles_dict[articles[13].replace(' ','_')+'.txt']) as article:\n",
        "        doc = article.read()\n",
        "\n",
        "c_doc = text_cleaner(doc)\n",
        "sentences = nltk.sent_tokenize(c_doc)\n",
        "sentences = [[sent, topic, articles[13]] for sent in sentences]\n",
        "\n",
        "ndf = pd.DataFrame(sentences, columns=['text', 'topic', 'article'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "outputId": "2f61086a-304d-4f87-af2f-9f5c691c2c90",
        "id": "fUGMQX4P-uBs",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "cdc_idx_dict = {}\n",
        "cdc_idx_sent = {}\n",
        "cdc_idx_art = {}\n",
        "\n",
        "for i,claim in enumerate(ref_data['clean_Claim']):\n",
        "    check_complete = False\n",
        "    while check_complete == False:\n",
        "        for idx,sentence in enumerate(ndf['text']):\n",
        "            test = claim.lower() in sentence.lower()\n",
        "            if test:\n",
        "                article = ref_data['Article'][i]\n",
        "                cdc_idx_dict[idx] = claim\n",
        "                cdc_idx_sent[idx] = [claim, sentence]\n",
        "                cdc_idx_art[idx] = [claim, article]\n",
        "                check_complete = True\n",
        "            elif idx == (len(ndf['text'])-1):\n",
        "                check_complete = True\n",
        "\n",
        "len(cdc_idx_dict), ref_data.shape[0]"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(1, 1332)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 636
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "outputId": "46072d36-c052-42ef-cf42-7dc23b4d2991",
        "id": "P_3AN4n4-uBt",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "cdc_idx_dict"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{4: 'multinationality in a single state should necessarily comprise the right to express and exercise national identity even by minorities'}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 637
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "f2MLCUaS-uBt",
        "colab": {}
      },
      "source": [
        "cdc = []\n",
        "\n",
        "for x in range(len(ndf)):\n",
        "    if x in list(cdc_idx_dict.keys()):\n",
        "        cdc.append(cdc_idx_dict.get(x))\n",
        "    else:\n",
        "        cdc.append('---')\n",
        "ndf['cdc'] = cdc\n",
        "\n",
        "df = pd.concat([ndf, df], axis=0, ignore_index=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "HOUo9RVA-uB1"
      },
      "source": [
        "#### Article 14 "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "jtt39-AA-uB1",
        "colab": {}
      },
      "source": [
        "with open(articles_dict[articles[14].replace(' ','_')+'.txt']) as article:\n",
        "        doc = article.read()\n",
        "\n",
        "c_doc = text_cleaner(doc)\n",
        "sentences = nltk.sent_tokenize(c_doc)\n",
        "sentences = [[sent, topic, articles[14]] for sent in sentences]\n",
        "\n",
        "ndf = pd.DataFrame(sentences, columns=['text', 'topic', 'article'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "outputId": "48b1da8a-2dbc-4289-f9b3-c6509be74061",
        "id": "_JVvZcC_-uB3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "cdc_idx_dict = {}\n",
        "cdc_idx_sent = {}\n",
        "cdc_idx_art = {}\n",
        "\n",
        "for i,claim in enumerate(ref_data['clean_Claim']):\n",
        "    check_complete = False\n",
        "    while check_complete == False:\n",
        "        for idx,sentence in enumerate(ndf['text']):\n",
        "            test = claim.lower() in sentence.lower()\n",
        "            if test:\n",
        "                article = ref_data['Article'][i]\n",
        "                cdc_idx_dict[idx] = claim\n",
        "                cdc_idx_sent[idx] = [claim, sentence]\n",
        "                cdc_idx_art[idx] = [claim, article]\n",
        "                check_complete = True\n",
        "            elif idx == (len(ndf['text'])-1):\n",
        "                check_complete = True\n",
        "\n",
        "len(cdc_idx_dict), ref_data.shape[0]"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(11, 1332)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 640
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "outputId": "e0719e3a-f890-480b-d9f7-73ed4998f147",
        "id": "WSimxIAj-uB4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "cdc_idx_dict"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{7: 'Multicultural classrooms promote decision-making and critical thinking',\n",
              " 16: 'multiculturalism is a tool for instilling students with pride and confidence in their unique and special backgrounds',\n",
              " 21: 'Multicultural education provides a relatively fairer learning environment for international students',\n",
              " 24: 'multicultural education may cause abandonment of original cultural',\n",
              " 57: 'Diversity is intrinsically valuable to the dominant culture',\n",
              " 99: 'A homogeneous community grounded on consensus may be unable to criticize the injustice and exclusionary practices that undermine it',\n",
              " 100: 'Reform of cultural pathology often comes from the recognition of difference',\n",
              " 112: 'Multiculturalism is a developmental journey through which an individual enhances knowledge and skills about different cultures',\n",
              " 131: 'Multicultural education in public schools would promote acceptance of diversity',\n",
              " 139: 'Citizens in a diverse democratic society should be able to maintain attachments to their cultural communities',\n",
              " 140: 'Unity without diversity results in cultural repression'}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 641
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "o-t95iOR-uB5",
        "colab": {}
      },
      "source": [
        "cdc = []\n",
        "\n",
        "for x in range(len(ndf)):\n",
        "    if x in list(cdc_idx_dict.keys()):\n",
        "        cdc.append(cdc_idx_dict.get(x))\n",
        "    else:\n",
        "        cdc.append('---')\n",
        "ndf['cdc'] = cdc\n",
        "\n",
        "df = pd.concat([ndf, df], axis=0, ignore_index=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "w3k4lSWx-uB6"
      },
      "source": [
        "#### Article 15"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "Sr6wY-Bw-uB6",
        "colab": {}
      },
      "source": [
        "with open(articles_dict[articles[15].replace(' ','_')+'.txt']) as article:\n",
        "        doc = article.read()\n",
        "\n",
        "c_doc = text_cleaner(doc)\n",
        "sentences = nltk.sent_tokenize(c_doc)\n",
        "sentences = [[sent, topic, articles[15]] for sent in sentences]\n",
        "\n",
        "ndf = pd.DataFrame(sentences, columns=['text', 'topic', 'article'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "outputId": "8208adad-20da-4103-d1ff-7a855acc3c56",
        "id": "Hi29c0Ey-uB6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "cdc_idx_dict = {}\n",
        "cdc_idx_sent = {}\n",
        "cdc_idx_art = {}\n",
        "\n",
        "for i,claim in enumerate(ref_data['clean_Claim']):\n",
        "    check_complete = False\n",
        "    while check_complete == False:\n",
        "        for idx,sentence in enumerate(ndf['text']):\n",
        "            test = claim.lower() in sentence.lower()\n",
        "            if test:\n",
        "                article = ref_data['Article'][i]\n",
        "                cdc_idx_dict[idx] = claim\n",
        "                cdc_idx_sent[idx] = [claim, sentence]\n",
        "                cdc_idx_art[idx] = [claim, article]\n",
        "                check_complete = True\n",
        "            elif idx == (len(ndf['text'])-1):\n",
        "                check_complete = True\n",
        "\n",
        "len(cdc_idx_dict), ref_data.shape[0]"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(4, 1332)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 644
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "outputId": "bc1249e5-ff8c-43b8-930f-f03cb9e1293f",
        "id": "U_kdvOuw-uB7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "cdc_idx_dict"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{78: \"recognition and rights accorded to specific groups may interfere with the state's need to establish a cohesive identity\",\n",
              " 80: 'where members of minorities see that their specific needs and ambitions have been acknowledged and catered for, they will commit themselves more willingly to accepting the legitimacy of the nation',\n",
              " 83: 'These may be considered necessary because the minority group in question is socially disadvantaged',\n",
              " 89: 'the political function of rights is precisely to protect minorities from oppression by majorities'}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 645
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "dKt2E2Fn-uB7",
        "colab": {}
      },
      "source": [
        "cdc = []\n",
        "\n",
        "for x in range(len(ndf)):\n",
        "    if x in list(cdc_idx_dict.keys()):\n",
        "        cdc.append(cdc_idx_dict.get(x))\n",
        "    else:\n",
        "        cdc.append('---')\n",
        "ndf['cdc'] = cdc\n",
        "\n",
        "df = pd.concat([ndf, df], axis=0, ignore_index=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "7gIbQEEK-uB8"
      },
      "source": [
        "#### Article 16"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "LQbY8Sg4-uB8",
        "colab": {}
      },
      "source": [
        "with open(articles_dict[articles[16].replace(' ','_')+'.txt']) as article:\n",
        "        doc = article.read()\n",
        "\n",
        "c_doc = text_cleaner(doc)\n",
        "sentences = nltk.sent_tokenize(c_doc)\n",
        "sentences = [[sent, topic, articles[16]] for sent in sentences]\n",
        "\n",
        "ndf = pd.DataFrame(sentences, columns=['text', 'topic', 'article'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "outputId": "c14c53a2-5cdd-4d82-87fe-c668d19e8d8b",
        "id": "70d9vQiO-uB9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "cdc_idx_dict = {}\n",
        "cdc_idx_sent = {}\n",
        "cdc_idx_art = {}\n",
        "\n",
        "for i,claim in enumerate(ref_data['clean_Claim']):\n",
        "    check_complete = False\n",
        "    while check_complete == False:\n",
        "        for idx,sentence in enumerate(ndf['text']):\n",
        "            test = claim.lower() in sentence.lower()\n",
        "            if test:\n",
        "                article = ref_data['Article'][i]\n",
        "                cdc_idx_dict[idx] = claim\n",
        "                cdc_idx_sent[idx] = [claim, sentence]\n",
        "                cdc_idx_art[idx] = [claim, article]\n",
        "                check_complete = True\n",
        "            elif idx == (len(ndf['text'])-1):\n",
        "                check_complete = True\n",
        "\n",
        "len(cdc_idx_dict), ref_data.shape[0]"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(16, 1332)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 648
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "outputId": "1fe9abd5-76c0-4fb7-d6e0-3133d8b8b28f",
        "id": "-_gALYLe-uB9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "cdc_idx_dict"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{10: 'A community of separate cultures fosters a rights mentality, rather than a responsibilities mentality',\n",
              " 11: 'It is divisive',\n",
              " 12: 'It works against quick and effective integration',\n",
              " 16: 'multiculturalism obscures the social costs associated with large scale immigration',\n",
              " 22: 'many multicultural societies have failed',\n",
              " 24: 'It is divisive',\n",
              " 25: 'It threatens social cohesion',\n",
              " 33: 'official multiculturalism limits the freedom of minority members',\n",
              " 39: 'multiculturalism works better in theory than in practice',\n",
              " 40: 'it hinders equity and equality in society',\n",
              " 54: 'would lead to acceptance of barbaric practices',\n",
              " 109: 'multiculturalism undermined national unity',\n",
              " 130: 'some forms of multiculturalism can divide people',\n",
              " 132: 'multiculturalism to be dangerous to the West',\n",
              " 140: 'the more racially diverse a community is, the greater the loss of trust',\n",
              " 156: 'it creates friction within society'}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 649
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "ot527Pfn-uB-",
        "colab": {}
      },
      "source": [
        "cdc = []\n",
        "\n",
        "for x in range(len(ndf)):\n",
        "    if x in list(cdc_idx_dict.keys()):\n",
        "        cdc.append(cdc_idx_dict.get(x))\n",
        "    else:\n",
        "        cdc.append('---')\n",
        "ndf['cdc'] = cdc\n",
        "\n",
        "df = pd.concat([ndf, df], axis=0, ignore_index=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "eTLqTwWs-uB_"
      },
      "source": [
        "#### Article 17"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "DWFlEdNy-uB_",
        "colab": {}
      },
      "source": [
        "with open(articles_dict[articles[17].replace(' ','_')+'.txt']) as article:\n",
        "        doc = article.read()\n",
        "\n",
        "c_doc = text_cleaner(doc)\n",
        "sentences = nltk.sent_tokenize(c_doc)\n",
        "sentences = [[sent, topic, articles[17]] for sent in sentences]\n",
        "\n",
        "ndf = pd.DataFrame(sentences, columns=['text', 'topic', 'article'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "outputId": "249f3ac5-21a2-4a5e-e792-e57d423a50fb",
        "id": "QvdyY4er-uB_",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "cdc_idx_dict = {}\n",
        "cdc_idx_sent = {}\n",
        "cdc_idx_art = {}\n",
        "\n",
        "for i,claim in enumerate(ref_data['clean_Claim']):\n",
        "    check_complete = False\n",
        "    while check_complete == False:\n",
        "        for idx,sentence in enumerate(ndf['text']):\n",
        "            test = claim.lower() in sentence.lower()\n",
        "            if test:\n",
        "                article = ref_data['Article'][i]\n",
        "                cdc_idx_dict[idx] = claim\n",
        "                cdc_idx_sent[idx] = [claim, sentence]\n",
        "                cdc_idx_art[idx] = [claim, article]\n",
        "                check_complete = True\n",
        "            elif idx == (len(ndf['text'])-1):\n",
        "                check_complete = True\n",
        "\n",
        "len(cdc_idx_dict), ref_data.shape[0]"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(2, 1332)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 652
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "outputId": "316fc73c-ef8b-476a-81a4-4482942c0bbb",
        "id": "aPG3Uq41-uCA",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "cdc_idx_dict"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{9: 'Diversity must be prevalent and valued',\n",
              " 11: 'differences are recognized as a uniting component rather than a separating one'}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 653
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "I948VBYA-uCB",
        "colab": {}
      },
      "source": [
        "cdc = []\n",
        "\n",
        "for x in range(len(ndf)):\n",
        "    if x in list(cdc_idx_dict.keys()):\n",
        "        cdc.append(cdc_idx_dict.get(x))\n",
        "    else:\n",
        "        cdc.append('---')\n",
        "ndf['cdc'] = cdc\n",
        "\n",
        "df = pd.concat([ndf, df], axis=0, ignore_index=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "eH954CV--uCB"
      },
      "source": [
        "#### Article 18 "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "7Sh5mgH_-uCB",
        "colab": {}
      },
      "source": [
        "with open(articles_dict[articles[18].replace(' ','_')+'.txt']) as article:\n",
        "        doc = article.read()\n",
        "\n",
        "c_doc = text_cleaner(doc)\n",
        "sentences = nltk.sent_tokenize(c_doc)\n",
        "sentences = [[sent, topic, articles[18]] for sent in sentences]\n",
        "\n",
        "ndf = pd.DataFrame(sentences, columns=['text', 'topic', 'article'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "outputId": "e84d2827-5803-4d8d-c2da-a68fb637744c",
        "id": "jDdSJl-b-uCC",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "cdc_idx_dict = {}\n",
        "cdc_idx_sent = {}\n",
        "cdc_idx_art = {}\n",
        "\n",
        "for i,claim in enumerate(ref_data['clean_Claim']):\n",
        "    check_complete = False\n",
        "    while check_complete == False:\n",
        "        for idx,sentence in enumerate(ndf['text']):\n",
        "            test = claim.lower() in sentence.lower()\n",
        "            if test:\n",
        "                article = ref_data['Article'][i]\n",
        "                cdc_idx_dict[idx] = claim\n",
        "                cdc_idx_sent[idx] = [claim, sentence]\n",
        "                cdc_idx_art[idx] = [claim, article]\n",
        "                check_complete = True\n",
        "            elif idx == (len(ndf['text'])-1):\n",
        "                check_complete = True\n",
        "\n",
        "len(cdc_idx_dict), ref_data.shape[0]"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(1, 1332)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 656
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "outputId": "3610d85b-d1cd-4ffb-d009-f6e444a9845c",
        "id": "64anPe6y-uCD",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "cdc_idx_dict"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{60: 'diversity brings progress and social cohesion'}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 657
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "tVrOSOFH-uCD",
        "colab": {}
      },
      "source": [
        "cdc = []\n",
        "\n",
        "for x in range(len(ndf)):\n",
        "    if x in list(cdc_idx_dict.keys()):\n",
        "        cdc.append(cdc_idx_dict.get(x))\n",
        "    else:\n",
        "        cdc.append('---')\n",
        "ndf['cdc'] = cdc\n",
        "\n",
        "df = pd.concat([ndf, df], axis=0, ignore_index=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "0cQ5PcNDJypv"
      },
      "source": [
        "#### Article 19"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "rP9RhBTVJypw",
        "colab": {}
      },
      "source": [
        "with open(articles_dict[articles[19].replace(' ','_')+'.txt']) as article:\n",
        "        doc = article.read()\n",
        "\n",
        "c_doc = text_cleaner(doc)\n",
        "sentences = nltk.sent_tokenize(c_doc)\n",
        "sentences = [[sent, topic, articles[19]] for sent in sentences]\n",
        "\n",
        "ndf = pd.DataFrame(sentences, columns=['text', 'topic', 'article'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "outputId": "04e6ecc6-45eb-4c24-8e1a-845da5a5283b",
        "id": "TDe0xj_bJypx",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "cdc_idx_dict = {}\n",
        "cdc_idx_sent = {}\n",
        "cdc_idx_art = {}\n",
        "\n",
        "for i,claim in enumerate(ref_data['clean_Claim']):\n",
        "    check_complete = False\n",
        "    while check_complete == False:\n",
        "        for idx,sentence in enumerate(ndf['text']):\n",
        "            test = claim.lower() in sentence.lower()\n",
        "            if test:\n",
        "                article = ref_data['Article'][i]\n",
        "                cdc_idx_dict[idx] = claim\n",
        "                cdc_idx_sent[idx] = [claim, sentence]\n",
        "                cdc_idx_art[idx] = [claim, article]\n",
        "                check_complete = True\n",
        "            elif idx == (len(ndf['text'])-1):\n",
        "                check_complete = True\n",
        "\n",
        "len(cdc_idx_dict), ref_data.shape[0]"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(1, 1332)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 660
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "outputId": "ca9e4a0b-fd05-40a0-92e3-8828403223c0",
        "id": "E0yqkd2yJypz",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "cdc_idx_dict"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{233: 'the community is enriched as difference accrues'}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 661
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "Yfz9LIOeJyp1",
        "colab": {}
      },
      "source": [
        "cdc = []\n",
        "\n",
        "for x in range(len(ndf)):\n",
        "    if x in list(cdc_idx_dict.keys()):\n",
        "        cdc.append(cdc_idx_dict.get(x))\n",
        "    else:\n",
        "        cdc.append('---')\n",
        "ndf['cdc'] = cdc\n",
        "\n",
        "df = pd.concat([ndf, df], axis=0, ignore_index=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "Mbx_Vm_WJyQw"
      },
      "source": [
        "#### Article 20"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "k8GNzSPOJyQx",
        "colab": {}
      },
      "source": [
        "with open(articles_dict[articles[20].replace(' ','_')+'.txt']) as article:\n",
        "        doc = article.read()\n",
        "\n",
        "c_doc = text_cleaner(doc)\n",
        "sentences = nltk.sent_tokenize(c_doc)\n",
        "sentences = [[sent, topic, articles[20]] for sent in sentences]\n",
        "\n",
        "ndf = pd.DataFrame(sentences, columns=['text', 'topic', 'article'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "outputId": "0732d301-fec4-49bb-e063-55bf2a7260af",
        "id": "7T_GXNKGJyQy",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "cdc_idx_dict = {}\n",
        "cdc_idx_sent = {}\n",
        "cdc_idx_art = {}\n",
        "\n",
        "for i,claim in enumerate(ref_data['clean_Claim']):\n",
        "    check_complete = False\n",
        "    while check_complete == False:\n",
        "        for idx,sentence in enumerate(ndf['text']):\n",
        "            test = claim.lower() in sentence.lower()\n",
        "            if test:\n",
        "                article = ref_data['Article'][i]\n",
        "                cdc_idx_dict[idx] = claim\n",
        "                cdc_idx_sent[idx] = [claim, sentence]\n",
        "                cdc_idx_art[idx] = [claim, article]\n",
        "                check_complete = True\n",
        "            elif idx == (len(ndf['text'])-1):\n",
        "                check_complete = True\n",
        "\n",
        "len(cdc_idx_dict), ref_data.shape[0]"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(1, 1332)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 664
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "outputId": "ee46d6c2-6c74-4c59-e2b5-ae7f70d3273e",
        "id": "okYkAop4JyQz",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "cdc_idx_dict"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{72: 'there is no rational ground for curtailing the cultural freedoms'}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 665
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "wHKtMEIcJyQ1",
        "colab": {}
      },
      "source": [
        "cdc = []\n",
        "\n",
        "for x in range(len(ndf)):\n",
        "    if x in list(cdc_idx_dict.keys()):\n",
        "        cdc.append(cdc_idx_dict.get(x))\n",
        "    else:\n",
        "        cdc.append('---')\n",
        "ndf['cdc'] = cdc\n",
        "\n",
        "df = pd.concat([ndf, df], axis=0, ignore_index=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "CuZUJDlxJx4r"
      },
      "source": [
        "#### Article 21"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "3vtOPgXlJx4s",
        "colab": {}
      },
      "source": [
        "with open(articles_dict[articles[21].replace(' ','_')+'.txt']) as article:\n",
        "        doc = article.read()\n",
        "\n",
        "c_doc = text_cleaner(doc)\n",
        "sentences = nltk.sent_tokenize(c_doc)\n",
        "sentences = [[sent, topic, articles[21]] for sent in sentences]\n",
        "\n",
        "ndf = pd.DataFrame(sentences, columns=['text', 'topic', 'article'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "outputId": "df0863e2-5a37-462b-fe0f-29eee8907024",
        "id": "pxMHF1WkJx4t",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "cdc_idx_dict = {}\n",
        "cdc_idx_sent = {}\n",
        "cdc_idx_art = {}\n",
        "\n",
        "for i,claim in enumerate(ref_data['clean_Claim']):\n",
        "    check_complete = False\n",
        "    while check_complete == False:\n",
        "        for idx,sentence in enumerate(ndf['text']):\n",
        "            test = claim.lower() in sentence.lower()\n",
        "            if test:\n",
        "                article = ref_data['Article'][i]\n",
        "                cdc_idx_dict[idx] = claim\n",
        "                cdc_idx_sent[idx] = [claim, sentence]\n",
        "                cdc_idx_art[idx] = [claim, article]\n",
        "                check_complete = True\n",
        "            elif idx == (len(ndf['text'])-1):\n",
        "                check_complete = True\n",
        "\n",
        "len(cdc_idx_dict), ref_data.shape[0]"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(1, 1332)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 668
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "outputId": "b377e2e2-5fb3-42d4-b25e-18435a33d3ca",
        "id": "mQLklpymJx4v",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        }
      },
      "source": [
        "cdc_idx_dict"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{86: 'Multiculturalism can become a polite and euphemistic way of affirming and persisting unequal power relationships'}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 669
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "fA0haSiZJx4x",
        "colab": {}
      },
      "source": [
        "cdc = []\n",
        "\n",
        "for x in range(len(ndf)):\n",
        "    if x in list(cdc_idx_dict.keys()):\n",
        "        cdc.append(cdc_idx_dict.get(x))\n",
        "    else:\n",
        "        cdc.append('---')\n",
        "ndf['cdc'] = cdc\n",
        "\n",
        "df = pd.concat([ndf, df], axis=0, ignore_index=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "sYloYupWJxc6"
      },
      "source": [
        "#### Article 22 "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "xVdvYy44Jxc6",
        "colab": {}
      },
      "source": [
        "with open(articles_dict[articles[22].replace(' ','_')+'.txt']) as article:\n",
        "        doc = article.read()\n",
        "\n",
        "c_doc = text_cleaner(doc)\n",
        "sentences = nltk.sent_tokenize(c_doc)\n",
        "sentences = [[sent, topic, articles[22]] for sent in sentences]\n",
        "\n",
        "ndf = pd.DataFrame(sentences, columns=['text', 'topic', 'article'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "outputId": "408e74a7-d2d0-4e60-f255-c2c0066be965",
        "id": "c6M8kJ9VJxc8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "cdc_idx_dict = {}\n",
        "cdc_idx_sent = {}\n",
        "cdc_idx_art = {}\n",
        "\n",
        "for i,claim in enumerate(ref_data['clean_Claim']):\n",
        "    check_complete = False\n",
        "    while check_complete == False:\n",
        "        for idx,sentence in enumerate(ndf['text']):\n",
        "            test = claim.lower() in sentence.lower()\n",
        "            if test:\n",
        "                article = ref_data['Article'][i]\n",
        "                cdc_idx_dict[idx] = claim\n",
        "                cdc_idx_sent[idx] = [claim, sentence]\n",
        "                cdc_idx_art[idx] = [claim, article]\n",
        "                check_complete = True\n",
        "            elif idx == (len(ndf['text'])-1):\n",
        "                check_complete = True\n",
        "\n",
        "len(cdc_idx_dict), ref_data.shape[0]"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(2, 1332)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 672
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "outputId": "22ab52b4-7428-4800-bf8a-cfc3e3c0be7a",
        "id": "60R-led5Jxc9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 71
        }
      },
      "source": [
        "cdc_idx_dict"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{36: 'had reached the end of its useful life',\n",
              " 37: 'Multiculturalism could not be allowed to create a society where all values were equal'}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 673
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "sCAg6ll7Jxc-",
        "colab": {}
      },
      "source": [
        "cdc = []\n",
        "\n",
        "for x in range(len(ndf)):\n",
        "    if x in list(cdc_idx_dict.keys()):\n",
        "        cdc.append(cdc_idx_dict.get(x))\n",
        "    else:\n",
        "        cdc.append('---')\n",
        "ndf['cdc'] = cdc\n",
        "\n",
        "df = pd.concat([ndf, df], axis=0, ignore_index=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "w0lQeXb-Jwk8"
      },
      "source": [
        "#### Article 23"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "1SkLFIuBJwk9",
        "colab": {}
      },
      "source": [
        "with open(articles_dict[articles[23].replace(' ','_')+'.txt']) as article:\n",
        "        doc = article.read()\n",
        "\n",
        "c_doc = text_cleaner(doc)\n",
        "sentences = nltk.sent_tokenize(c_doc)\n",
        "sentences = [[sent, topic, articles[23]] for sent in sentences]\n",
        "\n",
        "ndf = pd.DataFrame(sentences, columns=['text', 'topic', 'article'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "outputId": "16f6e4b1-047e-4275-c11b-ae90c8dba1f7",
        "id": "JbDQ2WhLJwk_",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "cdc_idx_dict = {}\n",
        "cdc_idx_sent = {}\n",
        "cdc_idx_art = {}\n",
        "\n",
        "for i,claim in enumerate(ref_data['clean_Claim']):\n",
        "    check_complete = False\n",
        "    while check_complete == False:\n",
        "        for idx,sentence in enumerate(ndf['text']):\n",
        "            test = claim.lower() in sentence.lower()\n",
        "            if test:\n",
        "                article = ref_data['Article'][i]\n",
        "                cdc_idx_dict[idx] = claim\n",
        "                cdc_idx_sent[idx] = [claim, sentence]\n",
        "                cdc_idx_art[idx] = [claim, article]\n",
        "                check_complete = True\n",
        "            elif idx == (len(ndf['text'])-1):\n",
        "                check_complete = True\n",
        "\n",
        "len(cdc_idx_dict), ref_data.shape[0]"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(2, 1332)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 676
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "outputId": "aed0dbe6-55d1-4c7d-b445-a3f26574175a",
        "id": "EaGedY4JJwlA",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 71
        }
      },
      "source": [
        "cdc_idx_dict"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{14: 'should be treated and promoted equally',\n",
              " 26: \"people have the right to maintain an affiliation with one's ethnic group\"}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 677
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "Vw6YbKzEJwlC",
        "colab": {}
      },
      "source": [
        "cdc = []\n",
        "\n",
        "for x in range(len(ndf)):\n",
        "    if x in list(cdc_idx_dict.keys()):\n",
        "        cdc.append(cdc_idx_dict.get(x))\n",
        "    else:\n",
        "        cdc.append('---')\n",
        "ndf['cdc'] = cdc\n",
        "\n",
        "df = pd.concat([ndf, df], axis=0, ignore_index=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ig_gb7zMy5Fn",
        "colab_type": "text"
      },
      "source": [
        "### 'parents to genetically screen foetuses for heritable diseases '"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "outputId": "f0c8eadf-81f9-4675-d86d-782e814cfc8e",
        "id": "SW1BY2GW1b2O",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 102
        }
      },
      "source": [
        "topic = 'parents to genetically screen foetuses for heritable diseases '\n",
        "\n",
        "articles = topic_article_dict[topic]\n",
        "articles"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['Preimplantation genetic diagnosis',\n",
              " 'Genetic testing',\n",
              " 'Human genetic engineering',\n",
              " 'Prenatal diagnosis',\n",
              " 'In vitro fertilisation']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 679
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "X0co3Ey-1b2P"
      },
      "source": [
        "#### Article 0 "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "619DGTRY1b2P",
        "colab": {}
      },
      "source": [
        "with open(articles_dict[articles[0].replace(' ','_')+'.txt']) as article:\n",
        "        doc = article.read()\n",
        "\n",
        "c_doc = text_cleaner(doc)\n",
        "sentences = nltk.sent_tokenize(c_doc)\n",
        "sentences = [[sent, topic, articles[0]] for sent in sentences]\n",
        "\n",
        "ndf = pd.DataFrame(sentences, columns=['text', 'topic', 'article'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "outputId": "974d7ad0-00f0-466b-ea45-9a48ebcaf936",
        "id": "X8JrR1ud1b2P",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "cdc_idx_dict = {}\n",
        "cdc_idx_sent = {}\n",
        "cdc_idx_art = {}\n",
        "\n",
        "for i,claim in enumerate(ref_data['clean_Claim']):\n",
        "    check_complete = False\n",
        "    while check_complete == False:\n",
        "        for idx,sentence in enumerate(ndf['text']):\n",
        "            test = claim.lower() in sentence.lower()\n",
        "            if test:\n",
        "                article = ref_data['Article'][i]\n",
        "                cdc_idx_dict[idx] = claim\n",
        "                cdc_idx_sent[idx] = [claim, sentence]\n",
        "                cdc_idx_art[idx] = [claim, article]\n",
        "                check_complete = True\n",
        "            elif idx == (len(ndf['text'])-1):\n",
        "                check_complete = True\n",
        "\n",
        "len(cdc_idx_dict), ref_data.shape[0]"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(1, 1332)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 681
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "outputId": "cb1d9b8c-349b-4733-f75f-0895fa8ec5a6",
        "id": "W0GPaeOs1b2Q",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "cdc_idx_dict"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{200: 'it involves the destruction of human life'}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 682
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "L7j6Ah7i1b2R",
        "colab": {}
      },
      "source": [
        "cdc = []\n",
        "\n",
        "for x in range(len(ndf)):\n",
        "    if x in list(cdc_idx_dict.keys()):\n",
        "        cdc.append(cdc_idx_dict.get(x))\n",
        "    else:\n",
        "        cdc.append('---')\n",
        "ndf['cdc'] = cdc\n",
        "\n",
        "df = pd.concat([ndf, df], axis=0, ignore_index=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "T_sTYhbI1b2S"
      },
      "source": [
        "#### Article 1 "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "dKbzttRt1b2S",
        "colab": {}
      },
      "source": [
        "with open(articles_dict[articles[1].replace(' ','_')+'.txt']) as article:\n",
        "        doc = article.read()\n",
        "\n",
        "c_doc = text_cleaner(doc)\n",
        "sentences = nltk.sent_tokenize(c_doc)\n",
        "sentences = [[sent, topic, articles[1]] for sent in sentences]\n",
        "\n",
        "ndf = pd.DataFrame(sentences, columns=['text', 'topic', 'article'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "outputId": "2610d20e-845c-45a9-ced9-e588dc8d91fd",
        "id": "oR9Ak9sG1b2T",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "cdc_idx_dict = {}\n",
        "cdc_idx_sent = {}\n",
        "cdc_idx_art = {}\n",
        "\n",
        "for i,claim in enumerate(ref_data['clean_Claim']):\n",
        "    check_complete = False\n",
        "    while check_complete == False:\n",
        "        for idx,sentence in enumerate(ndf['text']):\n",
        "            test = claim.lower() in sentence.lower()\n",
        "            if test:\n",
        "                article = ref_data['Article'][i]\n",
        "                cdc_idx_dict[idx] = claim\n",
        "                cdc_idx_sent[idx] = [claim, sentence]\n",
        "                cdc_idx_art[idx] = [claim, article]\n",
        "                check_complete = True\n",
        "            elif idx == (len(ndf['text'])-1):\n",
        "                check_complete = True\n",
        "\n",
        "len(cdc_idx_dict), ref_data.shape[0]"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(2, 1332)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 685
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "outputId": "132afa2f-46b8-4701-c822-e07bb94c17da",
        "id": "wJxaARP51b2T",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "cdc_idx_dict"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{72: 'The procedures used for prenatal testing carry a small but real risk of losing the pregnancy',\n",
              " 97: 'There is no stronger antidote for fear than information'}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 686
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "iZ4TXzEb1b2U",
        "colab": {}
      },
      "source": [
        "cdc = []\n",
        "\n",
        "for x in range(len(ndf)):\n",
        "    if x in list(cdc_idx_dict.keys()):\n",
        "        cdc.append(cdc_idx_dict.get(x))\n",
        "    else:\n",
        "        cdc.append('---')\n",
        "ndf['cdc'] = cdc\n",
        "\n",
        "df = pd.concat([df, ndf], axis=0, ignore_index=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "IfT7R5K41b2V"
      },
      "source": [
        "#### Article 2 "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "zMJpBBC-1b2V",
        "colab": {}
      },
      "source": [
        "with open(articles_dict[articles[2].replace(' ','_')+'.txt']) as article:\n",
        "        doc = article.read()\n",
        "\n",
        "c_doc = text_cleaner(doc)\n",
        "sentences = nltk.sent_tokenize(c_doc)\n",
        "sentences = [[sent, topic, articles[2]] for sent in sentences]\n",
        "\n",
        "ndf = pd.DataFrame(sentences, columns=['text', 'topic', 'article'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "outputId": "d48ac394-d3ca-4815-f469-ee305e949ec7",
        "id": "rbRaFNlB1b2W",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "cdc_idx_dict = {}\n",
        "cdc_idx_sent = {}\n",
        "cdc_idx_art = {}\n",
        "\n",
        "for i,claim in enumerate(ref_data['clean_Claim']):\n",
        "    check_complete = False\n",
        "    while check_complete == False:\n",
        "        for idx,sentence in enumerate(ndf['text']):\n",
        "            test = claim.lower() in sentence.lower()\n",
        "            if test:\n",
        "                article = ref_data['Article'][i]\n",
        "                cdc_idx_dict[idx] = claim\n",
        "                cdc_idx_sent[idx] = [claim, sentence]\n",
        "                cdc_idx_art[idx] = [claim, article]\n",
        "                check_complete = True\n",
        "            elif idx == (len(ndf['text'])-1):\n",
        "                check_complete = True\n",
        "\n",
        "len(cdc_idx_dict), ref_data.shape[0]"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(1, 1332)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 689
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "outputId": "b131fb94-75e0-4146-d0ee-7a2929b6ebef",
        "id": "1dyvbAOT1b2W",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "cdc_idx_dict"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{19: 'every child has the right to be born free from preventable diseases'}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 690
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "0tbeZRC31b2X",
        "colab": {}
      },
      "source": [
        "cdc = []\n",
        "\n",
        "for x in range(len(ndf)):\n",
        "    if x in list(cdc_idx_dict.keys()):\n",
        "        cdc.append(cdc_idx_dict.get(x))\n",
        "    else:\n",
        "        cdc.append('---')\n",
        "ndf['cdc'] = cdc\n",
        "\n",
        "df = pd.concat([ndf, df], axis=0, ignore_index=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "-xwY8sCS1b2Y"
      },
      "source": [
        "#### Article 3 "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "kzUkxmv31b2Y",
        "colab": {}
      },
      "source": [
        "with open(articles_dict[articles[3].replace(' ','_')+'.txt']) as article:\n",
        "        doc = article.read()\n",
        "\n",
        "c_doc = text_cleaner(doc)\n",
        "sentences = nltk.sent_tokenize(c_doc)\n",
        "sentences = [[sent, topic, articles[3]] for sent in sentences]\n",
        "\n",
        "ndf = pd.DataFrame(sentences, columns=['text', 'topic', 'article'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "outputId": "0aeaa4eb-f99b-4b8e-df72-11f97ea80128",
        "id": "jmO_xouI1b2Z",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "cdc_idx_dict = {}\n",
        "cdc_idx_sent = {}\n",
        "cdc_idx_art = {}\n",
        "\n",
        "for i,claim in enumerate(ref_data['clean_Claim']):\n",
        "    check_complete = False\n",
        "    while check_complete == False:\n",
        "        for idx,sentence in enumerate(ndf['text']):\n",
        "            test = claim.lower() in sentence.lower()\n",
        "            if test:\n",
        "                article = ref_data['Article'][i]\n",
        "                cdc_idx_dict[idx] = claim\n",
        "                cdc_idx_sent[idx] = [claim, sentence]\n",
        "                cdc_idx_art[idx] = [claim, article]\n",
        "                check_complete = True\n",
        "            elif idx == (len(ndf['text'])-1):\n",
        "                check_complete = True\n",
        "\n",
        "len(cdc_idx_dict), ref_data.shape[0]"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(3, 1332)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 693
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "outputId": "700b119c-2b4f-468f-9877-49b99cc8520f",
        "id": "U2_AD_cF1b2Z",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "cdc_idx_dict"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{21: 'Having this information in advance of the birth means that healthcare staff as well as parents can better prepare themselves for the delivery of a child with a health problem',\n",
              " 119: 'may give the option of fetal surgery during pregnancy',\n",
              " 128: 'Early diagnosis gives the parents time to research and discuss post-natal treatment and care'}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 694
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "ngARUvIP1b2a",
        "colab": {}
      },
      "source": [
        "cdc = []\n",
        "\n",
        "for x in range(len(ndf)):\n",
        "    if x in list(cdc_idx_dict.keys()):\n",
        "        cdc.append(cdc_idx_dict.get(x))\n",
        "    else:\n",
        "        cdc.append('---')\n",
        "ndf['cdc'] = cdc\n",
        "\n",
        "df = pd.concat([ndf, df], axis=0, ignore_index=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "Fi78P-zC1b2b"
      },
      "source": [
        "#### Article 4 "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "nvajbvih1b2b",
        "colab": {}
      },
      "source": [
        "with open(articles_dict[articles[4].replace(' ','_')+'.txt']) as article:\n",
        "        doc = article.read()\n",
        "\n",
        "c_doc = text_cleaner(doc)\n",
        "sentences = nltk.sent_tokenize(c_doc)\n",
        "sentences = [[sent, topic, articles[4]] for sent in sentences]\n",
        "\n",
        "ndf = pd.DataFrame(sentences, columns=['text', 'topic', 'article'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "outputId": "c020c959-3fc4-4c10-dccd-8be62fcc1e07",
        "id": "06OHgRpE1b2c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "cdc_idx_dict = {}\n",
        "cdc_idx_sent = {}\n",
        "cdc_idx_art = {}\n",
        "\n",
        "for i,claim in enumerate(ref_data['clean_Claim']):\n",
        "    check_complete = False\n",
        "    while check_complete == False:\n",
        "        for idx,sentence in enumerate(ndf['text']):\n",
        "            test = claim.lower() in sentence.lower()\n",
        "            if test:\n",
        "                article = ref_data['Article'][i]\n",
        "                cdc_idx_dict[idx] = claim\n",
        "                cdc_idx_sent[idx] = [claim, sentence]\n",
        "                cdc_idx_art[idx] = [claim, article]\n",
        "                check_complete = True\n",
        "            elif idx == (len(ndf['text'])-1):\n",
        "                check_complete = True\n",
        "\n",
        "len(cdc_idx_dict), ref_data.shape[0]"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(2, 1332)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 697
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "outputId": "89ab9634-6050-442e-c53c-8baae001435a",
        "id": "Ieno6XS81b2d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "cdc_idx_dict"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{187: 'PGS can reduce the risk of multiple pregnancies because fewer embryos are needed for implantation',\n",
              " 250: 'intentionally culling out blind or deaf embryos might prevent considerable future suffering'}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 698
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "QFlqCvO71b2e",
        "colab": {}
      },
      "source": [
        "cdc = []\n",
        "\n",
        "for x in range(len(ndf)):\n",
        "    if x in list(cdc_idx_dict.keys()):\n",
        "        cdc.append(cdc_idx_dict.get(x))\n",
        "    else:\n",
        "        cdc.append('---')\n",
        "ndf['cdc'] = cdc\n",
        "\n",
        "df = pd.concat([ndf, df], axis=0, ignore_index=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uzTW3foey-Yi",
        "colab_type": "text"
      },
      "source": [
        "### 'partial birth abortions '"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "outputId": "274e8911-3ae9-4032-ab3f-612392a5584a",
        "id": "PdWd6Q551dax",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 255
        }
      },
      "source": [
        "topic = 'partial birth abortions '\n",
        "\n",
        "articles = topic_article_dict[topic]\n",
        "articles"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['Religion and abortion',\n",
              " 'Legalized abortion and crime effect',\n",
              " 'Gonzales v Carhart',\n",
              " 'Roe v Wade',\n",
              " 'Stenberg v Carhart',\n",
              " 'Societal attitudes towards abortion',\n",
              " 'Philosophical aspects of the abortion debate',\n",
              " 'Intact dilation and extraction',\n",
              " 'Partial-Birth Abortion Ban Act',\n",
              " 'Support for the legalization of abortion',\n",
              " 'Judaism and abortion',\n",
              " 'Abortion and mental health',\n",
              " 'Abortion debate',\n",
              " 'Abortion in the United States']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 700
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TmMZsNMB1dMa",
        "colab_type": "code",
        "outputId": "107b4ac6-ab6f-442c-afa9-4a0d50a33d74",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "len(articles)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "14"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 701
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "VAtzlzhT1da0"
      },
      "source": [
        "#### Article 0 "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "cYqVZiqc1da0",
        "colab": {}
      },
      "source": [
        "with open(articles_dict[articles[0].replace(' ','_')+'.txt']) as article:\n",
        "        doc = article.read()\n",
        "\n",
        "c_doc = text_cleaner(doc)\n",
        "sentences = nltk.sent_tokenize(c_doc)\n",
        "sentences = [[sent, topic, articles[0]] for sent in sentences]\n",
        "\n",
        "ndf = pd.DataFrame(sentences, columns=['text', 'topic', 'article'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "outputId": "c2f5a119-0df7-47a5-b2ea-c76f266134b7",
        "id": "hx2G1FAA1da1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "cdc_idx_dict = {}\n",
        "cdc_idx_sent = {}\n",
        "cdc_idx_art = {}\n",
        "\n",
        "for i,claim in enumerate(ref_data['clean_Claim']):\n",
        "    check_complete = False\n",
        "    while check_complete == False:\n",
        "        for idx,sentence in enumerate(ndf['text']):\n",
        "            test = claim.lower() in sentence.lower()\n",
        "            if test:\n",
        "                article = ref_data['Article'][i]\n",
        "                cdc_idx_dict[idx] = claim\n",
        "                cdc_idx_sent[idx] = [claim, sentence]\n",
        "                cdc_idx_art[idx] = [claim, article]\n",
        "                check_complete = True\n",
        "            elif idx == (len(ndf['text'])-1):\n",
        "                check_complete = True\n",
        "\n",
        "len(cdc_idx_dict), ref_data.shape[0]"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(2, 1332)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 703
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "outputId": "1c84a824-9420-426c-9f4f-f2601097387b",
        "id": "pfEw8J4m1da2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "cdc_idx_dict"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{2: 'abortion, which would then involve the deliberate destruction of life, should be rejected',\n",
              " 6: 'abortion should be approved or disapproved according to each circumstance'}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 704
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "IM_39VVU1da3",
        "colab": {}
      },
      "source": [
        "cdc = []\n",
        "\n",
        "for x in range(len(ndf)):\n",
        "    if x in list(cdc_idx_dict.keys()):\n",
        "        cdc.append(cdc_idx_dict.get(x))\n",
        "    else:\n",
        "        cdc.append('---')\n",
        "ndf['cdc'] = cdc\n",
        "\n",
        "df = pd.concat([ndf, df], axis=0, ignore_index=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "SI2zcRYc1da3"
      },
      "source": [
        "#### Article 1 "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "8hQsme151da4",
        "colab": {}
      },
      "source": [
        "with open(articles_dict[articles[1].replace(' ','_')+'.txt']) as article:\n",
        "        doc = article.read()\n",
        "\n",
        "c_doc = text_cleaner(doc)\n",
        "sentences = nltk.sent_tokenize(c_doc)\n",
        "sentences = [[sent, topic, articles[1]] for sent in sentences]\n",
        "\n",
        "ndf = pd.DataFrame(sentences, columns=['text', 'topic', 'article'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "outputId": "4b920f66-6bdb-4f16-d804-44d3cc8402be",
        "id": "oNtVMQ0U1da5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "cdc_idx_dict = {}\n",
        "cdc_idx_sent = {}\n",
        "cdc_idx_art = {}\n",
        "\n",
        "for i,claim in enumerate(ref_data['clean_Claim']):\n",
        "    check_complete = False\n",
        "    while check_complete == False:\n",
        "        for idx,sentence in enumerate(ndf['text']):\n",
        "            test = claim.lower() in sentence.lower()\n",
        "            if test:\n",
        "                article = ref_data['Article'][i]\n",
        "                cdc_idx_dict[idx] = claim\n",
        "                cdc_idx_sent[idx] = [claim, sentence]\n",
        "                cdc_idx_art[idx] = [claim, article]\n",
        "                check_complete = True\n",
        "            elif idx == (len(ndf['text'])-1):\n",
        "                check_complete = True\n",
        "\n",
        "len(cdc_idx_dict), ref_data.shape[0]"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(1, 1332)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 707
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "outputId": "e71cc617-df83-4005-e55e-ec9e4d75ec90",
        "id": "3YOzR7sB1da6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "cdc_idx_dict"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{5: 'abortion has negative effects on society'}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 708
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "Z9mvqZVG1da8",
        "colab": {}
      },
      "source": [
        "cdc = []\n",
        "\n",
        "for x in range(len(ndf)):\n",
        "    if x in list(cdc_idx_dict.keys()):\n",
        "        cdc.append(cdc_idx_dict.get(x))\n",
        "    else:\n",
        "        cdc.append('---')\n",
        "ndf['cdc'] = cdc\n",
        "\n",
        "df = pd.concat([df, ndf], axis=0, ignore_index=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "XEuE1nvj1da8"
      },
      "source": [
        "#### Article 2 "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "WfVeifg21da9",
        "colab": {}
      },
      "source": [
        "with open(articles_dict[articles[2].replace(' ','_')+'.txt']) as article:\n",
        "        doc = article.read()\n",
        "\n",
        "c_doc = text_cleaner(doc)\n",
        "sentences = nltk.sent_tokenize(c_doc)\n",
        "sentences = [[sent, topic, articles[2]] for sent in sentences]\n",
        "\n",
        "ndf = pd.DataFrame(sentences, columns=['text', 'topic', 'article'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "outputId": "3c3c415b-a48a-4404-af90-ed0401f4607b",
        "id": "9xuKTLPE1da9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "cdc_idx_dict = {}\n",
        "cdc_idx_sent = {}\n",
        "cdc_idx_art = {}\n",
        "\n",
        "for i,claim in enumerate(ref_data['clean_Claim']):\n",
        "    check_complete = False\n",
        "    while check_complete == False:\n",
        "        for idx,sentence in enumerate(ndf['text']):\n",
        "            test = claim.lower() in sentence.lower()\n",
        "            if test:\n",
        "                article = ref_data['Article'][i]\n",
        "                cdc_idx_dict[idx] = claim\n",
        "                cdc_idx_sent[idx] = [claim, sentence]\n",
        "                cdc_idx_art[idx] = [claim, article]\n",
        "                check_complete = True\n",
        "            elif idx == (len(ndf['text'])-1):\n",
        "                check_complete = True\n",
        "\n",
        "len(cdc_idx_dict), ref_data.shape[0]"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(2, 1332)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 711
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "outputId": "cdaa8313-d1eb-401f-f079-348caac59104",
        "id": "pFygZGR81da-",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "cdc_idx_dict"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{26: 'the state has an interest in preserving fetal life',\n",
              " 27: 'intact dilation and extraction procedure is never needed to protect the health of a pregnant woman'}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 712
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "lbLrFebV1da_",
        "colab": {}
      },
      "source": [
        "cdc = []\n",
        "\n",
        "for x in range(len(ndf)):\n",
        "    if x in list(cdc_idx_dict.keys()):\n",
        "        cdc.append(cdc_idx_dict.get(x))\n",
        "    else:\n",
        "        cdc.append('---')\n",
        "ndf['cdc'] = cdc\n",
        "\n",
        "df = pd.concat([ndf, df], axis=0, ignore_index=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "iT7daN471dbA"
      },
      "source": [
        "#### Article 3 "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "brnnD3TG1dbA",
        "colab": {}
      },
      "source": [
        "with open(articles_dict[articles[3].replace(' ','_')+'.txt']) as article:\n",
        "        doc = article.read()\n",
        "\n",
        "c_doc = text_cleaner(doc)\n",
        "sentences = nltk.sent_tokenize(c_doc)\n",
        "sentences = [[sent, topic, articles[3]] for sent in sentences]\n",
        "\n",
        "ndf = pd.DataFrame(sentences, columns=['text', 'topic', 'article'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "outputId": "b2d9b07d-25ce-4bf8-87e8-722f7580cdca",
        "id": "I_OPys2F1dbB",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "cdc_idx_dict = {}\n",
        "cdc_idx_sent = {}\n",
        "cdc_idx_art = {}\n",
        "\n",
        "for i,claim in enumerate(ref_data['clean_Claim']):\n",
        "    check_complete = False\n",
        "    while check_complete == False:\n",
        "        for idx,sentence in enumerate(ndf['text']):\n",
        "            test = claim.lower() in sentence.lower()\n",
        "            if test:\n",
        "                article = ref_data['Article'][i]\n",
        "                cdc_idx_dict[idx] = claim\n",
        "                cdc_idx_sent[idx] = [claim, sentence]\n",
        "                cdc_idx_art[idx] = [claim, article]\n",
        "                check_complete = True\n",
        "            elif idx == (len(ndf['text'])-1):\n",
        "                check_complete = True\n",
        "\n",
        "len(cdc_idx_dict), ref_data.shape[0]"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(3, 1332)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 715
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "outputId": "de102593-9ad7-4ede-e857-60d85c0653fe",
        "id": "m_Y4VkCW1dbC",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "cdc_idx_dict"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{46: 'abortion a fundamental right',\n",
              " 50: 'the decision to abort must be left to the mother and her physician',\n",
              " 150: 'a state\\'s ban on \"partial birth abortion\" was unconstitutional'}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 716
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "midKHf6v1dbI",
        "colab": {}
      },
      "source": [
        "cdc = []\n",
        "\n",
        "for x in range(len(ndf)):\n",
        "    if x in list(cdc_idx_dict.keys()):\n",
        "        cdc.append(cdc_idx_dict.get(x))\n",
        "    else:\n",
        "        cdc.append('---')\n",
        "ndf['cdc'] = cdc\n",
        "\n",
        "df = pd.concat([ndf, df], axis=0, ignore_index=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "Xu1QNC4n1dbI"
      },
      "source": [
        "#### Article 4 "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "G5s4bVPu1dbJ",
        "colab": {}
      },
      "source": [
        "with open(articles_dict[articles[4].replace(' ','_')+'.txt']) as article:\n",
        "        doc = article.read()\n",
        "\n",
        "c_doc = text_cleaner(doc)\n",
        "sentences = nltk.sent_tokenize(c_doc)\n",
        "sentences = [[sent, topic, articles[4]] for sent in sentences]\n",
        "\n",
        "ndf = pd.DataFrame(sentences, columns=['text', 'topic', 'article'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "outputId": "1832b3ac-cae8-4e48-f6ee-9752502ab4f8",
        "id": "M3H23iLv1dbJ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "cdc_idx_dict = {}\n",
        "cdc_idx_sent = {}\n",
        "cdc_idx_art = {}\n",
        "\n",
        "for i,claim in enumerate(ref_data['clean_Claim']):\n",
        "    check_complete = False\n",
        "    while check_complete == False:\n",
        "        for idx,sentence in enumerate(ndf['text']):\n",
        "            test = claim.lower() in sentence.lower()\n",
        "            if test:\n",
        "                article = ref_data['Article'][i]\n",
        "                cdc_idx_dict[idx] = claim\n",
        "                cdc_idx_sent[idx] = [claim, sentence]\n",
        "                cdc_idx_art[idx] = [claim, article]\n",
        "                check_complete = True\n",
        "            elif idx == (len(ndf['text'])-1):\n",
        "                check_complete = True\n",
        "\n",
        "len(cdc_idx_dict), ref_data.shape[0]"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(4, 1332)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 719
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "outputId": "0c7006cd-4be6-4fb4-fe32-6bf505b84413",
        "id": "lUTUEc991dbK",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "cdc_idx_dict"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{5: 'a state law banning certain forms of abortion was unconstitutional',\n",
              " 11: 'it would be safer and would involve fewer risks for the women',\n",
              " 20: 'D&X abortions were never medically necessary',\n",
              " 29: 'government had no right to force doctors to perform any procedure other than what they felt would be the safest'}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 720
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "71Ix9WI61dbL",
        "colab": {}
      },
      "source": [
        "cdc = []\n",
        "\n",
        "for x in range(len(ndf)):\n",
        "    if x in list(cdc_idx_dict.keys()):\n",
        "        cdc.append(cdc_idx_dict.get(x))\n",
        "    else:\n",
        "        cdc.append('---')\n",
        "ndf['cdc'] = cdc\n",
        "\n",
        "df = pd.concat([ndf, df], axis=0, ignore_index=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "xZAS15TB--Tr"
      },
      "source": [
        "#### Article 5 "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "I6kJKJHL--Ts",
        "colab": {}
      },
      "source": [
        "with open(articles_dict[articles[5].replace(' ','_')+'.txt']) as article:\n",
        "        doc = article.read()\n",
        "\n",
        "c_doc = text_cleaner(doc)\n",
        "sentences = nltk.sent_tokenize(c_doc)\n",
        "sentences = [[sent, topic, articles[5]] for sent in sentences]\n",
        "\n",
        "ndf = pd.DataFrame(sentences, columns=['text', 'topic', 'article'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "outputId": "a208b41b-edf9-4ed7-f0fe-78248dde3639",
        "id": "Vy3Wu_c0--Ts",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "cdc_idx_dict = {}\n",
        "cdc_idx_sent = {}\n",
        "cdc_idx_art = {}\n",
        "\n",
        "for i,claim in enumerate(ref_data['clean_Claim']):\n",
        "    check_complete = False\n",
        "    while check_complete == False:\n",
        "        for idx,sentence in enumerate(ndf['text']):\n",
        "            test = claim.lower() in sentence.lower()\n",
        "            if test:\n",
        "                article = ref_data['Article'][i]\n",
        "                cdc_idx_dict[idx] = claim\n",
        "                cdc_idx_sent[idx] = [claim, sentence]\n",
        "                cdc_idx_art[idx] = [claim, article]\n",
        "                check_complete = True\n",
        "            elif idx == (len(ndf['text'])-1):\n",
        "                check_complete = True\n",
        "\n",
        "len(cdc_idx_dict), ref_data.shape[0]"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(2, 1332)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 723
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "outputId": "22bda93f-74dc-4d10-ca80-cf82f07e0915",
        "id": "N6cQ-gMK--Tt",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "cdc_idx_dict"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{10: 'abortion should be legal in all circumstances',\n",
              " 18: 'The government should not interfere with a woman’s ability to have an abortion'}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 724
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "xW6Ngrai--Tu",
        "colab": {}
      },
      "source": [
        "cdc = []\n",
        "\n",
        "for x in range(len(ndf)):\n",
        "    if x in list(cdc_idx_dict.keys()):\n",
        "        cdc.append(cdc_idx_dict.get(x))\n",
        "    else:\n",
        "        cdc.append('---')\n",
        "ndf['cdc'] = cdc\n",
        "\n",
        "df = pd.concat([ndf, df], axis=0, ignore_index=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "dJRYPO7o--UA"
      },
      "source": [
        "#### Article 6"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "YMaGfAwr--UA",
        "colab": {}
      },
      "source": [
        "with open(articles_dict[articles[6].replace(' ','_')+'.txt']) as article:\n",
        "        doc = article.read()\n",
        "\n",
        "c_doc = text_cleaner(doc)\n",
        "sentences = nltk.sent_tokenize(c_doc)\n",
        "sentences = [[sent, topic, articles[6]] for sent in sentences]\n",
        "\n",
        "ndf = pd.DataFrame(sentences, columns=['text', 'topic', 'article'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "outputId": "cf44a937-5845-4cb9-b818-f18eab1af9a8",
        "id": "RSn8e8ze--UB",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "cdc_idx_dict = {}\n",
        "cdc_idx_sent = {}\n",
        "cdc_idx_art = {}\n",
        "\n",
        "for i,claim in enumerate(ref_data['clean_Claim']):\n",
        "    check_complete = False\n",
        "    while check_complete == False:\n",
        "        for idx,sentence in enumerate(ndf['text']):\n",
        "            test = claim.lower() in sentence.lower()\n",
        "            if test:\n",
        "                article = ref_data['Article'][i]\n",
        "                cdc_idx_dict[idx] = claim\n",
        "                cdc_idx_sent[idx] = [claim, sentence]\n",
        "                cdc_idx_art[idx] = [claim, article]\n",
        "                check_complete = True\n",
        "            elif idx == (len(ndf['text'])-1):\n",
        "                check_complete = True\n",
        "\n",
        "len(cdc_idx_dict), ref_data.shape[0]"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(12, 1332)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 727
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "outputId": "a68f030b-d0fd-4ece-8a5f-dc1ad5217f87",
        "id": "xeRVSAlP--UC",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "cdc_idx_dict"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{3: 'induced abortion is the deliberate and unjust killing of the embryo in violation of its right to life',\n",
              " 4: 'the law should not criminalize just exercises of the right to control one’s own body',\n",
              " 8: 'criminalizing abortion will lead to the deaths of many women through ‘back-alley abortions',\n",
              " 11: 'the embryo has a right to life',\n",
              " 13: 'the embryo has a right to life',\n",
              " 46: 'life begins at conception',\n",
              " 55: 'abortion is wrong because it deprives the embryo of a valuable future',\n",
              " 59: 'as a standard embryo does have a highly valuable future, killing it is seriously wrong',\n",
              " 60: 'deliberate abortions are seriously immoral',\n",
              " 86: 'the embryo has a right to life',\n",
              " 93: 'the embryo has a right to life',\n",
              " 108: 'the fetus has a right to life'}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 728
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "3rxn4UcH--UC",
        "colab": {}
      },
      "source": [
        "cdc = []\n",
        "\n",
        "for x in range(len(ndf)):\n",
        "    if x in list(cdc_idx_dict.keys()):\n",
        "        cdc.append(cdc_idx_dict.get(x))\n",
        "    else:\n",
        "        cdc.append('---')\n",
        "ndf['cdc'] = cdc\n",
        "\n",
        "df = pd.concat([ndf, df], axis=0, ignore_index=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "TDtrIcL8--UD"
      },
      "source": [
        "#### Article 7"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "QK0eOlQk--UD",
        "colab": {}
      },
      "source": [
        "with open(articles_dict[articles[7].replace(' ','_')+'.txt']) as article:\n",
        "        doc = article.read()\n",
        "\n",
        "c_doc = text_cleaner(doc)\n",
        "sentences = nltk.sent_tokenize(c_doc)\n",
        "sentences = [[sent, topic, articles[7]] for sent in sentences]\n",
        "\n",
        "ndf = pd.DataFrame(sentences, columns=['text', 'topic', 'article'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "outputId": "5171d2d9-5aeb-4637-db7e-94d26a41bd94",
        "id": "Rv11iyRH--UE",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "cdc_idx_dict = {}\n",
        "cdc_idx_sent = {}\n",
        "cdc_idx_art = {}\n",
        "\n",
        "for i,claim in enumerate(ref_data['clean_Claim']):\n",
        "    check_complete = False\n",
        "    while check_complete == False:\n",
        "        for idx,sentence in enumerate(ndf['text']):\n",
        "            test = claim.lower() in sentence.lower()\n",
        "            if test:\n",
        "                article = ref_data['Article'][i]\n",
        "                cdc_idx_dict[idx] = claim\n",
        "                cdc_idx_sent[idx] = [claim, sentence]\n",
        "                cdc_idx_art[idx] = [claim, article]\n",
        "                check_complete = True\n",
        "            elif idx == (len(ndf['text'])-1):\n",
        "                check_complete = True\n",
        "\n",
        "len(cdc_idx_dict), ref_data.shape[0]"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(2, 1332)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 731
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "outputId": "bcf9ed70-77d8-4900-e6d7-cb7265992a8f",
        "id": "pn-YUUhe--UE",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "cdc_idx_dict"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{35: 'abortion, and especially late-term abortion, is unjust',\n",
              " 36: 'Critics consider the procedure to be infanticide'}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 732
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "o8cy5Owm--UF",
        "colab": {}
      },
      "source": [
        "cdc = []\n",
        "\n",
        "for x in range(len(ndf)):\n",
        "    if x in list(cdc_idx_dict.keys()):\n",
        "        cdc.append(cdc_idx_dict.get(x))\n",
        "    else:\n",
        "        cdc.append('---')\n",
        "ndf['cdc'] = cdc\n",
        "\n",
        "df = pd.concat([ndf, df], axis=0, ignore_index=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "1C7fCiEG--UF"
      },
      "source": [
        "#### Article 8"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "n1XU9SkM--UG",
        "colab": {}
      },
      "source": [
        "with open(articles_dict[articles[8].replace(' ','_')+'.txt']) as article:\n",
        "        doc = article.read()\n",
        "\n",
        "c_doc = text_cleaner(doc)\n",
        "sentences = nltk.sent_tokenize(c_doc)\n",
        "sentences = [[sent, topic, articles[8]] for sent in sentences]\n",
        "\n",
        "ndf = pd.DataFrame(sentences, columns=['text', 'topic', 'article'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "outputId": "7432907f-6313-42d9-eabf-c77fa6f723f0",
        "id": "BwP8mIGR--UG",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "cdc_idx_dict = {}\n",
        "cdc_idx_sent = {}\n",
        "cdc_idx_art = {}\n",
        "\n",
        "for i,claim in enumerate(ref_data['clean_Claim']):\n",
        "    check_complete = False\n",
        "    while check_complete == False:\n",
        "        for idx,sentence in enumerate(ndf['text']):\n",
        "            test = claim.lower() in sentence.lower()\n",
        "            if test:\n",
        "                article = ref_data['Article'][i]\n",
        "                cdc_idx_dict[idx] = claim\n",
        "                cdc_idx_sent[idx] = [claim, sentence]\n",
        "                cdc_idx_art[idx] = [claim, article]\n",
        "                check_complete = True\n",
        "            elif idx == (len(ndf['text'])-1):\n",
        "                check_complete = True\n",
        "\n",
        "len(cdc_idx_dict), ref_data.shape[0]"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(2, 1332)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 735
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "outputId": "df84d1ee-454e-4a53-e5f5-5bd04a7bc331",
        "id": "jIPRKals--UH",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "cdc_idx_dict"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{9: 'partial-birth abortion.. is.. unnecessary to preserve the health of the mother',\n",
              " 11: 'a partial-birth abortion bore no relevance to any measure needed to advance the health of any woman'}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 736
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "qW8aheyb--UI",
        "colab": {}
      },
      "source": [
        "cdc = []\n",
        "\n",
        "for x in range(len(ndf)):\n",
        "    if x in list(cdc_idx_dict.keys()):\n",
        "        cdc.append(cdc_idx_dict.get(x))\n",
        "    else:\n",
        "        cdc.append('---')\n",
        "ndf['cdc'] = cdc\n",
        "\n",
        "df = pd.concat([ndf, df], axis=0, ignore_index=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "ijA2uwue--UI"
      },
      "source": [
        "#### Article 9"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "lQtn4VrW--UI",
        "colab": {}
      },
      "source": [
        "with open(articles_dict[articles[9].replace(' ','_')+'.txt']) as article:\n",
        "        doc = article.read()\n",
        "\n",
        "c_doc = text_cleaner(doc)\n",
        "sentences = nltk.sent_tokenize(c_doc)\n",
        "sentences = [[sent, topic, articles[9]] for sent in sentences]\n",
        "\n",
        "ndf = pd.DataFrame(sentences, columns=['text', 'topic', 'article'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "outputId": "1e371459-d202-4716-f0ca-0f9594e45e33",
        "id": "pPhc1u6j--UJ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "cdc_idx_dict = {}\n",
        "cdc_idx_sent = {}\n",
        "cdc_idx_art = {}\n",
        "\n",
        "for i,claim in enumerate(ref_data['clean_Claim']):\n",
        "    check_complete = False\n",
        "    while check_complete == False:\n",
        "        for idx,sentence in enumerate(ndf['text']):\n",
        "            test = claim.lower() in sentence.lower()\n",
        "            if test:\n",
        "                article = ref_data['Article'][i]\n",
        "                cdc_idx_dict[idx] = claim\n",
        "                cdc_idx_sent[idx] = [claim, sentence]\n",
        "                cdc_idx_art[idx] = [claim, article]\n",
        "                check_complete = True\n",
        "            elif idx == (len(ndf['text'])-1):\n",
        "                check_complete = True\n",
        "\n",
        "len(cdc_idx_dict), ref_data.shape[0]"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(5, 1332)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 739
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "outputId": "d15e1193-cd37-42bf-ec71-60f1b02066c7",
        "id": "wzX9Gt1f--UK",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "cdc_idx_dict"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{3: 'is a person and therefore has a right to life',\n",
              " 4: 'whether or not to continue with a pregnancy is an inviolable personal choice',\n",
              " 9: 'legal abortion under medically controlled conditions is preferable to illegal back-alley abortion without proper medical supervision',\n",
              " 17: 'they could be used to form a slippery slope against all abortions',\n",
              " 62: \"women's lives are lost due to unsafe abortions when abortion is illegal\"}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 740
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "jWeSGBad--UK",
        "colab": {}
      },
      "source": [
        "cdc = []\n",
        "\n",
        "for x in range(len(ndf)):\n",
        "    if x in list(cdc_idx_dict.keys()):\n",
        "        cdc.append(cdc_idx_dict.get(x))\n",
        "    else:\n",
        "        cdc.append('---')\n",
        "ndf['cdc'] = cdc\n",
        "\n",
        "df = pd.concat([ndf, df], axis=0, ignore_index=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "Pauq2bKA--UL"
      },
      "source": [
        "#### Article 10"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "zQi_JcvS--UL",
        "colab": {}
      },
      "source": [
        "with open(articles_dict[articles[10].replace(' ','_')+'.txt']) as article:\n",
        "        doc = article.read()\n",
        "\n",
        "c_doc = text_cleaner(doc)\n",
        "sentences = nltk.sent_tokenize(c_doc)\n",
        "sentences = [[sent, topic, articles[10]] for sent in sentences]\n",
        "\n",
        "ndf = pd.DataFrame(sentences, columns=['text', 'topic', 'article'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "outputId": "cfbf3853-60ab-4cfa-ae66-b219775212c8",
        "id": "ZrFLscem--UM",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "cdc_idx_dict = {}\n",
        "cdc_idx_sent = {}\n",
        "cdc_idx_art = {}\n",
        "\n",
        "for i,claim in enumerate(ref_data['clean_Claim']):\n",
        "    check_complete = False\n",
        "    while check_complete == False:\n",
        "        for idx,sentence in enumerate(ndf['text']):\n",
        "            test = claim.lower() in sentence.lower()\n",
        "            if test:\n",
        "                article = ref_data['Article'][i]\n",
        "                cdc_idx_dict[idx] = claim\n",
        "                cdc_idx_sent[idx] = [claim, sentence]\n",
        "                cdc_idx_art[idx] = [claim, article]\n",
        "                check_complete = True\n",
        "            elif idx == (len(ndf['text'])-1):\n",
        "                check_complete = True\n",
        "\n",
        "len(cdc_idx_dict), ref_data.shape[0]"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(4, 1332)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 743
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "outputId": "437c9299-b21a-4131-f936-6345972253b8",
        "id": "2OAoF0tp--UN",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "cdc_idx_dict"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{18: 'one must abort a fetus if the continuation of pregnancy might imperil the life of the woman',\n",
              " 81: 'abortion is justifiable if a continuation of pregnancy might cause the woman severe physical or psychological harm',\n",
              " 87: 'In all circumstances, it should be her decision whether or not to terminate a pregnancy',\n",
              " 89: 'any decision should be left up to the woman within whose body the fetus is growing'}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 744
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "Ace6_o6J--UN",
        "colab": {}
      },
      "source": [
        "cdc = []\n",
        "\n",
        "for x in range(len(ndf)):\n",
        "    if x in list(cdc_idx_dict.keys()):\n",
        "        cdc.append(cdc_idx_dict.get(x))\n",
        "    else:\n",
        "        cdc.append('---')\n",
        "ndf['cdc'] = cdc\n",
        "\n",
        "df = pd.concat([ndf, df], axis=0, ignore_index=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "3zCzOzOF--UO"
      },
      "source": [
        "#### Article 11 "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "cEcM8SAi--UO",
        "colab": {}
      },
      "source": [
        "with open(articles_dict[articles[11].replace(' ','_')+'.txt']) as article:\n",
        "        doc = article.read()\n",
        "\n",
        "c_doc = text_cleaner(doc)\n",
        "sentences = nltk.sent_tokenize(c_doc)\n",
        "sentences = [[sent, topic, articles[11]] for sent in sentences]\n",
        "\n",
        "ndf = pd.DataFrame(sentences, columns=['text', 'topic', 'article'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "outputId": "99bd0690-1a91-4679-9bcd-259d26a4c87e",
        "id": "PFrFz2Ze--UP",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "cdc_idx_dict = {}\n",
        "cdc_idx_sent = {}\n",
        "cdc_idx_art = {}\n",
        "\n",
        "for i,claim in enumerate(ref_data['clean_Claim']):\n",
        "    check_complete = False\n",
        "    while check_complete == False:\n",
        "        for idx,sentence in enumerate(ndf['text']):\n",
        "            test = claim.lower() in sentence.lower()\n",
        "            if test:\n",
        "                article = ref_data['Article'][i]\n",
        "                cdc_idx_dict[idx] = claim\n",
        "                cdc_idx_sent[idx] = [claim, sentence]\n",
        "                cdc_idx_art[idx] = [claim, article]\n",
        "                check_complete = True\n",
        "            elif idx == (len(ndf['text'])-1):\n",
        "                check_complete = True\n",
        "\n",
        "len(cdc_idx_dict), ref_data.shape[0]"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(2, 1332)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 747
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "outputId": "6ba214d7-90ff-489c-ed0a-131c07afd782",
        "id": "a_edPAE7--UP",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "cdc_idx_dict"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{47: 'abortion causes mental health problems',\n",
              " 48: 'abortion causes mental health problems'}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 748
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "wuN63Ig2--UQ",
        "colab": {}
      },
      "source": [
        "cdc = []\n",
        "\n",
        "for x in range(len(ndf)):\n",
        "    if x in list(cdc_idx_dict.keys()):\n",
        "        cdc.append(cdc_idx_dict.get(x))\n",
        "    else:\n",
        "        cdc.append('---')\n",
        "ndf['cdc'] = cdc\n",
        "\n",
        "df = pd.concat([ndf, df], axis=0, ignore_index=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "JLH_xpyT--UQ"
      },
      "source": [
        "#### Article 12"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "JdUxjrdE--UR",
        "colab": {}
      },
      "source": [
        "with open(articles_dict[articles[12].replace(' ','_')+'.txt']) as article:\n",
        "        doc = article.read()\n",
        "\n",
        "c_doc = text_cleaner(doc)\n",
        "sentences = nltk.sent_tokenize(c_doc)\n",
        "sentences = [[sent, topic, articles[12]] for sent in sentences]\n",
        "\n",
        "ndf = pd.DataFrame(sentences, columns=['text', 'topic', 'article'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "outputId": "3266fc24-76a4-4354-a3e7-f805a07e986d",
        "id": "M_MSAC79--UR",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "cdc_idx_dict = {}\n",
        "cdc_idx_sent = {}\n",
        "cdc_idx_art = {}\n",
        "\n",
        "for i,claim in enumerate(ref_data['clean_Claim']):\n",
        "    check_complete = False\n",
        "    while check_complete == False:\n",
        "        for idx,sentence in enumerate(ndf['text']):\n",
        "            test = claim.lower() in sentence.lower()\n",
        "            if test:\n",
        "                article = ref_data['Article'][i]\n",
        "                cdc_idx_dict[idx] = claim\n",
        "                cdc_idx_sent[idx] = [claim, sentence]\n",
        "                cdc_idx_art[idx] = [claim, article]\n",
        "                check_complete = True\n",
        "            elif idx == (len(ndf['text'])-1):\n",
        "                check_complete = True\n",
        "\n",
        "len(cdc_idx_dict), ref_data.shape[0]"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(16, 1332)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 751
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "outputId": "c005ae40-0b11-457b-e8e5-049d5c485017",
        "id": "NncS5-kg--US",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "cdc_idx_dict"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{34: 'it should be illegal for governments to regulate abortion',\n",
              " 54: 'the state has an \"important and legitimate interest in protecting the potentiality of human life',\n",
              " 63: 'while the state has an interest in protecting the fetus \"at some point\", this interest cannot override that of the pregnant woman',\n",
              " 79: 'the fetus has a right to life',\n",
              " 118: 'abortion is morally wrong',\n",
              " 119: 'while the fetus is innocent and biologically human, it is not a person with a right to life',\n",
              " 131: 'a right to life beginning at conception',\n",
              " 139: 'the fetus has a right to life',\n",
              " 157: 'abortion involves unjust discrimination against the unborn',\n",
              " 160: 'abortion is morally wrong',\n",
              " 163: 'deliberate abortions are placed in the \"same moral category\" as killing an innocent adult human being',\n",
              " 169: 'the fetus has a right to life',\n",
              " 171: 'the fetus has a right to life',\n",
              " 177: 'life begins at conception',\n",
              " 178: 'abortion to be morally wrong',\n",
              " 186: 'abortion should be legal in all circumstances'}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 752
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "E28uQf21--US",
        "colab": {}
      },
      "source": [
        "cdc = []\n",
        "\n",
        "for x in range(len(ndf)):\n",
        "    if x in list(cdc_idx_dict.keys()):\n",
        "        cdc.append(cdc_idx_dict.get(x))\n",
        "    else:\n",
        "        cdc.append('---')\n",
        "ndf['cdc'] = cdc\n",
        "\n",
        "df = pd.concat([ndf, df], axis=0, ignore_index=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "CXMXsaNc--UT"
      },
      "source": [
        "#### Article 13"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "UudZ86mv--UT",
        "colab": {}
      },
      "source": [
        "with open(articles_dict[articles[13].replace(' ','_')+'.txt']) as article:\n",
        "        doc = article.read()\n",
        "\n",
        "c_doc = text_cleaner(doc)\n",
        "sentences = nltk.sent_tokenize(c_doc)\n",
        "sentences = [[sent, topic, articles[13]] for sent in sentences]\n",
        "\n",
        "ndf = pd.DataFrame(sentences, columns=['text', 'topic', 'article'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "outputId": "2cb58296-d892-46e7-9d24-07073fc35c1f",
        "id": "_h7p9A5r--UU",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "cdc_idx_dict = {}\n",
        "cdc_idx_sent = {}\n",
        "cdc_idx_art = {}\n",
        "\n",
        "for i,claim in enumerate(ref_data['clean_Claim']):\n",
        "    check_complete = False\n",
        "    while check_complete == False:\n",
        "        for idx,sentence in enumerate(ndf['text']):\n",
        "            test = claim.lower() in sentence.lower()\n",
        "            if test:\n",
        "                article = ref_data['Article'][i]\n",
        "                cdc_idx_dict[idx] = claim\n",
        "                cdc_idx_sent[idx] = [claim, sentence]\n",
        "                cdc_idx_art[idx] = [claim, article]\n",
        "                check_complete = True\n",
        "            elif idx == (len(ndf['text'])-1):\n",
        "                check_complete = True\n",
        "\n",
        "len(cdc_idx_dict), ref_data.shape[0]"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(5, 1332)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 755
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "outputId": "d54036d3-3dfa-46f9-810c-738d8e2854c3",
        "id": "aEeNGp_e--UU",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "cdc_idx_dict"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{2: 'the right of personal privacy includes the abortion decision',\n",
              " 4: 'there is a fundamental right to privacy encompassing the decision about abortion',\n",
              " 152: 'abortions should be legal under any circumstances',\n",
              " 155: 'abortions should be legal under any circumstances',\n",
              " 173: 'unborn children to have an inherent right to life'}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 756
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "Wgs5SH8I--UV",
        "colab": {}
      },
      "source": [
        "cdc = []\n",
        "\n",
        "for x in range(len(ndf)):\n",
        "    if x in list(cdc_idx_dict.keys()):\n",
        "        cdc.append(cdc_idx_dict.get(x))\n",
        "    else:\n",
        "        cdc.append('---')\n",
        "ndf['cdc'] = cdc\n",
        "\n",
        "df = pd.concat([ndf, df], axis=0, ignore_index=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5htG9_IxzDCl",
        "colab_type": "text"
      },
      "source": [
        "### 're engage with Myanmar '"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "outputId": "c65176b1-eb59-4597-8f64-b96fe7f7f955",
        "id": "wF-zPe_b1e53",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 136
        }
      },
      "source": [
        "topic = 're engage with Myanmar '\n",
        "\n",
        "articles = topic_article_dict[topic]\n",
        "articles"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['2007 Burmese anti-government protests',\n",
              " 'Maung Zarni',\n",
              " 'Burma',\n",
              " 'Burma Campaign UK',\n",
              " 'Foreign relations of Burma',\n",
              " 'International reaction to the 2007 Burmese anti-government protests',\n",
              " 'Burmese general election, 2010']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 758
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oXRkZvP_1erx",
        "colab_type": "code",
        "outputId": "54e8aaaf-fb5b-4c34-df85-c4274230f6ed",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "len(articles)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "7"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 759
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "4nlZPiMR1e54"
      },
      "source": [
        "#### Article 0 "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "VaIZcrFS1e54",
        "colab": {}
      },
      "source": [
        "with open(articles_dict[articles[0].replace(' ','_')+'.txt']) as article:\n",
        "        doc = article.read()\n",
        "\n",
        "c_doc = text_cleaner(doc)\n",
        "sentences = nltk.sent_tokenize(c_doc)\n",
        "sentences = [[sent, topic, articles[0]] for sent in sentences]\n",
        "\n",
        "ndf = pd.DataFrame(sentences, columns=['text', 'topic', 'article'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "outputId": "f9704fc1-abd8-4f64-ea84-a63b49a123d4",
        "id": "310t6awV1e55",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "cdc_idx_dict = {}\n",
        "cdc_idx_sent = {}\n",
        "cdc_idx_art = {}\n",
        "\n",
        "for i,claim in enumerate(ref_data['clean_Claim']):\n",
        "    check_complete = False\n",
        "    while check_complete == False:\n",
        "        for idx,sentence in enumerate(ndf['text']):\n",
        "            test = claim.lower() in sentence.lower()\n",
        "            if test:\n",
        "                article = ref_data['Article'][i]\n",
        "                cdc_idx_dict[idx] = claim\n",
        "                cdc_idx_sent[idx] = [claim, sentence]\n",
        "                cdc_idx_art[idx] = [claim, article]\n",
        "                check_complete = True\n",
        "            elif idx == (len(ndf['text'])-1):\n",
        "                check_complete = True\n",
        "\n",
        "len(cdc_idx_dict), ref_data.shape[0]"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(2, 1332)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 761
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "outputId": "5a676330-80c0-4852-bf04-059b323ac388",
        "id": "qFFSaYq11e56",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "cdc_idx_dict"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{324: \"Burma's rulers continue to defy the world's just demand to stop their vicious persecution\",\n",
              " 335: 'the government wants to engage again in constructive dialogue'}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 762
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "i8OBZFLz1e57",
        "colab": {}
      },
      "source": [
        "cdc = []\n",
        "\n",
        "for x in range(len(ndf)):\n",
        "    if x in list(cdc_idx_dict.keys()):\n",
        "        cdc.append(cdc_idx_dict.get(x))\n",
        "    else:\n",
        "        cdc.append('---')\n",
        "ndf['cdc'] = cdc\n",
        "\n",
        "df = pd.concat([ndf, df], axis=0, ignore_index=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "6kh8vHLM1e58"
      },
      "source": [
        "#### Article 1 "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "sTQnj42p1e58",
        "colab": {}
      },
      "source": [
        "with open(articles_dict[articles[1].replace(' ','_')+'.txt']) as article:\n",
        "        doc = article.read()\n",
        "\n",
        "c_doc = text_cleaner(doc)\n",
        "sentences = nltk.sent_tokenize(c_doc)\n",
        "sentences = [[sent, topic, articles[1]] for sent in sentences]\n",
        "\n",
        "ndf = pd.DataFrame(sentences, columns=['text', 'topic', 'article'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "outputId": "eec9dd16-05c3-4e25-80eb-b185b1add0d0",
        "id": "plITADd-1e59",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "cdc_idx_dict = {}\n",
        "cdc_idx_sent = {}\n",
        "cdc_idx_art = {}\n",
        "\n",
        "for i,claim in enumerate(ref_data['clean_Claim']):\n",
        "    check_complete = False\n",
        "    while check_complete == False:\n",
        "        for idx,sentence in enumerate(ndf['text']):\n",
        "            test = claim.lower() in sentence.lower()\n",
        "            if test:\n",
        "                article = ref_data['Article'][i]\n",
        "                cdc_idx_dict[idx] = claim\n",
        "                cdc_idx_sent[idx] = [claim, sentence]\n",
        "                cdc_idx_art[idx] = [claim, article]\n",
        "                check_complete = True\n",
        "            elif idx == (len(ndf['text'])-1):\n",
        "                check_complete = True\n",
        "\n",
        "len(cdc_idx_dict), ref_data.shape[0]"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(3, 1332)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 765
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "outputId": "0f164ce0-af85-4553-c7b5-c58fb39b4da2",
        "id": "ghLjYnvp1e59",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "cdc_idx_dict"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{14: 'economic sanctions and political pressure by Western countries on Burma was counter-productive and futile',\n",
              " 30: 'economic sanctions and political pressure on the Burmese military regime remain the only feasible policy to achieve a restoration of democracy and human rights in Burma',\n",
              " 33: 'efforts to sanction Burma were useless'}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 766
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "WFQhItzv1e5-",
        "colab": {}
      },
      "source": [
        "cdc = []\n",
        "\n",
        "for x in range(len(ndf)):\n",
        "    if x in list(cdc_idx_dict.keys()):\n",
        "        cdc.append(cdc_idx_dict.get(x))\n",
        "    else:\n",
        "        cdc.append('---')\n",
        "ndf['cdc'] = cdc\n",
        "\n",
        "df = pd.concat([df, ndf], axis=0, ignore_index=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "W_p6o2Xi1e5_"
      },
      "source": [
        "#### Article 2 "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "yQnP4zDC1e5_",
        "colab": {}
      },
      "source": [
        "with open(articles_dict[articles[2].replace(' ','_')+'.txt']) as article:\n",
        "        doc = article.read()\n",
        "\n",
        "c_doc = text_cleaner(doc)\n",
        "sentences = nltk.sent_tokenize(c_doc)\n",
        "sentences = [[sent, topic, articles[2]] for sent in sentences]\n",
        "\n",
        "ndf = pd.DataFrame(sentences, columns=['text', 'topic', 'article'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "outputId": "273dd058-3f39-4cf5-e9b7-06343d19fd5a",
        "id": "EVAxHj2R1e5_",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "cdc_idx_dict = {}\n",
        "cdc_idx_sent = {}\n",
        "cdc_idx_art = {}\n",
        "\n",
        "for i,claim in enumerate(ref_data['clean_Claim']):\n",
        "    check_complete = False\n",
        "    while check_complete == False:\n",
        "        for idx,sentence in enumerate(ndf['text']):\n",
        "            test = claim.lower() in sentence.lower()\n",
        "            if test:\n",
        "                article = ref_data['Article'][i]\n",
        "                cdc_idx_dict[idx] = claim\n",
        "                cdc_idx_sent[idx] = [claim, sentence]\n",
        "                cdc_idx_art[idx] = [claim, article]\n",
        "                check_complete = True\n",
        "            elif idx == (len(ndf['text'])-1):\n",
        "                check_complete = True\n",
        "\n",
        "len(cdc_idx_dict), ref_data.shape[0]"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(4, 1332)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 769
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "outputId": "00cf5c2d-bc96-43e4-e158-63337907d161",
        "id": "nF9tkps51e6A",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "cdc_idx_dict"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{157: 'the government has embarked on a series of reforms toward liberal democracy',\n",
              " 223: \"the military regime in Burma is one of the world's most repressive and abusive regimes\",\n",
              " 236: \"Burma's human rights record has been improving\",\n",
              " 273: 'the American-led sanctions have had adverse effects on the civilian population'}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 770
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "IhzNx_nF1e6B",
        "colab": {}
      },
      "source": [
        "cdc = []\n",
        "\n",
        "for x in range(len(ndf)):\n",
        "    if x in list(cdc_idx_dict.keys()):\n",
        "        cdc.append(cdc_idx_dict.get(x))\n",
        "    else:\n",
        "        cdc.append('---')\n",
        "ndf['cdc'] = cdc\n",
        "\n",
        "df = pd.concat([ndf, df], axis=0, ignore_index=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "APQfmvX41e6C"
      },
      "source": [
        "#### Article 3 "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "Ggi_MTWf1e6C",
        "colab": {}
      },
      "source": [
        "with open(articles_dict[articles[3].replace(' ','_')+'.txt']) as article:\n",
        "        doc = article.read()\n",
        "\n",
        "c_doc = text_cleaner(doc)\n",
        "sentences = nltk.sent_tokenize(c_doc)\n",
        "sentences = [[sent, topic, articles[3]] for sent in sentences]\n",
        "\n",
        "ndf = pd.DataFrame(sentences, columns=['text', 'topic', 'article'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "outputId": "84589858-0ac2-4b8f-9d6b-3eba12511b0d",
        "id": "dyHDzc0O1e6D",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "cdc_idx_dict = {}\n",
        "cdc_idx_sent = {}\n",
        "cdc_idx_art = {}\n",
        "\n",
        "for i,claim in enumerate(ref_data['clean_Claim']):\n",
        "    check_complete = False\n",
        "    while check_complete == False:\n",
        "        for idx,sentence in enumerate(ndf['text']):\n",
        "            test = claim.lower() in sentence.lower()\n",
        "            if test:\n",
        "                article = ref_data['Article'][i]\n",
        "                cdc_idx_dict[idx] = claim\n",
        "                cdc_idx_sent[idx] = [claim, sentence]\n",
        "                cdc_idx_art[idx] = [claim, article]\n",
        "                check_complete = True\n",
        "            elif idx == (len(ndf['text'])-1):\n",
        "                check_complete = True\n",
        "\n",
        "len(cdc_idx_dict), ref_data.shape[0]"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(1, 1332)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 773
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "outputId": "d1bf6a23-c000-4223-b717-32cd74646638",
        "id": "T_keMFCs1e6D",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "cdc_idx_dict"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{23: 'sanctions are designed to pressure the regime to enter into dialogue with the demcoracy movement'}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 774
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "iH5saiqd1e6E",
        "colab": {}
      },
      "source": [
        "cdc = []\n",
        "\n",
        "for x in range(len(ndf)):\n",
        "    if x in list(cdc_idx_dict.keys()):\n",
        "        cdc.append(cdc_idx_dict.get(x))\n",
        "    else:\n",
        "        cdc.append('---')\n",
        "ndf['cdc'] = cdc\n",
        "\n",
        "df = pd.concat([ndf, df], axis=0, ignore_index=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "khZQSvV21e6K"
      },
      "source": [
        "#### Article 4 "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "eAzcRGr51e6K",
        "colab": {}
      },
      "source": [
        "with open(articles_dict[articles[4].replace(' ','_')+'.txt']) as article:\n",
        "        doc = article.read()\n",
        "\n",
        "c_doc = text_cleaner(doc)\n",
        "sentences = nltk.sent_tokenize(c_doc)\n",
        "sentences = [[sent, topic, articles[4]] for sent in sentences]\n",
        "\n",
        "ndf = pd.DataFrame(sentences, columns=['text', 'topic', 'article'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "outputId": "a976c695-7975-43f2-cc95-302788ef267d",
        "id": "9XVnx7mT1e6L",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "cdc_idx_dict = {}\n",
        "cdc_idx_sent = {}\n",
        "cdc_idx_art = {}\n",
        "\n",
        "for i,claim in enumerate(ref_data['clean_Claim']):\n",
        "    check_complete = False\n",
        "    while check_complete == False:\n",
        "        for idx,sentence in enumerate(ndf['text']):\n",
        "            test = claim.lower() in sentence.lower()\n",
        "            if test:\n",
        "                article = ref_data['Article'][i]\n",
        "                cdc_idx_dict[idx] = claim\n",
        "                cdc_idx_sent[idx] = [claim, sentence]\n",
        "                cdc_idx_art[idx] = [claim, article]\n",
        "                check_complete = True\n",
        "            elif idx == (len(ndf['text'])-1):\n",
        "                check_complete = True\n",
        "\n",
        "len(cdc_idx_dict), ref_data.shape[0]"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(1, 1332)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 777
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "outputId": "eb96ebdf-8e92-4339-e679-603dbe6b22d1",
        "id": "cxFrPEJh1e6M",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "cdc_idx_dict"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{13: 'the American-led sanctions have had adverse effects on the civilian population'}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 778
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "Z48YgeFH1e6M",
        "colab": {}
      },
      "source": [
        "cdc = []\n",
        "\n",
        "for x in range(len(ndf)):\n",
        "    if x in list(cdc_idx_dict.keys()):\n",
        "        cdc.append(cdc_idx_dict.get(x))\n",
        "    else:\n",
        "        cdc.append('---')\n",
        "ndf['cdc'] = cdc\n",
        "\n",
        "df = pd.concat([ndf, df], axis=0, ignore_index=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "Jzioo_sf_HdF"
      },
      "source": [
        "#### Article 5 "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "v2Vt4PuZ_Hdi",
        "colab": {}
      },
      "source": [
        "with open(articles_dict[articles[5].replace(' ','_')+'.txt']) as article:\n",
        "        doc = article.read()\n",
        "\n",
        "c_doc = text_cleaner(doc)\n",
        "sentences = nltk.sent_tokenize(c_doc)\n",
        "sentences = [[sent, topic, articles[5]] for sent in sentences]\n",
        "\n",
        "ndf = pd.DataFrame(sentences, columns=['text', 'topic', 'article'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "outputId": "71fcaa00-89c0-4f28-c62f-5f477867809f",
        "id": "yfsSsFlI_Heb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "cdc_idx_dict = {}\n",
        "cdc_idx_sent = {}\n",
        "cdc_idx_art = {}\n",
        "\n",
        "for i,claim in enumerate(ref_data['clean_Claim']):\n",
        "    check_complete = False\n",
        "    while check_complete == False:\n",
        "        for idx,sentence in enumerate(ndf['text']):\n",
        "            test = claim.lower() in sentence.lower()\n",
        "            if test:\n",
        "                article = ref_data['Article'][i]\n",
        "                cdc_idx_dict[idx] = claim\n",
        "                cdc_idx_sent[idx] = [claim, sentence]\n",
        "                cdc_idx_art[idx] = [claim, article]\n",
        "                check_complete = True\n",
        "            elif idx == (len(ndf['text'])-1):\n",
        "                check_complete = True\n",
        "\n",
        "len(cdc_idx_dict), ref_data.shape[0]"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(2, 1332)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 781
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "outputId": "cf34fde9-7189-4f42-c6c7-553ae41bf59b",
        "id": "Q53sO0s1_Hfh",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "cdc_idx_dict"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{42: 'the best way to go is through engagement and encouragement',\n",
              " 48: 'constructive engagement with the Burmese junta has failed'}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 782
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "U9o8i_VO_Hgs",
        "colab": {}
      },
      "source": [
        "cdc = []\n",
        "\n",
        "for x in range(len(ndf)):\n",
        "    if x in list(cdc_idx_dict.keys()):\n",
        "        cdc.append(cdc_idx_dict.get(x))\n",
        "    else:\n",
        "        cdc.append('---')\n",
        "ndf['cdc'] = cdc\n",
        "\n",
        "df = pd.concat([ndf, df], axis=0, ignore_index=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "LPK9ip67_Hhi"
      },
      "source": [
        "#### Article 6"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "WxpSZUPL_Hh8",
        "colab": {}
      },
      "source": [
        "with open(articles_dict[articles[6].replace(' ','_')+'.txt']) as article:\n",
        "        doc = article.read()\n",
        "\n",
        "c_doc = text_cleaner(doc)\n",
        "sentences = nltk.sent_tokenize(c_doc)\n",
        "sentences = [[sent, topic, articles[6]] for sent in sentences]\n",
        "\n",
        "ndf = pd.DataFrame(sentences, columns=['text', 'topic', 'article'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "outputId": "db77ed9a-a55c-420f-c4b4-02b63ac40dbb",
        "id": "Eh5YzQAV_Hi0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "cdc_idx_dict = {}\n",
        "cdc_idx_sent = {}\n",
        "cdc_idx_art = {}\n",
        "\n",
        "for i,claim in enumerate(ref_data['clean_Claim']):\n",
        "    check_complete = False\n",
        "    while check_complete == False:\n",
        "        for idx,sentence in enumerate(ndf['text']):\n",
        "            test = claim.lower() in sentence.lower()\n",
        "            if test:\n",
        "                article = ref_data['Article'][i]\n",
        "                cdc_idx_dict[idx] = claim\n",
        "                cdc_idx_sent[idx] = [claim, sentence]\n",
        "                cdc_idx_art[idx] = [claim, article]\n",
        "                check_complete = True\n",
        "            elif idx == (len(ndf['text'])-1):\n",
        "                check_complete = True\n",
        "\n",
        "len(cdc_idx_dict), ref_data.shape[0]"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(2, 1332)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 785
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "outputId": "0a15f7b7-887c-45bc-818b-dab5f3a6938b",
        "id": "1MBn8d9G_Hj4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "cdc_idx_dict"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{63: 'The international community can provide constructive help and refrain from any negative impact on the domestic political process of Myanmar',\n",
              " 93: 'When peaceful democratic movements are suppressed – as in Burma – then the democracies of the world cannot remain silent&nbsp'}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 786
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "VakZdOF8_Hk5",
        "colab": {}
      },
      "source": [
        "cdc = []\n",
        "\n",
        "for x in range(len(ndf)):\n",
        "    if x in list(cdc_idx_dict.keys()):\n",
        "        cdc.append(cdc_idx_dict.get(x))\n",
        "    else:\n",
        "        cdc.append('---')\n",
        "ndf['cdc'] = cdc\n",
        "\n",
        "df = pd.concat([ndf, df], axis=0, ignore_index=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M24EypVWzH28",
        "colab_type": "text"
      },
      "source": [
        "### 'reintroduce national service '"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "outputId": "ee6013b8-3999-4918-81a9-e2dcdc7f0235",
        "id": "5sputouI1gfH",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 119
        }
      },
      "source": [
        "topic = 'reintroduce national service '\n",
        "\n",
        "articles = topic_article_dict[topic]\n",
        "articles"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['Conscription',\n",
              " 'Charles B Rangel',\n",
              " 'Conscription in Germany',\n",
              " 'Conscription in the United States',\n",
              " 'National Service Act of 2006',\n",
              " 'Counter-recruitment']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 788
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4s4t-eKT1gRC",
        "colab_type": "code",
        "outputId": "107efb5a-d9a2-47e7-d934-4fca2c9678fe",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "len(articles)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "6"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 789
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "1gOXGCdM1gfI"
      },
      "source": [
        "#### Article 0 "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "p5xlw3BY1gfI",
        "colab": {}
      },
      "source": [
        "with open(articles_dict[articles[0].replace(' ','_')+'.txt']) as article:\n",
        "        doc = article.read()\n",
        "\n",
        "c_doc = text_cleaner(doc)\n",
        "sentences = nltk.sent_tokenize(c_doc)\n",
        "sentences = [[sent, topic, articles[0]] for sent in sentences]\n",
        "\n",
        "ndf = pd.DataFrame(sentences, columns=['text', 'topic', 'article'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "outputId": "1a0fd444-6c37-4633-9595-0700b744d4f4",
        "id": "rnjzcijv1gfJ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "cdc_idx_dict = {}\n",
        "cdc_idx_sent = {}\n",
        "cdc_idx_art = {}\n",
        "\n",
        "for i,claim in enumerate(ref_data['clean_Claim']):\n",
        "    check_complete = False\n",
        "    while check_complete == False:\n",
        "        for idx,sentence in enumerate(ndf['text']):\n",
        "            test = claim.lower() in sentence.lower()\n",
        "            if test:\n",
        "                article = ref_data['Article'][i]\n",
        "                cdc_idx_dict[idx] = claim\n",
        "                cdc_idx_sent[idx] = [claim, sentence]\n",
        "                cdc_idx_art[idx] = [claim, article]\n",
        "                check_complete = True\n",
        "            elif idx == (len(ndf['text'])-1):\n",
        "                check_complete = True\n",
        "\n",
        "len(cdc_idx_dict), ref_data.shape[0]"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(13, 1332)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 791
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "outputId": "fb07ecae-28c4-49e5-e2a8-fb5f0fbf37cf",
        "id": "3mJS6rLu1gfK",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "cdc_idx_dict"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{7: 'it violates individual rights',\n",
              " 327: 'represents slavery and involuntary servitude',\n",
              " 328: 'Of all the statist violations of individual rights in a mixed economy, the military draft is the worst',\n",
              " 329: 'It is an abrogation of rights',\n",
              " 330: 'It negates man’s fundamental right—the right to life',\n",
              " 334: 'the very conception of a just government in its duty to the citizen includes the reciprocal obligation of the citizen to render military service in case of need',\n",
              " 335: 'in a cost-to-benefit ratio, conscription during peace time is not worthwhile',\n",
              " 336: 'Months or years of service amongst the most fit and capable subtracts from the productivity of the economy',\n",
              " 341: 'The work effort of the conscripts is effectively wasted',\n",
              " 343: 'professionally-skilled conscripts are also difficult to replace in the civilian workforce',\n",
              " 344: 'Every soldier conscripted in the army is taken away from his civilian work, and away from contributing to the economy which funds the military',\n",
              " 348: 'it was the right and privilege of every citizen to participate to the defense of the whole society',\n",
              " 352: 'mandatory military and national service as ways of instilling maturity in young adults'}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 792
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "mdPYmOP_1gfL",
        "colab": {}
      },
      "source": [
        "cdc = []\n",
        "\n",
        "for x in range(len(ndf)):\n",
        "    if x in list(cdc_idx_dict.keys()):\n",
        "        cdc.append(cdc_idx_dict.get(x))\n",
        "    else:\n",
        "        cdc.append('---')\n",
        "ndf['cdc'] = cdc\n",
        "\n",
        "df = pd.concat([ndf, df], axis=0, ignore_index=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "0XMmyhCl1gfM"
      },
      "source": [
        "#### Article 1 "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "JrXunWuq1gfM",
        "colab": {}
      },
      "source": [
        "with open(articles_dict[articles[1].replace(' ','_')+'.txt']) as article:\n",
        "        doc = article.read()\n",
        "\n",
        "c_doc = text_cleaner(doc)\n",
        "sentences = nltk.sent_tokenize(c_doc)\n",
        "sentences = [[sent, topic, articles[1]] for sent in sentences]\n",
        "\n",
        "ndf = pd.DataFrame(sentences, columns=['text', 'topic', 'article'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "outputId": "5d5d104f-02ef-4dbb-b0ef-c176692353fb",
        "id": "CIagmzgT1gfN",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "cdc_idx_dict = {}\n",
        "cdc_idx_sent = {}\n",
        "cdc_idx_art = {}\n",
        "\n",
        "for i,claim in enumerate(ref_data['clean_Claim']):\n",
        "    check_complete = False\n",
        "    while check_complete == False:\n",
        "        for idx,sentence in enumerate(ndf['text']):\n",
        "            test = claim.lower() in sentence.lower()\n",
        "            if test:\n",
        "                article = ref_data['Article'][i]\n",
        "                cdc_idx_dict[idx] = claim\n",
        "                cdc_idx_sent[idx] = [claim, sentence]\n",
        "                cdc_idx_art[idx] = [claim, article]\n",
        "                check_complete = True\n",
        "            elif idx == (len(ndf['text'])-1):\n",
        "                check_complete = True\n",
        "\n",
        "len(cdc_idx_dict), ref_data.shape[0]"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(1, 1332)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 795
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "outputId": "72ae6d2d-1cca-46d0-ccf3-a8eea8502ae3",
        "id": "oQ49_Hre1gfN",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "cdc_idx_dict"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{213: 'Fairness dictates that the sons and daughters of the white middle and upper classes share the burden of war'}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 796
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "sQzSTiSl1gfO",
        "colab": {}
      },
      "source": [
        "cdc = []\n",
        "\n",
        "for x in range(len(ndf)):\n",
        "    if x in list(cdc_idx_dict.keys()):\n",
        "        cdc.append(cdc_idx_dict.get(x))\n",
        "    else:\n",
        "        cdc.append('---')\n",
        "ndf['cdc'] = cdc\n",
        "\n",
        "df = pd.concat([df, ndf], axis=0, ignore_index=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "dEqZRCeZ1gfP"
      },
      "source": [
        "#### Article 2 "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "UAVZ7Wwd1gfP",
        "colab": {}
      },
      "source": [
        "with open(articles_dict[articles[2].replace(' ','_')+'.txt']) as article:\n",
        "        doc = article.read()\n",
        "\n",
        "c_doc = text_cleaner(doc)\n",
        "sentences = nltk.sent_tokenize(c_doc)\n",
        "sentences = [[sent, topic, articles[2]] for sent in sentences]\n",
        "\n",
        "ndf = pd.DataFrame(sentences, columns=['text', 'topic', 'article'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "outputId": "48637fd2-d71d-45a6-c0ad-601ab373a8fe",
        "id": "Ow-1IAVl1gfQ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "cdc_idx_dict = {}\n",
        "cdc_idx_sent = {}\n",
        "cdc_idx_art = {}\n",
        "\n",
        "for i,claim in enumerate(ref_data['clean_Claim']):\n",
        "    check_complete = False\n",
        "    while check_complete == False:\n",
        "        for idx,sentence in enumerate(ndf['text']):\n",
        "            test = claim.lower() in sentence.lower()\n",
        "            if test:\n",
        "                article = ref_data['Article'][i]\n",
        "                cdc_idx_dict[idx] = claim\n",
        "                cdc_idx_sent[idx] = [claim, sentence]\n",
        "                cdc_idx_art[idx] = [claim, article]\n",
        "                check_complete = True\n",
        "            elif idx == (len(ndf['text'])-1):\n",
        "                check_complete = True\n",
        "\n",
        "len(cdc_idx_dict), ref_data.shape[0]"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(6, 1332)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 799
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "outputId": "467b334f-5257-42d4-e870-cece66f840b9",
        "id": "uAnKzh8A1gfR",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "cdc_idx_dict"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{84: 'some service is better than none at all, bringing citizens in contact with their military',\n",
              " 88: 'the abolition of the draft would lead to recruitment shortages even for higher ranking positions',\n",
              " 89: 'considerable savings in defence spending from abolishing the draft',\n",
              " 92: 'professional armed forces can be more expensive than a draft-based military',\n",
              " 95: 'the draft was simply anachronistic',\n",
              " 97: 'The draft obliged male citizens to pay society back through their military or civilian service'}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 800
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "_UUgKEtK1gfR",
        "colab": {}
      },
      "source": [
        "cdc = []\n",
        "\n",
        "for x in range(len(ndf)):\n",
        "    if x in list(cdc_idx_dict.keys()):\n",
        "        cdc.append(cdc_idx_dict.get(x))\n",
        "    else:\n",
        "        cdc.append('---')\n",
        "ndf['cdc'] = cdc\n",
        "\n",
        "df = pd.concat([ndf, df], axis=0, ignore_index=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "4z_OgZ5G1gfS"
      },
      "source": [
        "#### Article 3 "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "_lw_FwSg1gfS",
        "colab": {}
      },
      "source": [
        "with open(articles_dict[articles[3].replace(' ','_')+'.txt']) as article:\n",
        "        doc = article.read()\n",
        "\n",
        "c_doc = text_cleaner(doc)\n",
        "sentences = nltk.sent_tokenize(c_doc)\n",
        "sentences = [[sent, topic, articles[3]] for sent in sentences]\n",
        "\n",
        "ndf = pd.DataFrame(sentences, columns=['text', 'topic', 'article'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "outputId": "35f92105-008e-448f-b946-e0dbc0cdfa40",
        "id": "JpwyTwgF1gfT",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "cdc_idx_dict = {}\n",
        "cdc_idx_sent = {}\n",
        "cdc_idx_art = {}\n",
        "\n",
        "for i,claim in enumerate(ref_data['clean_Claim']):\n",
        "    check_complete = False\n",
        "    while check_complete == False:\n",
        "        for idx,sentence in enumerate(ndf['text']):\n",
        "            test = claim.lower() in sentence.lower()\n",
        "            if test:\n",
        "                article = ref_data['Article'][i]\n",
        "                cdc_idx_dict[idx] = claim\n",
        "                cdc_idx_sent[idx] = [claim, sentence]\n",
        "                cdc_idx_art[idx] = [claim, article]\n",
        "                check_complete = True\n",
        "            elif idx == (len(ndf['text'])-1):\n",
        "                check_complete = True\n",
        "\n",
        "len(cdc_idx_dict), ref_data.shape[0]"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(7, 1332)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 803
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "outputId": "4be223a9-4ee6-4bff-f6fe-64f142fd48e6",
        "id": "vUNzZBdu1gfU",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "cdc_idx_dict"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{86: 'conscription would not provide adequate protection for the rights of conscientious objectors',\n",
              " 212: 'adequate military strength could be maintained without having conscription',\n",
              " 275: 'the draft is fundamentally unfair',\n",
              " 280: 'The draft has been perceived by some as unfairly targeting the poor and lower middle classes',\n",
              " 298: 'it was less likely that a republic with conscription would engage in preemptive wars',\n",
              " 328: 'the draft should be reinstated to make the military more equal',\n",
              " 329: 'the draft \"does bring people from all quarters of our society together in the common purpose of serving'}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 804
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "Fwp3pAWA1gfU",
        "colab": {}
      },
      "source": [
        "cdc = []\n",
        "\n",
        "for x in range(len(ndf)):\n",
        "    if x in list(cdc_idx_dict.keys()):\n",
        "        cdc.append(cdc_idx_dict.get(x))\n",
        "    else:\n",
        "        cdc.append('---')\n",
        "ndf['cdc'] = cdc\n",
        "\n",
        "df = pd.concat([ndf, df], axis=0, ignore_index=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "GbXdb9Xo1gfV"
      },
      "source": [
        "#### Article 4 "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "YDnWbXJs1gfV",
        "colab": {}
      },
      "source": [
        "with open(articles_dict[articles[4].replace(' ','_')+'.txt']) as article:\n",
        "        doc = article.read()\n",
        "\n",
        "c_doc = text_cleaner(doc)\n",
        "sentences = nltk.sent_tokenize(c_doc)\n",
        "sentences = [[sent, topic, articles[4]] for sent in sentences]\n",
        "\n",
        "ndf = pd.DataFrame(sentences, columns=['text', 'topic', 'article'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "outputId": "27124a39-df4b-42f7-a930-5a80d0bcdb65",
        "id": "TTu_lXJk1gfW",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "cdc_idx_dict = {}\n",
        "cdc_idx_sent = {}\n",
        "cdc_idx_art = {}\n",
        "\n",
        "for i,claim in enumerate(ref_data['clean_Claim']):\n",
        "    check_complete = False\n",
        "    while check_complete == False:\n",
        "        for idx,sentence in enumerate(ndf['text']):\n",
        "            test = claim.lower() in sentence.lower()\n",
        "            if test:\n",
        "                article = ref_data['Article'][i]\n",
        "                cdc_idx_dict[idx] = claim\n",
        "                cdc_idx_sent[idx] = [claim, sentence]\n",
        "                cdc_idx_art[idx] = [claim, article]\n",
        "                check_complete = True\n",
        "            elif idx == (len(ndf['text'])-1):\n",
        "                check_complete = True\n",
        "\n",
        "len(cdc_idx_dict), ref_data.shape[0]"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(2, 1332)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 807
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "outputId": "a92c2b11-7ce9-44f1-f827-6c5fba68caad",
        "id": "e0EZrWM51gfX",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "cdc_idx_dict"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{4: 'in the case of a mandatory draft members of the U.S. Congress would be much less likely to authorize an unnecessary war',\n",
              " 5: 'bringing back the draft would remedy the social disparity'}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 808
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "lCmXW7vI1gfX",
        "colab": {}
      },
      "source": [
        "cdc = []\n",
        "\n",
        "for x in range(len(ndf)):\n",
        "    if x in list(cdc_idx_dict.keys()):\n",
        "        cdc.append(cdc_idx_dict.get(x))\n",
        "    else:\n",
        "        cdc.append('---')\n",
        "ndf['cdc'] = cdc\n",
        "\n",
        "df = pd.concat([ndf, df], axis=0, ignore_index=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "76sB3CvJ_RAC"
      },
      "source": [
        "#### Article 5 "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "P8GwJoJG_RAD",
        "colab": {}
      },
      "source": [
        "with open(articles_dict[articles[5].replace(' ','_')+'.txt']) as article:\n",
        "        doc = article.read()\n",
        "\n",
        "c_doc = text_cleaner(doc)\n",
        "sentences = nltk.sent_tokenize(c_doc)\n",
        "sentences = [[sent, topic, articles[5]] for sent in sentences]\n",
        "\n",
        "ndf = pd.DataFrame(sentences, columns=['text', 'topic', 'article'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "outputId": "492d8888-0287-47d9-d942-5683b707c8f4",
        "id": "hgU-FheW_RAP",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "cdc_idx_dict = {}\n",
        "cdc_idx_sent = {}\n",
        "cdc_idx_art = {}\n",
        "\n",
        "for i,claim in enumerate(ref_data['clean_Claim']):\n",
        "    check_complete = False\n",
        "    while check_complete == False:\n",
        "        for idx,sentence in enumerate(ndf['text']):\n",
        "            test = claim.lower() in sentence.lower()\n",
        "            if test:\n",
        "                article = ref_data['Article'][i]\n",
        "                cdc_idx_dict[idx] = claim\n",
        "                cdc_idx_sent[idx] = [claim, sentence]\n",
        "                cdc_idx_art[idx] = [claim, article]\n",
        "                check_complete = True\n",
        "            elif idx == (len(ndf['text'])-1):\n",
        "                check_complete = True\n",
        "\n",
        "len(cdc_idx_dict), ref_data.shape[0]"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(3, 1332)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 811
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "outputId": "d37252f5-fd6c-41cd-d477-d8b3c2037b23",
        "id": "3wTBPadl_RAQ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "cdc_idx_dict"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{64: 'military service provides job skills',\n",
              " 65: 'personal and technical skills learned in the military will improve later employment prospects in civilian life',\n",
              " 68: 'leadership skills acquired during military training can absolutely enhance one’s chances for success in corporate life'}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 812
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "FxUVWfvv_RAR",
        "colab": {}
      },
      "source": [
        "cdc = []\n",
        "\n",
        "for x in range(len(ndf)):\n",
        "    if x in list(cdc_idx_dict.keys()):\n",
        "        cdc.append(cdc_idx_dict.get(x))\n",
        "    else:\n",
        "        cdc.append('---')\n",
        "ndf['cdc'] = cdc\n",
        "\n",
        "df = pd.concat([ndf, df], axis=0, ignore_index=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GzaMnUsnzM6P",
        "colab_type": "text"
      },
      "source": [
        "### 'subsidise poor communities '"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "outputId": "0e53143b-28d3-4486-9240-abfad77855ca",
        "id": "CZeB1fXD1h21",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 187
        }
      },
      "source": [
        "topic = 'subsidise poor communities '\n",
        "\n",
        "articles = topic_article_dict[topic]\n",
        "articles"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[\"Welfare's effect on poverty\",\n",
              " 'Prodesis',\n",
              " 'Welfare culture',\n",
              " 'Subsidy',\n",
              " 'Criticisms of welfare',\n",
              " 'Poverty reduction',\n",
              " 'Cycle of poverty',\n",
              " 'Redistribution of wealth',\n",
              " 'Economic inequality',\n",
              " 'Social safety net']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 814
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ueTEKPFR1hor",
        "colab_type": "code",
        "outputId": "579a9cca-b2d6-41d7-b22a-941e5c26d2dd",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "len(articles)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "10"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 815
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "md3C8Zgf1h22"
      },
      "source": [
        "#### Article 0 "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "4vP7AIv81h22",
        "colab": {}
      },
      "source": [
        "with open(articles_dict[articles[0].replace(' ','_')+'.txt']) as article:\n",
        "        doc = article.read()\n",
        "\n",
        "c_doc = text_cleaner(doc)\n",
        "sentences = nltk.sent_tokenize(c_doc)\n",
        "sentences = [[sent, topic, articles[0]] for sent in sentences]\n",
        "\n",
        "ndf = pd.DataFrame(sentences, columns=['text', 'topic', 'article'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "outputId": "34846a91-2b95-4cb7-d459-6271beafb981",
        "id": "jM-H9fHQ1h23",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "cdc_idx_dict = {}\n",
        "cdc_idx_sent = {}\n",
        "cdc_idx_art = {}\n",
        "\n",
        "for i,claim in enumerate(ref_data['clean_Claim']):\n",
        "    check_complete = False\n",
        "    while check_complete == False:\n",
        "        for idx,sentence in enumerate(ndf['text']):\n",
        "            test = claim.lower() in sentence.lower()\n",
        "            if test:\n",
        "                article = ref_data['Article'][i]\n",
        "                cdc_idx_dict[idx] = claim\n",
        "                cdc_idx_sent[idx] = [claim, sentence]\n",
        "                cdc_idx_art[idx] = [claim, article]\n",
        "                check_complete = True\n",
        "            elif idx == (len(ndf['text'])-1):\n",
        "                check_complete = True\n",
        "\n",
        "len(cdc_idx_dict), ref_data.shape[0]"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(4, 1332)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 817
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "outputId": "c79f6594-d1f5-40ac-e8ad-8d61457b11dc",
        "id": "jMmorMiT1h24",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "cdc_idx_dict"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{2: 'sustains or even creates poverty',\n",
              " 3: 'poverty decreases after countries adapt welfare programs',\n",
              " 33: 'makes an incentive to not find work',\n",
              " 36: 'welfare not only increases poverty but also increases other problems'}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 818
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "o-7r52z41h24",
        "colab": {}
      },
      "source": [
        "cdc = []\n",
        "\n",
        "for x in range(len(ndf)):\n",
        "    if x in list(cdc_idx_dict.keys()):\n",
        "        cdc.append(cdc_idx_dict.get(x))\n",
        "    else:\n",
        "        cdc.append('---')\n",
        "ndf['cdc'] = cdc\n",
        "\n",
        "df = pd.concat([ndf, df], axis=0, ignore_index=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "ogfDC2Un1h25"
      },
      "source": [
        "#### Article 1 "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "KkksmXgK1h25",
        "colab": {}
      },
      "source": [
        "with open(articles_dict[articles[1].replace(' ','_')+'.txt']) as article:\n",
        "        doc = article.read()\n",
        "\n",
        "c_doc = text_cleaner(doc)\n",
        "sentences = nltk.sent_tokenize(c_doc)\n",
        "sentences = [[sent, topic, articles[1]] for sent in sentences]\n",
        "\n",
        "ndf = pd.DataFrame(sentences, columns=['text', 'topic', 'article'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "outputId": "6d029fd3-8c0d-4e98-da29-2cd091354ab0",
        "id": "8F9zM5Us1h27",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "cdc_idx_dict = {}\n",
        "cdc_idx_sent = {}\n",
        "cdc_idx_art = {}\n",
        "\n",
        "for i,claim in enumerate(ref_data['clean_Claim']):\n",
        "    check_complete = False\n",
        "    while check_complete == False:\n",
        "        for idx,sentence in enumerate(ndf['text']):\n",
        "            test = claim.lower() in sentence.lower()\n",
        "            if test:\n",
        "                article = ref_data['Article'][i]\n",
        "                cdc_idx_dict[idx] = claim\n",
        "                cdc_idx_sent[idx] = [claim, sentence]\n",
        "                cdc_idx_art[idx] = [claim, article]\n",
        "                check_complete = True\n",
        "            elif idx == (len(ndf['text'])-1):\n",
        "                check_complete = True\n",
        "\n",
        "len(cdc_idx_dict), ref_data.shape[0]"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(1, 1332)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 821
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "outputId": "5b9731bb-bd13-45ed-961b-6334085bcf2c",
        "id": "_VnZdBOH1h28",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "cdc_idx_dict"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{101: 'the availability of government funds has led to tensions within the community'}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 822
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "eUzTwYzp1h28",
        "colab": {}
      },
      "source": [
        "cdc = []\n",
        "\n",
        "for x in range(len(ndf)):\n",
        "    if x in list(cdc_idx_dict.keys()):\n",
        "        cdc.append(cdc_idx_dict.get(x))\n",
        "    else:\n",
        "        cdc.append('---')\n",
        "ndf['cdc'] = cdc\n",
        "\n",
        "df = pd.concat([df, ndf], axis=0, ignore_index=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "NkyNziLP1h29"
      },
      "source": [
        "#### Article 2 "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "S1Bv3f2r1h29",
        "colab": {}
      },
      "source": [
        "with open(articles_dict[articles[2].replace(' ','_')+'.txt']) as article:\n",
        "        doc = article.read()\n",
        "\n",
        "c_doc = text_cleaner(doc)\n",
        "sentences = nltk.sent_tokenize(c_doc)\n",
        "sentences = [[sent, topic, articles[2]] for sent in sentences]\n",
        "\n",
        "ndf = pd.DataFrame(sentences, columns=['text', 'topic', 'article'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "outputId": "d0956e72-6d62-4f2a-d7b7-f71a6ef81105",
        "id": "SPs61Gxo1h2-",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "cdc_idx_dict = {}\n",
        "cdc_idx_sent = {}\n",
        "cdc_idx_art = {}\n",
        "\n",
        "for i,claim in enumerate(ref_data['clean_Claim']):\n",
        "    check_complete = False\n",
        "    while check_complete == False:\n",
        "        for idx,sentence in enumerate(ndf['text']):\n",
        "            test = claim.lower() in sentence.lower()\n",
        "            if test:\n",
        "                article = ref_data['Article'][i]\n",
        "                cdc_idx_dict[idx] = claim\n",
        "                cdc_idx_sent[idx] = [claim, sentence]\n",
        "                cdc_idx_art[idx] = [claim, article]\n",
        "                check_complete = True\n",
        "            elif idx == (len(ndf['text'])-1):\n",
        "                check_complete = True\n",
        "\n",
        "len(cdc_idx_dict), ref_data.shape[0]"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(3, 1332)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 825
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "outputId": "7799449c-a4ad-4c07-b901-7027e42c3b96",
        "id": "FbWvitZp1h2_",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "cdc_idx_dict"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{2: 'breeds dependence on government aid',\n",
              " 26: 'welfare only bred dependence on the government',\n",
              " 44: 'welfare has demonstrated some proven effects for helping impoverished families'}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 826
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "9u6uNmpt1h2_",
        "colab": {}
      },
      "source": [
        "cdc = []\n",
        "\n",
        "for x in range(len(ndf)):\n",
        "    if x in list(cdc_idx_dict.keys()):\n",
        "        cdc.append(cdc_idx_dict.get(x))\n",
        "    else:\n",
        "        cdc.append('---')\n",
        "ndf['cdc'] = cdc\n",
        "\n",
        "df = pd.concat([ndf, df], axis=0, ignore_index=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "zpVWIKM81h3A"
      },
      "source": [
        "#### Article 3 "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "sXqRVMyf1h3A",
        "colab": {}
      },
      "source": [
        "with open(articles_dict[articles[3].replace(' ','_')+'.txt']) as article:\n",
        "        doc = article.read()\n",
        "\n",
        "c_doc = text_cleaner(doc)\n",
        "sentences = nltk.sent_tokenize(c_doc)\n",
        "sentences = [[sent, topic, articles[3]] for sent in sentences]\n",
        "\n",
        "ndf = pd.DataFrame(sentences, columns=['text', 'topic', 'article'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "outputId": "98a3186d-f9dd-488d-fa11-adcd1d22e305",
        "id": "cbxfB3H41h3B",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "cdc_idx_dict = {}\n",
        "cdc_idx_sent = {}\n",
        "cdc_idx_art = {}\n",
        "\n",
        "for i,claim in enumerate(ref_data['clean_Claim']):\n",
        "    check_complete = False\n",
        "    while check_complete == False:\n",
        "        for idx,sentence in enumerate(ndf['text']):\n",
        "            test = claim.lower() in sentence.lower()\n",
        "            if test:\n",
        "                article = ref_data['Article'][i]\n",
        "                cdc_idx_dict[idx] = claim\n",
        "                cdc_idx_sent[idx] = [claim, sentence]\n",
        "                cdc_idx_art[idx] = [claim, article]\n",
        "                check_complete = True\n",
        "            elif idx == (len(ndf['text'])-1):\n",
        "                check_complete = True\n",
        "\n",
        "len(cdc_idx_dict), ref_data.shape[0]"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(3, 1332)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 829
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "outputId": "9d1fede8-c0f5-4176-fb4f-4ad2135dc42f",
        "id": "6fVuIc6S1h3C",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "cdc_idx_dict"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{8: 'Subsidies may distort markets',\n",
              " 24: 'produce inefficiencies',\n",
              " 38: 'they are inefficient'}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 830
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "RSWc7v1f1h3C",
        "colab": {}
      },
      "source": [
        "cdc = []\n",
        "\n",
        "for x in range(len(ndf)):\n",
        "    if x in list(cdc_idx_dict.keys()):\n",
        "        cdc.append(cdc_idx_dict.get(x))\n",
        "    else:\n",
        "        cdc.append('---')\n",
        "ndf['cdc'] = cdc\n",
        "\n",
        "df = pd.concat([ndf, df], axis=0, ignore_index=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "v-WyBO_21h3D"
      },
      "source": [
        "#### Article 4 "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "ZeV-73LM1h3D",
        "colab": {}
      },
      "source": [
        "with open(articles_dict[articles[4].replace(' ','_')+'.txt']) as article:\n",
        "        doc = article.read()\n",
        "\n",
        "c_doc = text_cleaner(doc)\n",
        "sentences = nltk.sent_tokenize(c_doc)\n",
        "sentences = [[sent, topic, articles[4]] for sent in sentences]\n",
        "\n",
        "ndf = pd.DataFrame(sentences, columns=['text', 'topic', 'article'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "outputId": "a41dccc9-2ec1-4db0-a343-b87903589028",
        "id": "EEdVusbL1h3E",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "cdc_idx_dict = {}\n",
        "cdc_idx_sent = {}\n",
        "cdc_idx_art = {}\n",
        "\n",
        "for i,claim in enumerate(ref_data['clean_Claim']):\n",
        "    check_complete = False\n",
        "    while check_complete == False:\n",
        "        for idx,sentence in enumerate(ndf['text']):\n",
        "            test = claim.lower() in sentence.lower()\n",
        "            if test:\n",
        "                article = ref_data['Article'][i]\n",
        "                cdc_idx_dict[idx] = claim\n",
        "                cdc_idx_sent[idx] = [claim, sentence]\n",
        "                cdc_idx_art[idx] = [claim, article]\n",
        "                check_complete = True\n",
        "            elif idx == (len(ndf['text'])-1):\n",
        "                check_complete = True\n",
        "\n",
        "len(cdc_idx_dict), ref_data.shape[0]"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(2, 1332)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 833
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "outputId": "137c1853-d935-41b3-a6b0-cd6213806b7a",
        "id": "d4CoLbEa1h3F",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "cdc_idx_dict"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{4: 'the welfare state has produced a generation of dependents who, instead of working, rely solely upon the state for income',\n",
              " 11: 'it creates dependence to the state'}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 834
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "CQYXgsEi1h3G",
        "colab": {}
      },
      "source": [
        "cdc = []\n",
        "\n",
        "for x in range(len(ndf)):\n",
        "    if x in list(cdc_idx_dict.keys()):\n",
        "        cdc.append(cdc_idx_dict.get(x))\n",
        "    else:\n",
        "        cdc.append('---')\n",
        "ndf['cdc'] = cdc\n",
        "\n",
        "df = pd.concat([ndf, df], axis=0, ignore_index=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "IVsubjNI_ZCg"
      },
      "source": [
        "#### Article 5 "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "pnG-S_MB_ZCh",
        "colab": {}
      },
      "source": [
        "with open(articles_dict[articles[5].replace(' ','_')+'.txt']) as article:\n",
        "        doc = article.read()\n",
        "\n",
        "c_doc = text_cleaner(doc)\n",
        "sentences = nltk.sent_tokenize(c_doc)\n",
        "sentences = [[sent, topic, articles[5]] for sent in sentences]\n",
        "\n",
        "ndf = pd.DataFrame(sentences, columns=['text', 'topic', 'article'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "outputId": "004f9597-b685-4fc6-abce-c23c07b6fd22",
        "id": "7dkUvR4B_ZCj",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "cdc_idx_dict = {}\n",
        "cdc_idx_sent = {}\n",
        "cdc_idx_art = {}\n",
        "\n",
        "for i,claim in enumerate(ref_data['clean_Claim']):\n",
        "    check_complete = False\n",
        "    while check_complete == False:\n",
        "        for idx,sentence in enumerate(ndf['text']):\n",
        "            test = claim.lower() in sentence.lower()\n",
        "            if test:\n",
        "                article = ref_data['Article'][i]\n",
        "                cdc_idx_dict[idx] = claim\n",
        "                cdc_idx_sent[idx] = [claim, sentence]\n",
        "                cdc_idx_art[idx] = [claim, article]\n",
        "                check_complete = True\n",
        "            elif idx == (len(ndf['text'])-1):\n",
        "                check_complete = True\n",
        "\n",
        "len(cdc_idx_dict), ref_data.shape[0]"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(6, 1332)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 837
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "outputId": "c504de7a-7eef-4f2b-867d-88be18079378",
        "id": "8x-ePoKD_ZCk",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "cdc_idx_dict"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{26: 'helps growth',\n",
              " 28: 'is essential in providing better lives',\n",
              " 47: 'trade rules are often unfair as they block access to richer nations’ markets and ban poorer nations from supporting their industries',\n",
              " 130: 'Western monetary aid often only serves to increase poverty and social inequality',\n",
              " 131: 'higher aid levels erode the quality of governance',\n",
              " 133: 'aid is not spread properly'}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 838
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "Lm6E781e_ZCl",
        "colab": {}
      },
      "source": [
        "cdc = []\n",
        "\n",
        "for x in range(len(ndf)):\n",
        "    if x in list(cdc_idx_dict.keys()):\n",
        "        cdc.append(cdc_idx_dict.get(x))\n",
        "    else:\n",
        "        cdc.append('---')\n",
        "ndf['cdc'] = cdc\n",
        "\n",
        "df = pd.concat([ndf, df], axis=0, ignore_index=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "lKBPEime_ZCm"
      },
      "source": [
        "#### Article 6"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "ljVHoZ4N_ZCm",
        "colab": {}
      },
      "source": [
        "with open(articles_dict[articles[6].replace(' ','_')+'.txt']) as article:\n",
        "        doc = article.read()\n",
        "\n",
        "c_doc = text_cleaner(doc)\n",
        "sentences = nltk.sent_tokenize(c_doc)\n",
        "sentences = [[sent, topic, articles[6]] for sent in sentences]\n",
        "\n",
        "ndf = pd.DataFrame(sentences, columns=['text', 'topic', 'article'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "outputId": "55311d6f-b530-495a-f556-807a2e806244",
        "id": "mbLhy1l6_ZCn",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "cdc_idx_dict = {}\n",
        "cdc_idx_sent = {}\n",
        "cdc_idx_art = {}\n",
        "\n",
        "for i,claim in enumerate(ref_data['clean_Claim']):\n",
        "    check_complete = False\n",
        "    while check_complete == False:\n",
        "        for idx,sentence in enumerate(ndf['text']):\n",
        "            test = claim.lower() in sentence.lower()\n",
        "            if test:\n",
        "                article = ref_data['Article'][i]\n",
        "                cdc_idx_dict[idx] = claim\n",
        "                cdc_idx_sent[idx] = [claim, sentence]\n",
        "                cdc_idx_art[idx] = [claim, article]\n",
        "                check_complete = True\n",
        "            elif idx == (len(ndf['text'])-1):\n",
        "                check_complete = True\n",
        "\n",
        "len(cdc_idx_dict), ref_data.shape[0]"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(1, 1332)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 841
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "outputId": "6e043dc6-df1f-4014-c8cc-590cf501edf7",
        "id": "1FICY-pv_ZCo",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "cdc_idx_dict"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{0: 'poverty, once started, is likely to continue unless there is outside intervention'}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 842
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "H9auMoD3_ZCp",
        "colab": {}
      },
      "source": [
        "cdc = []\n",
        "\n",
        "for x in range(len(ndf)):\n",
        "    if x in list(cdc_idx_dict.keys()):\n",
        "        cdc.append(cdc_idx_dict.get(x))\n",
        "    else:\n",
        "        cdc.append('---')\n",
        "ndf['cdc'] = cdc\n",
        "\n",
        "df = pd.concat([ndf, df], axis=0, ignore_index=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "xh_nZmMm_ZCq"
      },
      "source": [
        "#### Article 7"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "43U22DRu_ZCq",
        "colab": {}
      },
      "source": [
        "with open(articles_dict[articles[7].replace(' ','_')+'.txt']) as article:\n",
        "        doc = article.read()\n",
        "\n",
        "c_doc = text_cleaner(doc)\n",
        "sentences = nltk.sent_tokenize(c_doc)\n",
        "sentences = [[sent, topic, articles[7]] for sent in sentences]\n",
        "\n",
        "ndf = pd.DataFrame(sentences, columns=['text', 'topic', 'article'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "outputId": "6dd94a53-164b-4714-e7f4-16af9957da08",
        "id": "3kr2NEk9_ZCr",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "cdc_idx_dict = {}\n",
        "cdc_idx_sent = {}\n",
        "cdc_idx_art = {}\n",
        "\n",
        "for i,claim in enumerate(ref_data['clean_Claim']):\n",
        "    check_complete = False\n",
        "    while check_complete == False:\n",
        "        for idx,sentence in enumerate(ndf['text']):\n",
        "            test = claim.lower() in sentence.lower()\n",
        "            if test:\n",
        "                article = ref_data['Article'][i]\n",
        "                cdc_idx_dict[idx] = claim\n",
        "                cdc_idx_sent[idx] = [claim, sentence]\n",
        "                cdc_idx_art[idx] = [claim, article]\n",
        "                check_complete = True\n",
        "            elif idx == (len(ndf['text'])-1):\n",
        "                check_complete = True\n",
        "\n",
        "len(cdc_idx_dict), ref_data.shape[0]"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(11, 1332)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 845
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "outputId": "348c9b4c-3795-4e20-c622-57b85f196f99",
        "id": "CSL8FWc__ZCs",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "cdc_idx_dict"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{17: 'less stratified economies are more socially just',\n",
              " 19: 'the rich have an obligation to assist the poor, thus creating a more financially egalitarian society',\n",
              " 23: 'the rich exploit the poor or otherwise gain unfair benefits, and thus should return some of those benefits',\n",
              " 24: 'a larger middle class benefits an economy by enabling more people to be consumers',\n",
              " 26: 'economic inequality contributes to crime',\n",
              " 28: 'a lower rate of redistribution in a given society increases the inequality found among future incomes',\n",
              " 31: 'reducing these inequalities is one way to prevent or ameliorate economic crises',\n",
              " 38: 'it improves social stability',\n",
              " 72: 'there is no encouragement of those receiving aid to resume working',\n",
              " 90: 'redistribution of legitimately obtained property cannot ever be just',\n",
              " 91: 'redistribution tends to benefit those with political clout to set spending priorities more than those in need'}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 846
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "w_PitsQK_ZCu",
        "colab": {}
      },
      "source": [
        "cdc = []\n",
        "\n",
        "for x in range(len(ndf)):\n",
        "    if x in list(cdc_idx_dict.keys()):\n",
        "        cdc.append(cdc_idx_dict.get(x))\n",
        "    else:\n",
        "        cdc.append('---')\n",
        "ndf['cdc'] = cdc\n",
        "\n",
        "df = pd.concat([ndf, df], axis=0, ignore_index=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "T1S895cq_ZCx"
      },
      "source": [
        "#### Article 8"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "4wiuun9f_ZCx",
        "colab": {}
      },
      "source": [
        "with open(articles_dict[articles[8].replace(' ','_')+'.txt']) as article:\n",
        "        doc = article.read()\n",
        "\n",
        "c_doc = text_cleaner(doc)\n",
        "sentences = nltk.sent_tokenize(c_doc)\n",
        "sentences = [[sent, topic, articles[8]] for sent in sentences]\n",
        "\n",
        "ndf = pd.DataFrame(sentences, columns=['text', 'topic', 'article'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "outputId": "537c125b-5918-44fe-d1f7-39f76a28aee6",
        "id": "p50W77WT_ZCy",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "cdc_idx_dict = {}\n",
        "cdc_idx_sent = {}\n",
        "cdc_idx_art = {}\n",
        "\n",
        "for i,claim in enumerate(ref_data['clean_Claim']):\n",
        "    check_complete = False\n",
        "    while check_complete == False:\n",
        "        for idx,sentence in enumerate(ndf['text']):\n",
        "            test = claim.lower() in sentence.lower()\n",
        "            if test:\n",
        "                article = ref_data['Article'][i]\n",
        "                cdc_idx_dict[idx] = claim\n",
        "                cdc_idx_sent[idx] = [claim, sentence]\n",
        "                cdc_idx_art[idx] = [claim, article]\n",
        "                check_complete = True\n",
        "            elif idx == (len(ndf['text'])-1):\n",
        "                check_complete = True\n",
        "\n",
        "len(cdc_idx_dict), ref_data.shape[0]"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(12, 1332)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 849
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "outputId": "ad40c81b-26bc-487e-f5a0-2641e325d92d",
        "id": "AvsBWjjp_ZCz",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "cdc_idx_dict"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{217: 'Higher levels of economic inequality tend to intensify social hierarchies and generally degrade the quality of social relations',\n",
              " 222: 'Economic inequality is thought to reduce distributive efficiency within society',\n",
              " 227: 'a society with more equality will have higher aggregate utility',\n",
              " 228: 'in societies where inequality is lower, population-wide satisfaction and happiness tend to be higher',\n",
              " 246: 'an increased gap between rich and poor increases the incentives for competition and innovation within an economy',\n",
              " 269: 'redistributive policies that have an adverse effect on investment and economic growth',\n",
              " 308: 'when there is economic inequality then political inequality is assured',\n",
              " 320: 'a certain amount of redistribution would be justified',\n",
              " 328: \"without redistribution, one generation's successful individuals would become the next generation's embedded caste\",\n",
              " 329: 'social justice requires redistribution of high incomes and large concentrations of wealth in a way that spreads it more widely',\n",
              " 332: 'economic inequality reduces social cohesion and increases social unrest',\n",
              " 335: 'economic inequality invariably translates to political inequality'}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 850
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "cWJIrddp_ZC0",
        "colab": {}
      },
      "source": [
        "cdc = []\n",
        "\n",
        "for x in range(len(ndf)):\n",
        "    if x in list(cdc_idx_dict.keys()):\n",
        "        cdc.append(cdc_idx_dict.get(x))\n",
        "    else:\n",
        "        cdc.append('---')\n",
        "ndf['cdc'] = cdc\n",
        "\n",
        "df = pd.concat([ndf, df], axis=0, ignore_index=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "vwHTzzdh_ZC1"
      },
      "source": [
        "#### Article 9"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "ZMIBNOiX_ZC1",
        "colab": {}
      },
      "source": [
        "with open(articles_dict[articles[9].replace(' ','_')+'.txt']) as article:\n",
        "        doc = article.read()\n",
        "\n",
        "c_doc = text_cleaner(doc)\n",
        "sentences = nltk.sent_tokenize(c_doc)\n",
        "sentences = [[sent, topic, articles[9]] for sent in sentences]\n",
        "\n",
        "ndf = pd.DataFrame(sentences, columns=['text', 'topic', 'article'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "outputId": "e418a1de-591b-4eec-8e8a-72c6cb254fec",
        "id": "zBAniZr4_ZC2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "cdc_idx_dict = {}\n",
        "cdc_idx_sent = {}\n",
        "cdc_idx_art = {}\n",
        "\n",
        "for i,claim in enumerate(ref_data['clean_Claim']):\n",
        "    check_complete = False\n",
        "    while check_complete == False:\n",
        "        for idx,sentence in enumerate(ndf['text']):\n",
        "            test = claim.lower() in sentence.lower()\n",
        "            if test:\n",
        "                article = ref_data['Article'][i]\n",
        "                cdc_idx_dict[idx] = claim\n",
        "                cdc_idx_sent[idx] = [claim, sentence]\n",
        "                cdc_idx_art[idx] = [claim, article]\n",
        "                check_complete = True\n",
        "            elif idx == (len(ndf['text'])-1):\n",
        "                check_complete = True\n",
        "\n",
        "len(cdc_idx_dict), ref_data.shape[0]"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(9, 1332)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 853
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "outputId": "100e93dd-6e02-4fb0-b0e5-bbd29f593357",
        "id": "c7kntOno_ZC3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "cdc_idx_dict"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{9: 'Safety nets enable households to make productive investments in their future that they may otherwise miss',\n",
              " 44: 'CCT Programs have been proved to be very well-targeted and effective',\n",
              " 48: 'CCT Programs are efficient tools for reducing poverty and inequality',\n",
              " 77: 'Subsidies guarantee access to essential commodities at prices that consumers can afford',\n",
              " 79: 'they tend to be expensive and regressive',\n",
              " 88: 'May distort production incentives',\n",
              " 128: 'Safety nets in low-income countries are increasingly being recognized as effective tools to reach out to the most vulnerable',\n",
              " 129: 'they protect households facing hard times from falling into deeper poverty and help them manage risk',\n",
              " 130: 'they can provide households with a cushion to invest resources more efficiently'}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 854
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "pv1oEvZS_ZC4",
        "colab": {}
      },
      "source": [
        "cdc = []\n",
        "\n",
        "for x in range(len(ndf)):\n",
        "    if x in list(cdc_idx_dict.keys()):\n",
        "        cdc.append(cdc_idx_dict.get(x))\n",
        "    else:\n",
        "        cdc.append('---')\n",
        "ndf['cdc'] = cdc\n",
        "\n",
        "df = pd.concat([ndf, df], axis=0, ignore_index=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KasG15QBzR6p",
        "colab_type": "text"
      },
      "source": [
        "### 'that the right to asylum should not be absolute '"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "outputId": "d03c0446-ebbb-49f8-e278-33659915fb1d",
        "id": "F4bKZ1W-1jJz",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 238
        }
      },
      "source": [
        "topic = 'that the right to asylum should not be absolute '\n",
        "\n",
        "articles = topic_article_dict[topic]\n",
        "articles"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['Russian Federation Law on Refugees',\n",
              " 'Boat people',\n",
              " 'Nativism (politics)',\n",
              " 'Convention Relating to the Status of Refugees',\n",
              " 'Immigration to the United Kingdom since 1922',\n",
              " 'UK Immigration Service',\n",
              " 'Right of asylum',\n",
              " 'United Nations High Commissioner for Refugees',\n",
              " 'Immigration',\n",
              " 'Immigration and crime',\n",
              " 'Illegal immigration',\n",
              " 'Refugee',\n",
              " 'Illegal immigration from Africa to Israel']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 856
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VjUID9Mh1i7F",
        "colab_type": "code",
        "outputId": "9fc3b556-3e75-4018-9809-32bf7e8e38ec",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "len(articles)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "13"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 857
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "Cd3_hOCc1jJ0"
      },
      "source": [
        "#### Article 0 "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "U7mhKny-1jJ0",
        "colab": {}
      },
      "source": [
        "with open(articles_dict[articles[0].replace(' ','_')+'.txt']) as article:\n",
        "        doc = article.read()\n",
        "\n",
        "c_doc = text_cleaner(doc)\n",
        "sentences = nltk.sent_tokenize(c_doc)\n",
        "sentences = [[sent, topic, articles[0]] for sent in sentences]\n",
        "\n",
        "ndf = pd.DataFrame(sentences, columns=['text', 'topic', 'article'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "outputId": "9c2daed0-32fa-45b5-c1bd-471eedc4a618",
        "id": "D1mLGGZX1jJ1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "cdc_idx_dict = {}\n",
        "cdc_idx_sent = {}\n",
        "cdc_idx_art = {}\n",
        "\n",
        "for i,claim in enumerate(ref_data['clean_Claim']):\n",
        "    check_complete = False\n",
        "    while check_complete == False:\n",
        "        for idx,sentence in enumerate(ndf['text']):\n",
        "            test = claim.lower() in sentence.lower()\n",
        "            if test:\n",
        "                article = ref_data['Article'][i]\n",
        "                cdc_idx_dict[idx] = claim\n",
        "                cdc_idx_sent[idx] = [claim, sentence]\n",
        "                cdc_idx_art[idx] = [claim, article]\n",
        "                check_complete = True\n",
        "            elif idx == (len(ndf['text'])-1):\n",
        "                check_complete = True\n",
        "\n",
        "len(cdc_idx_dict), ref_data.shape[0]"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(1, 1332)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 859
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "outputId": "97b46649-1328-4a8e-a296-10904c624220",
        "id": "QyL3ewXc1jJ1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "cdc_idx_dict"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{11: 'application for asylum could be denied regardless of the legitimacy of their claim'}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 860
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "d5xoANdN1jJ2",
        "colab": {}
      },
      "source": [
        "cdc = []\n",
        "\n",
        "for x in range(len(ndf)):\n",
        "    if x in list(cdc_idx_dict.keys()):\n",
        "        cdc.append(cdc_idx_dict.get(x))\n",
        "    else:\n",
        "        cdc.append('---')\n",
        "ndf['cdc'] = cdc\n",
        "\n",
        "df = pd.concat([ndf, df], axis=0, ignore_index=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "tUHbAN2V1jJ3"
      },
      "source": [
        "#### Article 1 "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "Sk_-HfdS1jJ3",
        "colab": {}
      },
      "source": [
        "with open(articles_dict[articles[1].replace(' ','_')+'.txt']) as article:\n",
        "        doc = article.read()\n",
        "\n",
        "c_doc = text_cleaner(doc)\n",
        "sentences = nltk.sent_tokenize(c_doc)\n",
        "sentences = [[sent, topic, articles[1]] for sent in sentences]\n",
        "\n",
        "ndf = pd.DataFrame(sentences, columns=['text', 'topic', 'article'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "outputId": "1b146275-75d4-4d9b-f46e-07c331b6a156",
        "id": "zDcfkJur1jJ4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "cdc_idx_dict = {}\n",
        "cdc_idx_sent = {}\n",
        "cdc_idx_art = {}\n",
        "\n",
        "for i,claim in enumerate(ref_data['clean_Claim']):\n",
        "    check_complete = False\n",
        "    while check_complete == False:\n",
        "        for idx,sentence in enumerate(ndf['text']):\n",
        "            test = claim.lower() in sentence.lower()\n",
        "            if test:\n",
        "                article = ref_data['Article'][i]\n",
        "                cdc_idx_dict[idx] = claim\n",
        "                cdc_idx_sent[idx] = [claim, sentence]\n",
        "                cdc_idx_art[idx] = [claim, article]\n",
        "                check_complete = True\n",
        "            elif idx == (len(ndf['text'])-1):\n",
        "                check_complete = True\n",
        "\n",
        "len(cdc_idx_dict), ref_data.shape[0]"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(2, 1332)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 863
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "outputId": "4ea4ab32-0333-4909-93d7-c31d8f4d98e4",
        "id": "sTOL9hBm1jJ5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "cdc_idx_dict"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{6: 'political refugees, may be fleeing for their lives',\n",
              " 41: 'The plight of the boat people became an international humanitarian crisis'}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 864
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "-7DNQEKU1jJ6",
        "colab": {}
      },
      "source": [
        "cdc = []\n",
        "\n",
        "for x in range(len(ndf)):\n",
        "    if x in list(cdc_idx_dict.keys()):\n",
        "        cdc.append(cdc_idx_dict.get(x))\n",
        "    else:\n",
        "        cdc.append('---')\n",
        "ndf['cdc'] = cdc\n",
        "\n",
        "df = pd.concat([df, ndf], axis=0, ignore_index=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "vSm8sM9f1jJ7"
      },
      "source": [
        "#### Article 2 "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "1ZxKIFzO1jJ7",
        "colab": {}
      },
      "source": [
        "with open(articles_dict[articles[2].replace(' ','_')+'.txt']) as article:\n",
        "        doc = article.read()\n",
        "\n",
        "c_doc = text_cleaner(doc)\n",
        "sentences = nltk.sent_tokenize(c_doc)\n",
        "sentences = [[sent, topic, articles[2]] for sent in sentences]\n",
        "\n",
        "ndf = pd.DataFrame(sentences, columns=['text', 'topic', 'article'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "outputId": "3f204d2b-2f7c-4483-a25d-7661fc35e7e5",
        "id": "D3c6VYZt1jJ7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "cdc_idx_dict = {}\n",
        "cdc_idx_sent = {}\n",
        "cdc_idx_art = {}\n",
        "\n",
        "for i,claim in enumerate(ref_data['clean_Claim']):\n",
        "    check_complete = False\n",
        "    while check_complete == False:\n",
        "        for idx,sentence in enumerate(ndf['text']):\n",
        "            test = claim.lower() in sentence.lower()\n",
        "            if test:\n",
        "                article = ref_data['Article'][i]\n",
        "                cdc_idx_dict[idx] = claim\n",
        "                cdc_idx_sent[idx] = [claim, sentence]\n",
        "                cdc_idx_art[idx] = [claim, article]\n",
        "                check_complete = True\n",
        "            elif idx == (len(ndf['text'])-1):\n",
        "                check_complete = True\n",
        "\n",
        "len(cdc_idx_dict), ref_data.shape[0]"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(7, 1332)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 867
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "outputId": "9847e133-db11-421b-bffc-9f9325782bf4",
        "id": "MLHVQ7OD1jJ8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "cdc_idx_dict"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{2: 'the groups are considered hostile or alien to the natural culture',\n",
              " 5: 'the immigrants will distort or spoil existing cultural values',\n",
              " 128: 'Acquire jobs which would have otherwise been available to native citizens, suppressing wages',\n",
              " 129: 'Damage a sense of community and nationality',\n",
              " 131: 'May overpopulate countries',\n",
              " 132: 'Can swamp a native population and replace its culture with their own',\n",
              " 134: 'immigrants can \"swamp\" a local population'}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 868
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "jWikzWBy1jJ9",
        "colab": {}
      },
      "source": [
        "cdc = []\n",
        "\n",
        "for x in range(len(ndf)):\n",
        "    if x in list(cdc_idx_dict.keys()):\n",
        "        cdc.append(cdc_idx_dict.get(x))\n",
        "    else:\n",
        "        cdc.append('---')\n",
        "ndf['cdc'] = cdc\n",
        "\n",
        "df = pd.concat([ndf, df], axis=0, ignore_index=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "3aB44DA41jJ9"
      },
      "source": [
        "#### Article 3 "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "bW8sJFw81jJ-",
        "colab": {}
      },
      "source": [
        "with open(articles_dict[articles[3].replace(' ','_')+'.txt']) as article:\n",
        "        doc = article.read()\n",
        "\n",
        "c_doc = text_cleaner(doc)\n",
        "sentences = nltk.sent_tokenize(c_doc)\n",
        "sentences = [[sent, topic, articles[3]] for sent in sentences]\n",
        "\n",
        "ndf = pd.DataFrame(sentences, columns=['text', 'topic', 'article'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "outputId": "42897935-bc1b-4c14-d3ee-011d96d1875d",
        "id": "khJH16XR1jJ_",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "cdc_idx_dict = {}\n",
        "cdc_idx_sent = {}\n",
        "cdc_idx_art = {}\n",
        "\n",
        "for i,claim in enumerate(ref_data['clean_Claim']):\n",
        "    check_complete = False\n",
        "    while check_complete == False:\n",
        "        for idx,sentence in enumerate(ndf['text']):\n",
        "            test = claim.lower() in sentence.lower()\n",
        "            if test:\n",
        "                article = ref_data['Article'][i]\n",
        "                cdc_idx_dict[idx] = claim\n",
        "                cdc_idx_sent[idx] = [claim, sentence]\n",
        "                cdc_idx_art[idx] = [claim, article]\n",
        "                check_complete = True\n",
        "            elif idx == (len(ndf['text'])-1):\n",
        "                check_complete = True\n",
        "\n",
        "len(cdc_idx_dict), ref_data.shape[0]"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(1, 1332)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 871
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "outputId": "104d7888-ab43-461e-8415-4248ddf07d3b",
        "id": "Adx2lgRs1jJ_",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "cdc_idx_dict"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{35: 'prohibition of forcible return is part of customary international law'}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 872
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "AqVSxasC1jKA",
        "colab": {}
      },
      "source": [
        "cdc = []\n",
        "\n",
        "for x in range(len(ndf)):\n",
        "    if x in list(cdc_idx_dict.keys()):\n",
        "        cdc.append(cdc_idx_dict.get(x))\n",
        "    else:\n",
        "        cdc.append('---')\n",
        "ndf['cdc'] = cdc\n",
        "\n",
        "df = pd.concat([ndf, df], axis=0, ignore_index=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "jaTkNZzv1jKB"
      },
      "source": [
        "#### Article 4 "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "cLQ7oiFG1jKB",
        "colab": {}
      },
      "source": [
        "with open(articles_dict[articles[4].replace(' ','_')+'.txt']) as article:\n",
        "        doc = article.read()\n",
        "\n",
        "c_doc = text_cleaner(doc)\n",
        "sentences = nltk.sent_tokenize(c_doc)\n",
        "sentences = [[sent, topic, articles[4]] for sent in sentences]\n",
        "\n",
        "ndf = pd.DataFrame(sentences, columns=['text', 'topic', 'article'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "outputId": "ae2e83ab-c46f-4580-f256-983ec1e0c4a2",
        "id": "3Hzlil4P1jKC",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "cdc_idx_dict = {}\n",
        "cdc_idx_sent = {}\n",
        "cdc_idx_art = {}\n",
        "\n",
        "for i,claim in enumerate(ref_data['clean_Claim']):\n",
        "    check_complete = False\n",
        "    while check_complete == False:\n",
        "        for idx,sentence in enumerate(ndf['text']):\n",
        "            test = claim.lower() in sentence.lower()\n",
        "            if test:\n",
        "                article = ref_data['Article'][i]\n",
        "                cdc_idx_dict[idx] = claim\n",
        "                cdc_idx_sent[idx] = [claim, sentence]\n",
        "                cdc_idx_art[idx] = [claim, article]\n",
        "                check_complete = True\n",
        "            elif idx == (len(ndf['text'])-1):\n",
        "                check_complete = True\n",
        "\n",
        "len(cdc_idx_dict), ref_data.shape[0]"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(1, 1332)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 875
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "outputId": "591b9e1e-292a-4669-f315-7e283ef6fbb1",
        "id": "zyWdec9j1jKC",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "cdc_idx_dict"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{99: 'the opposition to high levels of immigration by refugees is based on racism'}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 876
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "MnmMkrFG1jKD",
        "colab": {}
      },
      "source": [
        "cdc = []\n",
        "\n",
        "for x in range(len(ndf)):\n",
        "    if x in list(cdc_idx_dict.keys()):\n",
        "        cdc.append(cdc_idx_dict.get(x))\n",
        "    else:\n",
        "        cdc.append('---')\n",
        "ndf['cdc'] = cdc\n",
        "\n",
        "df = pd.concat([ndf, df], axis=0, ignore_index=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "pLVtper6_ic_"
      },
      "source": [
        "#### Article 5 "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "BMyxjwrb_idA",
        "colab": {}
      },
      "source": [
        "with open(articles_dict[articles[5].replace(' ','_')+'.txt']) as article:\n",
        "        doc = article.read()\n",
        "\n",
        "c_doc = text_cleaner(doc)\n",
        "sentences = nltk.sent_tokenize(c_doc)\n",
        "sentences = [[sent, topic, articles[5]] for sent in sentences]\n",
        "\n",
        "ndf = pd.DataFrame(sentences, columns=['text', 'topic', 'article'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "outputId": "91dcb450-03a1-4efc-d211-af5fe5cf6d45",
        "id": "d1pquvFM_idC",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "cdc_idx_dict = {}\n",
        "cdc_idx_sent = {}\n",
        "cdc_idx_art = {}\n",
        "\n",
        "for i,claim in enumerate(ref_data['clean_Claim']):\n",
        "    check_complete = False\n",
        "    while check_complete == False:\n",
        "        for idx,sentence in enumerate(ndf['text']):\n",
        "            test = claim.lower() in sentence.lower()\n",
        "            if test:\n",
        "                article = ref_data['Article'][i]\n",
        "                cdc_idx_dict[idx] = claim\n",
        "                cdc_idx_sent[idx] = [claim, sentence]\n",
        "                cdc_idx_art[idx] = [claim, article]\n",
        "                check_complete = True\n",
        "            elif idx == (len(ndf['text'])-1):\n",
        "                check_complete = True\n",
        "\n",
        "len(cdc_idx_dict), ref_data.shape[0]"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(3, 1332)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 879
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "outputId": "55988bcd-a6f0-405a-c893-561ffc084b15",
        "id": "Lc3OFg1L_idD",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "cdc_idx_dict"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{23: 'social and political issues surrounding the issue of immigration',\n",
              " 475: 'asylum seekers were motivated by the availability of benefits',\n",
              " 608: 'migration provided a positive resource for the economy'}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 880
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "VPshs8p3_idE",
        "colab": {}
      },
      "source": [
        "cdc = []\n",
        "\n",
        "for x in range(len(ndf)):\n",
        "    if x in list(cdc_idx_dict.keys()):\n",
        "        cdc.append(cdc_idx_dict.get(x))\n",
        "    else:\n",
        "        cdc.append('---')\n",
        "ndf['cdc'] = cdc\n",
        "\n",
        "df = pd.concat([ndf, df], axis=0, ignore_index=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "qr6ZwJm4_idF"
      },
      "source": [
        "#### Article 6"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "qRPRJKbV_idG",
        "colab": {}
      },
      "source": [
        "with open(articles_dict[articles[6].replace(' ','_')+'.txt']) as article:\n",
        "        doc = article.read()\n",
        "\n",
        "c_doc = text_cleaner(doc)\n",
        "sentences = nltk.sent_tokenize(c_doc)\n",
        "sentences = [[sent, topic, articles[6]] for sent in sentences]\n",
        "\n",
        "ndf = pd.DataFrame(sentences, columns=['text', 'topic', 'article'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "outputId": "051abd04-958a-49f4-b97a-5e97b480eee0",
        "id": "EQigl2tE_idG",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "cdc_idx_dict = {}\n",
        "cdc_idx_sent = {}\n",
        "cdc_idx_art = {}\n",
        "\n",
        "for i,claim in enumerate(ref_data['clean_Claim']):\n",
        "    check_complete = False\n",
        "    while check_complete == False:\n",
        "        for idx,sentence in enumerate(ndf['text']):\n",
        "            test = claim.lower() in sentence.lower()\n",
        "            if test:\n",
        "                article = ref_data['Article'][i]\n",
        "                cdc_idx_dict[idx] = claim\n",
        "                cdc_idx_sent[idx] = [claim, sentence]\n",
        "                cdc_idx_art[idx] = [claim, article]\n",
        "                check_complete = True\n",
        "            elif idx == (len(ndf['text'])-1):\n",
        "                check_complete = True\n",
        "\n",
        "len(cdc_idx_dict), ref_data.shape[0]"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(1, 1332)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 883
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "outputId": "9886b79c-a162-4dd4-a73e-cd9b3e78dfb7",
        "id": "w8o7ocP3_idH",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "cdc_idx_dict"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{41: 'everyone has the right to seek and to enjoy in other countries asylum from persecution'}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 884
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "exODVVYc_idI",
        "colab": {}
      },
      "source": [
        "cdc = []\n",
        "\n",
        "for x in range(len(ndf)):\n",
        "    if x in list(cdc_idx_dict.keys()):\n",
        "        cdc.append(cdc_idx_dict.get(x))\n",
        "    else:\n",
        "        cdc.append('---')\n",
        "ndf['cdc'] = cdc\n",
        "\n",
        "df = pd.concat([ndf, df], axis=0, ignore_index=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "fqPZxOyH_idX"
      },
      "source": [
        "#### Article 7"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "Et4J51ZO_idX",
        "colab": {}
      },
      "source": [
        "with open(articles_dict[articles[7].replace(' ','_')+'.txt']) as article:\n",
        "        doc = article.read()\n",
        "\n",
        "c_doc = text_cleaner(doc)\n",
        "sentences = nltk.sent_tokenize(c_doc)\n",
        "sentences = [[sent, topic, articles[7]] for sent in sentences]\n",
        "\n",
        "ndf = pd.DataFrame(sentences, columns=['text', 'topic', 'article'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "outputId": "8341df5e-4387-4f42-d1a6-25be87b5f3c3",
        "id": "kphg3Dk__idY",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "cdc_idx_dict = {}\n",
        "cdc_idx_sent = {}\n",
        "cdc_idx_art = {}\n",
        "\n",
        "for i,claim in enumerate(ref_data['clean_Claim']):\n",
        "    check_complete = False\n",
        "    while check_complete == False:\n",
        "        for idx,sentence in enumerate(ndf['text']):\n",
        "            test = claim.lower() in sentence.lower()\n",
        "            if test:\n",
        "                article = ref_data['Article'][i]\n",
        "                cdc_idx_dict[idx] = claim\n",
        "                cdc_idx_sent[idx] = [claim, sentence]\n",
        "                cdc_idx_art[idx] = [claim, article]\n",
        "                check_complete = True\n",
        "            elif idx == (len(ndf['text'])-1):\n",
        "                check_complete = True\n",
        "\n",
        "len(cdc_idx_dict), ref_data.shape[0]"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(1, 1332)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 887
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "outputId": "7727bfb1-b821-44e6-b4e9-d3bca590b2e9",
        "id": "HojvxtCn_idZ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "cdc_idx_dict"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{34: 'everyone can exercise the right to seek asylum and find safe refuge in another state'}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 888
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "8V9wZfmg_ida",
        "colab": {}
      },
      "source": [
        "cdc = []\n",
        "\n",
        "for x in range(len(ndf)):\n",
        "    if x in list(cdc_idx_dict.keys()):\n",
        "        cdc.append(cdc_idx_dict.get(x))\n",
        "    else:\n",
        "        cdc.append('---')\n",
        "ndf['cdc'] = cdc\n",
        "\n",
        "df = pd.concat([ndf, df], axis=0, ignore_index=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "eqmA8Vg9_idb"
      },
      "source": [
        "#### Article 8"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "nRTLj6KM_idb",
        "colab": {}
      },
      "source": [
        "with open(articles_dict[articles[8].replace(' ','_')+'.txt']) as article:\n",
        "        doc = article.read()\n",
        "\n",
        "c_doc = text_cleaner(doc)\n",
        "sentences = nltk.sent_tokenize(c_doc)\n",
        "sentences = [[sent, topic, articles[8]] for sent in sentences]\n",
        "\n",
        "ndf = pd.DataFrame(sentences, columns=['text', 'topic', 'article'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "outputId": "0db0e4cb-f792-4896-9421-c72183afd549",
        "id": "AA0pOudK_idc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "cdc_idx_dict = {}\n",
        "cdc_idx_sent = {}\n",
        "cdc_idx_art = {}\n",
        "\n",
        "for i,claim in enumerate(ref_data['clean_Claim']):\n",
        "    check_complete = False\n",
        "    while check_complete == False:\n",
        "        for idx,sentence in enumerate(ndf['text']):\n",
        "            test = claim.lower() in sentence.lower()\n",
        "            if test:\n",
        "                article = ref_data['Article'][i]\n",
        "                cdc_idx_dict[idx] = claim\n",
        "                cdc_idx_sent[idx] = [claim, sentence]\n",
        "                cdc_idx_art[idx] = [claim, article]\n",
        "                check_complete = True\n",
        "            elif idx == (len(ndf['text'])-1):\n",
        "                check_complete = True\n",
        "\n",
        "len(cdc_idx_dict), ref_data.shape[0]"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(7, 1332)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 891
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "outputId": "0db57d68-691a-4c1e-f672-cbad9e922f00",
        "id": "g010xUnN_idd",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "cdc_idx_dict"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{58: 'immigrants are thought to compete with employees who are already in the country',\n",
              " 84: 'immigration threatens national identity',\n",
              " 95: 'freedom of movement is often recognized as a civil right',\n",
              " 98: 'everyone has the right to leave or enter a country, along with movement within it',\n",
              " 99: 'everyone has the right to leave any country, including his own, and to return to his country',\n",
              " 100: 'the freedom of movement both within and between countries is a basic human right',\n",
              " 103: 'everyone has the right to seek and to enjoy in other countries asylum from persecution'}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 892
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "7BwjJhuu_ide",
        "colab": {}
      },
      "source": [
        "cdc = []\n",
        "\n",
        "for x in range(len(ndf)):\n",
        "    if x in list(cdc_idx_dict.keys()):\n",
        "        cdc.append(cdc_idx_dict.get(x))\n",
        "    else:\n",
        "        cdc.append('---')\n",
        "ndf['cdc'] = cdc\n",
        "\n",
        "df = pd.concat([ndf, df], axis=0, ignore_index=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "m0_fsp_I_ide"
      },
      "source": [
        "#### Article 9"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "3V_Fyw8J_idf",
        "colab": {}
      },
      "source": [
        "with open(articles_dict[articles[9].replace(' ','_')+'.txt']) as article:\n",
        "        doc = article.read()\n",
        "\n",
        "c_doc = text_cleaner(doc)\n",
        "sentences = nltk.sent_tokenize(c_doc)\n",
        "sentences = [[sent, topic, articles[9]] for sent in sentences]\n",
        "\n",
        "ndf = pd.DataFrame(sentences, columns=['text', 'topic', 'article'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "outputId": "60724553-0873-447d-ad49-097c98320ac4",
        "id": "oMVCef6q_idf",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "cdc_idx_dict = {}\n",
        "cdc_idx_sent = {}\n",
        "cdc_idx_art = {}\n",
        "\n",
        "for i,claim in enumerate(ref_data['clean_Claim']):\n",
        "    check_complete = False\n",
        "    while check_complete == False:\n",
        "        for idx,sentence in enumerate(ndf['text']):\n",
        "            test = claim.lower() in sentence.lower()\n",
        "            if test:\n",
        "                article = ref_data['Article'][i]\n",
        "                cdc_idx_dict[idx] = claim\n",
        "                cdc_idx_sent[idx] = [claim, sentence]\n",
        "                cdc_idx_art[idx] = [claim, article]\n",
        "                check_complete = True\n",
        "            elif idx == (len(ndf['text'])-1):\n",
        "                check_complete = True\n",
        "\n",
        "len(cdc_idx_dict), ref_data.shape[0]"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(1, 1332)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 895
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "outputId": "ed58ecbd-8bdc-4c2f-aa3a-437e097082b7",
        "id": "MIipypZS_idg",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "cdc_idx_dict"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{21: 'immigrants have high rates of criminality'}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 896
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "nzco_o8Z_idh",
        "colab": {}
      },
      "source": [
        "cdc = []\n",
        "\n",
        "for x in range(len(ndf)):\n",
        "    if x in list(cdc_idx_dict.keys()):\n",
        "        cdc.append(cdc_idx_dict.get(x))\n",
        "    else:\n",
        "        cdc.append('---')\n",
        "ndf['cdc'] = cdc\n",
        "\n",
        "df = pd.concat([ndf, df], axis=0, ignore_index=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "SqOUPL5H_idi"
      },
      "source": [
        "#### Article 10"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "3xjEPylN_idi",
        "colab": {}
      },
      "source": [
        "with open(articles_dict[articles[10].replace(' ','_')+'.txt']) as article:\n",
        "        doc = article.read()\n",
        "\n",
        "c_doc = text_cleaner(doc)\n",
        "sentences = nltk.sent_tokenize(c_doc)\n",
        "sentences = [[sent, topic, articles[10]] for sent in sentences]\n",
        "\n",
        "ndf = pd.DataFrame(sentences, columns=['text', 'topic', 'article'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "outputId": "b1c6c5bd-df93-4984-8ff0-3ddacdd79584",
        "id": "6Pzp7_C0_idj",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "cdc_idx_dict = {}\n",
        "cdc_idx_sent = {}\n",
        "cdc_idx_art = {}\n",
        "\n",
        "for i,claim in enumerate(ref_data['clean_Claim']):\n",
        "    check_complete = False\n",
        "    while check_complete == False:\n",
        "        for idx,sentence in enumerate(ndf['text']):\n",
        "            test = claim.lower() in sentence.lower()\n",
        "            if test:\n",
        "                article = ref_data['Article'][i]\n",
        "                cdc_idx_dict[idx] = claim\n",
        "                cdc_idx_sent[idx] = [claim, sentence]\n",
        "                cdc_idx_art[idx] = [claim, article]\n",
        "                check_complete = True\n",
        "            elif idx == (len(ndf['text'])-1):\n",
        "                check_complete = True\n",
        "\n",
        "len(cdc_idx_dict), ref_data.shape[0]"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(3, 1332)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 899
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "outputId": "563e6657-1f93-4860-a229-3bc1b0f4101f",
        "id": "-qUNemrb_idl",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "cdc_idx_dict"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{131: 'refugees (legally defined to be people who are persecuted in their original country and then enter another country seeking safety) should be exempted from immigration laws',\n",
              " 134: 'the freedom of movement both within and between countries is a basic human right',\n",
              " 159: 'repression and intolerance against immigrants will not solve the problems caused by the economic crisis'}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 900
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "tuEHjc8J_ido",
        "colab": {}
      },
      "source": [
        "cdc = []\n",
        "\n",
        "for x in range(len(ndf)):\n",
        "    if x in list(cdc_idx_dict.keys()):\n",
        "        cdc.append(cdc_idx_dict.get(x))\n",
        "    else:\n",
        "        cdc.append('---')\n",
        "ndf['cdc'] = cdc\n",
        "\n",
        "df = pd.concat([ndf, df], axis=0, ignore_index=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "sSIst5wm_idp"
      },
      "source": [
        "#### Article 11 "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "PDqe0eJ8_idp",
        "colab": {}
      },
      "source": [
        "with open(articles_dict[articles[11].replace(' ','_')+'.txt']) as article:\n",
        "        doc = article.read()\n",
        "\n",
        "c_doc = text_cleaner(doc)\n",
        "sentences = nltk.sent_tokenize(c_doc)\n",
        "sentences = [[sent, topic, articles[11]] for sent in sentences]\n",
        "\n",
        "ndf = pd.DataFrame(sentences, columns=['text', 'topic', 'article'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "outputId": "96e20bb9-fa53-4f60-9abc-83159b81b63b",
        "id": "kxFQmEIp_idr",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "cdc_idx_dict = {}\n",
        "cdc_idx_sent = {}\n",
        "cdc_idx_art = {}\n",
        "\n",
        "for i,claim in enumerate(ref_data['clean_Claim']):\n",
        "    check_complete = False\n",
        "    while check_complete == False:\n",
        "        for idx,sentence in enumerate(ndf['text']):\n",
        "            test = claim.lower() in sentence.lower()\n",
        "            if test:\n",
        "                article = ref_data['Article'][i]\n",
        "                cdc_idx_dict[idx] = claim\n",
        "                cdc_idx_sent[idx] = [claim, sentence]\n",
        "                cdc_idx_art[idx] = [claim, article]\n",
        "                check_complete = True\n",
        "            elif idx == (len(ndf['text'])-1):\n",
        "                check_complete = True\n",
        "\n",
        "len(cdc_idx_dict), ref_data.shape[0]"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(6, 1332)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 903
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "outputId": "29cb0fac-0f61-41b0-e541-b5c98cf41860",
        "id": "cuTvku64_ids",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "cdc_idx_dict"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{6: 'countries must be prepared to allow Open borders for people fleeing conflict',\n",
              " 102: 'everyone can exercise the right to seek asylum and find safe refuge in another state',\n",
              " 196: 'refugees have much to bring to the countries in which they are resettled in terms of culture and labor',\n",
              " 197: 'Frequently, these countries of asylum are some of the world’s poorest nations and cannot handle the large influx of persons',\n",
              " 367: 'The plight of the boat people became an international humanitarian crisis',\n",
              " 522: 'Refugee populations consist of people who are terrified and are away from familiar surroundings'}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 904
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "IjmM0gXp_idt",
        "colab": {}
      },
      "source": [
        "cdc = []\n",
        "\n",
        "for x in range(len(ndf)):\n",
        "    if x in list(cdc_idx_dict.keys()):\n",
        "        cdc.append(cdc_idx_dict.get(x))\n",
        "    else:\n",
        "        cdc.append('---')\n",
        "ndf['cdc'] = cdc\n",
        "\n",
        "df = pd.concat([ndf, df], axis=0, ignore_index=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "cv0bAseh_idv"
      },
      "source": [
        "#### Article 12"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "meY2Go6H_idw",
        "colab": {}
      },
      "source": [
        "with open(articles_dict[articles[12].replace(' ','_')+'.txt']) as article:\n",
        "        doc = article.read()\n",
        "\n",
        "c_doc = text_cleaner(doc)\n",
        "sentences = nltk.sent_tokenize(c_doc)\n",
        "sentences = [[sent, topic, articles[12]] for sent in sentences]\n",
        "\n",
        "ndf = pd.DataFrame(sentences, columns=['text', 'topic', 'article'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "outputId": "16397486-19fd-46b0-996e-7d1bc50b9405",
        "id": "G3NZrfWB_idx",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "cdc_idx_dict = {}\n",
        "cdc_idx_sent = {}\n",
        "cdc_idx_art = {}\n",
        "\n",
        "for i,claim in enumerate(ref_data['clean_Claim']):\n",
        "    check_complete = False\n",
        "    while check_complete == False:\n",
        "        for idx,sentence in enumerate(ndf['text']):\n",
        "            test = claim.lower() in sentence.lower()\n",
        "            if test:\n",
        "                article = ref_data['Article'][i]\n",
        "                cdc_idx_dict[idx] = claim\n",
        "                cdc_idx_sent[idx] = [claim, sentence]\n",
        "                cdc_idx_art[idx] = [claim, article]\n",
        "                check_complete = True\n",
        "            elif idx == (len(ndf['text'])-1):\n",
        "                check_complete = True\n",
        "\n",
        "len(cdc_idx_dict), ref_data.shape[0]"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(5, 1332)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 907
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "outputId": "c3060295-dca4-47e9-e94f-550ecc063475",
        "id": "8rADEtjh_idx",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "cdc_idx_dict"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{3: 'Only a fraction of all the illegal immigrants is actually eligible for this status',\n",
              " 15: \"In some of the illegal immigrants' countries of origin humanitarian hardship exists\",\n",
              " 46: 'they may serve as informants or as operatives of hostile states or terrorist organizations',\n",
              " 47: 'they are contributing to the congestion in the cities and to the rise in crime',\n",
              " 49: 'failing to stop the illegal immigration waves at an early stage will only lead to much larger waves of illegal immigration in the future'}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 908
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "W7HEPouK_idy",
        "colab": {}
      },
      "source": [
        "cdc = []\n",
        "\n",
        "for x in range(len(ndf)):\n",
        "    if x in list(cdc_idx_dict.keys()):\n",
        "        cdc.append(cdc_idx_dict.get(x))\n",
        "    else:\n",
        "        cdc.append('---')\n",
        "ndf['cdc'] = cdc\n",
        "\n",
        "df = pd.concat([ndf, df], axis=0, ignore_index=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9Aviynf8zZcF",
        "colab_type": "text"
      },
      "source": [
        "### 'the US is justified in using force to prevent states from acquiring nuclear weapons '"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "outputId": "3d399148-e108-4c7d-e0ba-d3e9256f5921",
        "id": "P1xAMdZQ1kpQ",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 136
        }
      },
      "source": [
        "topic = 'the US is justified in using force to prevent states from acquiring nuclear weapons '\n",
        "\n",
        "articles = topic_article_dict[topic]\n",
        "articles"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['Nuclear proliferation',\n",
              " 'Nuclear weapons debate',\n",
              " 'Deterrence theory',\n",
              " 'Nuclear peace',\n",
              " 'Treaty on the Non-Proliferation of Nuclear Weapons',\n",
              " 'Nuclear weapon',\n",
              " 'Criticism of American foreign policy']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 910
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZrT_CtGe1ka5",
        "colab_type": "code",
        "outputId": "d0118bcf-632a-45cb-d882-dbb4eb16d422",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "len(articles)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "7"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 911
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "RIxLHuRm1kpR"
      },
      "source": [
        "#### Article 0 "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "8zr0Z-Rb1kpR",
        "colab": {}
      },
      "source": [
        "with open(articles_dict[articles[0].replace(' ','_')+'.txt']) as article:\n",
        "        doc = article.read()\n",
        "\n",
        "c_doc = text_cleaner(doc)\n",
        "sentences = nltk.sent_tokenize(c_doc)\n",
        "sentences = [[sent, topic, articles[0]] for sent in sentences]\n",
        "\n",
        "ndf = pd.DataFrame(sentences, columns=['text', 'topic', 'article'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "outputId": "72f5d2e4-878e-4f59-b951-3519151ad5d3",
        "id": "0wZQYexk1kpR",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "cdc_idx_dict = {}\n",
        "cdc_idx_sent = {}\n",
        "cdc_idx_art = {}\n",
        "\n",
        "for i,claim in enumerate(ref_data['clean_Claim']):\n",
        "    check_complete = False\n",
        "    while check_complete == False:\n",
        "        for idx,sentence in enumerate(ndf['text']):\n",
        "            test = claim.lower() in sentence.lower()\n",
        "            if test:\n",
        "                article = ref_data['Article'][i]\n",
        "                cdc_idx_dict[idx] = claim\n",
        "                cdc_idx_sent[idx] = [claim, sentence]\n",
        "                cdc_idx_art[idx] = [claim, article]\n",
        "                check_complete = True\n",
        "            elif idx == (len(ndf['text'])-1):\n",
        "                check_complete = True\n",
        "\n",
        "len(cdc_idx_dict), ref_data.shape[0]"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(8, 1332)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 913
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "outputId": "9b21c2bd-fe2c-49f9-b69b-29de18594374",
        "id": "pqtKp6B31kpS",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "cdc_idx_dict"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{1: 'more countries with nuclear weapons may increase the possibility of nuclear warfare',\n",
              " 38: 'A fundamental goal for American and global security is to minimize the proliferation risks associated with the expansion of nuclear power',\n",
              " 401: 'the spread of nuclear weapons could increase international stability',\n",
              " 403: 'it will decrease the likelihood of war',\n",
              " 407: 'nuclear weapons promote caution in decision-makers',\n",
              " 421: 'weak states will be unable to prevent – or will actively provide for – the disastrous possibility of nuclear terrorism',\n",
              " 431: 'If one state produces a nuclear weapon it creates almost a domino effect within the region',\n",
              " 438: 'prohibition on nuclear proliferation has been characterised as a form of technological apartheid'}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 914
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "oZUpDoHp1kpT",
        "colab": {}
      },
      "source": [
        "cdc = []\n",
        "\n",
        "for x in range(len(ndf)):\n",
        "    if x in list(cdc_idx_dict.keys()):\n",
        "        cdc.append(cdc_idx_dict.get(x))\n",
        "    else:\n",
        "        cdc.append('---')\n",
        "ndf['cdc'] = cdc\n",
        "\n",
        "df = pd.concat([ndf, df], axis=0, ignore_index=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "ekPdDDeU1kpT"
      },
      "source": [
        "#### Article 1 "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "FEFhgXxj1kpU",
        "colab": {}
      },
      "source": [
        "with open(articles_dict[articles[1].replace(' ','_')+'.txt']) as article:\n",
        "        doc = article.read()\n",
        "\n",
        "c_doc = text_cleaner(doc)\n",
        "sentences = nltk.sent_tokenize(c_doc)\n",
        "sentences = [[sent, topic, articles[1]] for sent in sentences]\n",
        "\n",
        "ndf = pd.DataFrame(sentences, columns=['text', 'topic', 'article'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "outputId": "903969c8-c954-408e-d346-ffb24402a468",
        "id": "42b-qqP01kpU",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "cdc_idx_dict = {}\n",
        "cdc_idx_sent = {}\n",
        "cdc_idx_art = {}\n",
        "\n",
        "for i,claim in enumerate(ref_data['clean_Claim']):\n",
        "    check_complete = False\n",
        "    while check_complete == False:\n",
        "        for idx,sentence in enumerate(ndf['text']):\n",
        "            test = claim.lower() in sentence.lower()\n",
        "            if test:\n",
        "                article = ref_data['Article'][i]\n",
        "                cdc_idx_dict[idx] = claim\n",
        "                cdc_idx_sent[idx] = [claim, sentence]\n",
        "                cdc_idx_art[idx] = [claim, article]\n",
        "                check_complete = True\n",
        "            elif idx == (len(ndf['text'])-1):\n",
        "                check_complete = True\n",
        "\n",
        "len(cdc_idx_dict), ref_data.shape[0]"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(7, 1332)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 917
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "outputId": "1a5a0ecc-91be-457f-f5a0-464260ccba83",
        "id": "xtcMTULL1kpV",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "cdc_idx_dict"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{7: 'it would undermine deterrence',\n",
              " 10: 'no issue carries more importance to the long-term health and security of humanity than the effort to reduce, and perhaps one day, rid the world of nuclear weapons',\n",
              " 29: 'it would undermine deterrence',\n",
              " 31: 'Nuclear weapons are said to have induced \"nuclear peace',\n",
              " 34: 'is obsolete',\n",
              " 41: 'the likelihood that non-state terrorists will get their hands on nuclear weaponry is increasing',\n",
              " 44: 'no issue carries more importance to the long-term health and security of humanity than the effort to reduce, and perhaps one day, rid the world of nuclear weapons'}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 918
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "-1ZBiYQx1kpW",
        "colab": {}
      },
      "source": [
        "cdc = []\n",
        "\n",
        "for x in range(len(ndf)):\n",
        "    if x in list(cdc_idx_dict.keys()):\n",
        "        cdc.append(cdc_idx_dict.get(x))\n",
        "    else:\n",
        "        cdc.append('---')\n",
        "ndf['cdc'] = cdc\n",
        "\n",
        "df = pd.concat([df, ndf], axis=0, ignore_index=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "S8tGelhw1kpW"
      },
      "source": [
        "#### Article 2 "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "wRdwOGC_1kpX",
        "colab": {}
      },
      "source": [
        "with open(articles_dict[articles[2].replace(' ','_')+'.txt']) as article:\n",
        "        doc = article.read()\n",
        "\n",
        "c_doc = text_cleaner(doc)\n",
        "sentences = nltk.sent_tokenize(c_doc)\n",
        "sentences = [[sent, topic, articles[2]] for sent in sentences]\n",
        "\n",
        "ndf = pd.DataFrame(sentences, columns=['text', 'topic', 'article'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "outputId": "518bb80d-491d-446c-b5b6-3c4b8f4802db",
        "id": "kO4pAZtc1kpX",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "cdc_idx_dict = {}\n",
        "cdc_idx_sent = {}\n",
        "cdc_idx_art = {}\n",
        "\n",
        "for i,claim in enumerate(ref_data['clean_Claim']):\n",
        "    check_complete = False\n",
        "    while check_complete == False:\n",
        "        for idx,sentence in enumerate(ndf['text']):\n",
        "            test = claim.lower() in sentence.lower()\n",
        "            if test:\n",
        "                article = ref_data['Article'][i]\n",
        "                cdc_idx_dict[idx] = claim\n",
        "                cdc_idx_sent[idx] = [claim, sentence]\n",
        "                cdc_idx_art[idx] = [claim, article]\n",
        "                check_complete = True\n",
        "            elif idx == (len(ndf['text'])-1):\n",
        "                check_complete = True\n",
        "\n",
        "len(cdc_idx_dict), ref_data.shape[0]"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(5, 1332)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 921
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "outputId": "92cf1fdc-dd62-4228-f072-4af7d652e088",
        "id": "wotG5c7U1kpY",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "cdc_idx_dict"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{3: 'an inferior nuclear force, by virtue of its extreme destructive power, could deter a more powerful adversary',\n",
              " 16: 'nuclear weapons had become a source of extreme risk',\n",
              " 37: 'nuclear weapons are intended to deter other states from attacking with their nuclear weapons',\n",
              " 98: 'Nuclear weapons give nations the potential to not only destroy their enemies but humanity itself',\n",
              " 127: 'nuclear weapons had become a source of extreme risk'}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 922
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "Pdz7tLZK1kpZ",
        "colab": {}
      },
      "source": [
        "cdc = []\n",
        "\n",
        "for x in range(len(ndf)):\n",
        "    if x in list(cdc_idx_dict.keys()):\n",
        "        cdc.append(cdc_idx_dict.get(x))\n",
        "    else:\n",
        "        cdc.append('---')\n",
        "ndf['cdc'] = cdc\n",
        "\n",
        "df = pd.concat([ndf, df], axis=0, ignore_index=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "E5jmE6gh1kpa"
      },
      "source": [
        "#### Article 3 "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "nnzxN4xb1kpa",
        "colab": {}
      },
      "source": [
        "with open(articles_dict[articles[3].replace(' ','_')+'.txt']) as article:\n",
        "        doc = article.read()\n",
        "\n",
        "c_doc = text_cleaner(doc)\n",
        "sentences = nltk.sent_tokenize(c_doc)\n",
        "sentences = [[sent, topic, articles[3]] for sent in sentences]\n",
        "\n",
        "ndf = pd.DataFrame(sentences, columns=['text', 'topic', 'article'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "outputId": "7633f39b-43bf-41e2-f966-6c6355508f49",
        "id": "Ktv4z0hx1kpa",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "cdc_idx_dict = {}\n",
        "cdc_idx_sent = {}\n",
        "cdc_idx_art = {}\n",
        "\n",
        "for i,claim in enumerate(ref_data['clean_Claim']):\n",
        "    check_complete = False\n",
        "    while check_complete == False:\n",
        "        for idx,sentence in enumerate(ndf['text']):\n",
        "            test = claim.lower() in sentence.lower()\n",
        "            if test:\n",
        "                article = ref_data['Article'][i]\n",
        "                cdc_idx_dict[idx] = claim\n",
        "                cdc_idx_sent[idx] = [claim, sentence]\n",
        "                cdc_idx_art[idx] = [claim, article]\n",
        "                check_complete = True\n",
        "            elif idx == (len(ndf['text'])-1):\n",
        "                check_complete = True\n",
        "\n",
        "len(cdc_idx_dict), ref_data.shape[0]"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(9, 1332)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 925
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "outputId": "55c5fae0-3679-49ef-dfb3-73e6169a20c9",
        "id": "tSuVM97T1kpb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "cdc_idx_dict"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{0: 'decrease the chances of crisis escalation',\n",
              " 1: 'nuclear weapons are said to have induced stability',\n",
              " 2: 'nuclear proliferation may be beneficial for inducing stability',\n",
              " 3: 'increases the chances of nuclear material falling into the hands of non-state groups who are free from the threat of nuclear retaliation',\n",
              " 5: 'new nuclear states will use their acquired nuclear capabilities to deter threats and preserve peace',\n",
              " 6: 'new nuclear states often lack adequate organizational controls over their new weapons, which makes for a high risk of either deliberate or accidental nuclear war',\n",
              " 13: \"Nuclear weapons may also lessen a state's reliance on allies for security, thus preventing allies from dragging each other into wars\",\n",
              " 26: 'nuclear weapons induce stability',\n",
              " 27: 'nuclear weapons contribute to stability'}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 926
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "T2-QC8I61kpc",
        "colab": {}
      },
      "source": [
        "cdc = []\n",
        "\n",
        "for x in range(len(ndf)):\n",
        "    if x in list(cdc_idx_dict.keys()):\n",
        "        cdc.append(cdc_idx_dict.get(x))\n",
        "    else:\n",
        "        cdc.append('---')\n",
        "ndf['cdc'] = cdc\n",
        "\n",
        "df = pd.concat([ndf, df], axis=0, ignore_index=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "uEnPiLT61kpc"
      },
      "source": [
        "#### Article 4 "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "gTFXqhe11kpd",
        "colab": {}
      },
      "source": [
        "with open(articles_dict[articles[4].replace(' ','_')+'.txt']) as article:\n",
        "        doc = article.read()\n",
        "\n",
        "c_doc = text_cleaner(doc)\n",
        "sentences = nltk.sent_tokenize(c_doc)\n",
        "sentences = [[sent, topic, articles[4]] for sent in sentences]\n",
        "\n",
        "ndf = pd.DataFrame(sentences, columns=['text', 'topic', 'article'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "outputId": "6b56239b-77ba-4a5c-c1a6-03650fa3cf97",
        "id": "5t1XhiRJ1kpd",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "cdc_idx_dict = {}\n",
        "cdc_idx_sent = {}\n",
        "cdc_idx_art = {}\n",
        "\n",
        "for i,claim in enumerate(ref_data['clean_Claim']):\n",
        "    check_complete = False\n",
        "    while check_complete == False:\n",
        "        for idx,sentence in enumerate(ndf['text']):\n",
        "            test = claim.lower() in sentence.lower()\n",
        "            if test:\n",
        "                article = ref_data['Article'][i]\n",
        "                cdc_idx_dict[idx] = claim\n",
        "                cdc_idx_sent[idx] = [claim, sentence]\n",
        "                cdc_idx_art[idx] = [claim, article]\n",
        "                check_complete = True\n",
        "            elif idx == (len(ndf['text'])-1):\n",
        "                check_complete = True\n",
        "\n",
        "len(cdc_idx_dict), ref_data.shape[0]"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(3, 1332)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 929
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "outputId": "0bf4f5b4-d4ab-4f49-81b3-737df7b58836",
        "id": "DBaOoy-w1kpe",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "cdc_idx_dict"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{16: 'the NPT cannot stop the proliferation of nuclear weapons or the motivation to acquire them',\n",
              " 75: 'Having more nuclear nuclear-weapon states would reduce security for all',\n",
              " 100: 'nuclear forces continue to play an essential role in war prevention'}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 930
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "n4diFFtD1kpf",
        "colab": {}
      },
      "source": [
        "cdc = []\n",
        "\n",
        "for x in range(len(ndf)):\n",
        "    if x in list(cdc_idx_dict.keys()):\n",
        "        cdc.append(cdc_idx_dict.get(x))\n",
        "    else:\n",
        "        cdc.append('---')\n",
        "ndf['cdc'] = cdc\n",
        "\n",
        "df = pd.concat([ndf, df], axis=0, ignore_index=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "RAbF_NnU_sev"
      },
      "source": [
        "#### Article 5 "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "Xeqg-gfY_sev",
        "colab": {}
      },
      "source": [
        "with open(articles_dict[articles[5].replace(' ','_')+'.txt']) as article:\n",
        "        doc = article.read()\n",
        "\n",
        "c_doc = text_cleaner(doc)\n",
        "sentences = nltk.sent_tokenize(c_doc)\n",
        "sentences = [[sent, topic, articles[5]] for sent in sentences]\n",
        "\n",
        "ndf = pd.DataFrame(sentences, columns=['text', 'topic', 'article'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "outputId": "06fe32e0-66b8-4147-d05a-242a13bb6979",
        "id": "9R5xorsr_sew",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "cdc_idx_dict = {}\n",
        "cdc_idx_sent = {}\n",
        "cdc_idx_art = {}\n",
        "\n",
        "for i,claim in enumerate(ref_data['clean_Claim']):\n",
        "    check_complete = False\n",
        "    while check_complete == False:\n",
        "        for idx,sentence in enumerate(ndf['text']):\n",
        "            test = claim.lower() in sentence.lower()\n",
        "            if test:\n",
        "                article = ref_data['Article'][i]\n",
        "                cdc_idx_dict[idx] = claim\n",
        "                cdc_idx_sent[idx] = [claim, sentence]\n",
        "                cdc_idx_art[idx] = [claim, article]\n",
        "                check_complete = True\n",
        "            elif idx == (len(ndf['text'])-1):\n",
        "                check_complete = True\n",
        "\n",
        "len(cdc_idx_dict), ref_data.shape[0]"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(6, 1332)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 933
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "outputId": "8ead41bb-2ba9-4997-acaf-4f4c50b28463",
        "id": "sA---08i_sex",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "cdc_idx_dict"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{86: 'the significance of nuclear weapons is purely to deter war',\n",
              " 89: 'would generally be contrary to the rules of international law applicable in armed conflict',\n",
              " 90: 'nuclear proliferation would be desirable',\n",
              " 91: 'nuclear weapons successfully deter all-out war between states',\n",
              " 125: 'could lead to increased global instability',\n",
              " 128: 'no issue carries more importance to the long-term health and security of humanity than the effort to reduce, and perhaps one day, rid the world of nuclear weapons'}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 934
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "sJysFirF_sey",
        "colab": {}
      },
      "source": [
        "cdc = []\n",
        "\n",
        "for x in range(len(ndf)):\n",
        "    if x in list(cdc_idx_dict.keys()):\n",
        "        cdc.append(cdc_idx_dict.get(x))\n",
        "    else:\n",
        "        cdc.append('---')\n",
        "ndf['cdc'] = cdc\n",
        "\n",
        "df = pd.concat([ndf, df], axis=0, ignore_index=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "Z93KPE0e_sez"
      },
      "source": [
        "#### Article 6"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "S9S3DIRN_se0",
        "colab": {}
      },
      "source": [
        "with open(articles_dict[articles[6].replace(' ','_')+'.txt']) as article:\n",
        "        doc = article.read()\n",
        "\n",
        "c_doc = text_cleaner(doc)\n",
        "sentences = nltk.sent_tokenize(c_doc)\n",
        "sentences = [[sent, topic, articles[6]] for sent in sentences]\n",
        "\n",
        "ndf = pd.DataFrame(sentences, columns=['text', 'topic', 'article'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "outputId": "03e3adb5-db6c-404d-bf26-83daf9d94730",
        "id": "ZTtmki-x_se2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "cdc_idx_dict = {}\n",
        "cdc_idx_sent = {}\n",
        "cdc_idx_art = {}\n",
        "\n",
        "for i,claim in enumerate(ref_data['clean_Claim']):\n",
        "    check_complete = False\n",
        "    while check_complete == False:\n",
        "        for idx,sentence in enumerate(ndf['text']):\n",
        "            test = claim.lower() in sentence.lower()\n",
        "            if test:\n",
        "                article = ref_data['Article'][i]\n",
        "                cdc_idx_dict[idx] = claim\n",
        "                cdc_idx_sent[idx] = [claim, sentence]\n",
        "                cdc_idx_art[idx] = [claim, article]\n",
        "                check_complete = True\n",
        "            elif idx == (len(ndf['text'])-1):\n",
        "                check_complete = True\n",
        "\n",
        "len(cdc_idx_dict), ref_data.shape[0]"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(2, 1332)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 937
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "outputId": "ac0027e9-253f-4072-b969-370e541cda60",
        "id": "-Jacjoh6_se4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "cdc_idx_dict"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{31: 'the US keeps a huge stockpile of nuclear weapons while urging other nations not to get them',\n",
              " 60: 'the United Nations Charter, ratified by the U.S., prohibits members from using force against fellow members except against imminent attack'}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 938
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "mNqAy_qG_se5",
        "colab": {}
      },
      "source": [
        "cdc = []\n",
        "\n",
        "for x in range(len(ndf)):\n",
        "    if x in list(cdc_idx_dict.keys()):\n",
        "        cdc.append(cdc_idx_dict.get(x))\n",
        "    else:\n",
        "        cdc.append('---')\n",
        "ndf['cdc'] = cdc\n",
        "\n",
        "df = pd.concat([ndf, df], axis=0, ignore_index=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "euW_qhDlzezA",
        "colab_type": "text"
      },
      "source": [
        "### \"the United States is responsible for Mexico's drugs war \""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "outputId": "f18a3d5c-8fea-4cb0-e554-1db440cfcb6d",
        "id": "Mnyzt4Dm1mr3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "topic = \"the United States is responsible for Mexico's drugs war \"\n",
        "\n",
        "articles = topic_article_dict[topic]\n",
        "articles"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['Smuggling of firearms into Mexico',\n",
              " 'War on Drugs',\n",
              " 'Merida Initiative',\n",
              " 'Mexican Drug War',\n",
              " 'ATF gunwalking scandal']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 940
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AD4fLocY1mcF",
        "colab_type": "code",
        "outputId": "995eb2bf-8c85-4021-9f0d-d3694d1e307b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "len(articles)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "5"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 941
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "lf3SjSWO1mr4"
      },
      "source": [
        "#### Article 0 "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "4D_JgZfB1mr4",
        "colab": {}
      },
      "source": [
        "with open(articles_dict[articles[0].replace(' ','_')+'.txt']) as article:\n",
        "        doc = article.read()\n",
        "\n",
        "c_doc = text_cleaner(doc)\n",
        "sentences = nltk.sent_tokenize(c_doc)\n",
        "sentences = [[sent, topic, articles[0]] for sent in sentences]\n",
        "\n",
        "ndf = pd.DataFrame(sentences, columns=['text', 'topic', 'article'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "outputId": "64a62603-a64e-4a38-9d49-592406450570",
        "id": "cY3Fg3061mr5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "cdc_idx_dict = {}\n",
        "cdc_idx_sent = {}\n",
        "cdc_idx_art = {}\n",
        "\n",
        "for i,claim in enumerate(ref_data['clean_Claim']):\n",
        "    check_complete = False\n",
        "    while check_complete == False:\n",
        "        for idx,sentence in enumerate(ndf['text']):\n",
        "            test = claim.lower() in sentence.lower()\n",
        "            if test:\n",
        "                article = ref_data['Article'][i]\n",
        "                cdc_idx_dict[idx] = claim\n",
        "                cdc_idx_sent[idx] = [claim, sentence]\n",
        "                cdc_idx_art[idx] = [claim, article]\n",
        "                check_complete = True\n",
        "            elif idx == (len(ndf['text'])-1):\n",
        "                check_complete = True\n",
        "\n",
        "len(cdc_idx_dict), ref_data.shape[0]"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(4, 1332)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 943
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "outputId": "af2b7773-d5b0-427f-f838-02aae159725f",
        "id": "yU3INpfX1mr6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "cdc_idx_dict"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{24: \"a 'significant' percentage of their firearms originate from gun stores and other sources in the U.S\",\n",
              " 51: 'the majority of illegal guns in Mexico really come from the United States',\n",
              " 68: 'American guns are arming the Mexican drug cartels',\n",
              " 100: 'most weapons and arms trafficked into Mexico are from gun dealers in the United States'}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 944
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "JKcHCWqb1mr7",
        "colab": {}
      },
      "source": [
        "cdc = []\n",
        "\n",
        "for x in range(len(ndf)):\n",
        "    if x in list(cdc_idx_dict.keys()):\n",
        "        cdc.append(cdc_idx_dict.get(x))\n",
        "    else:\n",
        "        cdc.append('---')\n",
        "ndf['cdc'] = cdc\n",
        "\n",
        "df = pd.concat([ndf, df], axis=0, ignore_index=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "6JmLZJz61mr7"
      },
      "source": [
        "#### Article 1 "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "TXFbZxHt1mr8",
        "colab": {}
      },
      "source": [
        "with open(articles_dict[articles[1].replace(' ','_')+'.txt']) as article:\n",
        "        doc = article.read()\n",
        "\n",
        "c_doc = text_cleaner(doc)\n",
        "sentences = nltk.sent_tokenize(c_doc)\n",
        "sentences = [[sent, topic, articles[1]] for sent in sentences]\n",
        "\n",
        "ndf = pd.DataFrame(sentences, columns=['text', 'topic', 'article'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "outputId": "cf02d659-d2d4-4418-dbdb-680df530fd2b",
        "id": "MWxOLtQq1mr8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "cdc_idx_dict = {}\n",
        "cdc_idx_sent = {}\n",
        "cdc_idx_art = {}\n",
        "\n",
        "for i,claim in enumerate(ref_data['clean_Claim']):\n",
        "    check_complete = False\n",
        "    while check_complete == False:\n",
        "        for idx,sentence in enumerate(ndf['text']):\n",
        "            test = claim.lower() in sentence.lower()\n",
        "            if test:\n",
        "                article = ref_data['Article'][i]\n",
        "                cdc_idx_dict[idx] = claim\n",
        "                cdc_idx_sent[idx] = [claim, sentence]\n",
        "                cdc_idx_art[idx] = [claim, article]\n",
        "                check_complete = True\n",
        "            elif idx == (len(ndf['text'])-1):\n",
        "                check_complete = True\n",
        "\n",
        "len(cdc_idx_dict), ref_data.shape[0]"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(1, 1332)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 947
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "outputId": "e5442360-e342-4f87-cf2d-fe987f0afa1b",
        "id": "4dud_JKT1mr9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "cdc_idx_dict"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{224: 'by making drugs illegal rather than regulating them, the War on Drugs creates a highly profitable black market'}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 948
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "eHe0DWHx1mr-",
        "colab": {}
      },
      "source": [
        "cdc = []\n",
        "\n",
        "for x in range(len(ndf)):\n",
        "    if x in list(cdc_idx_dict.keys()):\n",
        "        cdc.append(cdc_idx_dict.get(x))\n",
        "    else:\n",
        "        cdc.append('---')\n",
        "ndf['cdc'] = cdc\n",
        "\n",
        "df = pd.concat([df, ndf], axis=0, ignore_index=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "9j7pLoL91msG"
      },
      "source": [
        "#### Article 2 "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "DUofgNtY1msG",
        "colab": {}
      },
      "source": [
        "with open(articles_dict[articles[2].replace(' ','_')+'.txt']) as article:\n",
        "        doc = article.read()\n",
        "\n",
        "c_doc = text_cleaner(doc)\n",
        "sentences = nltk.sent_tokenize(c_doc)\n",
        "sentences = [[sent, topic, articles[2]] for sent in sentences]\n",
        "\n",
        "ndf = pd.DataFrame(sentences, columns=['text', 'topic', 'article'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "outputId": "bd4a50f5-e53d-486b-8dcd-b064bb3ddc7a",
        "id": "gGwQ38V91msG",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "cdc_idx_dict = {}\n",
        "cdc_idx_sent = {}\n",
        "cdc_idx_art = {}\n",
        "\n",
        "for i,claim in enumerate(ref_data['clean_Claim']):\n",
        "    check_complete = False\n",
        "    while check_complete == False:\n",
        "        for idx,sentence in enumerate(ndf['text']):\n",
        "            test = claim.lower() in sentence.lower()\n",
        "            if test:\n",
        "                article = ref_data['Article'][i]\n",
        "                cdc_idx_dict[idx] = claim\n",
        "                cdc_idx_sent[idx] = [claim, sentence]\n",
        "                cdc_idx_art[idx] = [claim, article]\n",
        "                check_complete = True\n",
        "            elif idx == (len(ndf['text'])-1):\n",
        "                check_complete = True\n",
        "\n",
        "len(cdc_idx_dict), ref_data.shape[0]"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(4, 1332)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 951
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "outputId": "26aa16be-85c6-4c3c-c6af-44073d30db92",
        "id": "0yNo7g6b1msH",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "cdc_idx_dict"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{2: 'most of the financing for the Mexican traffickers comes from American drug consumers',\n",
              " 63: 'firearms recovered in Mexico came from U.S. gun dealers',\n",
              " 89: 'the root cause of the problem: U.S. demand',\n",
              " 104: 'American) government has been sending weapons to Mexico in a premeditated and systematic manner, knowing that their destinations were Mexican criminal organizations'}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 952
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "yQv3s3nr1msI",
        "colab": {}
      },
      "source": [
        "cdc = []\n",
        "\n",
        "for x in range(len(ndf)):\n",
        "    if x in list(cdc_idx_dict.keys()):\n",
        "        cdc.append(cdc_idx_dict.get(x))\n",
        "    else:\n",
        "        cdc.append('---')\n",
        "ndf['cdc'] = cdc\n",
        "\n",
        "df = pd.concat([ndf, df], axis=0, ignore_index=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "LoSkodjw1msJ"
      },
      "source": [
        "#### Article 3 "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "dUw1dE8u1msJ",
        "colab": {}
      },
      "source": [
        "with open(articles_dict[articles[3].replace(' ','_')+'.txt']) as article:\n",
        "        doc = article.read()\n",
        "\n",
        "c_doc = text_cleaner(doc)\n",
        "sentences = nltk.sent_tokenize(c_doc)\n",
        "sentences = [[sent, topic, articles[3]] for sent in sentences]\n",
        "\n",
        "ndf = pd.DataFrame(sentences, columns=['text', 'topic', 'article'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "outputId": "3047ee69-a80a-4c67-d8a7-f513983a0428",
        "id": "zj6D2m3Q1msJ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "cdc_idx_dict = {}\n",
        "cdc_idx_sent = {}\n",
        "cdc_idx_art = {}\n",
        "\n",
        "for i,claim in enumerate(ref_data['clean_Claim']):\n",
        "    check_complete = False\n",
        "    while check_complete == False:\n",
        "        for idx,sentence in enumerate(ndf['text']):\n",
        "            test = claim.lower() in sentence.lower()\n",
        "            if test:\n",
        "                article = ref_data['Article'][i]\n",
        "                cdc_idx_dict[idx] = claim\n",
        "                cdc_idx_sent[idx] = [claim, sentence]\n",
        "                cdc_idx_art[idx] = [claim, article]\n",
        "                check_complete = True\n",
        "            elif idx == (len(ndf['text'])-1):\n",
        "                check_complete = True\n",
        "\n",
        "len(cdc_idx_dict), ref_data.shape[0]"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(6, 1332)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 955
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "outputId": "74f0be68-4636-4cc9-d2b8-97a7c7cfccca",
        "id": "Wv1gQTwX1msK",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "cdc_idx_dict"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{132: 'A significant number of firearms that make their way to Mexico come from U.S. gunshops',\n",
              " 141: 'most weapons and arms trafficked into Mexico are from gun dealers in the United States',\n",
              " 142: 'Mexican crime guns traced to U.S. origins',\n",
              " 147: \"a 'significant' percentage of their firearms originate from gun stores and other sources in the U.S\",\n",
              " 255: 'most of the financing for the Mexican traffickers comes from American drug consumers',\n",
              " 264: 'the root cause of the problem: U.S. demand'}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 956
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "LokBs9JI1msL",
        "colab": {}
      },
      "source": [
        "cdc = []\n",
        "\n",
        "for x in range(len(ndf)):\n",
        "    if x in list(cdc_idx_dict.keys()):\n",
        "        cdc.append(cdc_idx_dict.get(x))\n",
        "    else:\n",
        "        cdc.append('---')\n",
        "ndf['cdc'] = cdc\n",
        "\n",
        "df = pd.concat([ndf, df], axis=0, ignore_index=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "WMGDjFr91msL"
      },
      "source": [
        "#### Article 4 "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "KBqwGjVK1msM",
        "colab": {}
      },
      "source": [
        "with open(articles_dict[articles[4].replace(' ','_')+'.txt']) as article:\n",
        "        doc = article.read()\n",
        "\n",
        "c_doc = text_cleaner(doc)\n",
        "sentences = nltk.sent_tokenize(c_doc)\n",
        "sentences = [[sent, topic, articles[4]] for sent in sentences]\n",
        "\n",
        "ndf = pd.DataFrame(sentences, columns=['text', 'topic', 'article'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "outputId": "28bc97ab-b31e-468b-d56f-0c50e9213187",
        "id": "gT_-xKOc1msM",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "cdc_idx_dict = {}\n",
        "cdc_idx_sent = {}\n",
        "cdc_idx_art = {}\n",
        "\n",
        "for i,claim in enumerate(ref_data['clean_Claim']):\n",
        "    check_complete = False\n",
        "    while check_complete == False:\n",
        "        for idx,sentence in enumerate(ndf['text']):\n",
        "            test = claim.lower() in sentence.lower()\n",
        "            if test:\n",
        "                article = ref_data['Article'][i]\n",
        "                cdc_idx_dict[idx] = claim\n",
        "                cdc_idx_sent[idx] = [claim, sentence]\n",
        "                cdc_idx_art[idx] = [claim, article]\n",
        "                check_complete = True\n",
        "            elif idx == (len(ndf['text'])-1):\n",
        "                check_complete = True\n",
        "\n",
        "len(cdc_idx_dict), ref_data.shape[0]"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(2, 1332)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 959
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "outputId": "dc2b2ff2-daef-4d1e-d493-7d746c804fa1",
        "id": "ZQrYwtfQ1msN",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "cdc_idx_dict"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{2: 'the ATF knowingly allowed thousands of guns to be bought by suspected arms traffickers (\"gunrunners\") working through straw purchasers on behalf of Mexican drug cartels',\n",
              " 170: 'American) government has been sending weapons to Mexico in a premeditated and systematic manner, knowing that their destinations were Mexican criminal organizations'}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 960
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "ZMOQJOrI1msO",
        "colab": {}
      },
      "source": [
        "cdc = []\n",
        "\n",
        "for x in range(len(ndf)):\n",
        "    if x in list(cdc_idx_dict.keys()):\n",
        "        cdc.append(cdc_idx_dict.get(x))\n",
        "    else:\n",
        "        cdc.append('---')\n",
        "ndf['cdc'] = cdc\n",
        "\n",
        "df = pd.concat([ndf, df], axis=0, ignore_index=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yiqy5HT1zjxj",
        "colab_type": "text"
      },
      "source": [
        "### 'the monarchy '"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "outputId": "0557e462-6e34-4a2f-e09b-8dfd012b548f",
        "id": "ysXE95-Q1pZu",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "topic = 'the monarchy '\n",
        "\n",
        "articles = topic_article_dict[topic]\n",
        "articles"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['Republicanism in Australia',\n",
              " 'Republicanism in Canada',\n",
              " 'Monarch',\n",
              " 'Monarchy of the United Kingdom',\n",
              " 'Monarchy of New Zealand',\n",
              " 'Right-wing politics',\n",
              " 'Enlightened absolutism',\n",
              " 'Monarchy',\n",
              " 'Debate on the monarchy in Canada',\n",
              " 'Constitutional monarchy',\n",
              " 'Republicanism in the United Kingdom',\n",
              " 'Monarchism']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 962
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_FeV2Ryw1pAs",
        "colab_type": "code",
        "outputId": "2fb04806-fa57-4dac-af20-e6458b606e12",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "len(articles)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "12"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 963
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "tfxHy_zD1pZv"
      },
      "source": [
        "#### Article 0 "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "vmK1UsL91pZv",
        "colab": {}
      },
      "source": [
        "with open(articles_dict[articles[0].replace(' ','_')+'.txt']) as article:\n",
        "        doc = article.read()\n",
        "\n",
        "c_doc = text_cleaner(doc)\n",
        "sentences = nltk.sent_tokenize(c_doc)\n",
        "sentences = [[sent, topic, articles[0]] for sent in sentences]\n",
        "\n",
        "ndf = pd.DataFrame(sentences, columns=['text', 'topic', 'article'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "outputId": "86b673f4-b8be-4ca7-9ff7-47802a3e0eca",
        "id": "KuTwVALL1pZw",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "cdc_idx_dict = {}\n",
        "cdc_idx_sent = {}\n",
        "cdc_idx_art = {}\n",
        "\n",
        "for i,claim in enumerate(ref_data['clean_Claim']):\n",
        "    check_complete = False\n",
        "    while check_complete == False:\n",
        "        for idx,sentence in enumerate(ndf['text']):\n",
        "            test = claim.lower() in sentence.lower()\n",
        "            if test:\n",
        "                article = ref_data['Article'][i]\n",
        "                cdc_idx_dict[idx] = claim\n",
        "                cdc_idx_sent[idx] = [claim, sentence]\n",
        "                cdc_idx_art[idx] = [claim, article]\n",
        "                check_complete = True\n",
        "            elif idx == (len(ndf['text'])-1):\n",
        "                check_complete = True\n",
        "\n",
        "len(cdc_idx_dict), ref_data.shape[0]"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(2, 1332)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 965
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "outputId": "0ae8b5ca-0465-4dfb-cb70-f76f60382f0f",
        "id": "UAX_EbQs1pZw",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "cdc_idx_dict"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{21: 'The hereditary nature of the monarchy is said to conflict with egalitarianism and dislike of inherited privilege',\n",
              " 22: 'The laws of succession are held by some to be sexist'}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 966
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "HctTNRe51pZx",
        "colab": {}
      },
      "source": [
        "cdc = []\n",
        "\n",
        "for x in range(len(ndf)):\n",
        "    if x in list(cdc_idx_dict.keys()):\n",
        "        cdc.append(cdc_idx_dict.get(x))\n",
        "    else:\n",
        "        cdc.append('---')\n",
        "ndf['cdc'] = cdc\n",
        "\n",
        "df = pd.concat([ndf, df], axis=0, ignore_index=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "CHkn8hxu1pZy"
      },
      "source": [
        "#### Article 1 "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "9nwK-En11pZz",
        "colab": {}
      },
      "source": [
        "with open(articles_dict[articles[1].replace(' ','_')+'.txt']) as article:\n",
        "        doc = article.read()\n",
        "\n",
        "c_doc = text_cleaner(doc)\n",
        "sentences = nltk.sent_tokenize(c_doc)\n",
        "sentences = [[sent, topic, articles[1]] for sent in sentences]\n",
        "\n",
        "ndf = pd.DataFrame(sentences, columns=['text', 'topic', 'article'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "outputId": "2819229c-8c0a-4fdc-b38b-17895b94c374",
        "id": "w6MogpKd1pZ0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "cdc_idx_dict = {}\n",
        "cdc_idx_sent = {}\n",
        "cdc_idx_art = {}\n",
        "\n",
        "for i,claim in enumerate(ref_data['clean_Claim']):\n",
        "    check_complete = False\n",
        "    while check_complete == False:\n",
        "        for idx,sentence in enumerate(ndf['text']):\n",
        "            test = claim.lower() in sentence.lower()\n",
        "            if test:\n",
        "                article = ref_data['Article'][i]\n",
        "                cdc_idx_dict[idx] = claim\n",
        "                cdc_idx_sent[idx] = [claim, sentence]\n",
        "                cdc_idx_art[idx] = [claim, article]\n",
        "                check_complete = True\n",
        "            elif idx == (len(ndf['text'])-1):\n",
        "                check_complete = True\n",
        "\n",
        "len(cdc_idx_dict), ref_data.shape[0]"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(6, 1332)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 969
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "outputId": "07b65fb2-0ba2-4693-c0bc-a94d183930cb",
        "id": "QneRhwWN1pZ0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "cdc_idx_dict"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{7: 'the monarchy is inherently contrary to egalitarianism and multiculturalism',\n",
              " 9: 'national pride is diminished by the monarchy',\n",
              " 13: 'people are given greater dignity from choosing their head of state',\n",
              " 28: \"the country's head of state should be elected\",\n",
              " 45: 'monarchy as \"outdated and irrelevant',\n",
              " 84: 'The monarchy remains a symbol of imperialism and colonialism'}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 970
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "9T48ItYJ1pZ1",
        "colab": {}
      },
      "source": [
        "cdc = []\n",
        "\n",
        "for x in range(len(ndf)):\n",
        "    if x in list(cdc_idx_dict.keys()):\n",
        "        cdc.append(cdc_idx_dict.get(x))\n",
        "    else:\n",
        "        cdc.append('---')\n",
        "ndf['cdc'] = cdc\n",
        "\n",
        "df = pd.concat([df, ndf], axis=0, ignore_index=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "lG5sXKkU1pZ2"
      },
      "source": [
        "#### Article 2 "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "xaaxseA01pZ2",
        "colab": {}
      },
      "source": [
        "with open(articles_dict[articles[2].replace(' ','_')+'.txt']) as article:\n",
        "        doc = article.read()\n",
        "\n",
        "c_doc = text_cleaner(doc)\n",
        "sentences = nltk.sent_tokenize(c_doc)\n",
        "sentences = [[sent, topic, articles[2]] for sent in sentences]\n",
        "\n",
        "ndf = pd.DataFrame(sentences, columns=['text', 'topic', 'article'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "outputId": "1adfb817-b0ca-41d3-fec5-9132a2453af0",
        "id": "FwChR7z21pZ3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "cdc_idx_dict = {}\n",
        "cdc_idx_sent = {}\n",
        "cdc_idx_art = {}\n",
        "\n",
        "for i,claim in enumerate(ref_data['clean_Claim']):\n",
        "    check_complete = False\n",
        "    while check_complete == False:\n",
        "        for idx,sentence in enumerate(ndf['text']):\n",
        "            test = claim.lower() in sentence.lower()\n",
        "            if test:\n",
        "                article = ref_data['Article'][i]\n",
        "                cdc_idx_dict[idx] = claim\n",
        "                cdc_idx_sent[idx] = [claim, sentence]\n",
        "                cdc_idx_art[idx] = [claim, article]\n",
        "                check_complete = True\n",
        "            elif idx == (len(ndf['text'])-1):\n",
        "                check_complete = True\n",
        "\n",
        "len(cdc_idx_dict), ref_data.shape[0]"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(1, 1332)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 973
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "outputId": "da538c8f-c689-4f06-fd60-319f93657e48",
        "id": "3SpLCnWG1pZ4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "cdc_idx_dict"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{25: 'The principal advantage of hereditary monarchy is the immediate continuity of leadership'}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 974
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "JjPkWxGh1pZ4",
        "colab": {}
      },
      "source": [
        "cdc = []\n",
        "\n",
        "for x in range(len(ndf)):\n",
        "    if x in list(cdc_idx_dict.keys()):\n",
        "        cdc.append(cdc_idx_dict.get(x))\n",
        "    else:\n",
        "        cdc.append('---')\n",
        "ndf['cdc'] = cdc\n",
        "\n",
        "df = pd.concat([ndf, df], axis=0, ignore_index=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "A-iT7yIT1pZ6"
      },
      "source": [
        "#### Article 3 "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "EA-VRIqO1pZ6",
        "colab": {}
      },
      "source": [
        "with open(articles_dict[articles[3].replace(' ','_')+'.txt']) as article:\n",
        "        doc = article.read()\n",
        "\n",
        "c_doc = text_cleaner(doc)\n",
        "sentences = nltk.sent_tokenize(c_doc)\n",
        "sentences = [[sent, topic, articles[3]] for sent in sentences]\n",
        "\n",
        "ndf = pd.DataFrame(sentences, columns=['text', 'topic', 'article'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "outputId": "b63b48ea-4d3b-43b2-cc6b-7482f0ca923d",
        "id": "OOCakY8U1pZ7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "cdc_idx_dict = {}\n",
        "cdc_idx_sent = {}\n",
        "cdc_idx_art = {}\n",
        "\n",
        "for i,claim in enumerate(ref_data['clean_Claim']):\n",
        "    check_complete = False\n",
        "    while check_complete == False:\n",
        "        for idx,sentence in enumerate(ndf['text']):\n",
        "            test = claim.lower() in sentence.lower()\n",
        "            if test:\n",
        "                article = ref_data['Article'][i]\n",
        "                cdc_idx_dict[idx] = claim\n",
        "                cdc_idx_sent[idx] = [claim, sentence]\n",
        "                cdc_idx_art[idx] = [claim, article]\n",
        "                check_complete = True\n",
        "            elif idx == (len(ndf['text'])-1):\n",
        "                check_complete = True\n",
        "\n",
        "len(cdc_idx_dict), ref_data.shape[0]"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(1, 1332)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 977
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "outputId": "b2b7e1c3-87b2-43a7-82da-dba1014be12b",
        "id": "FDEU5R5_1pZ8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "cdc_idx_dict"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{79: 'the monarch cannot be prosecuted for criminal offences'}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 978
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "0bwx_YWG1pZ8",
        "colab": {}
      },
      "source": [
        "cdc = []\n",
        "\n",
        "for x in range(len(ndf)):\n",
        "    if x in list(cdc_idx_dict.keys()):\n",
        "        cdc.append(cdc_idx_dict.get(x))\n",
        "    else:\n",
        "        cdc.append('---')\n",
        "ndf['cdc'] = cdc\n",
        "\n",
        "df = pd.concat([ndf, df], axis=0, ignore_index=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "cYhiDZDP1pZ9"
      },
      "source": [
        "#### Article 4 "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "S0K4YN1d1pZ9",
        "colab": {}
      },
      "source": [
        "with open(articles_dict[articles[4].replace(' ','_')+'.txt']) as article:\n",
        "        doc = article.read()\n",
        "\n",
        "c_doc = text_cleaner(doc)\n",
        "sentences = nltk.sent_tokenize(c_doc)\n",
        "sentences = [[sent, topic, articles[4]] for sent in sentences]\n",
        "\n",
        "ndf = pd.DataFrame(sentences, columns=['text', 'topic', 'article'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "outputId": "34f43f9f-2cb3-4144-e113-11fc23fb7868",
        "id": "7uAuc8Eo1pZ-",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "cdc_idx_dict = {}\n",
        "cdc_idx_sent = {}\n",
        "cdc_idx_art = {}\n",
        "\n",
        "for i,claim in enumerate(ref_data['clean_Claim']):\n",
        "    check_complete = False\n",
        "    while check_complete == False:\n",
        "        for idx,sentence in enumerate(ndf['text']):\n",
        "            test = claim.lower() in sentence.lower()\n",
        "            if test:\n",
        "                article = ref_data['Article'][i]\n",
        "                cdc_idx_dict[idx] = claim\n",
        "                cdc_idx_sent[idx] = [claim, sentence]\n",
        "                cdc_idx_art[idx] = [claim, article]\n",
        "                check_complete = True\n",
        "            elif idx == (len(ndf['text'])-1):\n",
        "                check_complete = True\n",
        "\n",
        "len(cdc_idx_dict), ref_data.shape[0]"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(2, 1332)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 981
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "outputId": "8d970afc-b384-4337-c7e7-39cbe8cc1e93",
        "id": "68jneRpS1pZ_",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "cdc_idx_dict"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{73: 'The monarch is immune from criminal prosecution',\n",
              " 167: 'a republic is \"inevitable'}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 982
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "so0SLHTn1pZ_",
        "colab": {}
      },
      "source": [
        "cdc = []\n",
        "\n",
        "for x in range(len(ndf)):\n",
        "    if x in list(cdc_idx_dict.keys()):\n",
        "        cdc.append(cdc_idx_dict.get(x))\n",
        "    else:\n",
        "        cdc.append('---')\n",
        "ndf['cdc'] = cdc\n",
        "\n",
        "df = pd.concat([ndf, df], axis=0, ignore_index=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "rg9KdHe2ABfV"
      },
      "source": [
        "#### Article 5 "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "mg7GOcT3ABfW",
        "colab": {}
      },
      "source": [
        "with open(articles_dict[articles[5].replace(' ','_')+'.txt']) as article:\n",
        "        doc = article.read()\n",
        "\n",
        "c_doc = text_cleaner(doc)\n",
        "sentences = nltk.sent_tokenize(c_doc)\n",
        "sentences = [[sent, topic, articles[5]] for sent in sentences]\n",
        "\n",
        "ndf = pd.DataFrame(sentences, columns=['text', 'topic', 'article'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "outputId": "ff99b16f-c3fe-4ea2-99fe-8f601036b054",
        "id": "suGWH1d5ABfX",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "cdc_idx_dict = {}\n",
        "cdc_idx_sent = {}\n",
        "cdc_idx_art = {}\n",
        "\n",
        "for i,claim in enumerate(ref_data['clean_Claim']):\n",
        "    check_complete = False\n",
        "    while check_complete == False:\n",
        "        for idx,sentence in enumerate(ndf['text']):\n",
        "            test = claim.lower() in sentence.lower()\n",
        "            if test:\n",
        "                article = ref_data['Article'][i]\n",
        "                cdc_idx_dict[idx] = claim\n",
        "                cdc_idx_sent[idx] = [claim, sentence]\n",
        "                cdc_idx_art[idx] = [claim, article]\n",
        "                check_complete = True\n",
        "            elif idx == (len(ndf['text'])-1):\n",
        "                check_complete = True\n",
        "\n",
        "len(cdc_idx_dict), ref_data.shape[0]"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(1, 1332)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 985
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "outputId": "0996a48c-36f7-4140-e2be-bd8f890fcd77",
        "id": "UqVGyYYfABfX",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "cdc_idx_dict"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{91: 'social traditions or hierarchies that are essential for social order'}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 986
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "iE2-Ud0qABfY",
        "colab": {}
      },
      "source": [
        "cdc = []\n",
        "\n",
        "for x in range(len(ndf)):\n",
        "    if x in list(cdc_idx_dict.keys()):\n",
        "        cdc.append(cdc_idx_dict.get(x))\n",
        "    else:\n",
        "        cdc.append('---')\n",
        "ndf['cdc'] = cdc\n",
        "\n",
        "df = pd.concat([ndf, df], axis=0, ignore_index=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "aaj1LMGpABfZ"
      },
      "source": [
        "#### Article 6"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "VeTpKUN2ABfZ",
        "colab": {}
      },
      "source": [
        "with open(articles_dict[articles[6].replace(' ','_')+'.txt']) as article:\n",
        "        doc = article.read()\n",
        "\n",
        "c_doc = text_cleaner(doc)\n",
        "sentences = nltk.sent_tokenize(c_doc)\n",
        "sentences = [[sent, topic, articles[6]] for sent in sentences]\n",
        "\n",
        "ndf = pd.DataFrame(sentences, columns=['text', 'topic', 'article'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "outputId": "a50e06c6-5baf-42da-e513-6299fe234bc0",
        "id": "1irHkDN_ABfa",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "cdc_idx_dict = {}\n",
        "cdc_idx_sent = {}\n",
        "cdc_idx_art = {}\n",
        "\n",
        "for i,claim in enumerate(ref_data['clean_Claim']):\n",
        "    check_complete = False\n",
        "    while check_complete == False:\n",
        "        for idx,sentence in enumerate(ndf['text']):\n",
        "            test = claim.lower() in sentence.lower()\n",
        "            if test:\n",
        "                article = ref_data['Article'][i]\n",
        "                cdc_idx_dict[idx] = claim\n",
        "                cdc_idx_sent[idx] = [claim, sentence]\n",
        "                cdc_idx_art[idx] = [claim, article]\n",
        "                check_complete = True\n",
        "            elif idx == (len(ndf['text'])-1):\n",
        "                check_complete = True\n",
        "\n",
        "len(cdc_idx_dict), ref_data.shape[0]"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(2, 1332)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 989
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "outputId": "178bb34d-0c45-4205-84d1-1a7b560af1a8",
        "id": "UXnr0JHrABfa",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "cdc_idx_dict"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{8: 'monarchs ruled with the intent of improving the lives of their subjects',\n",
              " 9: 'the sovereign knew the interests of his subjects better than they themselves'}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 990
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "j2X4XF0qABfd",
        "colab": {}
      },
      "source": [
        "cdc = []\n",
        "\n",
        "for x in range(len(ndf)):\n",
        "    if x in list(cdc_idx_dict.keys()):\n",
        "        cdc.append(cdc_idx_dict.get(x))\n",
        "    else:\n",
        "        cdc.append('---')\n",
        "ndf['cdc'] = cdc\n",
        "\n",
        "df = pd.concat([ndf, df], axis=0, ignore_index=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "3qnuD7TeABfd"
      },
      "source": [
        "#### Article 7"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "FWh22MG7ABfe",
        "colab": {}
      },
      "source": [
        "with open(articles_dict[articles[7].replace(' ','_')+'.txt']) as article:\n",
        "        doc = article.read()\n",
        "\n",
        "c_doc = text_cleaner(doc)\n",
        "sentences = nltk.sent_tokenize(c_doc)\n",
        "sentences = [[sent, topic, articles[7]] for sent in sentences]\n",
        "\n",
        "ndf = pd.DataFrame(sentences, columns=['text', 'topic', 'article'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "outputId": "62ade727-5a29-4f8b-aeb1-178906c72bdf",
        "id": "sk15IMjgABfe",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "cdc_idx_dict = {}\n",
        "cdc_idx_sent = {}\n",
        "cdc_idx_art = {}\n",
        "\n",
        "for i,claim in enumerate(ref_data['clean_Claim']):\n",
        "    check_complete = False\n",
        "    while check_complete == False:\n",
        "        for idx,sentence in enumerate(ndf['text']):\n",
        "            test = claim.lower() in sentence.lower()\n",
        "            if test:\n",
        "                article = ref_data['Article'][i]\n",
        "                cdc_idx_dict[idx] = claim\n",
        "                cdc_idx_sent[idx] = [claim, sentence]\n",
        "                cdc_idx_art[idx] = [claim, article]\n",
        "                check_complete = True\n",
        "            elif idx == (len(ndf['text'])-1):\n",
        "                check_complete = True\n",
        "\n",
        "len(cdc_idx_dict), ref_data.shape[0]"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(4, 1332)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 993
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "outputId": "aeb6a86f-7cb9-4990-baba-d6833d2d931a",
        "id": "xzsmeF4nABff",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "cdc_idx_dict"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{21: 'The system of monarchy since antiquity has contrasted with forms of democracy',\n",
              " 35: 'The principal advantage of hereditary monarchy is the immediate continuity of leadership',\n",
              " 47: 'The monarch serves as a ceremonial figurehead symbol of national unity and state continuity',\n",
              " 75: 'a morally-based, balanced monarchy is stressed as the ideal form of government'}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 994
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "JV-Nk2fbABfg",
        "colab": {}
      },
      "source": [
        "cdc = []\n",
        "\n",
        "for x in range(len(ndf)):\n",
        "    if x in list(cdc_idx_dict.keys()):\n",
        "        cdc.append(cdc_idx_dict.get(x))\n",
        "    else:\n",
        "        cdc.append('---')\n",
        "ndf['cdc'] = cdc\n",
        "\n",
        "df = pd.concat([ndf, df], axis=0, ignore_index=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "tRGuT_g-ABfg"
      },
      "source": [
        "#### Article 8"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "01W37RkAABfg",
        "colab": {}
      },
      "source": [
        "with open(articles_dict[articles[8].replace(' ','_')+'.txt']) as article:\n",
        "        doc = article.read()\n",
        "\n",
        "c_doc = text_cleaner(doc)\n",
        "sentences = nltk.sent_tokenize(c_doc)\n",
        "sentences = [[sent, topic, articles[8]] for sent in sentences]\n",
        "\n",
        "ndf = pd.DataFrame(sentences, columns=['text', 'topic', 'article'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "outputId": "b4b34180-e703-48e9-f726-07d1deabf35e",
        "id": "eCHKN3NOABfh",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "cdc_idx_dict = {}\n",
        "cdc_idx_sent = {}\n",
        "cdc_idx_art = {}\n",
        "\n",
        "for i,claim in enumerate(ref_data['clean_Claim']):\n",
        "    check_complete = False\n",
        "    while check_complete == False:\n",
        "        for idx,sentence in enumerate(ndf['text']):\n",
        "            test = claim.lower() in sentence.lower()\n",
        "            if test:\n",
        "                article = ref_data['Article'][i]\n",
        "                cdc_idx_dict[idx] = claim\n",
        "                cdc_idx_sent[idx] = [claim, sentence]\n",
        "                cdc_idx_art[idx] = [claim, article]\n",
        "                check_complete = True\n",
        "            elif idx == (len(ndf['text'])-1):\n",
        "                check_complete = True\n",
        "\n",
        "len(cdc_idx_dict), ref_data.shape[0]"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(4, 1332)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 997
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "outputId": "82773f8f-da08-4e10-8a17-e83736c3085e",
        "id": "y6ysxEnnABfi",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "cdc_idx_dict"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{17: 'the monarchy had worked well',\n",
              " 56: 'the monarchy is an outdated and regressive institution',\n",
              " 64: 'royals were simply celebrities who should not have any formal role',\n",
              " 76: 'constitutional monarchy was outdated'}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 998
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "SCDTkckCABfi",
        "colab": {}
      },
      "source": [
        "cdc = []\n",
        "\n",
        "for x in range(len(ndf)):\n",
        "    if x in list(cdc_idx_dict.keys()):\n",
        "        cdc.append(cdc_idx_dict.get(x))\n",
        "    else:\n",
        "        cdc.append('---')\n",
        "ndf['cdc'] = cdc\n",
        "\n",
        "df = pd.concat([ndf, df], axis=0, ignore_index=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "PpIwA0tXABfj"
      },
      "source": [
        "#### Article 9"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "JCxunUIDABfj",
        "colab": {}
      },
      "source": [
        "with open(articles_dict[articles[9].replace(' ','_')+'.txt']) as article:\n",
        "        doc = article.read()\n",
        "\n",
        "c_doc = text_cleaner(doc)\n",
        "sentences = nltk.sent_tokenize(c_doc)\n",
        "sentences = [[sent, topic, articles[9]] for sent in sentences]\n",
        "\n",
        "ndf = pd.DataFrame(sentences, columns=['text', 'topic', 'article'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "outputId": "0f37f681-bc16-424b-ca41-7ea856934324",
        "id": "_CRZY12zABfk",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "cdc_idx_dict = {}\n",
        "cdc_idx_sent = {}\n",
        "cdc_idx_art = {}\n",
        "\n",
        "for i,claim in enumerate(ref_data['clean_Claim']):\n",
        "    check_complete = False\n",
        "    while check_complete == False:\n",
        "        for idx,sentence in enumerate(ndf['text']):\n",
        "            test = claim.lower() in sentence.lower()\n",
        "            if test:\n",
        "                article = ref_data['Article'][i]\n",
        "                cdc_idx_dict[idx] = claim\n",
        "                cdc_idx_sent[idx] = [claim, sentence]\n",
        "                cdc_idx_art[idx] = [claim, article]\n",
        "                check_complete = True\n",
        "            elif idx == (len(ndf['text'])-1):\n",
        "                check_complete = True\n",
        "\n",
        "len(cdc_idx_dict), ref_data.shape[0]"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(4, 1332)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 1001
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "outputId": "15d2fcf6-02e9-4e83-d761-ce33b6dbe76b",
        "id": "1aJf0sBXABfl",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "cdc_idx_dict"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{3: 'monarch may have strictly ceremonial duties',\n",
              " 33: 'serves the traditional role of embodying and representing the nation',\n",
              " 53: 'a source of checks and balances against elected politicians who might seek powers in excess of those conferred by their respective constitutions',\n",
              " 63: 'a check against possible illegal action by politicians'}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 1002
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "Yz0_lWjBABfm",
        "colab": {}
      },
      "source": [
        "cdc = []\n",
        "\n",
        "for x in range(len(ndf)):\n",
        "    if x in list(cdc_idx_dict.keys()):\n",
        "        cdc.append(cdc_idx_dict.get(x))\n",
        "    else:\n",
        "        cdc.append('---')\n",
        "ndf['cdc'] = cdc\n",
        "\n",
        "df = pd.concat([ndf, df], axis=0, ignore_index=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "ies-9GU5ABfm"
      },
      "source": [
        "#### Article 10"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "VKw5phvWABfn",
        "colab": {}
      },
      "source": [
        "with open(articles_dict[articles[10].replace(' ','_')+'.txt']) as article:\n",
        "        doc = article.read()\n",
        "\n",
        "c_doc = text_cleaner(doc)\n",
        "sentences = nltk.sent_tokenize(c_doc)\n",
        "sentences = [[sent, topic, articles[10]] for sent in sentences]\n",
        "\n",
        "ndf = pd.DataFrame(sentences, columns=['text', 'topic', 'article'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "outputId": "0720084c-b121-4ae6-8a8f-709d4b0770a6",
        "id": "zOKC1oqZABfn",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "cdc_idx_dict = {}\n",
        "cdc_idx_sent = {}\n",
        "cdc_idx_art = {}\n",
        "\n",
        "for i,claim in enumerate(ref_data['clean_Claim']):\n",
        "    check_complete = False\n",
        "    while check_complete == False:\n",
        "        for idx,sentence in enumerate(ndf['text']):\n",
        "            test = claim.lower() in sentence.lower()\n",
        "            if test:\n",
        "                article = ref_data['Article'][i]\n",
        "                cdc_idx_dict[idx] = claim\n",
        "                cdc_idx_sent[idx] = [claim, sentence]\n",
        "                cdc_idx_art[idx] = [claim, article]\n",
        "                check_complete = True\n",
        "            elif idx == (len(ndf['text'])-1):\n",
        "                check_complete = True\n",
        "\n",
        "len(cdc_idx_dict), ref_data.shape[0]"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(25, 1332)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 1005
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "outputId": "9baec7bd-e58d-4815-ef5f-a01bd9b4a630",
        "id": "SokZikgrABfo",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "cdc_idx_dict"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{68: 'republicanism is the next logical step toward a fully democratic constitution',\n",
              " 72: 'monarchy is unfair and elitist',\n",
              " 73: 'in a modern and democratic society no one should be expected to defer to another simply because of his birth',\n",
              " 74: 'it encourages attitudes which are more suited to a bygone age of imperialism',\n",
              " 75: 'encourages a feeling of dependency in many people who should instead have confidence in themselves and their fellow citizens',\n",
              " 76: \"the people', not the members of one family, should be sovereign\",\n",
              " 77: 'it should be a fundamental right of the people of any nation to elect their head of state and for every citizen to be eligible to hold that office',\n",
              " 79: 'Monarchical prerogative powers can be used to circumvent normal democratic process with no accountability',\n",
              " 80: 'Monarchy is ethnic-discrimination',\n",
              " 85: 'Monarchy is gender-discriminative',\n",
              " 88: 'A monarchy demands deference',\n",
              " 89: 'It is the enemy of merit and aspiration',\n",
              " 92: 'It devalues intellect and achievement',\n",
              " 96: 'a hereditary system condemns each heir to the throne to an abnormal childhood',\n",
              " 100: 'monarchs are not impartial',\n",
              " 101: 'monarchs are not accountable',\n",
              " 104: 'monarchy is expensive',\n",
              " 111: 'it is archaic',\n",
              " 115: 'Provides a safeguard against government instability',\n",
              " 117: 'Safeguards the constitutional rights of the individual',\n",
              " 122: 'can act as an effective intermediary between various levels of government and political parties',\n",
              " 123: 'the Crown is a guarantor against the misuse of constitutional power by politicians',\n",
              " 126: 'can provide a focus for national unity',\n",
              " 127: 'having a long serving monarch would increase the sense of duty and continued stability of a nation',\n",
              " 131: 'monarchy is an impetus for significantly greater national income from tourism'}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 1006
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "EgPEBOJEABfp",
        "colab": {}
      },
      "source": [
        "cdc = []\n",
        "\n",
        "for x in range(len(ndf)):\n",
        "    if x in list(cdc_idx_dict.keys()):\n",
        "        cdc.append(cdc_idx_dict.get(x))\n",
        "    else:\n",
        "        cdc.append('---')\n",
        "ndf['cdc'] = cdc\n",
        "\n",
        "df = pd.concat([ndf, df], axis=0, ignore_index=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "xmwxNXC4ABfq"
      },
      "source": [
        "#### Article 11 "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "uhtPpMDYABfq",
        "colab": {}
      },
      "source": [
        "with open(articles_dict[articles[11].replace(' ','_')+'.txt']) as article:\n",
        "        doc = article.read()\n",
        "\n",
        "c_doc = text_cleaner(doc)\n",
        "sentences = nltk.sent_tokenize(c_doc)\n",
        "sentences = [[sent, topic, articles[11]] for sent in sentences]\n",
        "\n",
        "ndf = pd.DataFrame(sentences, columns=['text', 'topic', 'article'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "outputId": "164642ad-c235-4286-ccb5-25e57407eb09",
        "id": "Me4fVmZfABfr",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "cdc_idx_dict = {}\n",
        "cdc_idx_sent = {}\n",
        "cdc_idx_art = {}\n",
        "\n",
        "for i,claim in enumerate(ref_data['clean_Claim']):\n",
        "    check_complete = False\n",
        "    while check_complete == False:\n",
        "        for idx,sentence in enumerate(ndf['text']):\n",
        "            test = claim.lower() in sentence.lower()\n",
        "            if test:\n",
        "                article = ref_data['Article'][i]\n",
        "                cdc_idx_dict[idx] = claim\n",
        "                cdc_idx_sent[idx] = [claim, sentence]\n",
        "                cdc_idx_art[idx] = [claim, article]\n",
        "                check_complete = True\n",
        "            elif idx == (len(ndf['text'])-1):\n",
        "                check_complete = True\n",
        "\n",
        "len(cdc_idx_dict), ref_data.shape[0]"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(1, 1332)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 1009
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "outputId": "cef82421-7243-4d35-af9f-fd0846a4b80d",
        "id": "pu6z7r6BABfr",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "cdc_idx_dict"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{28: 'it strengthens popular liberty'}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 1010
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "gSp2FOLjABfs",
        "colab": {}
      },
      "source": [
        "cdc = []\n",
        "\n",
        "for x in range(len(ndf)):\n",
        "    if x in list(cdc_idx_dict.keys()):\n",
        "        cdc.append(cdc_idx_dict.get(x))\n",
        "    else:\n",
        "        cdc.append('---')\n",
        "ndf['cdc'] = cdc\n",
        "\n",
        "df = pd.concat([ndf, df], axis=0, ignore_index=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yGAeeT1zzoYO",
        "colab_type": "text"
      },
      "source": [
        "### 'the one child policy of the republic of China '"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "outputId": "b87077de-5b1d-4a6f-af5d-6e7d60bccb01",
        "id": "w8ZN7A2I1rGh",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "topic = 'the one child policy of the republic of China '\n",
        "\n",
        "articles = topic_article_dict[topic]\n",
        "articles"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['Family planning',\n",
              " 'Voluntary Human Extinction Movement',\n",
              " 'Little Emperor Syndrome',\n",
              " 'Reproductive rights',\n",
              " \"Human rights in the People's Republic of China\",\n",
              " 'Only child',\n",
              " 'Sex selection',\n",
              " 'One-child policy',\n",
              " 'Two-child policy',\n",
              " 'Overpopulation',\n",
              " 'Demographics of China',\n",
              " 'Human population control',\n",
              " 'Compulsory sterilization']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 1012
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IkLiQuzu1q2f",
        "colab_type": "code",
        "outputId": "dedf3284-76a4-4edc-ff55-0e7a3915e820",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "len(articles)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "13"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 1013
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "evLpqlXO1rGi"
      },
      "source": [
        "#### Article 0 "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "6Vrl4dwY1rGi",
        "colab": {}
      },
      "source": [
        "with open(articles_dict[articles[0].replace(' ','_')+'.txt']) as article:\n",
        "        doc = article.read()\n",
        "\n",
        "c_doc = text_cleaner(doc)\n",
        "sentences = nltk.sent_tokenize(c_doc)\n",
        "sentences = [[sent, topic, articles[0]] for sent in sentences]\n",
        "\n",
        "ndf = pd.DataFrame(sentences, columns=['text', 'topic', 'article'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "outputId": "7f138166-baf5-45a0-b96d-5c8ff4348750",
        "id": "Tz3pqe3e1rGj",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "cdc_idx_dict = {}\n",
        "cdc_idx_sent = {}\n",
        "cdc_idx_art = {}\n",
        "\n",
        "for i,claim in enumerate(ref_data['clean_Claim']):\n",
        "    check_complete = False\n",
        "    while check_complete == False:\n",
        "        for idx,sentence in enumerate(ndf['text']):\n",
        "            test = claim.lower() in sentence.lower()\n",
        "            if test:\n",
        "                article = ref_data['Article'][i]\n",
        "                cdc_idx_dict[idx] = claim\n",
        "                cdc_idx_sent[idx] = [claim, sentence]\n",
        "                cdc_idx_art[idx] = [claim, article]\n",
        "                check_complete = True\n",
        "            elif idx == (len(ndf['text'])-1):\n",
        "                check_complete = True\n",
        "\n",
        "len(cdc_idx_dict), ref_data.shape[0]"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(3, 1332)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 1015
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "outputId": "4a924a1b-5734-4e32-8a99-de98f4273704",
        "id": "CZngofTu1rGj",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "cdc_idx_dict"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{46: 'a continuation of the rapid population growth that had been occurring would hinder their development as a nation',\n",
              " 52: 'the policy has created abuse for women in China',\n",
              " 53: 'implementation of the policy has involved forced abortions and forced sterilization'}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 1016
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "0pqSHz3y1rGk",
        "colab": {}
      },
      "source": [
        "cdc = []\n",
        "\n",
        "for x in range(len(ndf)):\n",
        "    if x in list(cdc_idx_dict.keys()):\n",
        "        cdc.append(cdc_idx_dict.get(x))\n",
        "    else:\n",
        "        cdc.append('---')\n",
        "ndf['cdc'] = cdc\n",
        "\n",
        "df = pd.concat([ndf, df], axis=0, ignore_index=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "GHWdiwfS1rGl"
      },
      "source": [
        "#### Article 1 "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "-Oq92hdj1rGl",
        "colab": {}
      },
      "source": [
        "with open(articles_dict[articles[1].replace(' ','_')+'.txt']) as article:\n",
        "        doc = article.read()\n",
        "\n",
        "c_doc = text_cleaner(doc)\n",
        "sentences = nltk.sent_tokenize(c_doc)\n",
        "sentences = [[sent, topic, articles[1]] for sent in sentences]\n",
        "\n",
        "ndf = pd.DataFrame(sentences, columns=['text', 'topic', 'article'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "outputId": "269236c4-1e85-4ff7-be3c-bad82f82d271",
        "id": "dKfGif2T1rGl",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "cdc_idx_dict = {}\n",
        "cdc_idx_sent = {}\n",
        "cdc_idx_art = {}\n",
        "\n",
        "for i,claim in enumerate(ref_data['clean_Claim']):\n",
        "    check_complete = False\n",
        "    while check_complete == False:\n",
        "        for idx,sentence in enumerate(ndf['text']):\n",
        "            test = claim.lower() in sentence.lower()\n",
        "            if test:\n",
        "                article = ref_data['Article'][i]\n",
        "                cdc_idx_dict[idx] = claim\n",
        "                cdc_idx_sent[idx] = [claim, sentence]\n",
        "                cdc_idx_art[idx] = [claim, article]\n",
        "                check_complete = True\n",
        "            elif idx == (len(ndf['text'])-1):\n",
        "                check_complete = True\n",
        "\n",
        "len(cdc_idx_dict), ref_data.shape[0]"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(1, 1332)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 1019
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "outputId": "d7885c9d-841d-4abc-ebff-fb180968d6c5",
        "id": "M_XjPxYN1rGm",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "cdc_idx_dict"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{3: 'a decrease in the human population would prevent a significant amount of man-made human suffering'}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 1020
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "mdHlX1_E1rGn",
        "colab": {}
      },
      "source": [
        "cdc = []\n",
        "\n",
        "for x in range(len(ndf)):\n",
        "    if x in list(cdc_idx_dict.keys()):\n",
        "        cdc.append(cdc_idx_dict.get(x))\n",
        "    else:\n",
        "        cdc.append('---')\n",
        "ndf['cdc'] = cdc\n",
        "\n",
        "df = pd.concat([df, ndf], axis=0, ignore_index=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "DPRzWQMw1rGn"
      },
      "source": [
        "#### Article 2 "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "OIksDvGZ1rGo",
        "colab": {}
      },
      "source": [
        "with open(articles_dict[articles[2].replace(' ','_')+'.txt']) as article:\n",
        "        doc = article.read()\n",
        "\n",
        "c_doc = text_cleaner(doc)\n",
        "sentences = nltk.sent_tokenize(c_doc)\n",
        "sentences = [[sent, topic, articles[2]] for sent in sentences]\n",
        "\n",
        "ndf = pd.DataFrame(sentences, columns=['text', 'topic', 'article'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "outputId": "37e0ad4e-8251-464d-ffdc-35222115c0bf",
        "id": "33hXFNCR1rGo",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "cdc_idx_dict = {}\n",
        "cdc_idx_sent = {}\n",
        "cdc_idx_art = {}\n",
        "\n",
        "for i,claim in enumerate(ref_data['clean_Claim']):\n",
        "    check_complete = False\n",
        "    while check_complete == False:\n",
        "        for idx,sentence in enumerate(ndf['text']):\n",
        "            test = claim.lower() in sentence.lower()\n",
        "            if test:\n",
        "                article = ref_data['Article'][i]\n",
        "                cdc_idx_dict[idx] = claim\n",
        "                cdc_idx_sent[idx] = [claim, sentence]\n",
        "                cdc_idx_art[idx] = [claim, article]\n",
        "                check_complete = True\n",
        "            elif idx == (len(ndf['text'])-1):\n",
        "                check_complete = True\n",
        "\n",
        "len(cdc_idx_dict), ref_data.shape[0]"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(1, 1332)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 1023
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "outputId": "21b31d7d-e895-4124-8f00-cef357da40ad",
        "id": "OoOEMe3G1rGp",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "cdc_idx_dict"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{16: 'this four-two-one reconfiguration of the familial structure has distinct ramifications for Chinese society'}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 1024
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "W7G4Jkad1rGq",
        "colab": {}
      },
      "source": [
        "cdc = []\n",
        "\n",
        "for x in range(len(ndf)):\n",
        "    if x in list(cdc_idx_dict.keys()):\n",
        "        cdc.append(cdc_idx_dict.get(x))\n",
        "    else:\n",
        "        cdc.append('---')\n",
        "ndf['cdc'] = cdc\n",
        "\n",
        "df = pd.concat([ndf, df], axis=0, ignore_index=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "y0rx3xot1rGr"
      },
      "source": [
        "#### Article 3 "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "sbjm66gD1rGr",
        "colab": {}
      },
      "source": [
        "with open(articles_dict[articles[3].replace(' ','_')+'.txt']) as article:\n",
        "        doc = article.read()\n",
        "\n",
        "c_doc = text_cleaner(doc)\n",
        "sentences = nltk.sent_tokenize(c_doc)\n",
        "sentences = [[sent, topic, articles[3]] for sent in sentences]\n",
        "\n",
        "ndf = pd.DataFrame(sentences, columns=['text', 'topic', 'article'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "outputId": "307c0f56-5f63-48e3-c0f7-f45cb8ec398c",
        "id": "_gVz8IvY1rGs",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "cdc_idx_dict = {}\n",
        "cdc_idx_sent = {}\n",
        "cdc_idx_art = {}\n",
        "\n",
        "for i,claim in enumerate(ref_data['clean_Claim']):\n",
        "    check_complete = False\n",
        "    while check_complete == False:\n",
        "        for idx,sentence in enumerate(ndf['text']):\n",
        "            test = claim.lower() in sentence.lower()\n",
        "            if test:\n",
        "                article = ref_data['Article'][i]\n",
        "                cdc_idx_dict[idx] = claim\n",
        "                cdc_idx_sent[idx] = [claim, sentence]\n",
        "                cdc_idx_art[idx] = [claim, article]\n",
        "                check_complete = True\n",
        "            elif idx == (len(ndf['text'])-1):\n",
        "                check_complete = True\n",
        "\n",
        "len(cdc_idx_dict), ref_data.shape[0]"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(8, 1332)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 1027
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "outputId": "e5fb97df-2f7c-4bc5-9546-323be8abeebb",
        "id": "IbIwor111rGs",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "cdc_idx_dict"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{7: 'Parents have a basic human right to determine freely and responsibly the number and the spacing of their children',\n",
              " 14: 'Parents have a basic right to decide freely and responsibly on the number and spacing of their children',\n",
              " 16: 'Parents have the exclusive right to determine freely and responsibly the number and spacing of their children',\n",
              " 19: \"governments have a responsibility to meet individuals' reproductive needs\",\n",
              " 31: 'The human rights of women include their right to have control over and decide freely and responsibly on matters related to their sexuality',\n",
              " 54: 'Control over reproduction is a basic need and a basic right for all women',\n",
              " 58: 'Programs that do not take the interests of women into account are unlikely to succeed',\n",
              " 106: \"the policies' narrow focus led to coercion and decreased quality of care\"}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 1028
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "BNk3ZN9a1rGt",
        "colab": {}
      },
      "source": [
        "cdc = []\n",
        "\n",
        "for x in range(len(ndf)):\n",
        "    if x in list(cdc_idx_dict.keys()):\n",
        "        cdc.append(cdc_idx_dict.get(x))\n",
        "    else:\n",
        "        cdc.append('---')\n",
        "ndf['cdc'] = cdc\n",
        "\n",
        "df = pd.concat([ndf, df], axis=0, ignore_index=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "h07b996E1rGu"
      },
      "source": [
        "#### Article 4 "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "mAvUdMQj1rGu",
        "colab": {}
      },
      "source": [
        "with open(articles_dict[articles[4].replace(' ','_')+'.txt']) as article:\n",
        "        doc = article.read()\n",
        "\n",
        "c_doc = text_cleaner(doc)\n",
        "sentences = nltk.sent_tokenize(c_doc)\n",
        "sentences = [[sent, topic, articles[4]] for sent in sentences]\n",
        "\n",
        "ndf = pd.DataFrame(sentences, columns=['text', 'topic', 'article'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "outputId": "86f8ebd3-ed37-4e90-c4a8-aad08496555a",
        "id": "SWlmBvrc1rGv",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "cdc_idx_dict = {}\n",
        "cdc_idx_sent = {}\n",
        "cdc_idx_art = {}\n",
        "\n",
        "for i,claim in enumerate(ref_data['clean_Claim']):\n",
        "    check_complete = False\n",
        "    while check_complete == False:\n",
        "        for idx,sentence in enumerate(ndf['text']):\n",
        "            test = claim.lower() in sentence.lower()\n",
        "            if test:\n",
        "                article = ref_data['Article'][i]\n",
        "                cdc_idx_dict[idx] = claim\n",
        "                cdc_idx_sent[idx] = [claim, sentence]\n",
        "                cdc_idx_art[idx] = [claim, article]\n",
        "                check_complete = True\n",
        "            elif idx == (len(ndf['text'])-1):\n",
        "                check_complete = True\n",
        "\n",
        "len(cdc_idx_dict), ref_data.shape[0]"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(3, 1332)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 1031
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "outputId": "6e6b99b3-c10d-4069-e6d2-8edaa82d6e7f",
        "id": "t_VwHCWw1rGw",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "cdc_idx_dict"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{119: 'it contributes to forced abortions',\n",
              " 120: 'This is thought to have been a significant contribution to the gender imbalance in mainland China',\n",
              " 122: 'the dramatic decrease in Chinese fertility started before the program began in for unrelated factors'}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 1032
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "0uV5kK0k1rGw",
        "colab": {}
      },
      "source": [
        "cdc = []\n",
        "\n",
        "for x in range(len(ndf)):\n",
        "    if x in list(cdc_idx_dict.keys()):\n",
        "        cdc.append(cdc_idx_dict.get(x))\n",
        "    else:\n",
        "        cdc.append('---')\n",
        "ndf['cdc'] = cdc\n",
        "\n",
        "df = pd.concat([ndf, df], axis=0, ignore_index=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "G15LWMwfAP16"
      },
      "source": [
        "#### Article 5 "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "oNbRD75JAP18",
        "colab": {}
      },
      "source": [
        "with open(articles_dict[articles[5].replace(' ','_')+'.txt']) as article:\n",
        "        doc = article.read()\n",
        "\n",
        "c_doc = text_cleaner(doc)\n",
        "sentences = nltk.sent_tokenize(c_doc)\n",
        "sentences = [[sent, topic, articles[5]] for sent in sentences]\n",
        "\n",
        "ndf = pd.DataFrame(sentences, columns=['text', 'topic', 'article'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "outputId": "bbd9f782-356d-4d91-ce5a-d27ccc8b1df3",
        "id": "dzHeQPX3AP19",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "cdc_idx_dict = {}\n",
        "cdc_idx_sent = {}\n",
        "cdc_idx_art = {}\n",
        "\n",
        "for i,claim in enumerate(ref_data['clean_Claim']):\n",
        "    check_complete = False\n",
        "    while check_complete == False:\n",
        "        for idx,sentence in enumerate(ndf['text']):\n",
        "            test = claim.lower() in sentence.lower()\n",
        "            if test:\n",
        "                article = ref_data['Article'][i]\n",
        "                cdc_idx_dict[idx] = claim\n",
        "                cdc_idx_sent[idx] = [claim, sentence]\n",
        "                cdc_idx_art[idx] = [claim, article]\n",
        "                check_complete = True\n",
        "            elif idx == (len(ndf['text'])-1):\n",
        "                check_complete = True\n",
        "\n",
        "len(cdc_idx_dict), ref_data.shape[0]"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(8, 1332)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 1035
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "outputId": "171390dd-5a29-4320-b210-4c6fcd72f155",
        "id": "qSYtGRMGAP1_",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "cdc_idx_dict"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{15: 'only children are spoiled',\n",
              " 17: 'only children have aversive social skills',\n",
              " 19: 'the lack of siblings has been blamed for a number of social ills',\n",
              " 21: 'The one child policy has also been speculated to be the underlying cause of forced abortions',\n",
              " 23: 'it is more difficult for only children to cooperate in a conventional family environment',\n",
              " 31: 'only children are higher in achievement motivation',\n",
              " 36: 'children with many siblings receive fewer resources',\n",
              " 40: 'Only children are also more likely to make outside friends'}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 1036
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "bh3b2VxDAP2A",
        "colab": {}
      },
      "source": [
        "cdc = []\n",
        "\n",
        "for x in range(len(ndf)):\n",
        "    if x in list(cdc_idx_dict.keys()):\n",
        "        cdc.append(cdc_idx_dict.get(x))\n",
        "    else:\n",
        "        cdc.append('---')\n",
        "ndf['cdc'] = cdc\n",
        "\n",
        "df = pd.concat([ndf, df], axis=0, ignore_index=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "r-uK--1KAP2B"
      },
      "source": [
        "#### Article 6"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "3T1zGpfYAP2C",
        "colab": {}
      },
      "source": [
        "with open(articles_dict[articles[6].replace(' ','_')+'.txt']) as article:\n",
        "        doc = article.read()\n",
        "\n",
        "c_doc = text_cleaner(doc)\n",
        "sentences = nltk.sent_tokenize(c_doc)\n",
        "sentences = [[sent, topic, articles[6]] for sent in sentences]\n",
        "\n",
        "ndf = pd.DataFrame(sentences, columns=['text', 'topic', 'article'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "outputId": "8174399a-14fa-4b89-cd00-aa68ce778cd9",
        "id": "0s3ayij7AP2D",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "cdc_idx_dict = {}\n",
        "cdc_idx_sent = {}\n",
        "cdc_idx_art = {}\n",
        "\n",
        "for i,claim in enumerate(ref_data['clean_Claim']):\n",
        "    check_complete = False\n",
        "    while check_complete == False:\n",
        "        for idx,sentence in enumerate(ndf['text']):\n",
        "            test = claim.lower() in sentence.lower()\n",
        "            if test:\n",
        "                article = ref_data['Article'][i]\n",
        "                cdc_idx_dict[idx] = claim\n",
        "                cdc_idx_sent[idx] = [claim, sentence]\n",
        "                cdc_idx_art[idx] = [claim, article]\n",
        "                check_complete = True\n",
        "            elif idx == (len(ndf['text'])-1):\n",
        "                check_complete = True\n",
        "\n",
        "len(cdc_idx_dict), ref_data.shape[0]"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(4, 1332)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 1039
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "outputId": "6629ca17-4728-4231-981e-47e1df922d33",
        "id": "AD7WYqUkAP2F",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "cdc_idx_dict"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{52: 'sex selection is an expression of reproductive rights',\n",
              " 61: \"China's gender imbalance is further increased by the One Child Policy\",\n",
              " 62: 'a lack of opportunity for many men to marry is believed to be producing increases in crime',\n",
              " 68: 'if female babies worth their weight in rupees and yuan, economic and educational opportunities for girls would soon follow'}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 1040
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "VjEEO34sAP2G",
        "colab": {}
      },
      "source": [
        "cdc = []\n",
        "\n",
        "for x in range(len(ndf)):\n",
        "    if x in list(cdc_idx_dict.keys()):\n",
        "        cdc.append(cdc_idx_dict.get(x))\n",
        "    else:\n",
        "        cdc.append('---')\n",
        "ndf['cdc'] = cdc\n",
        "\n",
        "df = pd.concat([ndf, df], axis=0, ignore_index=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "1IBLMlncAP2I"
      },
      "source": [
        "#### Article 7"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "bguOdQ3fAP2I",
        "colab": {}
      },
      "source": [
        "with open(articles_dict[articles[7].replace(' ','_')+'.txt']) as article:\n",
        "        doc = article.read()\n",
        "\n",
        "c_doc = text_cleaner(doc)\n",
        "sentences = nltk.sent_tokenize(c_doc)\n",
        "sentences = [[sent, topic, articles[7]] for sent in sentences]\n",
        "\n",
        "ndf = pd.DataFrame(sentences, columns=['text', 'topic', 'article'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "outputId": "30120238-b902-4750-a9d4-cd79b079d473",
        "id": "N3RwBquVAP2K",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "cdc_idx_dict = {}\n",
        "cdc_idx_sent = {}\n",
        "cdc_idx_art = {}\n",
        "\n",
        "for i,claim in enumerate(ref_data['clean_Claim']):\n",
        "    check_complete = False\n",
        "    while check_complete == False:\n",
        "        for idx,sentence in enumerate(ndf['text']):\n",
        "            test = claim.lower() in sentence.lower()\n",
        "            if test:\n",
        "                article = ref_data['Article'][i]\n",
        "                cdc_idx_dict[idx] = claim\n",
        "                cdc_idx_sent[idx] = [claim, sentence]\n",
        "                cdc_idx_art[idx] = [claim, article]\n",
        "                check_complete = True\n",
        "            elif idx == (len(ndf['text'])-1):\n",
        "                check_complete = True\n",
        "\n",
        "len(cdc_idx_dict), ref_data.shape[0]"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(17, 1332)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 1043
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "outputId": "39ad424b-8cdf-4071-862e-0ffa3d5cbe18",
        "id": "PGHvO_CCAP2L",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "cdc_idx_dict"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{8: 'The policy is controversial both within and outside China because of the manner in which the policy has been implemented, and because of concerns about negative social consequences',\n",
              " 9: \"possible cause behind China's gender imbalance\",\n",
              " 55: 'it had proved \"remarkably effective',\n",
              " 62: \"great success in helping to implement China's current economic growth\",\n",
              " 63: 'The reduction in the fertility rate and thus population growth has reduced the severity of problems that come with overpopulation',\n",
              " 65: 'the focus of China on population control helps provide a better health service for women',\n",
              " 67: 'The individual savings rate has increased since the one-child policy was introduced',\n",
              " 72: 'less intrusive options, including those that emphasized delay and spacing of births, could have achieved the same results over an extended period of time',\n",
              " 83: 'China could have expected a continued reduction in its fertility rate just from continued economic development, had it kept to the previous policy',\n",
              " 84: \"The one-child policy is challenged in principle and in practice for violating a human right to determine the size of one's own family\",\n",
              " 97: 'leaves the older generations with increased chances of dependency on retirement funds or charity in order to receive support',\n",
              " 99: 'If, for any reason, the single child is unable to care for their older adult relatives, the oldest generations would face a lack of resources and necessities',\n",
              " 102: 'Some parents may over-indulge their only child',\n",
              " 108: 'social problems and personality disorders in young people',\n",
              " 160: 'Only if equality of males and females is strongly promoted.. will the harmonious and sustainable development of society be possible',\n",
              " 161: 'The social pressure exerted by the one-child policy has affected the rate at which parents abandon undesirable children',\n",
              " 176: \"China's family planning programs contribute to infanticide\"}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 1044
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "bZho0E5yAP2N",
        "colab": {}
      },
      "source": [
        "cdc = []\n",
        "\n",
        "for x in range(len(ndf)):\n",
        "    if x in list(cdc_idx_dict.keys()):\n",
        "        cdc.append(cdc_idx_dict.get(x))\n",
        "    else:\n",
        "        cdc.append('---')\n",
        "ndf['cdc'] = cdc\n",
        "\n",
        "df = pd.concat([ndf, df], axis=0, ignore_index=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "pa5by1pRAP2O"
      },
      "source": [
        "#### Article 8"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "ZCLLxUi8AP2P",
        "colab": {}
      },
      "source": [
        "with open(articles_dict[articles[8].replace(' ','_')+'.txt']) as article:\n",
        "        doc = article.read()\n",
        "\n",
        "c_doc = text_cleaner(doc)\n",
        "sentences = nltk.sent_tokenize(c_doc)\n",
        "sentences = [[sent, topic, articles[8]] for sent in sentences]\n",
        "\n",
        "ndf = pd.DataFrame(sentences, columns=['text', 'topic', 'article'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "outputId": "0f93706b-cc2c-465e-c81c-f263df029bd9",
        "id": "iF9n4M42AP2Q",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "cdc_idx_dict = {}\n",
        "cdc_idx_sent = {}\n",
        "cdc_idx_art = {}\n",
        "\n",
        "for i,claim in enumerate(ref_data['clean_Claim']):\n",
        "    check_complete = False\n",
        "    while check_complete == False:\n",
        "        for idx,sentence in enumerate(ndf['text']):\n",
        "            test = claim.lower() in sentence.lower()\n",
        "            if test:\n",
        "                article = ref_data['Article'][i]\n",
        "                cdc_idx_dict[idx] = claim\n",
        "                cdc_idx_sent[idx] = [claim, sentence]\n",
        "                cdc_idx_art[idx] = [claim, article]\n",
        "                check_complete = True\n",
        "            elif idx == (len(ndf['text'])-1):\n",
        "                check_complete = True\n",
        "\n",
        "len(cdc_idx_dict), ref_data.shape[0]"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(1, 1332)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 1047
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "outputId": "1a627bb7-ca92-4b94-b979-4796049be091",
        "id": "I8Bu5IwXAP2R",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "cdc_idx_dict"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{7: 'a single child would be left with having to provide support for his or her two parents and four grandparents'}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 1048
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "fJFp9qJAAP2T",
        "colab": {}
      },
      "source": [
        "cdc = []\n",
        "\n",
        "for x in range(len(ndf)):\n",
        "    if x in list(cdc_idx_dict.keys()):\n",
        "        cdc.append(cdc_idx_dict.get(x))\n",
        "    else:\n",
        "        cdc.append('---')\n",
        "ndf['cdc'] = cdc\n",
        "\n",
        "df = pd.concat([ndf, df], axis=0, ignore_index=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "Kgt5Xp3aAP2U"
      },
      "source": [
        "#### Article 9"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "eqaPHAWMAP2U",
        "colab": {}
      },
      "source": [
        "with open(articles_dict[articles[9].replace(' ','_')+'.txt']) as article:\n",
        "        doc = article.read()\n",
        "\n",
        "c_doc = text_cleaner(doc)\n",
        "sentences = nltk.sent_tokenize(c_doc)\n",
        "sentences = [[sent, topic, articles[9]] for sent in sentences]\n",
        "\n",
        "ndf = pd.DataFrame(sentences, columns=['text', 'topic', 'article'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "outputId": "0c23b292-6a32-4002-fad8-7cd807401bd9",
        "id": "hmmGViohAP2V",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "cdc_idx_dict = {}\n",
        "cdc_idx_sent = {}\n",
        "cdc_idx_art = {}\n",
        "\n",
        "for i,claim in enumerate(ref_data['clean_Claim']):\n",
        "    check_complete = False\n",
        "    while check_complete == False:\n",
        "        for idx,sentence in enumerate(ndf['text']):\n",
        "            test = claim.lower() in sentence.lower()\n",
        "            if test:\n",
        "                article = ref_data['Article'][i]\n",
        "                cdc_idx_dict[idx] = claim\n",
        "                cdc_idx_sent[idx] = [claim, sentence]\n",
        "                cdc_idx_art[idx] = [claim, article]\n",
        "                check_complete = True\n",
        "            elif idx == (len(ndf['text'])-1):\n",
        "                check_complete = True\n",
        "\n",
        "len(cdc_idx_dict), ref_data.shape[0]"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(2, 1332)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 1051
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "outputId": "9d3fcf6c-fcd4-4921-f38c-0e98a47824f7",
        "id": "o9wJ89t3AP2X",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "cdc_idx_dict"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{140: \"rapid population growth damages the Earth's resources and diminishes human well-being\",\n",
              " 367: 'overpopulation as a serious threat to the quality of human life'}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 1052
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "sNHOyKlcAP2Z",
        "colab": {}
      },
      "source": [
        "cdc = []\n",
        "\n",
        "for x in range(len(ndf)):\n",
        "    if x in list(cdc_idx_dict.keys()):\n",
        "        cdc.append(cdc_idx_dict.get(x))\n",
        "    else:\n",
        "        cdc.append('---')\n",
        "ndf['cdc'] = cdc\n",
        "\n",
        "df = pd.concat([ndf, df], axis=0, ignore_index=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "mN_vYKOhAP2p"
      },
      "source": [
        "#### Article 10"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "UZgkpnnuAP2p",
        "colab": {}
      },
      "source": [
        "with open(articles_dict[articles[10].replace(' ','_')+'.txt']) as article:\n",
        "        doc = article.read()\n",
        "\n",
        "c_doc = text_cleaner(doc)\n",
        "sentences = nltk.sent_tokenize(c_doc)\n",
        "sentences = [[sent, topic, articles[10]] for sent in sentences]\n",
        "\n",
        "ndf = pd.DataFrame(sentences, columns=['text', 'topic', 'article'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "outputId": "9f1023c3-4062-4239-dd52-ee38758a5795",
        "id": "m90PmMDUAP2q",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "cdc_idx_dict = {}\n",
        "cdc_idx_sent = {}\n",
        "cdc_idx_art = {}\n",
        "\n",
        "for i,claim in enumerate(ref_data['clean_Claim']):\n",
        "    check_complete = False\n",
        "    while check_complete == False:\n",
        "        for idx,sentence in enumerate(ndf['text']):\n",
        "            test = claim.lower() in sentence.lower()\n",
        "            if test:\n",
        "                article = ref_data['Article'][i]\n",
        "                cdc_idx_dict[idx] = claim\n",
        "                cdc_idx_sent[idx] = [claim, sentence]\n",
        "                cdc_idx_art[idx] = [claim, article]\n",
        "                check_complete = True\n",
        "            elif idx == (len(ndf['text'])-1):\n",
        "                check_complete = True\n",
        "\n",
        "len(cdc_idx_dict), ref_data.shape[0]"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(5, 1332)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 1055
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "outputId": "3f77fcbb-b906-40da-9a9f-c05d8505a871",
        "id": "HOwxcsy2AP2r",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "cdc_idx_dict"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{57: 'As a result of the policy, China successfully achieved its goal of a more stable and much-reduced fertility rate',\n",
              " 90: 'rapid population growth as an obstacle to development',\n",
              " 101: 'population control was necessary for economic growth and improved living standards',\n",
              " 125: 'coercive measures used to achieve the desired results of the one-child policy',\n",
              " 134: 'Rapid fertility reduction associated with the one-child policy has potentially negative results'}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 1056
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "-0IOYXkqAP2s",
        "colab": {}
      },
      "source": [
        "cdc = []\n",
        "\n",
        "for x in range(len(ndf)):\n",
        "    if x in list(cdc_idx_dict.keys()):\n",
        "        cdc.append(cdc_idx_dict.get(x))\n",
        "    else:\n",
        "        cdc.append('---')\n",
        "ndf['cdc'] = cdc\n",
        "\n",
        "df = pd.concat([ndf, df], axis=0, ignore_index=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "NFEanRvWAP2t"
      },
      "source": [
        "#### Article 11 "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "MYEGftPOAP2u",
        "colab": {}
      },
      "source": [
        "with open(articles_dict[articles[11].replace(' ','_')+'.txt']) as article:\n",
        "        doc = article.read()\n",
        "\n",
        "c_doc = text_cleaner(doc)\n",
        "sentences = nltk.sent_tokenize(c_doc)\n",
        "sentences = [[sent, topic, articles[11]] for sent in sentences]\n",
        "\n",
        "ndf = pd.DataFrame(sentences, columns=['text', 'topic', 'article'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "outputId": "dd0b7063-7b71-4aba-fabc-9313c220d5c0",
        "id": "GEFKpKtkAP2v",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "cdc_idx_dict = {}\n",
        "cdc_idx_sent = {}\n",
        "cdc_idx_art = {}\n",
        "\n",
        "for i,claim in enumerate(ref_data['clean_Claim']):\n",
        "    check_complete = False\n",
        "    while check_complete == False:\n",
        "        for idx,sentence in enumerate(ndf['text']):\n",
        "            test = claim.lower() in sentence.lower()\n",
        "            if test:\n",
        "                article = ref_data['Article'][i]\n",
        "                cdc_idx_dict[idx] = claim\n",
        "                cdc_idx_sent[idx] = [claim, sentence]\n",
        "                cdc_idx_art[idx] = [claim, article]\n",
        "                check_complete = True\n",
        "            elif idx == (len(ndf['text'])-1):\n",
        "                check_complete = True\n",
        "\n",
        "len(cdc_idx_dict), ref_data.shape[0]"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(14, 1332)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 1059
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "outputId": "769cd451-1cf1-4546-e1e5-88758c39fa82",
        "id": "yXiClixXAP2w",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "cdc_idx_dict"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{3: \"population control can involve measures that improve people's lives\",\n",
              " 19: 'a large increase in population would bring, \"certain poverty on the citizenry',\n",
              " 21: 'excessive growth may reduce output per worker',\n",
              " 48: 'a larger population would mean more production',\n",
              " 80: 'overpopulation has been blamed for a variety of issues, including increasing poverty',\n",
              " 93: 'reduction of the population is a key to economic growth',\n",
              " 94: 'economists doubt that a correlation between population reduction and economic growth exists',\n",
              " 95: 'poverty and famine are caused by bad government and bad economic policies, not by overpopulation',\n",
              " 96: 'higher population density leads to more specialization and technological innovation, which in turn leads to a higher standard of living',\n",
              " 97: 'human beings are the ultimate resource',\n",
              " 99: 'there is no correlation between population density and poverty and starvation',\n",
              " 129: 'number of problems associated with overpopulation',\n",
              " 137: 'The success of the policy has been questioned, and reduction in fertility has also been attributed to the modernization of China',\n",
              " 138: 'The policy is controversial both within and outside of China'}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 1060
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "Q3hEctt0AP2x",
        "colab": {}
      },
      "source": [
        "cdc = []\n",
        "\n",
        "for x in range(len(ndf)):\n",
        "    if x in list(cdc_idx_dict.keys()):\n",
        "        cdc.append(cdc_idx_dict.get(x))\n",
        "    else:\n",
        "        cdc.append('---')\n",
        "ndf['cdc'] = cdc\n",
        "\n",
        "df = pd.concat([ndf, df], axis=0, ignore_index=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "LynRW547AP2y"
      },
      "source": [
        "#### Article 12"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "2o7sjHXhAP2z",
        "colab": {}
      },
      "source": [
        "with open(articles_dict[articles[12].replace(' ','_')+'.txt']) as article:\n",
        "        doc = article.read()\n",
        "\n",
        "c_doc = text_cleaner(doc)\n",
        "sentences = nltk.sent_tokenize(c_doc)\n",
        "sentences = [[sent, topic, articles[12]] for sent in sentences]\n",
        "\n",
        "ndf = pd.DataFrame(sentences, columns=['text', 'topic', 'article'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "outputId": "db91f679-071a-440a-8efc-673cd996cf96",
        "id": "s2iSXrdzAP20",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "cdc_idx_dict = {}\n",
        "cdc_idx_sent = {}\n",
        "cdc_idx_art = {}\n",
        "\n",
        "for i,claim in enumerate(ref_data['clean_Claim']):\n",
        "    check_complete = False\n",
        "    while check_complete == False:\n",
        "        for idx,sentence in enumerate(ndf['text']):\n",
        "            test = claim.lower() in sentence.lower()\n",
        "            if test:\n",
        "                article = ref_data['Article'][i]\n",
        "                cdc_idx_dict[idx] = claim\n",
        "                cdc_idx_sent[idx] = [claim, sentence]\n",
        "                cdc_idx_art[idx] = [claim, article]\n",
        "                check_complete = True\n",
        "            elif idx == (len(ndf['text'])-1):\n",
        "                check_complete = True\n",
        "\n",
        "len(cdc_idx_dict), ref_data.shape[0]"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(1, 1332)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 1063
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "outputId": "b3d996d0-010e-47fb-cbc7-03ac44fcefe0",
        "id": "xVTINaRjAP21",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "cdc_idx_dict"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{34: 'Coercive sterilization to enforce the one child policy has occurred in China'}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 1064
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "OYTv59IEAP23",
        "colab": {}
      },
      "source": [
        "cdc = []\n",
        "\n",
        "for x in range(len(ndf)):\n",
        "    if x in list(cdc_idx_dict.keys()):\n",
        "        cdc.append(cdc_idx_dict.get(x))\n",
        "    else:\n",
        "        cdc.append('---')\n",
        "ndf['cdc'] = cdc\n",
        "\n",
        "df = pd.concat([ndf, df], axis=0, ignore_index=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M8cxTkhbzsO-",
        "colab_type": "text"
      },
      "source": [
        "### 'the sale of violent video games to minors '"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "outputId": "48ccf633-7ef8-4830-f4f1-ed4e1945adb5",
        "id": "ws3SOe2b1spI",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "topic = 'the sale of violent video games to minors '\n",
        "\n",
        "articles = topic_article_dict[topic]\n",
        "articles"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['Gender representation in video games',\n",
              " 'Video game',\n",
              " 'Video game content rating system',\n",
              " 'Nonviolent video game',\n",
              " 'Violence',\n",
              " 'Console game',\n",
              " 'Grand Theft Childhood',\n",
              " 'Brown v Entertainment Merchants Association',\n",
              " 'Video game controversies',\n",
              " 'Media influence',\n",
              " 'Graphic violence',\n",
              " 'California Assembly Bills 1792 and 1793',\n",
              " 'School violence',\n",
              " 'Media violence research',\n",
              " 'Video game culture']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 1066
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GJiSPwdg1sZY",
        "colab_type": "code",
        "outputId": "1a008830-2451-425e-c588-52eb17e1aca7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "len(articles)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "15"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 1067
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "GwzIlO8g1spJ"
      },
      "source": [
        "#### Article 0 "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "CCLVgKti1spJ",
        "colab": {}
      },
      "source": [
        "with open(articles_dict[articles[0].replace(' ','_')+'.txt']) as article:\n",
        "        doc = article.read()\n",
        "\n",
        "c_doc = text_cleaner(doc)\n",
        "sentences = nltk.sent_tokenize(c_doc)\n",
        "sentences = [[sent, topic, articles[0]] for sent in sentences]\n",
        "\n",
        "ndf = pd.DataFrame(sentences, columns=['text', 'topic', 'article'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "outputId": "d32c2701-f67d-48a7-c37d-5ee45e133e0e",
        "id": "tfC_QEEJ1spK",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "cdc_idx_dict = {}\n",
        "cdc_idx_sent = {}\n",
        "cdc_idx_art = {}\n",
        "\n",
        "for i,claim in enumerate(ref_data['clean_Claim']):\n",
        "    check_complete = False\n",
        "    while check_complete == False:\n",
        "        for idx,sentence in enumerate(ndf['text']):\n",
        "            test = claim.lower() in sentence.lower()\n",
        "            if test:\n",
        "                article = ref_data['Article'][i]\n",
        "                cdc_idx_dict[idx] = claim\n",
        "                cdc_idx_sent[idx] = [claim, sentence]\n",
        "                cdc_idx_art[idx] = [claim, article]\n",
        "                check_complete = True\n",
        "            elif idx == (len(ndf['text'])-1):\n",
        "                check_complete = True\n",
        "\n",
        "len(cdc_idx_dict), ref_data.shape[0]"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(1, 1332)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 1069
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "outputId": "34d0eb3e-b880-4afd-9c49-4e777b9aa3c5",
        "id": "oAIn5h2v1spL",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "cdc_idx_dict"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{29: \"violent video games are influencing their children's view about violence\"}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 1070
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "TYAUc0Sa1spL",
        "colab": {}
      },
      "source": [
        "cdc = []\n",
        "\n",
        "for x in range(len(ndf)):\n",
        "    if x in list(cdc_idx_dict.keys()):\n",
        "        cdc.append(cdc_idx_dict.get(x))\n",
        "    else:\n",
        "        cdc.append('---')\n",
        "ndf['cdc'] = cdc\n",
        "\n",
        "df = pd.concat([ndf, df], axis=0, ignore_index=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "rE0yDOYl1spM"
      },
      "source": [
        "#### Article 1 "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "oJ5E7TRH1spM",
        "colab": {}
      },
      "source": [
        "with open(articles_dict[articles[1].replace(' ','_')+'.txt']) as article:\n",
        "        doc = article.read()\n",
        "\n",
        "c_doc = text_cleaner(doc)\n",
        "sentences = nltk.sent_tokenize(c_doc)\n",
        "sentences = [[sent, topic, articles[1]] for sent in sentences]\n",
        "\n",
        "ndf = pd.DataFrame(sentences, columns=['text', 'topic', 'article'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "outputId": "2a033eb9-87a8-4577-c4f3-8a314bc3d226",
        "id": "s5dQhOAe1spN",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "cdc_idx_dict = {}\n",
        "cdc_idx_sent = {}\n",
        "cdc_idx_art = {}\n",
        "\n",
        "for i,claim in enumerate(ref_data['clean_Claim']):\n",
        "    check_complete = False\n",
        "    while check_complete == False:\n",
        "        for idx,sentence in enumerate(ndf['text']):\n",
        "            test = claim.lower() in sentence.lower()\n",
        "            if test:\n",
        "                article = ref_data['Article'][i]\n",
        "                cdc_idx_dict[idx] = claim\n",
        "                cdc_idx_sent[idx] = [claim, sentence]\n",
        "                cdc_idx_art[idx] = [claim, article]\n",
        "                check_complete = True\n",
        "            elif idx == (len(ndf['text'])-1):\n",
        "                check_complete = True\n",
        "\n",
        "len(cdc_idx_dict), ref_data.shape[0]"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(1, 1332)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 1073
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "outputId": "14a2ff83-5a82-41b1-d79a-5fadd05f85a8",
        "id": "unr7MvlK1spN",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "cdc_idx_dict"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{183: 'Various games have been accused of causing addiction and even violent behavior'}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 1074
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "EoeecaVr1spO",
        "colab": {}
      },
      "source": [
        "cdc = []\n",
        "\n",
        "for x in range(len(ndf)):\n",
        "    if x in list(cdc_idx_dict.keys()):\n",
        "        cdc.append(cdc_idx_dict.get(x))\n",
        "    else:\n",
        "        cdc.append('---')\n",
        "ndf['cdc'] = cdc\n",
        "\n",
        "df = pd.concat([df, ndf], axis=0, ignore_index=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "TxapxnAB1spP"
      },
      "source": [
        "#### Article 2 "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "8AmhoL4D1spP",
        "colab": {}
      },
      "source": [
        "with open(articles_dict[articles[2].replace(' ','_')+'.txt']) as article:\n",
        "        doc = article.read()\n",
        "\n",
        "c_doc = text_cleaner(doc)\n",
        "sentences = nltk.sent_tokenize(c_doc)\n",
        "sentences = [[sent, topic, articles[2]] for sent in sentences]\n",
        "\n",
        "ndf = pd.DataFrame(sentences, columns=['text', 'topic', 'article'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "outputId": "9f81c800-c32d-4b2d-f8bb-f15119ff61c3",
        "id": "KO3_xOLM1spQ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "cdc_idx_dict = {}\n",
        "cdc_idx_sent = {}\n",
        "cdc_idx_art = {}\n",
        "\n",
        "for i,claim in enumerate(ref_data['clean_Claim']):\n",
        "    check_complete = False\n",
        "    while check_complete == False:\n",
        "        for idx,sentence in enumerate(ndf['text']):\n",
        "            test = claim.lower() in sentence.lower()\n",
        "            if test:\n",
        "                article = ref_data['Article'][i]\n",
        "                cdc_idx_dict[idx] = claim\n",
        "                cdc_idx_sent[idx] = [claim, sentence]\n",
        "                cdc_idx_art[idx] = [claim, article]\n",
        "                check_complete = True\n",
        "            elif idx == (len(ndf['text'])-1):\n",
        "                check_complete = True\n",
        "\n",
        "len(cdc_idx_dict), ref_data.shape[0]"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(1, 1332)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 1077
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "outputId": "dfb1faa0-317e-471c-abf1-1c9fad17ff94",
        "id": "CpF7-nZd1spQ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "cdc_idx_dict"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{41: 'numerous researchers have proposed potential positive effects of video games'}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 1078
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "tA5F_yBF1spR",
        "colab": {}
      },
      "source": [
        "cdc = []\n",
        "\n",
        "for x in range(len(ndf)):\n",
        "    if x in list(cdc_idx_dict.keys()):\n",
        "        cdc.append(cdc_idx_dict.get(x))\n",
        "    else:\n",
        "        cdc.append('---')\n",
        "ndf['cdc'] = cdc\n",
        "\n",
        "df = pd.concat([ndf, df], axis=0, ignore_index=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "gp273bjn1spS"
      },
      "source": [
        "#### Article 3 "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "Idqp-32q1spS",
        "colab": {}
      },
      "source": [
        "with open(articles_dict[articles[3].replace(' ','_')+'.txt']) as article:\n",
        "        doc = article.read()\n",
        "\n",
        "c_doc = text_cleaner(doc)\n",
        "sentences = nltk.sent_tokenize(c_doc)\n",
        "sentences = [[sent, topic, articles[3]] for sent in sentences]\n",
        "\n",
        "ndf = pd.DataFrame(sentences, columns=['text', 'topic', 'article'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "outputId": "6b40ecf8-0b72-46e8-fe88-c467e5b6c763",
        "id": "48tUzLuU1spT",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "cdc_idx_dict = {}\n",
        "cdc_idx_sent = {}\n",
        "cdc_idx_art = {}\n",
        "\n",
        "for i,claim in enumerate(ref_data['clean_Claim']):\n",
        "    check_complete = False\n",
        "    while check_complete == False:\n",
        "        for idx,sentence in enumerate(ndf['text']):\n",
        "            test = claim.lower() in sentence.lower()\n",
        "            if test:\n",
        "                article = ref_data['Article'][i]\n",
        "                cdc_idx_dict[idx] = claim\n",
        "                cdc_idx_sent[idx] = [claim, sentence]\n",
        "                cdc_idx_art[idx] = [claim, article]\n",
        "                check_complete = True\n",
        "            elif idx == (len(ndf['text'])-1):\n",
        "                check_complete = True\n",
        "\n",
        "len(cdc_idx_dict), ref_data.shape[0]"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(6, 1332)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 1081
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "outputId": "ccb289db-ccad-485d-de02-96ff313c469a",
        "id": "KzRO1aKp1spT",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "cdc_idx_dict"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{46: 'violent games cause youth violence',\n",
              " 47: 'a high degree of relationship between violent games and youth violence',\n",
              " 48: 'video game violence leads to youth violence',\n",
              " 56: 'video game content was a form of freedom of expression',\n",
              " 61: 'there is social utility in expressive and imaginative forms of entertainment, even if they contain violence',\n",
              " 213: 'there are tangible benefits to violence in action games'}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 1082
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "4vOI4FHJ1spU",
        "colab": {}
      },
      "source": [
        "cdc = []\n",
        "\n",
        "for x in range(len(ndf)):\n",
        "    if x in list(cdc_idx_dict.keys()):\n",
        "        cdc.append(cdc_idx_dict.get(x))\n",
        "    else:\n",
        "        cdc.append('---')\n",
        "ndf['cdc'] = cdc\n",
        "\n",
        "df = pd.concat([ndf, df], axis=0, ignore_index=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "7VrWTuEN1spV"
      },
      "source": [
        "#### Article 4 "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "j_x3TVQh1spV",
        "colab": {}
      },
      "source": [
        "with open(articles_dict[articles[4].replace(' ','_')+'.txt']) as article:\n",
        "        doc = article.read()\n",
        "\n",
        "c_doc = text_cleaner(doc)\n",
        "sentences = nltk.sent_tokenize(c_doc)\n",
        "sentences = [[sent, topic, articles[4]] for sent in sentences]\n",
        "\n",
        "ndf = pd.DataFrame(sentences, columns=['text', 'topic', 'article'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "outputId": "95d95254-8e9b-4c60-b75b-426482ff95e1",
        "id": "Sfib7VPK1spV",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "cdc_idx_dict = {}\n",
        "cdc_idx_sent = {}\n",
        "cdc_idx_art = {}\n",
        "\n",
        "for i,claim in enumerate(ref_data['clean_Claim']):\n",
        "    check_complete = False\n",
        "    while check_complete == False:\n",
        "        for idx,sentence in enumerate(ndf['text']):\n",
        "            test = claim.lower() in sentence.lower()\n",
        "            if test:\n",
        "                article = ref_data['Article'][i]\n",
        "                cdc_idx_dict[idx] = claim\n",
        "                cdc_idx_sent[idx] = [claim, sentence]\n",
        "                cdc_idx_art[idx] = [claim, article]\n",
        "                check_complete = True\n",
        "            elif idx == (len(ndf['text'])-1):\n",
        "                check_complete = True\n",
        "\n",
        "len(cdc_idx_dict), ref_data.shape[0]"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(1, 1332)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 1085
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "outputId": "bad5581c-fa6b-4708-d1ef-6b4f4db9a521",
        "id": "4fZpiuN21spW",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "cdc_idx_dict"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{295: 'evidence for harmful effects were inconclusive'}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 1086
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "2tD8fy-W1spX",
        "colab": {}
      },
      "source": [
        "cdc = []\n",
        "\n",
        "for x in range(len(ndf)):\n",
        "    if x in list(cdc_idx_dict.keys()):\n",
        "        cdc.append(cdc_idx_dict.get(x))\n",
        "    else:\n",
        "        cdc.append('---')\n",
        "ndf['cdc'] = cdc\n",
        "\n",
        "df = pd.concat([ndf, df], axis=0, ignore_index=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "Y8eoBEqtAZp4"
      },
      "source": [
        "#### Article 5 "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "67iTKiS9AZp5",
        "colab": {}
      },
      "source": [
        "with open(articles_dict[articles[5].replace(' ','_')+'.txt']) as article:\n",
        "        doc = article.read()\n",
        "\n",
        "c_doc = text_cleaner(doc)\n",
        "sentences = nltk.sent_tokenize(c_doc)\n",
        "sentences = [[sent, topic, articles[5]] for sent in sentences]\n",
        "\n",
        "ndf = pd.DataFrame(sentences, columns=['text', 'topic', 'article'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "outputId": "47e01670-7f11-4824-ad5a-3833434e8766",
        "id": "mI1ygJe6AZp6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "cdc_idx_dict = {}\n",
        "cdc_idx_sent = {}\n",
        "cdc_idx_art = {}\n",
        "\n",
        "for i,claim in enumerate(ref_data['clean_Claim']):\n",
        "    check_complete = False\n",
        "    while check_complete == False:\n",
        "        for idx,sentence in enumerate(ndf['text']):\n",
        "            test = claim.lower() in sentence.lower()\n",
        "            if test:\n",
        "                article = ref_data['Article'][i]\n",
        "                cdc_idx_dict[idx] = claim\n",
        "                cdc_idx_sent[idx] = [claim, sentence]\n",
        "                cdc_idx_art[idx] = [claim, article]\n",
        "                check_complete = True\n",
        "            elif idx == (len(ndf['text'])-1):\n",
        "                check_complete = True\n",
        "\n",
        "len(cdc_idx_dict), ref_data.shape[0]"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(2, 1332)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 1089
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "outputId": "e043860f-b20c-4a7f-b99b-a6e93bfd4c14",
        "id": "jUMZ31pwAZp8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "cdc_idx_dict"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{33: 'video games allow children to act out crimes',\n",
              " 35: 'violence in video games is not causally linked with aggressive tendencies'}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 1090
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "mufG5_uZAZp-",
        "colab": {}
      },
      "source": [
        "cdc = []\n",
        "\n",
        "for x in range(len(ndf)):\n",
        "    if x in list(cdc_idx_dict.keys()):\n",
        "        cdc.append(cdc_idx_dict.get(x))\n",
        "    else:\n",
        "        cdc.append('---')\n",
        "ndf['cdc'] = cdc\n",
        "\n",
        "df = pd.concat([ndf, df], axis=0, ignore_index=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "dxIg39TPAZp_"
      },
      "source": [
        "#### Article 6"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "0g_w3jsvAZp_",
        "colab": {}
      },
      "source": [
        "with open(articles_dict[articles[6].replace(' ','_')+'.txt']) as article:\n",
        "        doc = article.read()\n",
        "\n",
        "c_doc = text_cleaner(doc)\n",
        "sentences = nltk.sent_tokenize(c_doc)\n",
        "sentences = [[sent, topic, articles[6]] for sent in sentences]\n",
        "\n",
        "ndf = pd.DataFrame(sentences, columns=['text', 'topic', 'article'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "outputId": "920ea355-b935-4bf9-f1b9-468becac5eae",
        "id": "z6SnJ7p9AZqB",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "cdc_idx_dict = {}\n",
        "cdc_idx_sent = {}\n",
        "cdc_idx_art = {}\n",
        "\n",
        "for i,claim in enumerate(ref_data['clean_Claim']):\n",
        "    check_complete = False\n",
        "    while check_complete == False:\n",
        "        for idx,sentence in enumerate(ndf['text']):\n",
        "            test = claim.lower() in sentence.lower()\n",
        "            if test:\n",
        "                article = ref_data['Article'][i]\n",
        "                cdc_idx_dict[idx] = claim\n",
        "                cdc_idx_sent[idx] = [claim, sentence]\n",
        "                cdc_idx_art[idx] = [claim, article]\n",
        "                check_complete = True\n",
        "            elif idx == (len(ndf['text'])-1):\n",
        "                check_complete = True\n",
        "\n",
        "len(cdc_idx_dict), ref_data.shape[0]"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(3, 1332)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 1093
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "outputId": "eac05f1b-7810-4a5e-d03f-6b9f83f2cc17",
        "id": "Niisk0EIAZqC",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "cdc_idx_dict"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{29: 'correlations between violent gameplay and some common childhood problems',\n",
              " 33: 'most children who play violent games do not have problems',\n",
              " 34: 'many creative, social and emotional benefits from video game play—even games with violent content'}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 1094
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "ZNPrfbMDAZqE",
        "colab": {}
      },
      "source": [
        "cdc = []\n",
        "\n",
        "for x in range(len(ndf)):\n",
        "    if x in list(cdc_idx_dict.keys()):\n",
        "        cdc.append(cdc_idx_dict.get(x))\n",
        "    else:\n",
        "        cdc.append('---')\n",
        "ndf['cdc'] = cdc\n",
        "\n",
        "df = pd.concat([ndf, df], axis=0, ignore_index=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "YaCql3yjAZqF"
      },
      "source": [
        "#### Article 7"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "kvKtq813AZqG",
        "colab": {}
      },
      "source": [
        "with open(articles_dict[articles[7].replace(' ','_')+'.txt']) as article:\n",
        "        doc = article.read()\n",
        "\n",
        "c_doc = text_cleaner(doc)\n",
        "sentences = nltk.sent_tokenize(c_doc)\n",
        "sentences = [[sent, topic, articles[7]] for sent in sentences]\n",
        "\n",
        "ndf = pd.DataFrame(sentences, columns=['text', 'topic', 'article'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "outputId": "6f5d8735-fafb-4ae3-9a6b-c083355c5403",
        "id": "qbeLRB1aAZqH",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "cdc_idx_dict = {}\n",
        "cdc_idx_sent = {}\n",
        "cdc_idx_art = {}\n",
        "\n",
        "for i,claim in enumerate(ref_data['clean_Claim']):\n",
        "    check_complete = False\n",
        "    while check_complete == False:\n",
        "        for idx,sentence in enumerate(ndf['text']):\n",
        "            test = claim.lower() in sentence.lower()\n",
        "            if test:\n",
        "                article = ref_data['Article'][i]\n",
        "                cdc_idx_dict[idx] = claim\n",
        "                cdc_idx_sent[idx] = [claim, sentence]\n",
        "                cdc_idx_art[idx] = [claim, article]\n",
        "                check_complete = True\n",
        "            elif idx == (len(ndf['text'])-1):\n",
        "                check_complete = True\n",
        "\n",
        "len(cdc_idx_dict), ref_data.shape[0]"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(8, 1332)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 1097
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "outputId": "914d05e8-46cb-44a4-f837-e06e17b0770b",
        "id": "-dxOMfx2AZqK",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "cdc_idx_dict"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{2: 'video games were protected speech under the First Amendment',\n",
              " 36: 'there was a connection between video games and violence',\n",
              " 54: 'content-based regulations are presumptively invalid',\n",
              " 88: 'content-based regulations are presumptively invalid',\n",
              " 117: 'no evidence linked video games to youth violence',\n",
              " 136: 'there was no \"compelling\" link between violent video games and its effects on children',\n",
              " 148: 'parents, not government bureaucrats, have the right to decide what is appropriate for their children',\n",
              " 169: 'parents should make the decision” about what video games they purchase for their children, and what constitutes “too violent'}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 1098
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "7YM3yiySAZqL",
        "colab": {}
      },
      "source": [
        "cdc = []\n",
        "\n",
        "for x in range(len(ndf)):\n",
        "    if x in list(cdc_idx_dict.keys()):\n",
        "        cdc.append(cdc_idx_dict.get(x))\n",
        "    else:\n",
        "        cdc.append('---')\n",
        "ndf['cdc'] = cdc\n",
        "\n",
        "df = pd.concat([ndf, df], axis=0, ignore_index=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "_xiB8OENAZqM"
      },
      "source": [
        "#### Article 8"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "4PSKP23rAZqN",
        "colab": {}
      },
      "source": [
        "with open(articles_dict[articles[8].replace(' ','_')+'.txt']) as article:\n",
        "        doc = article.read()\n",
        "\n",
        "c_doc = text_cleaner(doc)\n",
        "sentences = nltk.sent_tokenize(c_doc)\n",
        "sentences = [[sent, topic, articles[8]] for sent in sentences]\n",
        "\n",
        "ndf = pd.DataFrame(sentences, columns=['text', 'topic', 'article'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "outputId": "fd9b33cf-366e-42a0-ea94-0be162d99c24",
        "id": "mCY6LqjmAZqO",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "cdc_idx_dict = {}\n",
        "cdc_idx_sent = {}\n",
        "cdc_idx_art = {}\n",
        "\n",
        "for i,claim in enumerate(ref_data['clean_Claim']):\n",
        "    check_complete = False\n",
        "    while check_complete == False:\n",
        "        for idx,sentence in enumerate(ndf['text']):\n",
        "            test = claim.lower() in sentence.lower()\n",
        "            if test:\n",
        "                article = ref_data['Article'][i]\n",
        "                cdc_idx_dict[idx] = claim\n",
        "                cdc_idx_sent[idx] = [claim, sentence]\n",
        "                cdc_idx_art[idx] = [claim, article]\n",
        "                check_complete = True\n",
        "            elif idx == (len(ndf['text'])-1):\n",
        "                check_complete = True\n",
        "\n",
        "len(cdc_idx_dict), ref_data.shape[0]"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(31, 1332)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 1101
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "outputId": "50b628b0-4eb4-4a0b-dcfc-12ad8fa4b259",
        "id": "d2m3LFasAZqP",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "cdc_idx_dict"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{4: 'exposure to violent video games causes at least a temporary increase in aggression and that this exposure correlates with aggression in the real world',\n",
              " 6: 'video game violence is not related to serious aggressive behavior in real life',\n",
              " 8: 'some violent video games may actually have a prosocial effect in some contexts',\n",
              " 10: 'exposure to violent video games causes both short term and long term aggression in players and decreases empathy and prosocial behavior',\n",
              " 21: 'they increase the violent tendencies among youth',\n",
              " 22: 'have shown no conclusive link between video game usage and violent activity',\n",
              " 30: 'violent video games are significantly associated with: increased aggressive behavior, thoughts, and affect; increased physiological arousal; and decreased pro-social (helping) behavior',\n",
              " 37: 'video game publishers unethically train children in the use of weapons and, more importantly, harden them emotionally to the act of murder',\n",
              " 39: 'violent video games may increase mild forms of aggressive behavior in children and young adults',\n",
              " 40: 'exposure to violent video games results in increased physiological arousal, aggression-related thoughts and feelings as well as decreased prosocial behavior',\n",
              " 50: 'violence in video games is not causally linked with aggressive tendencies',\n",
              " 57: 'no long-term relationship between playing violent video game and youth violence or bullying',\n",
              " 58: 'aggressive children tend to select more violent video games, not the inverse',\n",
              " 59: 'no evidence violent games are psychologically harmful to minors',\n",
              " 62: \"video game play is part of an adolescent boy's normal social setting\",\n",
              " 75: 'Other biological theories of aggression and violence have specifically excluded video game and other media effects',\n",
              " 99: 'Reinforcement of sexist stereotypes has also been claimed as an effect of violent video games',\n",
              " 104: 'a correlation between children playing violent video games and suffering psychological effects',\n",
              " 105: \"violent video games can increase children's aggression\",\n",
              " 190: 'media influences are too weak and distant to have much influence',\n",
              " 195: 'violent video games promote violent behavior, attitudes and beliefs by desensitizing an individual to aggression',\n",
              " 225: 'Excessive exposure to violent video games and other violent media has been linked to aggressive behaviour',\n",
              " 226: 'neurological link between playing violent video games and aggressive behaviour in children and teenagers',\n",
              " 234: 'there was no direct link between violent video games and their influence on children',\n",
              " 235: 'numerous researchers have proposed potential positive effects of video games',\n",
              " 237: \"Video games also develop the individual's intelligence\",\n",
              " 239: 'violent games help students deal with stress and aggression',\n",
              " 241: 'violent games affect students positively and not negatively',\n",
              " 254: 'many skills can be learned from the gaming experience, it builds practical and intellectual skills',\n",
              " 256: 'media cannot cause violence because humans have the ability to recognize what is wrong, and what is right',\n",
              " 262: 'they can be a safe outlet for aggression and frustration'}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 1102
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "B5o0dpjrAZqQ",
        "colab": {}
      },
      "source": [
        "cdc = []\n",
        "\n",
        "for x in range(len(ndf)):\n",
        "    if x in list(cdc_idx_dict.keys()):\n",
        "        cdc.append(cdc_idx_dict.get(x))\n",
        "    else:\n",
        "        cdc.append('---')\n",
        "ndf['cdc'] = cdc\n",
        "\n",
        "df = pd.concat([ndf, df], axis=0, ignore_index=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "l-gKwZSXAZqR"
      },
      "source": [
        "#### Article 9"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "Zo9kRKQjAZqR",
        "colab": {}
      },
      "source": [
        "with open(articles_dict[articles[9].replace(' ','_')+'.txt']) as article:\n",
        "        doc = article.read()\n",
        "\n",
        "c_doc = text_cleaner(doc)\n",
        "sentences = nltk.sent_tokenize(c_doc)\n",
        "sentences = [[sent, topic, articles[9]] for sent in sentences]\n",
        "\n",
        "ndf = pd.DataFrame(sentences, columns=['text', 'topic', 'article'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "outputId": "d6a4a6f2-b4c8-4e47-bf72-3720c842d612",
        "id": "wAhAPYgrAZqS",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "cdc_idx_dict = {}\n",
        "cdc_idx_sent = {}\n",
        "cdc_idx_art = {}\n",
        "\n",
        "for i,claim in enumerate(ref_data['clean_Claim']):\n",
        "    check_complete = False\n",
        "    while check_complete == False:\n",
        "        for idx,sentence in enumerate(ndf['text']):\n",
        "            test = claim.lower() in sentence.lower()\n",
        "            if test:\n",
        "                article = ref_data['Article'][i]\n",
        "                cdc_idx_dict[idx] = claim\n",
        "                cdc_idx_sent[idx] = [claim, sentence]\n",
        "                cdc_idx_art[idx] = [claim, article]\n",
        "                check_complete = True\n",
        "            elif idx == (len(ndf['text'])-1):\n",
        "                check_complete = True\n",
        "\n",
        "len(cdc_idx_dict), ref_data.shape[0]"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(4, 1332)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 1105
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "outputId": "eb08c4d8-04ca-466b-a0ef-cb4561a42e35",
        "id": "6OdYfCscAZqV",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "cdc_idx_dict"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{11: 'not all depictions of violence are even bad to witness',\n",
              " 42: 'no connection between exposure to media violence and real life violence',\n",
              " 43: 'exposure alone does not cause a child to commit crimes',\n",
              " 49: 'there is no convincing evidence that prove that media violence cause violent crime or any type of real life violence'}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 1106
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "xywNCR-vAZqX",
        "colab": {}
      },
      "source": [
        "cdc = []\n",
        "\n",
        "for x in range(len(ndf)):\n",
        "    if x in list(cdc_idx_dict.keys()):\n",
        "        cdc.append(cdc_idx_dict.get(x))\n",
        "    else:\n",
        "        cdc.append('---')\n",
        "ndf['cdc'] = cdc\n",
        "\n",
        "df = pd.concat([ndf, df], axis=0, ignore_index=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "63vLOIqmAZqY"
      },
      "source": [
        "#### Article 10"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "pi0XrEM-AZqY",
        "colab": {}
      },
      "source": [
        "with open(articles_dict[articles[10].replace(' ','_')+'.txt']) as article:\n",
        "        doc = article.read()\n",
        "\n",
        "c_doc = text_cleaner(doc)\n",
        "sentences = nltk.sent_tokenize(c_doc)\n",
        "sentences = [[sent, topic, articles[10]] for sent in sentences]\n",
        "\n",
        "ndf = pd.DataFrame(sentences, columns=['text', 'topic', 'article'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "outputId": "b7e60ee8-36f4-4408-f8db-76c9b756bfc0",
        "id": "Tkq9QCV2AZqZ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "cdc_idx_dict = {}\n",
        "cdc_idx_sent = {}\n",
        "cdc_idx_art = {}\n",
        "\n",
        "for i,claim in enumerate(ref_data['clean_Claim']):\n",
        "    check_complete = False\n",
        "    while check_complete == False:\n",
        "        for idx,sentence in enumerate(ndf['text']):\n",
        "            test = claim.lower() in sentence.lower()\n",
        "            if test:\n",
        "                article = ref_data['Article'][i]\n",
        "                cdc_idx_dict[idx] = claim\n",
        "                cdc_idx_sent[idx] = [claim, sentence]\n",
        "                cdc_idx_art[idx] = [claim, article]\n",
        "                check_complete = True\n",
        "            elif idx == (len(ndf['text'])-1):\n",
        "                check_complete = True\n",
        "\n",
        "len(cdc_idx_dict), ref_data.shape[0]"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(2, 1332)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 1109
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "outputId": "20491fb1-571f-4ba4-efeb-5ae497e5b77a",
        "id": "gXX8TV1RAZqa",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "cdc_idx_dict"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{13: 'exposure to graphic violence leads to desensitization to committing acts of violence in person',\n",
              " 26: 'violence in games hardens children to unethical acts'}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 1110
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "-V0rlFOQAZqb",
        "colab": {}
      },
      "source": [
        "cdc = []\n",
        "\n",
        "for x in range(len(ndf)):\n",
        "    if x in list(cdc_idx_dict.keys()):\n",
        "        cdc.append(cdc_idx_dict.get(x))\n",
        "    else:\n",
        "        cdc.append('---')\n",
        "ndf['cdc'] = cdc\n",
        "\n",
        "df = pd.concat([ndf, df], axis=0, ignore_index=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "biylW1qVAZqc"
      },
      "source": [
        "#### Article 11 "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "-MNifRFWAZqc",
        "colab": {}
      },
      "source": [
        "with open(articles_dict[articles[11].replace(' ','_')+'.txt']) as article:\n",
        "        doc = article.read()\n",
        "\n",
        "c_doc = text_cleaner(doc)\n",
        "sentences = nltk.sent_tokenize(c_doc)\n",
        "sentences = [[sent, topic, articles[11]] for sent in sentences]\n",
        "\n",
        "ndf = pd.DataFrame(sentences, columns=['text', 'topic', 'article'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "outputId": "65158f67-2ffe-4dd3-96df-46bcc4829d6e",
        "id": "xj4zgVSwAZqf",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "cdc_idx_dict = {}\n",
        "cdc_idx_sent = {}\n",
        "cdc_idx_art = {}\n",
        "\n",
        "for i,claim in enumerate(ref_data['clean_Claim']):\n",
        "    check_complete = False\n",
        "    while check_complete == False:\n",
        "        for idx,sentence in enumerate(ndf['text']):\n",
        "            test = claim.lower() in sentence.lower()\n",
        "            if test:\n",
        "                article = ref_data['Article'][i]\n",
        "                cdc_idx_dict[idx] = claim\n",
        "                cdc_idx_sent[idx] = [claim, sentence]\n",
        "                cdc_idx_art[idx] = [claim, article]\n",
        "                check_complete = True\n",
        "            elif idx == (len(ndf['text'])-1):\n",
        "                check_complete = True\n",
        "\n",
        "len(cdc_idx_dict), ref_data.shape[0]"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(1, 1332)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 1113
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "outputId": "a307dd30-1385-4f71-e1f6-167e1501cab6",
        "id": "y5GlHFroAZqk",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "cdc_idx_dict"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{6: 'violent video games—especially first-person shooter games—encouraged real-life acts of violence in teenagers'}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 1114
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "z7HKHccOAZql",
        "colab": {}
      },
      "source": [
        "cdc = []\n",
        "\n",
        "for x in range(len(ndf)):\n",
        "    if x in list(cdc_idx_dict.keys()):\n",
        "        cdc.append(cdc_idx_dict.get(x))\n",
        "    else:\n",
        "        cdc.append('---')\n",
        "ndf['cdc'] = cdc\n",
        "\n",
        "df = pd.concat([ndf, df], axis=0, ignore_index=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "EChPianRAZqm"
      },
      "source": [
        "#### Article 12"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "NYfOuO9KAZqo",
        "colab": {}
      },
      "source": [
        "with open(articles_dict[articles[12].replace(' ','_')+'.txt']) as article:\n",
        "        doc = article.read()\n",
        "\n",
        "c_doc = text_cleaner(doc)\n",
        "sentences = nltk.sent_tokenize(c_doc)\n",
        "sentences = [[sent, topic, articles[12]] for sent in sentences]\n",
        "\n",
        "ndf = pd.DataFrame(sentences, columns=['text', 'topic', 'article'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "outputId": "ffd039a2-a163-4240-8504-ab7fc7a17edd",
        "id": "YBv-37P4AZqo",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "cdc_idx_dict = {}\n",
        "cdc_idx_sent = {}\n",
        "cdc_idx_art = {}\n",
        "\n",
        "for i,claim in enumerate(ref_data['clean_Claim']):\n",
        "    check_complete = False\n",
        "    while check_complete == False:\n",
        "        for idx,sentence in enumerate(ndf['text']):\n",
        "            test = claim.lower() in sentence.lower()\n",
        "            if test:\n",
        "                article = ref_data['Article'][i]\n",
        "                cdc_idx_dict[idx] = claim\n",
        "                cdc_idx_sent[idx] = [claim, sentence]\n",
        "                cdc_idx_art[idx] = [claim, article]\n",
        "                check_complete = True\n",
        "            elif idx == (len(ndf['text'])-1):\n",
        "                check_complete = True\n",
        "\n",
        "len(cdc_idx_dict), ref_data.shape[0]"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(1, 1332)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 1117
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "outputId": "2bcf2e5f-44f3-4a43-c35e-857667870411",
        "id": "tBvBR_mbAZqp",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "cdc_idx_dict"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{52: 'violent video games is related to increased aggressiveness in children'}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 1118
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "wZVAPLiCAZqq",
        "colab": {}
      },
      "source": [
        "cdc = []\n",
        "\n",
        "for x in range(len(ndf)):\n",
        "    if x in list(cdc_idx_dict.keys()):\n",
        "        cdc.append(cdc_idx_dict.get(x))\n",
        "    else:\n",
        "        cdc.append('---')\n",
        "ndf['cdc'] = cdc\n",
        "\n",
        "df = pd.concat([ndf, df], axis=0, ignore_index=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "SXoU329cAZqr"
      },
      "source": [
        "#### Article 13"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "YkZ1bkrJAZqr",
        "colab": {}
      },
      "source": [
        "with open(articles_dict[articles[13].replace(' ','_')+'.txt']) as article:\n",
        "        doc = article.read()\n",
        "\n",
        "c_doc = text_cleaner(doc)\n",
        "sentences = nltk.sent_tokenize(c_doc)\n",
        "sentences = [[sent, topic, articles[13]] for sent in sentences]\n",
        "\n",
        "ndf = pd.DataFrame(sentences, columns=['text', 'topic', 'article'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "outputId": "754bab07-d37b-4855-e857-46a41f53d98f",
        "id": "IwSpRcxlAZqt",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "cdc_idx_dict = {}\n",
        "cdc_idx_sent = {}\n",
        "cdc_idx_art = {}\n",
        "\n",
        "for i,claim in enumerate(ref_data['clean_Claim']):\n",
        "    check_complete = False\n",
        "    while check_complete == False:\n",
        "        for idx,sentence in enumerate(ndf['text']):\n",
        "            test = claim.lower() in sentence.lower()\n",
        "            if test:\n",
        "                article = ref_data['Article'][i]\n",
        "                cdc_idx_dict[idx] = claim\n",
        "                cdc_idx_sent[idx] = [claim, sentence]\n",
        "                cdc_idx_art[idx] = [claim, article]\n",
        "                check_complete = True\n",
        "            elif idx == (len(ndf['text'])-1):\n",
        "                check_complete = True\n",
        "\n",
        "len(cdc_idx_dict), ref_data.shape[0]"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(3, 1332)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 1121
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "outputId": "8942dfde-8d2d-420f-bf3b-8bb961dc91d0",
        "id": "DhWky81kAZqu",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "cdc_idx_dict"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{13: 'children may imitate aggressive behaviors witnessed in media',\n",
              " 22: \"children don't automatically imitate aggression, but rather consider the context of aggression\",\n",
              " 124: 'societal media consumption and violent crime rates are not well associated'}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 1122
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "Lpgi_85rAZqv",
        "colab": {}
      },
      "source": [
        "cdc = []\n",
        "\n",
        "for x in range(len(ndf)):\n",
        "    if x in list(cdc_idx_dict.keys()):\n",
        "        cdc.append(cdc_idx_dict.get(x))\n",
        "    else:\n",
        "        cdc.append('---')\n",
        "ndf['cdc'] = cdc\n",
        "\n",
        "df = pd.concat([ndf, df], axis=0, ignore_index=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "ciPKA2s2AZq7"
      },
      "source": [
        "#### Article 14 "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "TZUuqW6ZAZq7",
        "colab": {}
      },
      "source": [
        "with open(articles_dict[articles[14].replace(' ','_')+'.txt']) as article:\n",
        "        doc = article.read()\n",
        "\n",
        "c_doc = text_cleaner(doc)\n",
        "sentences = nltk.sent_tokenize(c_doc)\n",
        "sentences = [[sent, topic, articles[14]] for sent in sentences]\n",
        "\n",
        "ndf = pd.DataFrame(sentences, columns=['text', 'topic', 'article'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "outputId": "a5b4e398-410c-4e9a-b2ac-ce18b3624bfc",
        "id": "5GAftnYHAZq8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "cdc_idx_dict = {}\n",
        "cdc_idx_sent = {}\n",
        "cdc_idx_art = {}\n",
        "\n",
        "for i,claim in enumerate(ref_data['clean_Claim']):\n",
        "    check_complete = False\n",
        "    while check_complete == False:\n",
        "        for idx,sentence in enumerate(ndf['text']):\n",
        "            test = claim.lower() in sentence.lower()\n",
        "            if test:\n",
        "                article = ref_data['Article'][i]\n",
        "                cdc_idx_dict[idx] = claim\n",
        "                cdc_idx_sent[idx] = [claim, sentence]\n",
        "                cdc_idx_art[idx] = [claim, article]\n",
        "                check_complete = True\n",
        "            elif idx == (len(ndf['text'])-1):\n",
        "                check_complete = True\n",
        "\n",
        "len(cdc_idx_dict), ref_data.shape[0]"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(3, 1332)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 1125
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "outputId": "0f5f87b5-ef31-4fb3-bada-5e0740b21e4a",
        "id": "IfcaIc_lAZq8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "cdc_idx_dict"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{111: 'computer games cause violence',\n",
              " 113: 'a correlation between violent content conveyed through media (including videogames) and violent or aggressive behavior',\n",
              " 149: 'Some serious psychological problems have been attributed to desensitization to violence in video games'}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 1126
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "NOdcB2-zAZq9",
        "colab": {}
      },
      "source": [
        "cdc = []\n",
        "\n",
        "for x in range(len(ndf)):\n",
        "    if x in list(cdc_idx_dict.keys()):\n",
        "        cdc.append(cdc_idx_dict.get(x))\n",
        "    else:\n",
        "        cdc.append('---')\n",
        "ndf['cdc'] = cdc\n",
        "\n",
        "df = pd.concat([ndf, df], axis=0, ignore_index=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XtRtfuXBzwJl",
        "colab_type": "text"
      },
      "source": [
        "### 'the use of affirmative action '"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "outputId": "a412cc80-24df-45c4-89b7-e69f6eb3f488",
        "id": "Ry1hgHAR1vks",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "topic = 'the use of affirmative action '\n",
        "\n",
        "articles = topic_article_dict[topic]\n",
        "articles"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['Civil Rights Act of 1964',\n",
              " 'Racial quota',\n",
              " 'Affirmative Action Around the World',\n",
              " 'Black Economic Empowerment',\n",
              " 'Reverse discrimination',\n",
              " 'Convention on the Elimination of All Forms of Racial Discrimination',\n",
              " 'Reservation in India',\n",
              " 'Convention on the Elimination of All Forms of Discrimination Against Women',\n",
              " 'Racism',\n",
              " 'Racism in the United States',\n",
              " 'Discrimination',\n",
              " 'Affirmative action bake sale',\n",
              " 'United Kingdom employment equality law',\n",
              " 'Minority group',\n",
              " 'Equal opportunity',\n",
              " 'Color blindness (race)',\n",
              " 'Symbolic racism',\n",
              " 'Meritocracy',\n",
              " 'Affirmative action in the United States',\n",
              " 'Affirmative action']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 1128
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JxGQ-r941vPj",
        "colab_type": "code",
        "outputId": "5586ee31-bcd0-47b2-f8f9-55b538a85dbd",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "len(articles)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "20"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 1129
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "_PVTvdMy1vkt"
      },
      "source": [
        "#### Article 0 "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "_7AzSCav1vkt",
        "colab": {}
      },
      "source": [
        "with open(articles_dict[articles[0].replace(' ','_')+'.txt']) as article:\n",
        "        doc = article.read()\n",
        "\n",
        "c_doc = text_cleaner(doc)\n",
        "sentences = nltk.sent_tokenize(c_doc)\n",
        "sentences = [[sent, topic, articles[0]] for sent in sentences]\n",
        "\n",
        "ndf = pd.DataFrame(sentences, columns=['text', 'topic', 'article'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "outputId": "446bc2ea-c4f4-4d59-d541-6688be1aeae6",
        "id": "IoMj8xvQ1vkt",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "cdc_idx_dict = {}\n",
        "cdc_idx_sent = {}\n",
        "cdc_idx_art = {}\n",
        "\n",
        "for i,claim in enumerate(ref_data['clean_Claim']):\n",
        "    check_complete = False\n",
        "    while check_complete == False:\n",
        "        for idx,sentence in enumerate(ndf['text']):\n",
        "            test = claim.lower() in sentence.lower()\n",
        "            if test:\n",
        "                article = ref_data['Article'][i]\n",
        "                cdc_idx_dict[idx] = claim\n",
        "                cdc_idx_sent[idx] = [claim, sentence]\n",
        "                cdc_idx_art[idx] = [claim, article]\n",
        "                check_complete = True\n",
        "            elif idx == (len(ndf['text'])-1):\n",
        "                check_complete = True\n",
        "\n",
        "len(cdc_idx_dict), ref_data.shape[0]"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(1, 1332)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 1131
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "outputId": "25c83f57-95c9-4bb9-ed4b-548591ef68c4",
        "id": "YIt3zK3c1vku",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "cdc_idx_dict"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{99: \"You can't legislate morality\"}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 1132
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "zR26Wjh_1vkv",
        "colab": {}
      },
      "source": [
        "cdc = []\n",
        "\n",
        "for x in range(len(ndf)):\n",
        "    if x in list(cdc_idx_dict.keys()):\n",
        "        cdc.append(cdc_idx_dict.get(x))\n",
        "    else:\n",
        "        cdc.append('---')\n",
        "ndf['cdc'] = cdc\n",
        "\n",
        "df = pd.concat([ndf, df], axis=0, ignore_index=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "NN8aigQs1vkw"
      },
      "source": [
        "#### Article 1 "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "zsXqAmC01vkw",
        "colab": {}
      },
      "source": [
        "with open(articles_dict[articles[1].replace(' ','_')+'.txt']) as article:\n",
        "        doc = article.read()\n",
        "\n",
        "c_doc = text_cleaner(doc)\n",
        "sentences = nltk.sent_tokenize(c_doc)\n",
        "sentences = [[sent, topic, articles[1]] for sent in sentences]\n",
        "\n",
        "ndf = pd.DataFrame(sentences, columns=['text', 'topic', 'article'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "outputId": "4b72417c-2ba0-4898-dbff-3e85d5e51fdc",
        "id": "x84lMFLb1vkx",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "cdc_idx_dict = {}\n",
        "cdc_idx_sent = {}\n",
        "cdc_idx_art = {}\n",
        "\n",
        "for i,claim in enumerate(ref_data['clean_Claim']):\n",
        "    check_complete = False\n",
        "    while check_complete == False:\n",
        "        for idx,sentence in enumerate(ndf['text']):\n",
        "            test = claim.lower() in sentence.lower()\n",
        "            if test:\n",
        "                article = ref_data['Article'][i]\n",
        "                cdc_idx_dict[idx] = claim\n",
        "                cdc_idx_sent[idx] = [claim, sentence]\n",
        "                cdc_idx_art[idx] = [claim, article]\n",
        "                check_complete = True\n",
        "            elif idx == (len(ndf['text'])-1):\n",
        "                check_complete = True\n",
        "\n",
        "len(cdc_idx_dict), ref_data.shape[0]"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(3, 1332)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 1135
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "outputId": "de503f45-33e0-4617-ec6c-01de8a9db666",
        "id": "aiRxXZjb1vkx",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "cdc_idx_dict"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{20: 'one group is favored at the expense of another whenever a quota is invoked',\n",
              " 21: 'using quotas displaces individuals that would normally be favored based on their individual achievements',\n",
              " 22: 'qualifications should be the only determining factor'}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 1136
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "VDgXl9YS1vky",
        "colab": {}
      },
      "source": [
        "cdc = []\n",
        "\n",
        "for x in range(len(ndf)):\n",
        "    if x in list(cdc_idx_dict.keys()):\n",
        "        cdc.append(cdc_idx_dict.get(x))\n",
        "    else:\n",
        "        cdc.append('---')\n",
        "ndf['cdc'] = cdc\n",
        "\n",
        "df = pd.concat([df, ndf], axis=0, ignore_index=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "KKIbtKrD1vkz"
      },
      "source": [
        "#### Article 2 "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "vkCM-88b1vkz",
        "colab": {}
      },
      "source": [
        "with open(articles_dict[articles[2].replace(' ','_')+'.txt']) as article:\n",
        "        doc = article.read()\n",
        "\n",
        "c_doc = text_cleaner(doc)\n",
        "sentences = nltk.sent_tokenize(c_doc)\n",
        "sentences = [[sent, topic, articles[2]] for sent in sentences]\n",
        "\n",
        "ndf = pd.DataFrame(sentences, columns=['text', 'topic', 'article'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "outputId": "612b3398-0991-413c-d801-289f5fe2a9b5",
        "id": "BWGH9FdH1vk0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "cdc_idx_dict = {}\n",
        "cdc_idx_sent = {}\n",
        "cdc_idx_art = {}\n",
        "\n",
        "for i,claim in enumerate(ref_data['clean_Claim']):\n",
        "    check_complete = False\n",
        "    while check_complete == False:\n",
        "        for idx,sentence in enumerate(ndf['text']):\n",
        "            test = claim.lower() in sentence.lower()\n",
        "            if test:\n",
        "                article = ref_data['Article'][i]\n",
        "                cdc_idx_dict[idx] = claim\n",
        "                cdc_idx_sent[idx] = [claim, sentence]\n",
        "                cdc_idx_art[idx] = [claim, article]\n",
        "                check_complete = True\n",
        "            elif idx == (len(ndf['text'])-1):\n",
        "                check_complete = True\n",
        "\n",
        "len(cdc_idx_dict), ref_data.shape[0]"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(3, 1332)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 1139
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "outputId": "9fcb20d0-da2a-4685-c964-76b0773ee956",
        "id": "fqWLB9Vp1vk0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "cdc_idx_dict"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{3: 'programs have at best a negligible impact on the groups they are intended to assist',\n",
              " 7: 'they tend to benefit primarily the most fortunate among the preferred group',\n",
              " 8: 'They reduce the incentives of both the preferred and non-preferred to perform at their best'}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 1140
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "neZoVAsf1vk1",
        "colab": {}
      },
      "source": [
        "cdc = []\n",
        "\n",
        "for x in range(len(ndf)):\n",
        "    if x in list(cdc_idx_dict.keys()):\n",
        "        cdc.append(cdc_idx_dict.get(x))\n",
        "    else:\n",
        "        cdc.append('---')\n",
        "ndf['cdc'] = cdc\n",
        "\n",
        "df = pd.concat([ndf, df], axis=0, ignore_index=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "doWdzTJn1vk2"
      },
      "source": [
        "#### Article 3 "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "0BeJ6-WN1vk2",
        "colab": {}
      },
      "source": [
        "with open(articles_dict[articles[3].replace(' ','_')+'.txt']) as article:\n",
        "        doc = article.read()\n",
        "\n",
        "c_doc = text_cleaner(doc)\n",
        "sentences = nltk.sent_tokenize(c_doc)\n",
        "sentences = [[sent, topic, articles[3]] for sent in sentences]\n",
        "\n",
        "ndf = pd.DataFrame(sentences, columns=['text', 'topic', 'article'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "outputId": "f60a4475-2a57-4e34-a7b5-062620b302f4",
        "id": "9SLZ_9Ld1vk2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "cdc_idx_dict = {}\n",
        "cdc_idx_sent = {}\n",
        "cdc_idx_art = {}\n",
        "\n",
        "for i,claim in enumerate(ref_data['clean_Claim']):\n",
        "    check_complete = False\n",
        "    while check_complete == False:\n",
        "        for idx,sentence in enumerate(ndf['text']):\n",
        "            test = claim.lower() in sentence.lower()\n",
        "            if test:\n",
        "                article = ref_data['Article'][i]\n",
        "                cdc_idx_dict[idx] = claim\n",
        "                cdc_idx_sent[idx] = [claim, sentence]\n",
        "                cdc_idx_art[idx] = [claim, article]\n",
        "                check_complete = True\n",
        "            elif idx == (len(ndf['text'])-1):\n",
        "                check_complete = True\n",
        "\n",
        "len(cdc_idx_dict), ref_data.shape[0]"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(1, 1332)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 1143
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "outputId": "f0956489-5ce2-46dc-e6ff-9f4eab5b38e1",
        "id": "kcjtJbLs1vk3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "cdc_idx_dict"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{2: 'direct intervention in the distribution of assets and opportunities was needed to resolve the economic disparities'}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 1144
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "Ky5P4K-p1vk4",
        "colab": {}
      },
      "source": [
        "cdc = []\n",
        "\n",
        "for x in range(len(ndf)):\n",
        "    if x in list(cdc_idx_dict.keys()):\n",
        "        cdc.append(cdc_idx_dict.get(x))\n",
        "    else:\n",
        "        cdc.append('---')\n",
        "ndf['cdc'] = cdc\n",
        "\n",
        "df = pd.concat([ndf, df], axis=0, ignore_index=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "sCo-hGAS1vk7"
      },
      "source": [
        "#### Article 4 "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "lxBA1Hje1vk7",
        "colab": {}
      },
      "source": [
        "with open(articles_dict[articles[4].replace(' ','_')+'.txt']) as article:\n",
        "        doc = article.read()\n",
        "\n",
        "c_doc = text_cleaner(doc)\n",
        "sentences = nltk.sent_tokenize(c_doc)\n",
        "sentences = [[sent, topic, articles[4]] for sent in sentences]\n",
        "\n",
        "ndf = pd.DataFrame(sentences, columns=['text', 'topic', 'article'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "outputId": "4ba841c4-3c58-47bd-cbbb-08dda9f662b7",
        "id": "oA8VowRq1vlB",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "cdc_idx_dict = {}\n",
        "cdc_idx_sent = {}\n",
        "cdc_idx_art = {}\n",
        "\n",
        "for i,claim in enumerate(ref_data['clean_Claim']):\n",
        "    check_complete = False\n",
        "    while check_complete == False:\n",
        "        for idx,sentence in enumerate(ndf['text']):\n",
        "            test = claim.lower() in sentence.lower()\n",
        "            if test:\n",
        "                article = ref_data['Article'][i]\n",
        "                cdc_idx_dict[idx] = claim\n",
        "                cdc_idx_sent[idx] = [claim, sentence]\n",
        "                cdc_idx_art[idx] = [claim, article]\n",
        "                check_complete = True\n",
        "            elif idx == (len(ndf['text'])-1):\n",
        "                check_complete = True\n",
        "\n",
        "len(cdc_idx_dict), ref_data.shape[0]"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(2, 1332)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 1147
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "outputId": "035611cc-f970-451e-aff1-2efaaa9c2c19",
        "id": "xYx1DPHT1vlC",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "cdc_idx_dict"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{4: 'discrimination inherent in affirmative action programs',\n",
              " 5: 'identical treatment may sometimes act to preserve inequality rather than eliminate it'}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 1148
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "l9Idq2Po1vlD",
        "colab": {}
      },
      "source": [
        "cdc = []\n",
        "\n",
        "for x in range(len(ndf)):\n",
        "    if x in list(cdc_idx_dict.keys()):\n",
        "        cdc.append(cdc_idx_dict.get(x))\n",
        "    else:\n",
        "        cdc.append('---')\n",
        "ndf['cdc'] = cdc\n",
        "\n",
        "df = pd.concat([ndf, df], axis=0, ignore_index=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "5YwKHasLAkVM"
      },
      "source": [
        "#### Article 5 "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "spdoAMWwAkVN",
        "colab": {}
      },
      "source": [
        "with open(articles_dict[articles[5].replace(' ','_')+'.txt']) as article:\n",
        "        doc = article.read()\n",
        "\n",
        "c_doc = text_cleaner(doc)\n",
        "sentences = nltk.sent_tokenize(c_doc)\n",
        "sentences = [[sent, topic, articles[5]] for sent in sentences]\n",
        "\n",
        "ndf = pd.DataFrame(sentences, columns=['text', 'topic', 'article'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "outputId": "e6b79e10-43e5-40ab-a392-fe76f58e6bd1",
        "id": "BgIoeDAXAkVO",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "cdc_idx_dict = {}\n",
        "cdc_idx_sent = {}\n",
        "cdc_idx_art = {}\n",
        "\n",
        "for i,claim in enumerate(ref_data['clean_Claim']):\n",
        "    check_complete = False\n",
        "    while check_complete == False:\n",
        "        for idx,sentence in enumerate(ndf['text']):\n",
        "            test = claim.lower() in sentence.lower()\n",
        "            if test:\n",
        "                article = ref_data['Article'][i]\n",
        "                cdc_idx_dict[idx] = claim\n",
        "                cdc_idx_sent[idx] = [claim, sentence]\n",
        "                cdc_idx_art[idx] = [claim, article]\n",
        "                check_complete = True\n",
        "            elif idx == (len(ndf['text'])-1):\n",
        "                check_complete = True\n",
        "\n",
        "len(cdc_idx_dict), ref_data.shape[0]"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(2, 1332)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 1151
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "outputId": "0805ad51-7ef3-4563-8b7d-161d18f5f3c0",
        "id": "nW8ULd0-AkVP",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "cdc_idx_dict"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{30: 'redress imbalances and promote equality',\n",
              " 40: 'affirmative action policies for specific racial groups to guarantee \"the full and equal enjoyment of human rights and fundamental freedoms'}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 1152
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "PpcsV5FkAkVQ",
        "colab": {}
      },
      "source": [
        "cdc = []\n",
        "\n",
        "for x in range(len(ndf)):\n",
        "    if x in list(cdc_idx_dict.keys()):\n",
        "        cdc.append(cdc_idx_dict.get(x))\n",
        "    else:\n",
        "        cdc.append('---')\n",
        "ndf['cdc'] = cdc\n",
        "\n",
        "df = pd.concat([ndf, df], axis=0, ignore_index=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "jrQBy9ZfAkVQ"
      },
      "source": [
        "#### Article 6"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "HKx7Hqy7AkVQ",
        "colab": {}
      },
      "source": [
        "with open(articles_dict[articles[6].replace(' ','_')+'.txt']) as article:\n",
        "        doc = article.read()\n",
        "\n",
        "c_doc = text_cleaner(doc)\n",
        "sentences = nltk.sent_tokenize(c_doc)\n",
        "sentences = [[sent, topic, articles[6]] for sent in sentences]\n",
        "\n",
        "ndf = pd.DataFrame(sentences, columns=['text', 'topic', 'article'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "outputId": "cb55850a-48b2-47fd-a0c6-5a3848292614",
        "id": "GUboCsjEAkVR",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "cdc_idx_dict = {}\n",
        "cdc_idx_sent = {}\n",
        "cdc_idx_art = {}\n",
        "\n",
        "for i,claim in enumerate(ref_data['clean_Claim']):\n",
        "    check_complete = False\n",
        "    while check_complete == False:\n",
        "        for idx,sentence in enumerate(ndf['text']):\n",
        "            test = claim.lower() in sentence.lower()\n",
        "            if test:\n",
        "                article = ref_data['Article'][i]\n",
        "                cdc_idx_dict[idx] = claim\n",
        "                cdc_idx_sent[idx] = [claim, sentence]\n",
        "                cdc_idx_art[idx] = [claim, article]\n",
        "                check_complete = True\n",
        "            elif idx == (len(ndf['text'])-1):\n",
        "                check_complete = True\n",
        "\n",
        "len(cdc_idx_dict), ref_data.shape[0]"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(2, 1332)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 1155
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "outputId": "0600d759-f96a-4cc6-eca1-383506f8d298",
        "id": "-2qYyTMhAkVS",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "cdc_idx_dict"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{1: 'affirmative action designed to improve the well being of perceived backward and under represented communities',\n",
              " 110: 'the identification of oppressed classes was difficult to carry out'}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 1156
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "TxOhqA1uAkVT",
        "colab": {}
      },
      "source": [
        "cdc = []\n",
        "\n",
        "for x in range(len(ndf)):\n",
        "    if x in list(cdc_idx_dict.keys()):\n",
        "        cdc.append(cdc_idx_dict.get(x))\n",
        "    else:\n",
        "        cdc.append('---')\n",
        "ndf['cdc'] = cdc\n",
        "\n",
        "df = pd.concat([ndf, df], axis=0, ignore_index=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "z3mcSXRDAkVU"
      },
      "source": [
        "#### Article 7"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "SLa631GuAkVU",
        "colab": {}
      },
      "source": [
        "with open(articles_dict[articles[7].replace(' ','_')+'.txt']) as article:\n",
        "        doc = article.read()\n",
        "\n",
        "c_doc = text_cleaner(doc)\n",
        "sentences = nltk.sent_tokenize(c_doc)\n",
        "sentences = [[sent, topic, articles[7]] for sent in sentences]\n",
        "\n",
        "ndf = pd.DataFrame(sentences, columns=['text', 'topic', 'article'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "outputId": "cd09a7c5-1a29-4f9f-938d-3b3a94268f38",
        "id": "fAl8_V8nAkVV",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "cdc_idx_dict = {}\n",
        "cdc_idx_sent = {}\n",
        "cdc_idx_art = {}\n",
        "\n",
        "for i,claim in enumerate(ref_data['clean_Claim']):\n",
        "    check_complete = False\n",
        "    while check_complete == False:\n",
        "        for idx,sentence in enumerate(ndf['text']):\n",
        "            test = claim.lower() in sentence.lower()\n",
        "            if test:\n",
        "                article = ref_data['Article'][i]\n",
        "                cdc_idx_dict[idx] = claim\n",
        "                cdc_idx_sent[idx] = [claim, sentence]\n",
        "                cdc_idx_art[idx] = [claim, article]\n",
        "                check_complete = True\n",
        "            elif idx == (len(ndf['text'])-1):\n",
        "                check_complete = True\n",
        "\n",
        "len(cdc_idx_dict), ref_data.shape[0]"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(1, 1332)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 1159
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "outputId": "058f3569-4c52-4b72-e836-8587a30d2d20",
        "id": "Y_t9j5-rAkVV",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "cdc_idx_dict"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{8: 'States must take measures to seek to eliminate prejudices'}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 1160
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "PqsWHARNAkVW",
        "colab": {}
      },
      "source": [
        "cdc = []\n",
        "\n",
        "for x in range(len(ndf)):\n",
        "    if x in list(cdc_idx_dict.keys()):\n",
        "        cdc.append(cdc_idx_dict.get(x))\n",
        "    else:\n",
        "        cdc.append('---')\n",
        "ndf['cdc'] = cdc\n",
        "\n",
        "df = pd.concat([ndf, df], axis=0, ignore_index=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "lnYPkkdoAkVX"
      },
      "source": [
        "#### Article 8"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "ceywQXdHAkVX",
        "colab": {}
      },
      "source": [
        "with open(articles_dict[articles[8].replace(' ','_')+'.txt']) as article:\n",
        "        doc = article.read()\n",
        "\n",
        "c_doc = text_cleaner(doc)\n",
        "sentences = nltk.sent_tokenize(c_doc)\n",
        "sentences = [[sent, topic, articles[8]] for sent in sentences]\n",
        "\n",
        "ndf = pd.DataFrame(sentences, columns=['text', 'topic', 'article'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "outputId": "00c08920-e5b2-40f6-d164-945529ea46d1",
        "id": "EIMMy6qOAkVY",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "cdc_idx_dict = {}\n",
        "cdc_idx_sent = {}\n",
        "cdc_idx_art = {}\n",
        "\n",
        "for i,claim in enumerate(ref_data['clean_Claim']):\n",
        "    check_complete = False\n",
        "    while check_complete == False:\n",
        "        for idx,sentence in enumerate(ndf['text']):\n",
        "            test = claim.lower() in sentence.lower()\n",
        "            if test:\n",
        "                article = ref_data['Article'][i]\n",
        "                cdc_idx_dict[idx] = claim\n",
        "                cdc_idx_sent[idx] = [claim, sentence]\n",
        "                cdc_idx_art[idx] = [claim, article]\n",
        "                check_complete = True\n",
        "            elif idx == (len(ndf['text'])-1):\n",
        "                check_complete = True\n",
        "\n",
        "len(cdc_idx_dict), ref_data.shape[0]"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(1, 1332)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 1163
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "outputId": "6f902aaa-ce80-4ba1-e112-a6fc7939e282",
        "id": "hIRw8X6WAkVZ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "cdc_idx_dict"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{5: 'is intended to ameliorate past discrimination'}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 1164
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "fFxyJzlfAkVZ",
        "colab": {}
      },
      "source": [
        "cdc = []\n",
        "\n",
        "for x in range(len(ndf)):\n",
        "    if x in list(cdc_idx_dict.keys()):\n",
        "        cdc.append(cdc_idx_dict.get(x))\n",
        "    else:\n",
        "        cdc.append('---')\n",
        "ndf['cdc'] = cdc\n",
        "\n",
        "df = pd.concat([ndf, df], axis=0, ignore_index=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "EvUhfXkSAkVa"
      },
      "source": [
        "#### Article 9"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "qkgIKAR0AkVa",
        "colab": {}
      },
      "source": [
        "with open(articles_dict[articles[9].replace(' ','_')+'.txt']) as article:\n",
        "        doc = article.read()\n",
        "\n",
        "c_doc = text_cleaner(doc)\n",
        "sentences = nltk.sent_tokenize(c_doc)\n",
        "sentences = [[sent, topic, articles[9]] for sent in sentences]\n",
        "\n",
        "ndf = pd.DataFrame(sentences, columns=['text', 'topic', 'article'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "outputId": "aa4eb7b4-ba70-48df-9408-a4bd95e63bb7",
        "id": "Dk2cU7__AkVb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "cdc_idx_dict = {}\n",
        "cdc_idx_sent = {}\n",
        "cdc_idx_art = {}\n",
        "\n",
        "for i,claim in enumerate(ref_data['clean_Claim']):\n",
        "    check_complete = False\n",
        "    while check_complete == False:\n",
        "        for idx,sentence in enumerate(ndf['text']):\n",
        "            test = claim.lower() in sentence.lower()\n",
        "            if test:\n",
        "                article = ref_data['Article'][i]\n",
        "                cdc_idx_dict[idx] = claim\n",
        "                cdc_idx_sent[idx] = [claim, sentence]\n",
        "                cdc_idx_art[idx] = [claim, article]\n",
        "                check_complete = True\n",
        "            elif idx == (len(ndf['text'])-1):\n",
        "                check_complete = True\n",
        "\n",
        "len(cdc_idx_dict), ref_data.shape[0]"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(7, 1332)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 1167
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "outputId": "67807d72-4174-4e11-960f-8cce94b01f4f",
        "id": "wZWr2tPlAkVc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "cdc_idx_dict"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{6: 'Historical racism continues to be reflected in socio-economic inequality',\n",
              " 7: 'Racial stratification continues to occur',\n",
              " 219: 'have been criticized as a form of \"reverse discrimination',\n",
              " 362: 'Motivation for affirmative action policies is to redress the effects of past discrimination',\n",
              " 366: 'these policies demonstrate an overt preference for applicants from particular backgrounds over better-qualified (or equally-qualified) candidates from other backgrounds',\n",
              " 367: 'the only consideration in choosing between applicants should be merit',\n",
              " 368: 'it perpetuates racial division'}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 1168
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "6km0YmeoAkVc",
        "colab": {}
      },
      "source": [
        "cdc = []\n",
        "\n",
        "for x in range(len(ndf)):\n",
        "    if x in list(cdc_idx_dict.keys()):\n",
        "        cdc.append(cdc_idx_dict.get(x))\n",
        "    else:\n",
        "        cdc.append('---')\n",
        "ndf['cdc'] = cdc\n",
        "\n",
        "df = pd.concat([ndf, df], axis=0, ignore_index=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "GtawIDp-AkVd"
      },
      "source": [
        "#### Article 10"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "4koVRr6pAkVd",
        "colab": {}
      },
      "source": [
        "with open(articles_dict[articles[10].replace(' ','_')+'.txt']) as article:\n",
        "        doc = article.read()\n",
        "\n",
        "c_doc = text_cleaner(doc)\n",
        "sentences = nltk.sent_tokenize(c_doc)\n",
        "sentences = [[sent, topic, articles[10]] for sent in sentences]\n",
        "\n",
        "ndf = pd.DataFrame(sentences, columns=['text', 'topic', 'article'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "outputId": "480a0bf4-46aa-4e17-d561-09d092194183",
        "id": "R5jAua1lAkVe",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "cdc_idx_dict = {}\n",
        "cdc_idx_sent = {}\n",
        "cdc_idx_art = {}\n",
        "\n",
        "for i,claim in enumerate(ref_data['clean_Claim']):\n",
        "    check_complete = False\n",
        "    while check_complete == False:\n",
        "        for idx,sentence in enumerate(ndf['text']):\n",
        "            test = claim.lower() in sentence.lower()\n",
        "            if test:\n",
        "                article = ref_data['Article'][i]\n",
        "                cdc_idx_dict[idx] = claim\n",
        "                cdc_idx_sent[idx] = [claim, sentence]\n",
        "                cdc_idx_art[idx] = [claim, article]\n",
        "                check_complete = True\n",
        "            elif idx == (len(ndf['text'])-1):\n",
        "                check_complete = True\n",
        "\n",
        "len(cdc_idx_dict), ref_data.shape[0]"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(3, 1332)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 1171
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "outputId": "5988afc5-dda0-4360-a093-2364004b4adb",
        "id": "R1sM-OCnAkVf",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "cdc_idx_dict"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{129: 'attempts at antidiscrimination have been criticized as reverse discrimination',\n",
              " 130: 'affirmative action) discriminate against members of a dominant or majority group',\n",
              " 135: \"each individual's civil rights include the right to be free from government sponsored social discrimination\"}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 1172
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "KdVdNx_tAkVh",
        "colab": {}
      },
      "source": [
        "cdc = []\n",
        "\n",
        "for x in range(len(ndf)):\n",
        "    if x in list(cdc_idx_dict.keys()):\n",
        "        cdc.append(cdc_idx_dict.get(x))\n",
        "    else:\n",
        "        cdc.append('---')\n",
        "ndf['cdc'] = cdc\n",
        "\n",
        "df = pd.concat([ndf, df], axis=0, ignore_index=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "LwvUg42gAkVk"
      },
      "source": [
        "#### Article 11 "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "U9DlQpKRAkVk",
        "colab": {}
      },
      "source": [
        "with open(articles_dict[articles[11].replace(' ','_')+'.txt']) as article:\n",
        "        doc = article.read()\n",
        "\n",
        "c_doc = text_cleaner(doc)\n",
        "sentences = nltk.sent_tokenize(c_doc)\n",
        "sentences = [[sent, topic, articles[11]] for sent in sentences]\n",
        "\n",
        "ndf = pd.DataFrame(sentences, columns=['text', 'topic', 'article'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "outputId": "1e0ead7e-2479-4a5e-8cd4-a57e7aeb164b",
        "id": "RSEq1EsaAkVl",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "cdc_idx_dict = {}\n",
        "cdc_idx_sent = {}\n",
        "cdc_idx_art = {}\n",
        "\n",
        "for i,claim in enumerate(ref_data['clean_Claim']):\n",
        "    check_complete = False\n",
        "    while check_complete == False:\n",
        "        for idx,sentence in enumerate(ndf['text']):\n",
        "            test = claim.lower() in sentence.lower()\n",
        "            if test:\n",
        "                article = ref_data['Article'][i]\n",
        "                cdc_idx_dict[idx] = claim\n",
        "                cdc_idx_sent[idx] = [claim, sentence]\n",
        "                cdc_idx_art[idx] = [claim, article]\n",
        "                check_complete = True\n",
        "            elif idx == (len(ndf['text'])-1):\n",
        "                check_complete = True\n",
        "\n",
        "len(cdc_idx_dict), ref_data.shape[0]"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(1, 1332)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 1175
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "outputId": "97b56706-a0a9-4eae-e996-7e1d280048d4",
        "id": "LhNvJaLUAkVl",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "cdc_idx_dict"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{16: 'affirmative action is racial division, not racial reconciliation'}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 1176
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "FplV78zHAkVm",
        "colab": {}
      },
      "source": [
        "cdc = []\n",
        "\n",
        "for x in range(len(ndf)):\n",
        "    if x in list(cdc_idx_dict.keys()):\n",
        "        cdc.append(cdc_idx_dict.get(x))\n",
        "    else:\n",
        "        cdc.append('---')\n",
        "ndf['cdc'] = cdc\n",
        "\n",
        "df = pd.concat([ndf, df], axis=0, ignore_index=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "FYUqZ40EAkVn"
      },
      "source": [
        "#### Article 12"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "BlN5oldwAkVn",
        "colab": {}
      },
      "source": [
        "with open(articles_dict[articles[12].replace(' ','_')+'.txt']) as article:\n",
        "        doc = article.read()\n",
        "\n",
        "c_doc = text_cleaner(doc)\n",
        "sentences = nltk.sent_tokenize(c_doc)\n",
        "sentences = [[sent, topic, articles[12]] for sent in sentences]\n",
        "\n",
        "ndf = pd.DataFrame(sentences, columns=['text', 'topic', 'article'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "outputId": "2bc2c66b-9ff4-4cc7-ae8d-16779e1a663d",
        "id": "ead9Dx7bAkVy",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "cdc_idx_dict = {}\n",
        "cdc_idx_sent = {}\n",
        "cdc_idx_art = {}\n",
        "\n",
        "for i,claim in enumerate(ref_data['clean_Claim']):\n",
        "    check_complete = False\n",
        "    while check_complete == False:\n",
        "        for idx,sentence in enumerate(ndf['text']):\n",
        "            test = claim.lower() in sentence.lower()\n",
        "            if test:\n",
        "                article = ref_data['Article'][i]\n",
        "                cdc_idx_dict[idx] = claim\n",
        "                cdc_idx_sent[idx] = [claim, sentence]\n",
        "                cdc_idx_art[idx] = [claim, article]\n",
        "                check_complete = True\n",
        "            elif idx == (len(ndf['text'])-1):\n",
        "                check_complete = True\n",
        "\n",
        "len(cdc_idx_dict), ref_data.shape[0]"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(1, 1332)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 1179
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "outputId": "8c455a06-e904-4b4c-8340-69582428d5a3",
        "id": "0byxR3TLAkVz",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "cdc_idx_dict"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{68: 'it violates the principle of equal treatment just as much as negative discrimination'}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 1180
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "2UFr48AkAkV0",
        "colab": {}
      },
      "source": [
        "cdc = []\n",
        "\n",
        "for x in range(len(ndf)):\n",
        "    if x in list(cdc_idx_dict.keys()):\n",
        "        cdc.append(cdc_idx_dict.get(x))\n",
        "    else:\n",
        "        cdc.append('---')\n",
        "ndf['cdc'] = cdc\n",
        "\n",
        "df = pd.concat([ndf, df], axis=0, ignore_index=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "nfv32dYqAkV1"
      },
      "source": [
        "#### Article 13"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "D8D0bEpiAkV1",
        "colab": {}
      },
      "source": [
        "with open(articles_dict[articles[13].replace(' ','_')+'.txt']) as article:\n",
        "        doc = article.read()\n",
        "\n",
        "c_doc = text_cleaner(doc)\n",
        "sentences = nltk.sent_tokenize(c_doc)\n",
        "sentences = [[sent, topic, articles[13]] for sent in sentences]\n",
        "\n",
        "ndf = pd.DataFrame(sentences, columns=['text', 'topic', 'article'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "outputId": "fd5239fe-2f7e-4f2f-85b1-2dd70a608c7d",
        "id": "b6s_PCJxAkV2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "cdc_idx_dict = {}\n",
        "cdc_idx_sent = {}\n",
        "cdc_idx_art = {}\n",
        "\n",
        "for i,claim in enumerate(ref_data['clean_Claim']):\n",
        "    check_complete = False\n",
        "    while check_complete == False:\n",
        "        for idx,sentence in enumerate(ndf['text']):\n",
        "            test = claim.lower() in sentence.lower()\n",
        "            if test:\n",
        "                article = ref_data['Article'][i]\n",
        "                cdc_idx_dict[idx] = claim\n",
        "                cdc_idx_sent[idx] = [claim, sentence]\n",
        "                cdc_idx_art[idx] = [claim, article]\n",
        "                check_complete = True\n",
        "            elif idx == (len(ndf['text'])-1):\n",
        "                check_complete = True\n",
        "\n",
        "len(cdc_idx_dict), ref_data.shape[0]"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(4, 1332)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 1183
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "outputId": "5da5cec6-fc3f-4df4-f8c1-045429e20e90",
        "id": "5OPb6lz1AkV3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "cdc_idx_dict"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{78: \"recognition and rights accorded to specific groups may interfere with the state's need to establish a cohesive identity\",\n",
              " 80: 'where members of minorities see that their specific needs and ambitions have been acknowledged and catered for, they will commit themselves more willingly to accepting the legitimacy of the nation',\n",
              " 83: 'These may be considered necessary because the minority group in question is socially disadvantaged',\n",
              " 89: 'the political function of rights is precisely to protect minorities from oppression by majorities'}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 1184
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "NcaZHrfhAkV3",
        "colab": {}
      },
      "source": [
        "cdc = []\n",
        "\n",
        "for x in range(len(ndf)):\n",
        "    if x in list(cdc_idx_dict.keys()):\n",
        "        cdc.append(cdc_idx_dict.get(x))\n",
        "    else:\n",
        "        cdc.append('---')\n",
        "ndf['cdc'] = cdc\n",
        "\n",
        "df = pd.concat([ndf, df], axis=0, ignore_index=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "Q5sdzRFJAkV4"
      },
      "source": [
        "#### Article 14 "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "S4H8elbLAkV4",
        "colab": {}
      },
      "source": [
        "with open(articles_dict[articles[14].replace(' ','_')+'.txt']) as article:\n",
        "        doc = article.read()\n",
        "\n",
        "c_doc = text_cleaner(doc)\n",
        "sentences = nltk.sent_tokenize(c_doc)\n",
        "sentences = [[sent, topic, articles[14]] for sent in sentences]\n",
        "\n",
        "ndf = pd.DataFrame(sentences, columns=['text', 'topic', 'article'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "outputId": "f4b7d6fa-5d00-401f-d5b7-980772588bb8",
        "id": "58GySRJfAkV5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "cdc_idx_dict = {}\n",
        "cdc_idx_sent = {}\n",
        "cdc_idx_art = {}\n",
        "\n",
        "for i,claim in enumerate(ref_data['clean_Claim']):\n",
        "    check_complete = False\n",
        "    while check_complete == False:\n",
        "        for idx,sentence in enumerate(ndf['text']):\n",
        "            test = claim.lower() in sentence.lower()\n",
        "            if test:\n",
        "                article = ref_data['Article'][i]\n",
        "                cdc_idx_dict[idx] = claim\n",
        "                cdc_idx_sent[idx] = [claim, sentence]\n",
        "                cdc_idx_art[idx] = [claim, article]\n",
        "                check_complete = True\n",
        "            elif idx == (len(ndf['text'])-1):\n",
        "                check_complete = True\n",
        "\n",
        "len(cdc_idx_dict), ref_data.shape[0]"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(8, 1332)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 1187
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "outputId": "38ce1f99-9fef-4fff-b541-17107b3b5681",
        "id": "dqWK4aWHAkV6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "cdc_idx_dict"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{1: 'jobs should go to those “most qualified',\n",
              " 29: 'The selection process should not be based on some arbitrary or irrelevant criterion',\n",
              " 52: \"race and sex shouldn't matter when getting a job\",\n",
              " 65: 'final selection for posts must be made according to the principle the best person for the job',\n",
              " 67: 'the overall idea is to give children from less fortunate backgrounds more of a chance',\n",
              " 78: 'The idea is to help disadvantaged groups get back to a normal starting position after a long period of discrimination',\n",
              " 192: 'any equalities achieved will entail future inequalities',\n",
              " 202: 'it is an ideal that cannot and should not be realized through the actions of the government'}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 1188
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "J3JZft-bAkV6",
        "colab": {}
      },
      "source": [
        "cdc = []\n",
        "\n",
        "for x in range(len(ndf)):\n",
        "    if x in list(cdc_idx_dict.keys()):\n",
        "        cdc.append(cdc_idx_dict.get(x))\n",
        "    else:\n",
        "        cdc.append('---')\n",
        "ndf['cdc'] = cdc\n",
        "\n",
        "df = pd.concat([ndf, df], axis=0, ignore_index=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "78PDnG-mAkV7"
      },
      "source": [
        "#### Article 15"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "XFlG8O30AkV7",
        "colab": {}
      },
      "source": [
        "with open(articles_dict[articles[15].replace(' ','_')+'.txt']) as article:\n",
        "        doc = article.read()\n",
        "\n",
        "c_doc = text_cleaner(doc)\n",
        "sentences = nltk.sent_tokenize(c_doc)\n",
        "sentences = [[sent, topic, articles[15]] for sent in sentences]\n",
        "\n",
        "ndf = pd.DataFrame(sentences, columns=['text', 'topic', 'article'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "outputId": "c6516033-d149-45d1-bfb7-cdeb5374fd1a",
        "id": "tFoKCywiAkV8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "cdc_idx_dict = {}\n",
        "cdc_idx_sent = {}\n",
        "cdc_idx_art = {}\n",
        "\n",
        "for i,claim in enumerate(ref_data['clean_Claim']):\n",
        "    check_complete = False\n",
        "    while check_complete == False:\n",
        "        for idx,sentence in enumerate(ndf['text']):\n",
        "            test = claim.lower() in sentence.lower()\n",
        "            if test:\n",
        "                article = ref_data['Article'][i]\n",
        "                cdc_idx_dict[idx] = claim\n",
        "                cdc_idx_sent[idx] = [claim, sentence]\n",
        "                cdc_idx_art[idx] = [claim, article]\n",
        "                check_complete = True\n",
        "            elif idx == (len(ndf['text'])-1):\n",
        "                check_complete = True\n",
        "\n",
        "len(cdc_idx_dict), ref_data.shape[0]"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(3, 1332)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 1191
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "outputId": "9fa55064-2dcb-47cf-cdde-b5ebb685fd13",
        "id": "747MK2s0AkV-",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "cdc_idx_dict"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{11: 'those that give preference to individuals solely based on their race or gender should not be permitted',\n",
              " 70: 'social inequality today is due to \"cultural deficits\" of individual people or racial or ethnic groups',\n",
              " 71: 'there is no need to pay \"systematic attention\" to any current inequities'}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 1192
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "88wizlwXAkWA",
        "colab": {}
      },
      "source": [
        "cdc = []\n",
        "\n",
        "for x in range(len(ndf)):\n",
        "    if x in list(cdc_idx_dict.keys()):\n",
        "        cdc.append(cdc_idx_dict.get(x))\n",
        "    else:\n",
        "        cdc.append('---')\n",
        "ndf['cdc'] = cdc\n",
        "\n",
        "df = pd.concat([ndf, df], axis=0, ignore_index=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "V0NaMqb_AkWC"
      },
      "source": [
        "#### Article 16"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "BZCUIzUXAkWD",
        "colab": {}
      },
      "source": [
        "with open(articles_dict[articles[16].replace(' ','_')+'.txt']) as article:\n",
        "        doc = article.read()\n",
        "\n",
        "c_doc = text_cleaner(doc)\n",
        "sentences = nltk.sent_tokenize(c_doc)\n",
        "sentences = [[sent, topic, articles[16]] for sent in sentences]\n",
        "\n",
        "ndf = pd.DataFrame(sentences, columns=['text', 'topic', 'article'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "outputId": "7763810b-4d98-40f8-8484-ff8338ba9cec",
        "id": "5Pm_BJlBAkWE",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "cdc_idx_dict = {}\n",
        "cdc_idx_sent = {}\n",
        "cdc_idx_art = {}\n",
        "\n",
        "for i,claim in enumerate(ref_data['clean_Claim']):\n",
        "    check_complete = False\n",
        "    while check_complete == False:\n",
        "        for idx,sentence in enumerate(ndf['text']):\n",
        "            test = claim.lower() in sentence.lower()\n",
        "            if test:\n",
        "                article = ref_data['Article'][i]\n",
        "                cdc_idx_dict[idx] = claim\n",
        "                cdc_idx_sent[idx] = [claim, sentence]\n",
        "                cdc_idx_art[idx] = [claim, article]\n",
        "                check_complete = True\n",
        "            elif idx == (len(ndf['text'])-1):\n",
        "                check_complete = True\n",
        "\n",
        "len(cdc_idx_dict), ref_data.shape[0]"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(1, 1332)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 1195
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "outputId": "751baef3-b1fa-43fe-f82d-68bf8817c39a",
        "id": "pQMs9DVUAkWG",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "cdc_idx_dict"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{4: 'Racial prejudice and discrimination no longer exists'}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 1196
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "EK_7HD1oAkWH",
        "colab": {}
      },
      "source": [
        "cdc = []\n",
        "\n",
        "for x in range(len(ndf)):\n",
        "    if x in list(cdc_idx_dict.keys()):\n",
        "        cdc.append(cdc_idx_dict.get(x))\n",
        "    else:\n",
        "        cdc.append('---')\n",
        "ndf['cdc'] = cdc\n",
        "\n",
        "df = pd.concat([ndf, df], axis=0, ignore_index=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "FDsbVYE6AkWH"
      },
      "source": [
        "#### Article 17"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "anEMs2Y3AkWI",
        "colab": {}
      },
      "source": [
        "with open(articles_dict[articles[17].replace(' ','_')+'.txt']) as article:\n",
        "        doc = article.read()\n",
        "\n",
        "c_doc = text_cleaner(doc)\n",
        "sentences = nltk.sent_tokenize(c_doc)\n",
        "sentences = [[sent, topic, articles[17]] for sent in sentences]\n",
        "\n",
        "ndf = pd.DataFrame(sentences, columns=['text', 'topic', 'article'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "outputId": "7d29bb8c-b027-4657-d879-0b4dd19b8b9c",
        "id": "2cjIJkSmAkWI",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "cdc_idx_dict = {}\n",
        "cdc_idx_sent = {}\n",
        "cdc_idx_art = {}\n",
        "\n",
        "for i,claim in enumerate(ref_data['clean_Claim']):\n",
        "    check_complete = False\n",
        "    while check_complete == False:\n",
        "        for idx,sentence in enumerate(ndf['text']):\n",
        "            test = claim.lower() in sentence.lower()\n",
        "            if test:\n",
        "                article = ref_data['Article'][i]\n",
        "                cdc_idx_dict[idx] = claim\n",
        "                cdc_idx_sent[idx] = [claim, sentence]\n",
        "                cdc_idx_art[idx] = [claim, article]\n",
        "                check_complete = True\n",
        "            elif idx == (len(ndf['text'])-1):\n",
        "                check_complete = True\n",
        "\n",
        "len(cdc_idx_dict), ref_data.shape[0]"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(1, 1332)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 1199
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "outputId": "ef8d4468-91be-467f-8e73-41859c28ebce",
        "id": "9NWF8d_TAkWJ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "cdc_idx_dict"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{4: 'merit\" itself should be a primary consideration during evaluation'}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 1200
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "vMfvl2PfAkWK",
        "colab": {}
      },
      "source": [
        "cdc = []\n",
        "\n",
        "for x in range(len(ndf)):\n",
        "    if x in list(cdc_idx_dict.keys()):\n",
        "        cdc.append(cdc_idx_dict.get(x))\n",
        "    else:\n",
        "        cdc.append('---')\n",
        "ndf['cdc'] = cdc\n",
        "\n",
        "df = pd.concat([ndf, df], axis=0, ignore_index=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "pmg2iDpZAkWK"
      },
      "source": [
        "#### Article 18 "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "m3_kbHKwAkWK",
        "colab": {}
      },
      "source": [
        "with open(articles_dict[articles[18].replace(' ','_')+'.txt']) as article:\n",
        "        doc = article.read()\n",
        "\n",
        "c_doc = text_cleaner(doc)\n",
        "sentences = nltk.sent_tokenize(c_doc)\n",
        "sentences = [[sent, topic, articles[18]] for sent in sentences]\n",
        "\n",
        "ndf = pd.DataFrame(sentences, columns=['text', 'topic', 'article'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "outputId": "37e1eb27-2784-42db-d75f-994130293ac0",
        "id": "TDxv6P2tAkWL",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "cdc_idx_dict = {}\n",
        "cdc_idx_sent = {}\n",
        "cdc_idx_art = {}\n",
        "\n",
        "for i,claim in enumerate(ref_data['clean_Claim']):\n",
        "    check_complete = False\n",
        "    while check_complete == False:\n",
        "        for idx,sentence in enumerate(ndf['text']):\n",
        "            test = claim.lower() in sentence.lower()\n",
        "            if test:\n",
        "                article = ref_data['Article'][i]\n",
        "                cdc_idx_dict[idx] = claim\n",
        "                cdc_idx_sent[idx] = [claim, sentence]\n",
        "                cdc_idx_art[idx] = [claim, article]\n",
        "                check_complete = True\n",
        "            elif idx == (len(ndf['text'])-1):\n",
        "                check_complete = True\n",
        "\n",
        "len(cdc_idx_dict), ref_data.shape[0]"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(15, 1332)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 1203
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "outputId": "b4a276d1-d7d6-451e-ae58-d8b1ac3fe452",
        "id": "u4wjjlj0AkWN",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "cdc_idx_dict"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{4: 'The impetus towards affirmative action is to redress the disadvantages associated with overt historical discrimination',\n",
              " 7: 'have been criticised as a form of reverse discrimination',\n",
              " 37: 'aims \"to correct the effects of past and present discrimination',\n",
              " 90: 'no one has a legal right to have any demographic characteristic they possess be considered a favorable point on their behalf',\n",
              " 110: 'Race-conscious affirmative action remains necessary to address race-based obstacles',\n",
              " 115: 'it is often contested on constitutional grounds',\n",
              " 134: 'affirmative action requires the very discrimination it is seeking to eliminate',\n",
              " 135: 'affirmative action counter-productive',\n",
              " 138: 'affirmative action lowers the bar',\n",
              " 141: 'it fails to achieve its goals',\n",
              " 142: 'encourages groups to identify themselves as disadvantaged, even if they are not',\n",
              " 143: 'It may increase racial tension',\n",
              " 147: \"affirmative action devalues the accomplishments of people who belong to a group it's supposed to help\",\n",
              " 150: 'it creates \"a cult of victimization',\n",
              " 153: 'They reduce the incentives of both the preferred and non-preferred to perform at their best'}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 1204
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "irAl0zpFAkWO",
        "colab": {}
      },
      "source": [
        "cdc = []\n",
        "\n",
        "for x in range(len(ndf)):\n",
        "    if x in list(cdc_idx_dict.keys()):\n",
        "        cdc.append(cdc_idx_dict.get(x))\n",
        "    else:\n",
        "        cdc.append('---')\n",
        "ndf['cdc'] = cdc\n",
        "\n",
        "df = pd.concat([ndf, df], axis=0, ignore_index=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "94rhiWH5MWHP"
      },
      "source": [
        "#### Article 19"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "s5txmi8gMWHQ",
        "colab": {}
      },
      "source": [
        "with open(articles_dict[articles[19].replace(' ','_')+'.txt']) as article:\n",
        "        doc = article.read()\n",
        "\n",
        "c_doc = text_cleaner(doc)\n",
        "sentences = nltk.sent_tokenize(c_doc)\n",
        "sentences = [[sent, topic, articles[19]] for sent in sentences]\n",
        "\n",
        "ndf = pd.DataFrame(sentences, columns=['text', 'topic', 'article'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "outputId": "ba2d6345-d36b-486b-f5ef-0b927d32ea5e",
        "id": "DeoI3XbwMWHS",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "cdc_idx_dict = {}\n",
        "cdc_idx_sent = {}\n",
        "cdc_idx_art = {}\n",
        "\n",
        "for i,claim in enumerate(ref_data['clean_Claim']):\n",
        "    check_complete = False\n",
        "    while check_complete == False:\n",
        "        for idx,sentence in enumerate(ndf['text']):\n",
        "            test = claim.lower() in sentence.lower()\n",
        "            if test:\n",
        "                article = ref_data['Article'][i]\n",
        "                cdc_idx_dict[idx] = claim\n",
        "                cdc_idx_sent[idx] = [claim, sentence]\n",
        "                cdc_idx_art[idx] = [claim, article]\n",
        "                check_complete = True\n",
        "            elif idx == (len(ndf['text'])-1):\n",
        "                check_complete = True\n",
        "\n",
        "len(cdc_idx_dict), ref_data.shape[0]"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(15, 1332)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 1207
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "outputId": "80d1533c-d2d3-4ca0-a7e7-23983f90a58a",
        "id": "1FYdtgLSMWHT",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "cdc_idx_dict"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{1: 'countering the effects of a history of discrimination',\n",
              " 7: 'Affirmative action is intended to promote equal opportunity',\n",
              " 8: 'to ensure that minority groups within a society are included in all programs',\n",
              " 9: 'it helps to compensate for past discrimination, persecution or exploitation by the ruling class of a culture',\n",
              " 18: 'the principle of equality sometimes requires States parties to take affirmative action in order to diminish or eliminate conditions which cause or help to perpetuate discrimination prohibited by the Covenant',\n",
              " 22: 'In some countries which have laws on racial equality, affirmative action is rendered illegal because it does not treat all races equally',\n",
              " 159: 'These laws cause disproportionally high costs for small companies and reduce economic growth and employment',\n",
              " 162: 'it is impossible to favor somebody without discriminating against others',\n",
              " 173: 'affirmative action devalues the accomplishments of people who are chosen based on the social group to which they belong rather than their qualifications',\n",
              " 174: 'affirmative action devalues the accomplishments of all those who belong to groups it is intended to help, therefore making affirmative action counterproductive',\n",
              " 175: 'affirmative action has undesirable side-effects',\n",
              " 176: 'undermines the achievements of minorities',\n",
              " 177: 'It may increase racial tension',\n",
              " 179: 'They reduce the incentives of both the preferred and non-preferred to perform at their best',\n",
              " 183: 'affirmative action hurts its intended beneficiaries'}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 1208
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "1Lh2KLWaMWHU",
        "colab": {}
      },
      "source": [
        "cdc = []\n",
        "\n",
        "for x in range(len(ndf)):\n",
        "    if x in list(cdc_idx_dict.keys()):\n",
        "        cdc.append(cdc_idx_dict.get(x))\n",
        "    else:\n",
        "        cdc.append('---')\n",
        "ndf['cdc'] = cdc\n",
        "\n",
        "df = pd.concat([ndf, df], axis=0, ignore_index=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OOV2-HQ1z2Um",
        "colab_type": "text"
      },
      "source": [
        "### 'the use of performance enhancing drugs in professional sports '"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "outputId": "b218d978-ef9a-4d6b-d8df-7e0bda787bf6",
        "id": "3EzCyfzt1xdo",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "topic = 'the use of performance enhancing drugs in professional sports '\n",
        "\n",
        "articles = topic_article_dict[topic]\n",
        "articles"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['Substance abuse',\n",
              " 'Anabolic steroid',\n",
              " 'Use of performance-enhancing drugs in sport',\n",
              " 'Ergogenic use of anabolic steroids',\n",
              " 'Mitchell Report',\n",
              " 'Drug Enforcement Administration',\n",
              " 'Doping in East Germany']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 1210
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-JRHSGb31xJ3",
        "colab_type": "code",
        "outputId": "0da1d3c3-ea2b-4b06-ea96-06c00bbdcde1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "len(articles)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "7"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 1211
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "FhsXqJFP1xdp"
      },
      "source": [
        "#### Article 0 "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "qzfpG-Bw1xdp",
        "colab": {}
      },
      "source": [
        "with open(articles_dict[articles[0].replace(' ','_')+'.txt']) as article:\n",
        "        doc = article.read()\n",
        "\n",
        "c_doc = text_cleaner(doc)\n",
        "sentences = nltk.sent_tokenize(c_doc)\n",
        "sentences = [[sent, topic, articles[0]] for sent in sentences]\n",
        "\n",
        "ndf = pd.DataFrame(sentences, columns=['text', 'topic', 'article'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "outputId": "c98a8351-f1a9-4976-e07a-c93397c043a2",
        "id": "B6bnc5Ao1xdr",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "cdc_idx_dict = {}\n",
        "cdc_idx_sent = {}\n",
        "cdc_idx_art = {}\n",
        "\n",
        "for i,claim in enumerate(ref_data['clean_Claim']):\n",
        "    check_complete = False\n",
        "    while check_complete == False:\n",
        "        for idx,sentence in enumerate(ndf['text']):\n",
        "            test = claim.lower() in sentence.lower()\n",
        "            if test:\n",
        "                article = ref_data['Article'][i]\n",
        "                cdc_idx_dict[idx] = claim\n",
        "                cdc_idx_sent[idx] = [claim, sentence]\n",
        "                cdc_idx_art[idx] = [claim, article]\n",
        "                check_complete = True\n",
        "            elif idx == (len(ndf['text'])-1):\n",
        "                check_complete = True\n",
        "\n",
        "len(cdc_idx_dict), ref_data.shape[0]"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(1, 1332)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 1213
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "outputId": "220a2816-ef4d-4522-ffc3-7cba24ee2225",
        "id": "jkLSh3yR1xdt",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "cdc_idx_dict"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{82: 'Substance abuse can be harmful to your health and may even be deadly in certain scenarios'}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 1214
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "iPiZRjHM1xdu",
        "colab": {}
      },
      "source": [
        "cdc = []\n",
        "\n",
        "for x in range(len(ndf)):\n",
        "    if x in list(cdc_idx_dict.keys()):\n",
        "        cdc.append(cdc_idx_dict.get(x))\n",
        "    else:\n",
        "        cdc.append('---')\n",
        "ndf['cdc'] = cdc\n",
        "\n",
        "df = pd.concat([ndf, df], axis=0, ignore_index=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "0IUZYqnS1xdv"
      },
      "source": [
        "#### Article 1 "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "Utp1PDTX1xdv",
        "colab": {}
      },
      "source": [
        "with open(articles_dict[articles[1].replace(' ','_')+'.txt']) as article:\n",
        "        doc = article.read()\n",
        "\n",
        "c_doc = text_cleaner(doc)\n",
        "sentences = nltk.sent_tokenize(c_doc)\n",
        "sentences = [[sent, topic, articles[1]] for sent in sentences]\n",
        "\n",
        "ndf = pd.DataFrame(sentences, columns=['text', 'topic', 'article'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "outputId": "18267dec-728c-4c9c-9f81-88ae781549e9",
        "id": "kOqicZj01xdw",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "cdc_idx_dict = {}\n",
        "cdc_idx_sent = {}\n",
        "cdc_idx_art = {}\n",
        "\n",
        "for i,claim in enumerate(ref_data['clean_Claim']):\n",
        "    check_complete = False\n",
        "    while check_complete == False:\n",
        "        for idx,sentence in enumerate(ndf['text']):\n",
        "            test = claim.lower() in sentence.lower()\n",
        "            if test:\n",
        "                article = ref_data['Article'][i]\n",
        "                cdc_idx_dict[idx] = claim\n",
        "                cdc_idx_sent[idx] = [claim, sentence]\n",
        "                cdc_idx_art[idx] = [claim, article]\n",
        "                check_complete = True\n",
        "            elif idx == (len(ndf['text'])-1):\n",
        "                check_complete = True\n",
        "\n",
        "len(cdc_idx_dict), ref_data.shape[0]"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(1, 1332)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 1217
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "outputId": "c0f765c3-c928-4a26-a488-84895f6064d6",
        "id": "GsUZGWE81xdx",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "cdc_idx_dict"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{6: 'Health risks can be produced by long-term use or excessive doses of anabolic steroids'}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 1218
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "O_i2rWSO1xdy",
        "colab": {}
      },
      "source": [
        "cdc = []\n",
        "\n",
        "for x in range(len(ndf)):\n",
        "    if x in list(cdc_idx_dict.keys()):\n",
        "        cdc.append(cdc_idx_dict.get(x))\n",
        "    else:\n",
        "        cdc.append('---')\n",
        "ndf['cdc'] = cdc\n",
        "\n",
        "df = pd.concat([df, ndf], axis=0, ignore_index=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "9YAUTI8M1xdy"
      },
      "source": [
        "#### Article 2 "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "2m_BmGO01xdy",
        "colab": {}
      },
      "source": [
        "with open(articles_dict[articles[2].replace(' ','_')+'.txt']) as article:\n",
        "        doc = article.read()\n",
        "\n",
        "c_doc = text_cleaner(doc)\n",
        "sentences = nltk.sent_tokenize(c_doc)\n",
        "sentences = [[sent, topic, articles[2]] for sent in sentences]\n",
        "\n",
        "ndf = pd.DataFrame(sentences, columns=['text', 'topic', 'article'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "outputId": "c3b0c1eb-1bb2-44ab-f89b-c20afe736eea",
        "id": "sNQvXb1k1xdz",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "cdc_idx_dict = {}\n",
        "cdc_idx_sent = {}\n",
        "cdc_idx_art = {}\n",
        "\n",
        "for i,claim in enumerate(ref_data['clean_Claim']):\n",
        "    check_complete = False\n",
        "    while check_complete == False:\n",
        "        for idx,sentence in enumerate(ndf['text']):\n",
        "            test = claim.lower() in sentence.lower()\n",
        "            if test:\n",
        "                article = ref_data['Article'][i]\n",
        "                cdc_idx_dict[idx] = claim\n",
        "                cdc_idx_sent[idx] = [claim, sentence]\n",
        "                cdc_idx_art[idx] = [claim, article]\n",
        "                check_complete = True\n",
        "            elif idx == (len(ndf['text'])-1):\n",
        "                check_complete = True\n",
        "\n",
        "len(cdc_idx_dict), ref_data.shape[0]"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(15, 1332)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 1221
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "outputId": "8abf6804-3594-49e8-b9ef-215d87f17af3",
        "id": "lgKMMNgf1xd0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "cdc_idx_dict"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{4: 'it is little different from the use of new materials in the construction of suits and sporting equipment, which similarly aid performance and can give competitors an unfair advantage over others',\n",
              " 190: 'The use of anabolic steroids is now banned by all major sporting bodies',\n",
              " 191: 'drug testing can be wildly inconsistent and, in some instances, has gone unenforced',\n",
              " 232: 'there is little danger from anabolica, as they call it, when the athletes are kept on strictly monitored programmes',\n",
              " 233: 'the extremely dangerous side-effects are admitted',\n",
              " 252: 'Often, doping was carried out without the knowledge of the athletes, some of them as young as ten years of age',\n",
              " 253: 'former athletes bear the physical and mental scars of years of drug abuse',\n",
              " 292: 'the pursuit of doping athletes has turned into a modern day witch-hunt',\n",
              " 294: 'Many sports organizations have banned the use of performance enhancing drugs and have very strict rules and consequences for people who are caught using them',\n",
              " 308: 'as outright prevention of doping is an impossibility, all doping should be legalised',\n",
              " 309: 'harmful long-term effects of many doping agents',\n",
              " 310: 'with no medical data to support these claimed health problems, it is, at best, questionable',\n",
              " 311: 'with doping legal, all competitive athletes would be compelled to use drugs, and the net effect would be a level playing field but with widespread health consequences',\n",
              " 313: 'doping could be legalized to some extent using a drug whitelist and medical counseling, such that medical safety is ensured, with all usage published',\n",
              " 339: 'some athletes point to the already dangerous environment in sports like football and martial arts and wonder if there is a double standard where health concerns brought by the aggressive nature of these sports is viewed acceptable but not PEDs'}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 1222
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "jHUwzzgz1xd1",
        "colab": {}
      },
      "source": [
        "cdc = []\n",
        "\n",
        "for x in range(len(ndf)):\n",
        "    if x in list(cdc_idx_dict.keys()):\n",
        "        cdc.append(cdc_idx_dict.get(x))\n",
        "    else:\n",
        "        cdc.append('---')\n",
        "ndf['cdc'] = cdc\n",
        "\n",
        "df = pd.concat([ndf, df], axis=0, ignore_index=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "uBGKRjIY1xd2"
      },
      "source": [
        "#### Article 3 "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "5hKh2oDj1xd2",
        "colab": {}
      },
      "source": [
        "with open(articles_dict[articles[3].replace(' ','_')+'.txt']) as article:\n",
        "        doc = article.read()\n",
        "\n",
        "c_doc = text_cleaner(doc)\n",
        "sentences = nltk.sent_tokenize(c_doc)\n",
        "sentences = [[sent, topic, articles[3]] for sent in sentences]\n",
        "\n",
        "ndf = pd.DataFrame(sentences, columns=['text', 'topic', 'article'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "outputId": "d4927c49-dfb4-4283-ac75-357d54016c19",
        "id": "WgQRyT6a1xd2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "cdc_idx_dict = {}\n",
        "cdc_idx_sent = {}\n",
        "cdc_idx_art = {}\n",
        "\n",
        "for i,claim in enumerate(ref_data['clean_Claim']):\n",
        "    check_complete = False\n",
        "    while check_complete == False:\n",
        "        for idx,sentence in enumerate(ndf['text']):\n",
        "            test = claim.lower() in sentence.lower()\n",
        "            if test:\n",
        "                article = ref_data['Article'][i]\n",
        "                cdc_idx_dict[idx] = claim\n",
        "                cdc_idx_sent[idx] = [claim, sentence]\n",
        "                cdc_idx_art[idx] = [claim, article]\n",
        "                check_complete = True\n",
        "            elif idx == (len(ndf['text'])-1):\n",
        "                check_complete = True\n",
        "\n",
        "len(cdc_idx_dict), ref_data.shape[0]"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(1, 1332)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 1225
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "outputId": "f7842036-05aa-44cb-afa3-538d568d6ba3",
        "id": "4pDXXjaF1xd3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "cdc_idx_dict"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{3: 'There is a wide range of health concerns for users'}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 1226
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "bb2uclV51xd4",
        "colab": {}
      },
      "source": [
        "cdc = []\n",
        "\n",
        "for x in range(len(ndf)):\n",
        "    if x in list(cdc_idx_dict.keys()):\n",
        "        cdc.append(cdc_idx_dict.get(x))\n",
        "    else:\n",
        "        cdc.append('---')\n",
        "ndf['cdc'] = cdc\n",
        "\n",
        "df = pd.concat([ndf, df], axis=0, ignore_index=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "MEFZ96LM1xd4"
      },
      "source": [
        "#### Article 4 "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "JB8htBtP1xd4",
        "colab": {}
      },
      "source": [
        "with open(articles_dict[articles[4].replace(' ','_')+'.txt']) as article:\n",
        "        doc = article.read()\n",
        "\n",
        "c_doc = text_cleaner(doc)\n",
        "sentences = nltk.sent_tokenize(c_doc)\n",
        "sentences = [[sent, topic, articles[4]] for sent in sentences]\n",
        "\n",
        "ndf = pd.DataFrame(sentences, columns=['text', 'topic', 'article'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "outputId": "e4c9bc43-0e04-40d2-8fde-a6cdc89385e8",
        "id": "BVe3u5lQ1xd5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "cdc_idx_dict = {}\n",
        "cdc_idx_sent = {}\n",
        "cdc_idx_art = {}\n",
        "\n",
        "for i,claim in enumerate(ref_data['clean_Claim']):\n",
        "    check_complete = False\n",
        "    while check_complete == False:\n",
        "        for idx,sentence in enumerate(ndf['text']):\n",
        "            test = claim.lower() in sentence.lower()\n",
        "            if test:\n",
        "                article = ref_data['Article'][i]\n",
        "                cdc_idx_dict[idx] = claim\n",
        "                cdc_idx_sent[idx] = [claim, sentence]\n",
        "                cdc_idx_art[idx] = [claim, article]\n",
        "                check_complete = True\n",
        "            elif idx == (len(ndf['text'])-1):\n",
        "                check_complete = True\n",
        "\n",
        "len(cdc_idx_dict), ref_data.shape[0]"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(1, 1332)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 1229
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "outputId": "0b39d4a8-da91-42e4-9267-674cd09a7819",
        "id": "wwy4BAsp1xd6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "cdc_idx_dict"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{42: 'The use of performance-enhancing substances by players is illegal and ethically \"wrong'}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 1230
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "0HraioV11xd6",
        "colab": {}
      },
      "source": [
        "cdc = []\n",
        "\n",
        "for x in range(len(ndf)):\n",
        "    if x in list(cdc_idx_dict.keys()):\n",
        "        cdc.append(cdc_idx_dict.get(x))\n",
        "    else:\n",
        "        cdc.append('---')\n",
        "ndf['cdc'] = cdc\n",
        "\n",
        "df = pd.concat([ndf, df], axis=0, ignore_index=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "I3QsIC0eAwe6"
      },
      "source": [
        "#### Article 5 "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "uKylAUq_Awe7",
        "colab": {}
      },
      "source": [
        "with open(articles_dict[articles[5].replace(' ','_')+'.txt']) as article:\n",
        "        doc = article.read()\n",
        "\n",
        "c_doc = text_cleaner(doc)\n",
        "sentences = nltk.sent_tokenize(c_doc)\n",
        "sentences = [[sent, topic, articles[5]] for sent in sentences]\n",
        "\n",
        "ndf = pd.DataFrame(sentences, columns=['text', 'topic', 'article'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "outputId": "91fb7b4d-6ebc-41c1-d63b-3eca026707e5",
        "id": "YJ5sSVmYAwe9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "cdc_idx_dict = {}\n",
        "cdc_idx_sent = {}\n",
        "cdc_idx_art = {}\n",
        "\n",
        "for i,claim in enumerate(ref_data['clean_Claim']):\n",
        "    check_complete = False\n",
        "    while check_complete == False:\n",
        "        for idx,sentence in enumerate(ndf['text']):\n",
        "            test = claim.lower() in sentence.lower()\n",
        "            if test:\n",
        "                article = ref_data['Article'][i]\n",
        "                cdc_idx_dict[idx] = claim\n",
        "                cdc_idx_sent[idx] = [claim, sentence]\n",
        "                cdc_idx_art[idx] = [claim, article]\n",
        "                check_complete = True\n",
        "            elif idx == (len(ndf['text'])-1):\n",
        "                check_complete = True\n",
        "\n",
        "len(cdc_idx_dict), ref_data.shape[0]"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(1, 1332)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 1233
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "outputId": "8d2aa777-edd0-452c-a503-eb0b1b3c8b8b",
        "id": "Q_hzq39MAwe-",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "cdc_idx_dict"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{90: 'anybody should be free to put any substance they choose into their own bodies for any reason'}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 1234
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "cbaIErOqAwfA",
        "colab": {}
      },
      "source": [
        "cdc = []\n",
        "\n",
        "for x in range(len(ndf)):\n",
        "    if x in list(cdc_idx_dict.keys()):\n",
        "        cdc.append(cdc_idx_dict.get(x))\n",
        "    else:\n",
        "        cdc.append('---')\n",
        "ndf['cdc'] = cdc\n",
        "\n",
        "df = pd.concat([ndf, df], axis=0, ignore_index=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "OAo9NJ3RAwfB"
      },
      "source": [
        "#### Article 6"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "xTcS4YwwAwfB",
        "colab": {}
      },
      "source": [
        "with open(articles_dict[articles[6].replace(' ','_')+'.txt']) as article:\n",
        "        doc = article.read()\n",
        "\n",
        "c_doc = text_cleaner(doc)\n",
        "sentences = nltk.sent_tokenize(c_doc)\n",
        "sentences = [[sent, topic, articles[6]] for sent in sentences]\n",
        "\n",
        "ndf = pd.DataFrame(sentences, columns=['text', 'topic', 'article'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "outputId": "5ec663af-e380-42a1-d0bb-81e73cbabc41",
        "id": "j4u9scSyAwfD",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "cdc_idx_dict = {}\n",
        "cdc_idx_sent = {}\n",
        "cdc_idx_art = {}\n",
        "\n",
        "for i,claim in enumerate(ref_data['clean_Claim']):\n",
        "    check_complete = False\n",
        "    while check_complete == False:\n",
        "        for idx,sentence in enumerate(ndf['text']):\n",
        "            test = claim.lower() in sentence.lower()\n",
        "            if test:\n",
        "                article = ref_data['Article'][i]\n",
        "                cdc_idx_dict[idx] = claim\n",
        "                cdc_idx_sent[idx] = [claim, sentence]\n",
        "                cdc_idx_art[idx] = [claim, article]\n",
        "                check_complete = True\n",
        "            elif idx == (len(ndf['text'])-1):\n",
        "                check_complete = True\n",
        "\n",
        "len(cdc_idx_dict), ref_data.shape[0]"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(5, 1332)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 1237
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "outputId": "a9c800b9-5d36-4434-af5b-e1061849890c",
        "id": "xnv9-DD9AwfE",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "cdc_idx_dict"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{3: 'Many former athletes suffer from health problems related to steroid consumption',\n",
              " 13: 'there is little danger from anabolica, as they call it, when the athletes are kept on strictly monitored programmes',\n",
              " 14: 'the extremely dangerous side-effects are admitted',\n",
              " 33: 'Often, doping was carried out without the knowledge of the athletes, some of them as young as ten years of age',\n",
              " 34: 'former athletes bear the physical and mental scars of years of drug abuse'}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 1238
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "mB7q1cLfAwfG",
        "colab": {}
      },
      "source": [
        "cdc = []\n",
        "\n",
        "for x in range(len(ndf)):\n",
        "    if x in list(cdc_idx_dict.keys()):\n",
        "        cdc.append(cdc_idx_dict.get(x))\n",
        "    else:\n",
        "        cdc.append('---')\n",
        "ndf['cdc'] = cdc\n",
        "\n",
        "df = pd.concat([ndf, df], axis=0, ignore_index=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2ZSPx55hz6fO",
        "colab_type": "text"
      },
      "source": [
        "### 'trade aid'"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "outputId": "5240b718-c813-436d-fd22-e0e50c54577b",
        "id": "kYlCfbQi2BYS",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 272
        }
      },
      "source": [
        "topic = 'trade aid'\n",
        "\n",
        "articles = topic_article_dict[topic]\n",
        "articles"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['Aid effectiveness',\n",
              " 'Development geography',\n",
              " 'Dambisa Moyo',\n",
              " 'Peter Thomas Bauer',\n",
              " 'Faith-based foreign aid',\n",
              " 'Poverty trap',\n",
              " 'Free trade debate',\n",
              " 'Poverty reduction',\n",
              " 'Trade and development',\n",
              " 'Poverty in Africa',\n",
              " 'William Easterly',\n",
              " 'Protectionism',\n",
              " 'Development aid',\n",
              " 'Aid',\n",
              " 'James Shikwati']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 1240
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2yZ2N3yV2A78",
        "colab_type": "code",
        "outputId": "54a5ad83-acf0-4bb9-c9d8-e2a63947fa2f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "len(articles)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "15"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 1241
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "h-WUbkhn2BYU"
      },
      "source": [
        "#### Article 0 "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "aFqDhzIE2BYV",
        "colab": {}
      },
      "source": [
        "with open(articles_dict[articles[0].replace(' ','_')+'.txt']) as article:\n",
        "        doc = article.read()\n",
        "\n",
        "c_doc = text_cleaner(doc)\n",
        "sentences = nltk.sent_tokenize(c_doc)\n",
        "sentences = [[sent, topic, articles[0]] for sent in sentences]\n",
        "\n",
        "ndf = pd.DataFrame(sentences, columns=['text', 'topic', 'article'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "outputId": "258790ad-8ac7-46d1-97a4-72b84c6cbffe",
        "id": "RwEO8u142BYW",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "cdc_idx_dict = {}\n",
        "cdc_idx_sent = {}\n",
        "cdc_idx_art = {}\n",
        "\n",
        "for i,claim in enumerate(ref_data['clean_Claim']):\n",
        "    check_complete = False\n",
        "    while check_complete == False:\n",
        "        for idx,sentence in enumerate(ndf['text']):\n",
        "            test = claim.lower() in sentence.lower()\n",
        "            if test:\n",
        "                article = ref_data['Article'][i]\n",
        "                cdc_idx_dict[idx] = claim\n",
        "                cdc_idx_sent[idx] = [claim, sentence]\n",
        "                cdc_idx_art[idx] = [claim, article]\n",
        "                check_complete = True\n",
        "            elif idx == (len(ndf['text'])-1):\n",
        "                check_complete = True\n",
        "\n",
        "len(cdc_idx_dict), ref_data.shape[0]"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(10, 1332)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 1243
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "outputId": "bb771439-e779-4e19-c6e1-6b7fa6b32417",
        "id": "jirgVxqd2BYY",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "cdc_idx_dict"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{24: 'aid is never effective',\n",
              " 25: 'it has achieved significant impact when it has been properly directed and managed',\n",
              " 61: 'aid is ineffective',\n",
              " 69: 'the impact of aid on GDP growth is positive',\n",
              " 70: 'aid has less or no significant impact in countries with \"poor\" institutions and policies',\n",
              " 78: 'aids used for infrastructure and investments will result in a positive economic growth',\n",
              " 79: 'aid is effective under a wide variety of circumstances',\n",
              " 96: 'aid alone is not enough to lift developing countries out of poverty',\n",
              " 97: 'aid actually has a significant impact on growth',\n",
              " 257: 'trade is an important tool for development'}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 1244
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "hu_AMcWf2BYc",
        "colab": {}
      },
      "source": [
        "cdc = []\n",
        "\n",
        "for x in range(len(ndf)):\n",
        "    if x in list(cdc_idx_dict.keys()):\n",
        "        cdc.append(cdc_idx_dict.get(x))\n",
        "    else:\n",
        "        cdc.append('---')\n",
        "ndf['cdc'] = cdc\n",
        "\n",
        "df = pd.concat([ndf, df], axis=0, ignore_index=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "aYXzpumN2BYe"
      },
      "source": [
        "#### Article 1 "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "mhHVHGK_2BYe",
        "colab": {}
      },
      "source": [
        "with open(articles_dict[articles[1].replace(' ','_')+'.txt']) as article:\n",
        "        doc = article.read()\n",
        "\n",
        "c_doc = text_cleaner(doc)\n",
        "sentences = nltk.sent_tokenize(c_doc)\n",
        "sentences = [[sent, topic, articles[1]] for sent in sentences]\n",
        "\n",
        "ndf = pd.DataFrame(sentences, columns=['text', 'topic', 'article'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "outputId": "eaa5eaba-18a5-44d1-cb97-1d1a913ef54c",
        "id": "AgJHnWxy2BYh",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "cdc_idx_dict = {}\n",
        "cdc_idx_sent = {}\n",
        "cdc_idx_art = {}\n",
        "\n",
        "for i,claim in enumerate(ref_data['clean_Claim']):\n",
        "    check_complete = False\n",
        "    while check_complete == False:\n",
        "        for idx,sentence in enumerate(ndf['text']):\n",
        "            test = claim.lower() in sentence.lower()\n",
        "            if test:\n",
        "                article = ref_data['Article'][i]\n",
        "                cdc_idx_dict[idx] = claim\n",
        "                cdc_idx_sent[idx] = [claim, sentence]\n",
        "                cdc_idx_art[idx] = [claim, article]\n",
        "                check_complete = True\n",
        "            elif idx == (len(ndf['text'])-1):\n",
        "                check_complete = True\n",
        "\n",
        "len(cdc_idx_dict), ref_data.shape[0]"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(4, 1332)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 1247
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "outputId": "e3690274-1da0-415d-a2ad-78376dea4d9a",
        "id": "KoZ344712BYi",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "cdc_idx_dict"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{57: 'Countries which rely on only a few exports for much of their income are very vulnerable to changes in the market value of those commodities',\n",
              " 71: 'Aid helps make the recipient country (the country that receives aid) get more developed',\n",
              " 73: 'Often aid does not even reach the poorest people',\n",
              " 76: 'the recipient country becomes more dependent on aid from a donor country'}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 1248
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "qsDGuiRM2BYj",
        "colab": {}
      },
      "source": [
        "cdc = []\n",
        "\n",
        "for x in range(len(ndf)):\n",
        "    if x in list(cdc_idx_dict.keys()):\n",
        "        cdc.append(cdc_idx_dict.get(x))\n",
        "    else:\n",
        "        cdc.append('---')\n",
        "ndf['cdc'] = cdc\n",
        "\n",
        "df = pd.concat([df, ndf], axis=0, ignore_index=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "iG5Sas7Y2BYn"
      },
      "source": [
        "#### Article 2 "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "vuhD0ctR2BYo",
        "colab": {}
      },
      "source": [
        "with open(articles_dict[articles[2].replace(' ','_')+'.txt']) as article:\n",
        "        doc = article.read()\n",
        "\n",
        "c_doc = text_cleaner(doc)\n",
        "sentences = nltk.sent_tokenize(c_doc)\n",
        "sentences = [[sent, topic, articles[2]] for sent in sentences]\n",
        "\n",
        "ndf = pd.DataFrame(sentences, columns=['text', 'topic', 'article'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "outputId": "22d53917-fefd-4b79-fb00-07fdc822639d",
        "id": "u5KlV_tU2BYq",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "cdc_idx_dict = {}\n",
        "cdc_idx_sent = {}\n",
        "cdc_idx_art = {}\n",
        "\n",
        "for i,claim in enumerate(ref_data['clean_Claim']):\n",
        "    check_complete = False\n",
        "    while check_complete == False:\n",
        "        for idx,sentence in enumerate(ndf['text']):\n",
        "            test = claim.lower() in sentence.lower()\n",
        "            if test:\n",
        "                article = ref_data['Article'][i]\n",
        "                cdc_idx_dict[idx] = claim\n",
        "                cdc_idx_sent[idx] = [claim, sentence]\n",
        "                cdc_idx_art[idx] = [claim, article]\n",
        "                check_complete = True\n",
        "            elif idx == (len(ndf['text'])-1):\n",
        "                check_complete = True\n",
        "\n",
        "len(cdc_idx_dict), ref_data.shape[0]"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(5, 1332)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 1251
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "outputId": "d2ede2bf-da42-4428-e406-0444bcd48a7a",
        "id": "CWqheFAL2BYr",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "cdc_idx_dict"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{1: 'Aid is Not Working',\n",
              " 19: 'foreign aid has harmed Africa',\n",
              " 25: 'hinders economic growth',\n",
              " 36: 'were aid cut, African governments would respond by turning to other sources of finance that would make them more accountable',\n",
              " 41: 'the path to long-term development would only be achieved through private sector involvement and free market solutions'}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 1252
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "K3mx7rc72BYs",
        "colab": {}
      },
      "source": [
        "cdc = []\n",
        "\n",
        "for x in range(len(ndf)):\n",
        "    if x in list(cdc_idx_dict.keys()):\n",
        "        cdc.append(cdc_idx_dict.get(x))\n",
        "    else:\n",
        "        cdc.append('---')\n",
        "ndf['cdc'] = cdc\n",
        "\n",
        "df = pd.concat([ndf, df], axis=0, ignore_index=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "x_fcGT0C2BYu"
      },
      "source": [
        "#### Article 3 "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "UguDNp2V2BYu",
        "colab": {}
      },
      "source": [
        "with open(articles_dict[articles[3].replace(' ','_')+'.txt']) as article:\n",
        "        doc = article.read()\n",
        "\n",
        "c_doc = text_cleaner(doc)\n",
        "sentences = nltk.sent_tokenize(c_doc)\n",
        "sentences = [[sent, topic, articles[3]] for sent in sentences]\n",
        "\n",
        "ndf = pd.DataFrame(sentences, columns=['text', 'topic', 'article'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "outputId": "3d4686c8-c8bb-4952-dc86-e134585d193e",
        "id": "E6_SWsi12BYv",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "cdc_idx_dict = {}\n",
        "cdc_idx_sent = {}\n",
        "cdc_idx_art = {}\n",
        "\n",
        "for i,claim in enumerate(ref_data['clean_Claim']):\n",
        "    check_complete = False\n",
        "    while check_complete == False:\n",
        "        for idx,sentence in enumerate(ndf['text']):\n",
        "            test = claim.lower() in sentence.lower()\n",
        "            if test:\n",
        "                article = ref_data['Article'][i]\n",
        "                cdc_idx_dict[idx] = claim\n",
        "                cdc_idx_sent[idx] = [claim, sentence]\n",
        "                cdc_idx_art[idx] = [claim, article]\n",
        "                check_complete = True\n",
        "            elif idx == (len(ndf['text'])-1):\n",
        "                check_complete = True\n",
        "\n",
        "len(cdc_idx_dict), ref_data.shape[0]"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(3, 1332)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 1255
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "outputId": "2c8caa3d-279b-4692-d4c7-efa734dfc059",
        "id": "QUMcXO-K2BYy",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "cdc_idx_dict"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{2: 'the most effective manner to help developing countries advance is through state-controlled foreign aid',\n",
              " 32: 'government-to-government aid was neither necessary nor sufficient for development',\n",
              " 33: 'erodes civil society'}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 1256
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "LfXNPJow2BY0",
        "colab": {}
      },
      "source": [
        "cdc = []\n",
        "\n",
        "for x in range(len(ndf)):\n",
        "    if x in list(cdc_idx_dict.keys()):\n",
        "        cdc.append(cdc_idx_dict.get(x))\n",
        "    else:\n",
        "        cdc.append('---')\n",
        "ndf['cdc'] = cdc\n",
        "\n",
        "df = pd.concat([ndf, df], axis=0, ignore_index=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "OF-Nt7AO2BY2"
      },
      "source": [
        "#### Article 4 "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "ESTrLLA-2BY3",
        "colab": {}
      },
      "source": [
        "with open(articles_dict[articles[4].replace(' ','_')+'.txt']) as article:\n",
        "        doc = article.read()\n",
        "\n",
        "c_doc = text_cleaner(doc)\n",
        "sentences = nltk.sent_tokenize(c_doc)\n",
        "sentences = [[sent, topic, articles[4]] for sent in sentences]\n",
        "\n",
        "ndf = pd.DataFrame(sentences, columns=['text', 'topic', 'article'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "outputId": "b3d9dd93-05ae-4fab-b69b-0c2cabcd111e",
        "id": "HQGfucxh2BY4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "cdc_idx_dict = {}\n",
        "cdc_idx_sent = {}\n",
        "cdc_idx_art = {}\n",
        "\n",
        "for i,claim in enumerate(ref_data['clean_Claim']):\n",
        "    check_complete = False\n",
        "    while check_complete == False:\n",
        "        for idx,sentence in enumerate(ndf['text']):\n",
        "            test = claim.lower() in sentence.lower()\n",
        "            if test:\n",
        "                article = ref_data['Article'][i]\n",
        "                cdc_idx_dict[idx] = claim\n",
        "                cdc_idx_sent[idx] = [claim, sentence]\n",
        "                cdc_idx_art[idx] = [claim, article]\n",
        "                check_complete = True\n",
        "            elif idx == (len(ndf['text'])-1):\n",
        "                check_complete = True\n",
        "\n",
        "len(cdc_idx_dict), ref_data.shape[0]"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(8, 1332)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 1259
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "outputId": "2272dff3-9b14-4ffe-ff38-9ec994af3c27",
        "id": "xiSTQfHM2BY6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "cdc_idx_dict"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{68: 'direct monetary assistance from industrialized countries has gone to increase the standard of living in many impoverished nations',\n",
              " 72: 'intervention by financial contributors could ease domestic unrest',\n",
              " 74: 'The contribution of funding to economically unstable nations has helped to create more economic opportunities',\n",
              " 83: 'some aid has been proven to help nations develop in the past',\n",
              " 84: 'When a country is given money because they cannot financially sustain themselves, several negative effects have the potential to develop',\n",
              " 85: 'it simply does not work',\n",
              " 87: 'In the case of federally funded aid, contributions have, in effect, crowded out any investment in the private sectors of many nations',\n",
              " 89: 'pouring vast amounts of money into development aid without any concern for results has failed'}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 1260
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "0XZnbU882BY7",
        "colab": {}
      },
      "source": [
        "cdc = []\n",
        "\n",
        "for x in range(len(ndf)):\n",
        "    if x in list(cdc_idx_dict.keys()):\n",
        "        cdc.append(cdc_idx_dict.get(x))\n",
        "    else:\n",
        "        cdc.append('---')\n",
        "ndf['cdc'] = cdc\n",
        "\n",
        "df = pd.concat([ndf, df], axis=0, ignore_index=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "ltqmGPWHA7ft"
      },
      "source": [
        "#### Article 5 "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "dhPRSfmXA7fu",
        "colab": {}
      },
      "source": [
        "with open(articles_dict[articles[5].replace(' ','_')+'.txt']) as article:\n",
        "        doc = article.read()\n",
        "\n",
        "c_doc = text_cleaner(doc)\n",
        "sentences = nltk.sent_tokenize(c_doc)\n",
        "sentences = [[sent, topic, articles[5]] for sent in sentences]\n",
        "\n",
        "ndf = pd.DataFrame(sentences, columns=['text', 'topic', 'article'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "outputId": "6c6b4b28-511d-4abe-833b-673189c526ac",
        "id": "-BZ--bDdA7fv",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "cdc_idx_dict = {}\n",
        "cdc_idx_sent = {}\n",
        "cdc_idx_art = {}\n",
        "\n",
        "for i,claim in enumerate(ref_data['clean_Claim']):\n",
        "    check_complete = False\n",
        "    while check_complete == False:\n",
        "        for idx,sentence in enumerate(ndf['text']):\n",
        "            test = claim.lower() in sentence.lower()\n",
        "            if test:\n",
        "                article = ref_data['Article'][i]\n",
        "                cdc_idx_dict[idx] = claim\n",
        "                cdc_idx_sent[idx] = [claim, sentence]\n",
        "                cdc_idx_art[idx] = [claim, article]\n",
        "                check_complete = True\n",
        "            elif idx == (len(ndf['text'])-1):\n",
        "                check_complete = True\n",
        "\n",
        "len(cdc_idx_dict), ref_data.shape[0]"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(2, 1332)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 1263
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "outputId": "736a0ac7-b70c-4ec4-bde9-cce9efaa569a",
        "id": "k1sCFc89A7fw",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "cdc_idx_dict"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{10: 'people continue to die at a high rate due in large part to lack of sufficient aid',\n",
              " 15: 'If the foreign assistance is substantial enough, and lasts long enough, the capital stock rises sufficiently to lift households above subsistence'}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 1264
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "ainMHUmXA7fx",
        "colab": {}
      },
      "source": [
        "cdc = []\n",
        "\n",
        "for x in range(len(ndf)):\n",
        "    if x in list(cdc_idx_dict.keys()):\n",
        "        cdc.append(cdc_idx_dict.get(x))\n",
        "    else:\n",
        "        cdc.append('---')\n",
        "ndf['cdc'] = cdc\n",
        "\n",
        "df = pd.concat([ndf, df], axis=0, ignore_index=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "sp5qW8OYA7fy"
      },
      "source": [
        "#### Article 6"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "BitIV4dzA7fy",
        "colab": {}
      },
      "source": [
        "with open(articles_dict[articles[6].replace(' ','_')+'.txt']) as article:\n",
        "        doc = article.read()\n",
        "\n",
        "c_doc = text_cleaner(doc)\n",
        "sentences = nltk.sent_tokenize(c_doc)\n",
        "sentences = [[sent, topic, articles[6]] for sent in sentences]\n",
        "\n",
        "ndf = pd.DataFrame(sentences, columns=['text', 'topic', 'article'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "outputId": "5cd6f408-5cd4-4b24-b2fe-0dba366c629d",
        "id": "YwlitfnQA7f0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "cdc_idx_dict = {}\n",
        "cdc_idx_sent = {}\n",
        "cdc_idx_art = {}\n",
        "\n",
        "for i,claim in enumerate(ref_data['clean_Claim']):\n",
        "    check_complete = False\n",
        "    while check_complete == False:\n",
        "        for idx,sentence in enumerate(ndf['text']):\n",
        "            test = claim.lower() in sentence.lower()\n",
        "            if test:\n",
        "                article = ref_data['Article'][i]\n",
        "                cdc_idx_dict[idx] = claim\n",
        "                cdc_idx_sent[idx] = [claim, sentence]\n",
        "                cdc_idx_art[idx] = [claim, article]\n",
        "                check_complete = True\n",
        "            elif idx == (len(ndf['text'])-1):\n",
        "                check_complete = True\n",
        "\n",
        "len(cdc_idx_dict), ref_data.shape[0]"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(6, 1332)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 1267
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "outputId": "178e59c3-8523-437c-e658-cfafe7b7c51e",
        "id": "Ljs_G_vAA7f1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "cdc_idx_dict"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{6: 'free trade will make society more prosperous',\n",
              " 84: 'Trade also allows for better quality produce and competitiveness between nations, effectively raising the living standards of those nations',\n",
              " 95: 'increased trade is the best way to relieve extreme poverty throughout the world',\n",
              " 109: 'free trade gives optimal economic advantages',\n",
              " 212: 'Free trade is generally considered to achieve an overall increase in utility in a society',\n",
              " 213: 'Individuals can be made worse off by an opening of trade'}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 1268
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "D_pT7uPsA7f3",
        "colab": {}
      },
      "source": [
        "cdc = []\n",
        "\n",
        "for x in range(len(ndf)):\n",
        "    if x in list(cdc_idx_dict.keys()):\n",
        "        cdc.append(cdc_idx_dict.get(x))\n",
        "    else:\n",
        "        cdc.append('---')\n",
        "ndf['cdc'] = cdc\n",
        "\n",
        "df = pd.concat([ndf, df], axis=0, ignore_index=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "oqcqdtNoA7f6"
      },
      "source": [
        "#### Article 7"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "W4cHBKwlA7f7",
        "colab": {}
      },
      "source": [
        "with open(articles_dict[articles[7].replace(' ','_')+'.txt']) as article:\n",
        "        doc = article.read()\n",
        "\n",
        "c_doc = text_cleaner(doc)\n",
        "sentences = nltk.sent_tokenize(c_doc)\n",
        "sentences = [[sent, topic, articles[7]] for sent in sentences]\n",
        "\n",
        "ndf = pd.DataFrame(sentences, columns=['text', 'topic', 'article'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "outputId": "ca83eb60-77b3-41ff-b135-03f4fe095e8a",
        "id": "IMqntJZ9A7f9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "cdc_idx_dict = {}\n",
        "cdc_idx_sent = {}\n",
        "cdc_idx_art = {}\n",
        "\n",
        "for i,claim in enumerate(ref_data['clean_Claim']):\n",
        "    check_complete = False\n",
        "    while check_complete == False:\n",
        "        for idx,sentence in enumerate(ndf['text']):\n",
        "            test = claim.lower() in sentence.lower()\n",
        "            if test:\n",
        "                article = ref_data['Article'][i]\n",
        "                cdc_idx_dict[idx] = claim\n",
        "                cdc_idx_sent[idx] = [claim, sentence]\n",
        "                cdc_idx_art[idx] = [claim, article]\n",
        "                check_complete = True\n",
        "            elif idx == (len(ndf['text'])-1):\n",
        "                check_complete = True\n",
        "\n",
        "len(cdc_idx_dict), ref_data.shape[0]"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(6, 1332)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 1271
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "outputId": "e2460a72-1e43-4ac2-8b3e-7611d928ad87",
        "id": "GAKvuW2qA7gA",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "cdc_idx_dict"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{26: 'helps growth',\n",
              " 28: 'is essential in providing better lives',\n",
              " 47: 'trade rules are often unfair as they block access to richer nations’ markets and ban poorer nations from supporting their industries',\n",
              " 130: 'Western monetary aid often only serves to increase poverty and social inequality',\n",
              " 131: 'higher aid levels erode the quality of governance',\n",
              " 133: 'aid is not spread properly'}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 1272
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "63mN4sW5A7gC",
        "colab": {}
      },
      "source": [
        "cdc = []\n",
        "\n",
        "for x in range(len(ndf)):\n",
        "    if x in list(cdc_idx_dict.keys()):\n",
        "        cdc.append(cdc_idx_dict.get(x))\n",
        "    else:\n",
        "        cdc.append('---')\n",
        "ndf['cdc'] = cdc\n",
        "\n",
        "df = pd.concat([ndf, df], axis=0, ignore_index=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "xKXJQ6ymA7gD"
      },
      "source": [
        "#### Article 8"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "ZoCf_wW1A7gE",
        "colab": {}
      },
      "source": [
        "with open(articles_dict[articles[8].replace(' ','_')+'.txt']) as article:\n",
        "        doc = article.read()\n",
        "\n",
        "c_doc = text_cleaner(doc)\n",
        "sentences = nltk.sent_tokenize(c_doc)\n",
        "sentences = [[sent, topic, articles[8]] for sent in sentences]\n",
        "\n",
        "ndf = pd.DataFrame(sentences, columns=['text', 'topic', 'article'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "outputId": "d5ebc806-c407-4823-cccf-22e6e19c2765",
        "id": "aVZnPLK3A7gF",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "cdc_idx_dict = {}\n",
        "cdc_idx_sent = {}\n",
        "cdc_idx_art = {}\n",
        "\n",
        "for i,claim in enumerate(ref_data['clean_Claim']):\n",
        "    check_complete = False\n",
        "    while check_complete == False:\n",
        "        for idx,sentence in enumerate(ndf['text']):\n",
        "            test = claim.lower() in sentence.lower()\n",
        "            if test:\n",
        "                article = ref_data['Article'][i]\n",
        "                cdc_idx_dict[idx] = claim\n",
        "                cdc_idx_sent[idx] = [claim, sentence]\n",
        "                cdc_idx_art[idx] = [claim, article]\n",
        "                check_complete = True\n",
        "            elif idx == (len(ndf['text'])-1):\n",
        "                check_complete = True\n",
        "\n",
        "len(cdc_idx_dict), ref_data.shape[0]"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(8, 1332)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 1275
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "outputId": "1cbff74d-6a6d-4499-cbd6-131331f8ab39",
        "id": "DL99UvKZA7gG",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "cdc_idx_dict"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{0: 'Trade is a key factor in economic development',\n",
              " 1: \"A successful use of trade can boost a country's development\",\n",
              " 2: 'opening up markets to international trade may leave local producers swamped by more competitive foreign producers',\n",
              " 3: 'trade, development, and poverty reduction are intimately linked',\n",
              " 4: 'trade and growth are strongly linked',\n",
              " 5: 'export-led growth has been a key part of many countries’ successful development strategies',\n",
              " 76: 'liberalization when institutions and the economy are not strong enough to face risks and opportunities can be harmful',\n",
              " 79: 'trade-led growth is pro-poor'}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 1276
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "O7CUPa3fA7gI",
        "colab": {}
      },
      "source": [
        "cdc = []\n",
        "\n",
        "for x in range(len(ndf)):\n",
        "    if x in list(cdc_idx_dict.keys()):\n",
        "        cdc.append(cdc_idx_dict.get(x))\n",
        "    else:\n",
        "        cdc.append('---')\n",
        "ndf['cdc'] = cdc\n",
        "\n",
        "df = pd.concat([ndf, df], axis=0, ignore_index=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "qrmz_DH5A7gJ"
      },
      "source": [
        "#### Article 9"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "JLaZxGS_A7gK",
        "colab": {}
      },
      "source": [
        "with open(articles_dict[articles[9].replace(' ','_')+'.txt']) as article:\n",
        "        doc = article.read()\n",
        "\n",
        "c_doc = text_cleaner(doc)\n",
        "sentences = nltk.sent_tokenize(c_doc)\n",
        "sentences = [[sent, topic, articles[9]] for sent in sentences]\n",
        "\n",
        "ndf = pd.DataFrame(sentences, columns=['text', 'topic', 'article'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "outputId": "934072e7-730f-48d8-fc3b-7dc940657ec7",
        "id": "8JAjpLvFA7gL",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "cdc_idx_dict = {}\n",
        "cdc_idx_sent = {}\n",
        "cdc_idx_art = {}\n",
        "\n",
        "for i,claim in enumerate(ref_data['clean_Claim']):\n",
        "    check_complete = False\n",
        "    while check_complete == False:\n",
        "        for idx,sentence in enumerate(ndf['text']):\n",
        "            test = claim.lower() in sentence.lower()\n",
        "            if test:\n",
        "                article = ref_data['Article'][i]\n",
        "                cdc_idx_dict[idx] = claim\n",
        "                cdc_idx_sent[idx] = [claim, sentence]\n",
        "                cdc_idx_art[idx] = [claim, article]\n",
        "                check_complete = True\n",
        "            elif idx == (len(ndf['text'])-1):\n",
        "                check_complete = True\n",
        "\n",
        "len(cdc_idx_dict), ref_data.shape[0]"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(1, 1332)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 1279
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "outputId": "72b438d8-d5fc-47f9-a7c5-c2aeed91119b",
        "id": "WRYuN8-NA7gM",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "cdc_idx_dict"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{63: 'foreign aid may not even be helpful in the long run to many African nations'}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 1280
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "-oev2NbJA7gN",
        "colab": {}
      },
      "source": [
        "cdc = []\n",
        "\n",
        "for x in range(len(ndf)):\n",
        "    if x in list(cdc_idx_dict.keys()):\n",
        "        cdc.append(cdc_idx_dict.get(x))\n",
        "    else:\n",
        "        cdc.append('---')\n",
        "ndf['cdc'] = cdc\n",
        "\n",
        "df = pd.concat([ndf, df], axis=0, ignore_index=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "wPpV7EdSA7gO"
      },
      "source": [
        "#### Article 10"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "q8w0XOeNA7gO",
        "colab": {}
      },
      "source": [
        "with open(articles_dict[articles[10].replace(' ','_')+'.txt']) as article:\n",
        "        doc = article.read()\n",
        "\n",
        "c_doc = text_cleaner(doc)\n",
        "sentences = nltk.sent_tokenize(c_doc)\n",
        "sentences = [[sent, topic, articles[10]] for sent in sentences]\n",
        "\n",
        "ndf = pd.DataFrame(sentences, columns=['text', 'topic', 'article'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "outputId": "ea693447-8a8c-4712-fa3f-e2829a4a93f4",
        "id": "Yxl5r8TkA7gP",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "cdc_idx_dict = {}\n",
        "cdc_idx_sent = {}\n",
        "cdc_idx_art = {}\n",
        "\n",
        "for i,claim in enumerate(ref_data['clean_Claim']):\n",
        "    check_complete = False\n",
        "    while check_complete == False:\n",
        "        for idx,sentence in enumerate(ndf['text']):\n",
        "            test = claim.lower() in sentence.lower()\n",
        "            if test:\n",
        "                article = ref_data['Article'][i]\n",
        "                cdc_idx_dict[idx] = claim\n",
        "                cdc_idx_sent[idx] = [claim, sentence]\n",
        "                cdc_idx_art[idx] = [claim, article]\n",
        "                check_complete = True\n",
        "            elif idx == (len(ndf['text'])-1):\n",
        "                check_complete = True\n",
        "\n",
        "len(cdc_idx_dict), ref_data.shape[0]"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(1, 1332)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 1283
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "outputId": "005aade1-945e-4739-d491-14319feeb8f7",
        "id": "MnUB8KXsA7gQ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "cdc_idx_dict"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{15: 'foreign aid to many third world countries has failed to produce sustainable growth'}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 1284
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "5QSpkscsA7gR",
        "colab": {}
      },
      "source": [
        "cdc = []\n",
        "\n",
        "for x in range(len(ndf)):\n",
        "    if x in list(cdc_idx_dict.keys()):\n",
        "        cdc.append(cdc_idx_dict.get(x))\n",
        "    else:\n",
        "        cdc.append('---')\n",
        "ndf['cdc'] = cdc\n",
        "\n",
        "df = pd.concat([ndf, df], axis=0, ignore_index=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "sI4FBkCeA7gS"
      },
      "source": [
        "#### Article 11 "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "fJ6w-F3zA7gT",
        "colab": {}
      },
      "source": [
        "with open(articles_dict[articles[11].replace(' ','_')+'.txt']) as article:\n",
        "        doc = article.read()\n",
        "\n",
        "c_doc = text_cleaner(doc)\n",
        "sentences = nltk.sent_tokenize(c_doc)\n",
        "sentences = [[sent, topic, articles[11]] for sent in sentences]\n",
        "\n",
        "ndf = pd.DataFrame(sentences, columns=['text', 'topic', 'article'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "outputId": "1d2e038b-76c7-4d76-990b-26a4839cade9",
        "id": "T-7qYyDfA7gU",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "cdc_idx_dict = {}\n",
        "cdc_idx_sent = {}\n",
        "cdc_idx_art = {}\n",
        "\n",
        "for i,claim in enumerate(ref_data['clean_Claim']):\n",
        "    check_complete = False\n",
        "    while check_complete == False:\n",
        "        for idx,sentence in enumerate(ndf['text']):\n",
        "            test = claim.lower() in sentence.lower()\n",
        "            if test:\n",
        "                article = ref_data['Article'][i]\n",
        "                cdc_idx_dict[idx] = claim\n",
        "                cdc_idx_sent[idx] = [claim, sentence]\n",
        "                cdc_idx_art[idx] = [claim, article]\n",
        "                check_complete = True\n",
        "            elif idx == (len(ndf['text'])-1):\n",
        "                check_complete = True\n",
        "\n",
        "len(cdc_idx_dict), ref_data.shape[0]"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(1, 1332)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 1287
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "outputId": "e5cab420-19f4-4c97-969a-6ea81987fba6",
        "id": "CnIytLOrA7gV",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "cdc_idx_dict"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{139: 'free trade helps workers in developing countries'}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 1288
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "6v_1OqVOA7gW",
        "colab": {}
      },
      "source": [
        "cdc = []\n",
        "\n",
        "for x in range(len(ndf)):\n",
        "    if x in list(cdc_idx_dict.keys()):\n",
        "        cdc.append(cdc_idx_dict.get(x))\n",
        "    else:\n",
        "        cdc.append('---')\n",
        "ndf['cdc'] = cdc\n",
        "\n",
        "df = pd.concat([ndf, df], axis=0, ignore_index=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "8PkT-D32A7ga"
      },
      "source": [
        "#### Article 12"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "i52d60S_A7gp",
        "colab": {}
      },
      "source": [
        "with open(articles_dict[articles[12].replace(' ','_')+'.txt']) as article:\n",
        "        doc = article.read()\n",
        "\n",
        "c_doc = text_cleaner(doc)\n",
        "sentences = nltk.sent_tokenize(c_doc)\n",
        "sentences = [[sent, topic, articles[12]] for sent in sentences]\n",
        "\n",
        "ndf = pd.DataFrame(sentences, columns=['text', 'topic', 'article'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "outputId": "034cf207-2ca1-4690-9f6d-c26f27cf5bea",
        "id": "RQlu9oKOA7gr",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "cdc_idx_dict = {}\n",
        "cdc_idx_sent = {}\n",
        "cdc_idx_art = {}\n",
        "\n",
        "for i,claim in enumerate(ref_data['clean_Claim']):\n",
        "    check_complete = False\n",
        "    while check_complete == False:\n",
        "        for idx,sentence in enumerate(ndf['text']):\n",
        "            test = claim.lower() in sentence.lower()\n",
        "            if test:\n",
        "                article = ref_data['Article'][i]\n",
        "                cdc_idx_dict[idx] = claim\n",
        "                cdc_idx_sent[idx] = [claim, sentence]\n",
        "                cdc_idx_art[idx] = [claim, article]\n",
        "                check_complete = True\n",
        "            elif idx == (len(ndf['text'])-1):\n",
        "                check_complete = True\n",
        "\n",
        "len(cdc_idx_dict), ref_data.shape[0]"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(8, 1332)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 1291
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "outputId": "98495ba0-9003-45e6-e8f9-221206e13145",
        "id": "maUxVfDfA7gs",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "cdc_idx_dict"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{46: 'aid is ineffective',\n",
              " 47: 'development aid has no effect on the speed with which countries develop',\n",
              " 49: 'much government-to-government aid was ineffective',\n",
              " 63: 'has an adverse effect on local production',\n",
              " 74: 'rich countries have put so many conditions on aid that it has reduced aid effectiveness',\n",
              " 77: 'a very large part of the spend money on development aid is simply wasted uselessly',\n",
              " 83: 'Development Assistance to the Third World Has Failed',\n",
              " 114: \"aid's complexity and the ever expanding budgets leave it vulnerable to corruption\"}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 1292
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "dXMhH9BZA7gt",
        "colab": {}
      },
      "source": [
        "cdc = []\n",
        "\n",
        "for x in range(len(ndf)):\n",
        "    if x in list(cdc_idx_dict.keys()):\n",
        "        cdc.append(cdc_idx_dict.get(x))\n",
        "    else:\n",
        "        cdc.append('---')\n",
        "ndf['cdc'] = cdc\n",
        "\n",
        "df = pd.concat([ndf, df], axis=0, ignore_index=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "LorhMiyAA7gu"
      },
      "source": [
        "#### Article 13"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "g5oI_YZgA7gu",
        "colab": {}
      },
      "source": [
        "with open(articles_dict[articles[13].replace(' ','_')+'.txt']) as article:\n",
        "        doc = article.read()\n",
        "\n",
        "c_doc = text_cleaner(doc)\n",
        "sentences = nltk.sent_tokenize(c_doc)\n",
        "sentences = [[sent, topic, articles[13]] for sent in sentences]\n",
        "\n",
        "ndf = pd.DataFrame(sentences, columns=['text', 'topic', 'article'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "outputId": "785053b3-da11-4d2f-ce58-af39a0ae3b92",
        "id": "sXN-meD0A7gv",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "cdc_idx_dict = {}\n",
        "cdc_idx_sent = {}\n",
        "cdc_idx_art = {}\n",
        "\n",
        "for i,claim in enumerate(ref_data['clean_Claim']):\n",
        "    check_complete = False\n",
        "    while check_complete == False:\n",
        "        for idx,sentence in enumerate(ndf['text']):\n",
        "            test = claim.lower() in sentence.lower()\n",
        "            if test:\n",
        "                article = ref_data['Article'][i]\n",
        "                cdc_idx_dict[idx] = claim\n",
        "                cdc_idx_sent[idx] = [claim, sentence]\n",
        "                cdc_idx_art[idx] = [claim, article]\n",
        "                check_complete = True\n",
        "            elif idx == (len(ndf['text'])-1):\n",
        "                check_complete = True\n",
        "\n",
        "len(cdc_idx_dict), ref_data.shape[0]"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(13, 1332)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 1295
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "outputId": "f842dae7-9897-4026-bbd0-1e9fe3b77151",
        "id": "zv2dIaE8A7gw",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "cdc_idx_dict"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{76: 'Aid to underdeveloped countries has sometimes been criticized as being more in the interest of the donor than the recipient',\n",
              " 80: 'it did not do what it was intended to do or help the people it was intended to help',\n",
              " 83: 'foreign aid generally does boost growth',\n",
              " 86: 'foreign assistance, especially foreign capitalism, has been somewhat deleterious to African development',\n",
              " 89: 'aid can often distort incentives in poor countries in various harmful ways',\n",
              " 100: 'An implementation of aid can easily be problematic, causing more problems than it solves',\n",
              " 101: 'hollows out the local economy',\n",
              " 117: 'encouraging developing economies to develop their agriculture with a focus on exports is not effective on a global market where key players, such as the US and EU, heavily subsidise their products',\n",
              " 127: 'aid is not targeting the most extreme poverty',\n",
              " 141: 'it neither goes where it was intended nor helps those intended',\n",
              " 161: 'Aid can make progress towards reducing poverty worldwide',\n",
              " 176: 'foreign aid is efficacious',\n",
              " 281: 'in many instances, aid is conditionally tied due to political motives, rather than notions of proper policy and implementation'}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 1296
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "cfuYrumuA7gx",
        "colab": {}
      },
      "source": [
        "cdc = []\n",
        "\n",
        "for x in range(len(ndf)):\n",
        "    if x in list(cdc_idx_dict.keys()):\n",
        "        cdc.append(cdc_idx_dict.get(x))\n",
        "    else:\n",
        "        cdc.append('---')\n",
        "ndf['cdc'] = cdc\n",
        "\n",
        "df = pd.concat([ndf, df], axis=0, ignore_index=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "uVxy5d9LA7gz"
      },
      "source": [
        "#### Article 14 "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "KcpvsQcHA7gz",
        "colab": {}
      },
      "source": [
        "with open(articles_dict[articles[14].replace(' ','_')+'.txt']) as article:\n",
        "        doc = article.read()\n",
        "\n",
        "c_doc = text_cleaner(doc)\n",
        "sentences = nltk.sent_tokenize(c_doc)\n",
        "sentences = [[sent, topic, articles[14]] for sent in sentences]\n",
        "\n",
        "ndf = pd.DataFrame(sentences, columns=['text', 'topic', 'article'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "outputId": "72375897-606e-4f16-e85a-cc80b5f34023",
        "id": "5Yb4-SKwA7g0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "cdc_idx_dict = {}\n",
        "cdc_idx_sent = {}\n",
        "cdc_idx_art = {}\n",
        "\n",
        "for i,claim in enumerate(ref_data['clean_Claim']):\n",
        "    check_complete = False\n",
        "    while check_complete == False:\n",
        "        for idx,sentence in enumerate(ndf['text']):\n",
        "            test = claim.lower() in sentence.lower()\n",
        "            if test:\n",
        "                article = ref_data['Article'][i]\n",
        "                cdc_idx_dict[idx] = claim\n",
        "                cdc_idx_sent[idx] = [claim, sentence]\n",
        "                cdc_idx_art[idx] = [claim, article]\n",
        "                check_complete = True\n",
        "            elif idx == (len(ndf['text'])-1):\n",
        "                check_complete = True\n",
        "\n",
        "len(cdc_idx_dict), ref_data.shape[0]"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(1, 1332)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 1299
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "outputId": "a39b0aca-f50a-4735-df90-4014f23355f6",
        "id": "KscrEKIDA7g2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "cdc_idx_dict"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{1: 'aid towards Africa does more harm than good'}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 1300
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "tpnqoBr_A7g3",
        "colab": {}
      },
      "source": [
        "cdc = []\n",
        "\n",
        "for x in range(len(ndf)):\n",
        "    if x in list(cdc_idx_dict.keys()):\n",
        "        cdc.append(cdc_idx_dict.get(x))\n",
        "    else:\n",
        "        cdc.append('---')\n",
        "ndf['cdc'] = cdc\n",
        "\n",
        "df = pd.concat([ndf, df], axis=0, ignore_index=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "g66ZaL5Q0BOu",
        "colab_type": "text"
      },
      "source": [
        "### 'wind power should be a primary focus of future energy supply '"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "outputId": "aa58ff52-4d6f-486c-f6e0-e8a9f3b29bc1",
        "id": "drYI0qRo2D-O",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "topic = 'wind power should be a primary focus of future energy supply '\n",
        "\n",
        "articles = topic_article_dict[topic]\n",
        "articles"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['Environmental impact of wind power',\n",
              " 'Wind power in Scotland',\n",
              " 'Wind power in Austria',\n",
              " 'Cost of electricity by source',\n",
              " 'Energy development',\n",
              " 'Wind power grid integration',\n",
              " 'Environmental impact of the energy industry']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 1302
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uRPv2-zV2Dp2",
        "colab_type": "code",
        "outputId": "a02eb453-ff00-4e0a-8b05-f688019d637a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "len(articles)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "7"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 1303
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "2ldDOBKL2D-Q"
      },
      "source": [
        "#### Article 0 "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "cDpSUCdj2D-Q",
        "colab": {}
      },
      "source": [
        "with open(articles_dict[articles[0].replace(' ','_')+'.txt']) as article:\n",
        "        doc = article.read()\n",
        "\n",
        "c_doc = text_cleaner(doc)\n",
        "sentences = nltk.sent_tokenize(c_doc)\n",
        "sentences = [[sent, topic, articles[0]] for sent in sentences]\n",
        "\n",
        "ndf = pd.DataFrame(sentences, columns=['text', 'topic', 'article'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "outputId": "7f28ff84-f7d3-46c8-b267-930822406f95",
        "id": "9czJDPgm2D-S",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "cdc_idx_dict = {}\n",
        "cdc_idx_sent = {}\n",
        "cdc_idx_art = {}\n",
        "\n",
        "for i,claim in enumerate(ref_data['clean_Claim']):\n",
        "    check_complete = False\n",
        "    while check_complete == False:\n",
        "        for idx,sentence in enumerate(ndf['text']):\n",
        "            test = claim.lower() in sentence.lower()\n",
        "            if test:\n",
        "                article = ref_data['Article'][i]\n",
        "                cdc_idx_dict[idx] = claim\n",
        "                cdc_idx_sent[idx] = [claim, sentence]\n",
        "                cdc_idx_art[idx] = [claim, article]\n",
        "                check_complete = True\n",
        "            elif idx == (len(ndf['text'])-1):\n",
        "                check_complete = True\n",
        "\n",
        "len(cdc_idx_dict), ref_data.shape[0]"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(10, 1332)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 1305
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "outputId": "b34610f1-13c6-4b01-9e07-a211af1e7105",
        "id": "o7os71gO2D-T",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "cdc_idx_dict"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{0: 'Compared to the environmental impact of traditional energy sources, the environmental impact of wind power is relatively minor',\n",
              " 1: 'Wind power consumes no fuel',\n",
              " 9: 'Wind power consumes no fuel',\n",
              " 17: 'Producing electricity from wind reduces the consumption of fossil fuels and therefore leads to emissions savings',\n",
              " 129: 'Wind turbines do not consume fuel or produce pollution during normal operation',\n",
              " 150: 'They have a smaller footprint than other forms of energy generation',\n",
              " 153: 'wind farms will damage tourism',\n",
              " 164: 'may cause physiological problems',\n",
              " 180: 'people living near wind power facilities are increasingly complaining of health problems',\n",
              " 201: 'wind farms causing annoyance and ill health in people'}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 1306
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "dIfbAwvo2D-U",
        "colab": {}
      },
      "source": [
        "cdc = []\n",
        "\n",
        "for x in range(len(ndf)):\n",
        "    if x in list(cdc_idx_dict.keys()):\n",
        "        cdc.append(cdc_idx_dict.get(x))\n",
        "    else:\n",
        "        cdc.append('---')\n",
        "ndf['cdc'] = cdc\n",
        "\n",
        "df = pd.concat([ndf, df], axis=0, ignore_index=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "ubSAZ4qI2D-W"
      },
      "source": [
        "#### Article 1 "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "RObeaADq2D-X",
        "colab": {}
      },
      "source": [
        "with open(articles_dict[articles[1].replace(' ','_')+'.txt']) as article:\n",
        "        doc = article.read()\n",
        "\n",
        "c_doc = text_cleaner(doc)\n",
        "sentences = nltk.sent_tokenize(c_doc)\n",
        "sentences = [[sent, topic, articles[1]] for sent in sentences]\n",
        "\n",
        "ndf = pd.DataFrame(sentences, columns=['text', 'topic', 'article'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "outputId": "31314429-395d-4700-f207-bb8990c5f940",
        "id": "WdgRhY_W2D-Y",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "cdc_idx_dict = {}\n",
        "cdc_idx_sent = {}\n",
        "cdc_idx_art = {}\n",
        "\n",
        "for i,claim in enumerate(ref_data['clean_Claim']):\n",
        "    check_complete = False\n",
        "    while check_complete == False:\n",
        "        for idx,sentence in enumerate(ndf['text']):\n",
        "            test = claim.lower() in sentence.lower()\n",
        "            if test:\n",
        "                article = ref_data['Article'][i]\n",
        "                cdc_idx_dict[idx] = claim\n",
        "                cdc_idx_sent[idx] = [claim, sentence]\n",
        "                cdc_idx_art[idx] = [claim, article]\n",
        "                check_complete = True\n",
        "            elif idx == (len(ndf['text'])-1):\n",
        "                check_complete = True\n",
        "\n",
        "len(cdc_idx_dict), ref_data.shape[0]"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(4, 1332)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 1309
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "outputId": "62976e7b-73e6-45c7-8e35-ce861ae51557",
        "id": "Hg4H9xvK2D-b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "cdc_idx_dict"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{30: 'The production of zero carbon electricity at the wind farm is expected to reduce emissions of carbon dioxide',\n",
              " 53: 'wind power \"cannot be relied upon to provide significant levels of power',\n",
              " 70: 'wind power as the cleanest source of renewable energy',\n",
              " 71: 'wind farms are necessary to meet current and future energy needs'}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 1310
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "XjtZ-Lrd2D-c",
        "colab": {}
      },
      "source": [
        "cdc = []\n",
        "\n",
        "for x in range(len(ndf)):\n",
        "    if x in list(cdc_idx_dict.keys()):\n",
        "        cdc.append(cdc_idx_dict.get(x))\n",
        "    else:\n",
        "        cdc.append('---')\n",
        "ndf['cdc'] = cdc\n",
        "\n",
        "df = pd.concat([df, ndf], axis=0, ignore_index=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "zCJPwsGI2D-d"
      },
      "source": [
        "#### Article 2 "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "UQufg7Xh2D-e",
        "colab": {}
      },
      "source": [
        "with open(articles_dict[articles[2].replace(' ','_')+'.txt']) as article:\n",
        "        doc = article.read()\n",
        "\n",
        "c_doc = text_cleaner(doc)\n",
        "sentences = nltk.sent_tokenize(c_doc)\n",
        "sentences = [[sent, topic, articles[2]] for sent in sentences]\n",
        "\n",
        "ndf = pd.DataFrame(sentences, columns=['text', 'topic', 'article'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "outputId": "ac80c0e7-15e7-4eaf-d36e-7584386273de",
        "id": "uS6QiAtl2D-f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "cdc_idx_dict = {}\n",
        "cdc_idx_sent = {}\n",
        "cdc_idx_art = {}\n",
        "\n",
        "for i,claim in enumerate(ref_data['clean_Claim']):\n",
        "    check_complete = False\n",
        "    while check_complete == False:\n",
        "        for idx,sentence in enumerate(ndf['text']):\n",
        "            test = claim.lower() in sentence.lower()\n",
        "            if test:\n",
        "                article = ref_data['Article'][i]\n",
        "                cdc_idx_dict[idx] = claim\n",
        "                cdc_idx_sent[idx] = [claim, sentence]\n",
        "                cdc_idx_art[idx] = [claim, article]\n",
        "                check_complete = True\n",
        "            elif idx == (len(ndf['text'])-1):\n",
        "                check_complete = True\n",
        "\n",
        "len(cdc_idx_dict), ref_data.shape[0]"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(4, 1332)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 1313
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "outputId": "48b9ea44-eac1-406f-9a06-a31b87dde7f9",
        "id": "Shebw1q52D-h",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "cdc_idx_dict"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{23: 'Wind power is a product with no hidden costs and economically the most inexpensive form of energy production',\n",
              " 42: 'The use of wind power reduces the necessity for importing electricity from abroad',\n",
              " 47: 'Production of wind power does not release any pollutants',\n",
              " 55: 'wind power does not pose a threat to people or the environment'}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 1314
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "RLRGDbZF2D-i",
        "colab": {}
      },
      "source": [
        "cdc = []\n",
        "\n",
        "for x in range(len(ndf)):\n",
        "    if x in list(cdc_idx_dict.keys()):\n",
        "        cdc.append(cdc_idx_dict.get(x))\n",
        "    else:\n",
        "        cdc.append('---')\n",
        "ndf['cdc'] = cdc\n",
        "\n",
        "df = pd.concat([ndf, df], axis=0, ignore_index=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "hexEd4352D-k"
      },
      "source": [
        "#### Article 3 "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "EXwKjS8y2D-l",
        "colab": {}
      },
      "source": [
        "with open(articles_dict[articles[3].replace(' ','_')+'.txt']) as article:\n",
        "        doc = article.read()\n",
        "\n",
        "c_doc = text_cleaner(doc)\n",
        "sentences = nltk.sent_tokenize(c_doc)\n",
        "sentences = [[sent, topic, articles[3]] for sent in sentences]\n",
        "\n",
        "ndf = pd.DataFrame(sentences, columns=['text', 'topic', 'article'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "outputId": "cc9808a2-7835-4121-9761-15e903f8102a",
        "id": "TxU0LOdE2D-n",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "cdc_idx_dict = {}\n",
        "cdc_idx_sent = {}\n",
        "cdc_idx_art = {}\n",
        "\n",
        "for i,claim in enumerate(ref_data['clean_Claim']):\n",
        "    check_complete = False\n",
        "    while check_complete == False:\n",
        "        for idx,sentence in enumerate(ndf['text']):\n",
        "            test = claim.lower() in sentence.lower()\n",
        "            if test:\n",
        "                article = ref_data['Article'][i]\n",
        "                cdc_idx_dict[idx] = claim\n",
        "                cdc_idx_sent[idx] = [claim, sentence]\n",
        "                cdc_idx_art[idx] = [claim, article]\n",
        "                check_complete = True\n",
        "            elif idx == (len(ndf['text'])-1):\n",
        "                check_complete = True\n",
        "\n",
        "len(cdc_idx_dict), ref_data.shape[0]"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(1, 1332)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 1317
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "outputId": "77caf1a3-31e1-43dc-8d15-f466bf8df3b4",
        "id": "SqvnAEO02D-o",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "cdc_idx_dict"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{163: 'Wind power has poor capacity contribution'}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 1318
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "SCsEJmTf2D-q",
        "colab": {}
      },
      "source": [
        "cdc = []\n",
        "\n",
        "for x in range(len(ndf)):\n",
        "    if x in list(cdc_idx_dict.keys()):\n",
        "        cdc.append(cdc_idx_dict.get(x))\n",
        "    else:\n",
        "        cdc.append('---')\n",
        "ndf['cdc'] = cdc\n",
        "\n",
        "df = pd.concat([ndf, df], axis=0, ignore_index=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "W4T4TSXg2D-r"
      },
      "source": [
        "#### Article 4 "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "OU6rxyz52D-s",
        "colab": {}
      },
      "source": [
        "with open(articles_dict[articles[4].replace(' ','_')+'.txt']) as article:\n",
        "        doc = article.read()\n",
        "\n",
        "c_doc = text_cleaner(doc)\n",
        "sentences = nltk.sent_tokenize(c_doc)\n",
        "sentences = [[sent, topic, articles[4]] for sent in sentences]\n",
        "\n",
        "ndf = pd.DataFrame(sentences, columns=['text', 'topic', 'article'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "outputId": "439c03a4-10ca-4207-fb57-ac87d2539aa0",
        "id": "xo9UbjDQ2D-t",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "cdc_idx_dict = {}\n",
        "cdc_idx_sent = {}\n",
        "cdc_idx_art = {}\n",
        "\n",
        "for i,claim in enumerate(ref_data['clean_Claim']):\n",
        "    check_complete = False\n",
        "    while check_complete == False:\n",
        "        for idx,sentence in enumerate(ndf['text']):\n",
        "            test = claim.lower() in sentence.lower()\n",
        "            if test:\n",
        "                article = ref_data['Article'][i]\n",
        "                cdc_idx_dict[idx] = claim\n",
        "                cdc_idx_sent[idx] = [claim, sentence]\n",
        "                cdc_idx_art[idx] = [claim, article]\n",
        "                check_complete = True\n",
        "            elif idx == (len(ndf['text'])-1):\n",
        "                check_complete = True\n",
        "\n",
        "len(cdc_idx_dict), ref_data.shape[0]"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(1, 1332)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 1321
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "outputId": "11eff6e4-7d24-4a9e-d753-dc30739dcedd",
        "id": "2Qxe_s7t2D-u",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "cdc_idx_dict"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{190: 'Renewable energy is sustainable in its production'}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 1322
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "YEjwVrPm2D-w",
        "colab": {}
      },
      "source": [
        "cdc = []\n",
        "\n",
        "for x in range(len(ndf)):\n",
        "    if x in list(cdc_idx_dict.keys()):\n",
        "        cdc.append(cdc_idx_dict.get(x))\n",
        "    else:\n",
        "        cdc.append('---')\n",
        "ndf['cdc'] = cdc\n",
        "\n",
        "df = pd.concat([ndf, df], axis=0, ignore_index=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "QU52t-ThBGG2"
      },
      "source": [
        "#### Article 5 "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "pJVirVEEBGG4",
        "colab": {}
      },
      "source": [
        "with open(articles_dict[articles[5].replace(' ','_')+'.txt']) as article:\n",
        "        doc = article.read()\n",
        "\n",
        "c_doc = text_cleaner(doc)\n",
        "sentences = nltk.sent_tokenize(c_doc)\n",
        "sentences = [[sent, topic, articles[5]] for sent in sentences]\n",
        "\n",
        "ndf = pd.DataFrame(sentences, columns=['text', 'topic', 'article'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "outputId": "a332687f-b03e-4848-d5b6-489e3e56c6fa",
        "id": "NrtX-wm8BGG5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "cdc_idx_dict = {}\n",
        "cdc_idx_sent = {}\n",
        "cdc_idx_art = {}\n",
        "\n",
        "for i,claim in enumerate(ref_data['clean_Claim']):\n",
        "    check_complete = False\n",
        "    while check_complete == False:\n",
        "        for idx,sentence in enumerate(ndf['text']):\n",
        "            test = claim.lower() in sentence.lower()\n",
        "            if test:\n",
        "                article = ref_data['Article'][i]\n",
        "                cdc_idx_dict[idx] = claim\n",
        "                cdc_idx_sent[idx] = [claim, sentence]\n",
        "                cdc_idx_art[idx] = [claim, article]\n",
        "                check_complete = True\n",
        "            elif idx == (len(ndf['text'])-1):\n",
        "                check_complete = True\n",
        "\n",
        "len(cdc_idx_dict), ref_data.shape[0]"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(6, 1332)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 1325
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "outputId": "b9ca07a3-cb36-4686-80cc-40b58cc8bb70",
        "id": "4oECfpRTBGG6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "cdc_idx_dict"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{1: 'Wind power is an intermittent energy source',\n",
              " 4: 'integrating wind energy into the utility grid can be problematic',\n",
              " 40: 'Electricity generated from wind power can be highly variable',\n",
              " 44: 'predictability of wind plant output remains low',\n",
              " 46: 'the non-dispatchable nature of wind energy production can raise costs',\n",
              " 57: 'peak wind speeds may not coincide with peak demand for electrical power'}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 1326
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "OXVs51xsBGG7",
        "colab": {}
      },
      "source": [
        "cdc = []\n",
        "\n",
        "for x in range(len(ndf)):\n",
        "    if x in list(cdc_idx_dict.keys()):\n",
        "        cdc.append(cdc_idx_dict.get(x))\n",
        "    else:\n",
        "        cdc.append('---')\n",
        "ndf['cdc'] = cdc\n",
        "\n",
        "df = pd.concat([ndf, df], axis=0, ignore_index=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "HvjL4eCIBGG8"
      },
      "source": [
        "#### Article 6"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "9W7FFaMhBGG8",
        "colab": {}
      },
      "source": [
        "with open(articles_dict[articles[6].replace(' ','_')+'.txt']) as article:\n",
        "        doc = article.read()\n",
        "\n",
        "c_doc = text_cleaner(doc)\n",
        "sentences = nltk.sent_tokenize(c_doc)\n",
        "sentences = [[sent, topic, articles[6]] for sent in sentences]\n",
        "\n",
        "ndf = pd.DataFrame(sentences, columns=['text', 'topic', 'article'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "outputId": "e300f74a-f913-40f3-ead1-b5e416f35926",
        "id": "qWcGkp-WBGG9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "cdc_idx_dict = {}\n",
        "cdc_idx_sent = {}\n",
        "cdc_idx_art = {}\n",
        "\n",
        "for i,claim in enumerate(ref_data['clean_Claim']):\n",
        "    check_complete = False\n",
        "    while check_complete == False:\n",
        "        for idx,sentence in enumerate(ndf['text']):\n",
        "            test = claim.lower() in sentence.lower()\n",
        "            if test:\n",
        "                article = ref_data['Article'][i]\n",
        "                cdc_idx_dict[idx] = claim\n",
        "                cdc_idx_sent[idx] = [claim, sentence]\n",
        "                cdc_idx_art[idx] = [claim, article]\n",
        "                check_complete = True\n",
        "            elif idx == (len(ndf['text'])-1):\n",
        "                check_complete = True\n",
        "\n",
        "len(cdc_idx_dict), ref_data.shape[0]"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(2, 1332)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 1329
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "outputId": "39910f8c-1fc3-4da7-f281-412736c8c670",
        "id": "UWOo6RT_BGG-",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "cdc_idx_dict"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{47: 'the environmental effects of wind power are relatively minor',\n",
              " 48: 'Wind power consumes no fuel'}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 1330
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "nYxzFCKKBGG_",
        "colab": {}
      },
      "source": [
        "cdc = []\n",
        "\n",
        "for x in range(len(ndf)):\n",
        "    if x in list(cdc_idx_dict.keys()):\n",
        "        cdc.append(cdc_idx_dict.get(x))\n",
        "    else:\n",
        "        cdc.append('---')\n",
        "ndf['cdc'] = cdc\n",
        "\n",
        "df = pd.concat([ndf, df], axis=0, ignore_index=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CC17ZC0b0Gtd",
        "colab_type": "text"
      },
      "source": [
        "### 'year round schooling '"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "outputId": "a8b86716-9113-44a7-b024-5b48e61e1a9e",
        "id": "PbXWY7Dw135T",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "topic = 'year round schooling '\n",
        "\n",
        "articles = topic_article_dict[topic]\n",
        "articles"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['Year-round school',\n",
              " 'Summer learning loss',\n",
              " 'Summer vacation',\n",
              " 'After-school activity']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 1332
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XULtZJIR13jM",
        "colab_type": "code",
        "outputId": "574983b5-a12f-42f6-bebd-237095310b48",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "len(articles)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "4"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 1333
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "dYGb1pkp135U"
      },
      "source": [
        "#### Article 0 "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "r-Zydemm135V",
        "colab": {}
      },
      "source": [
        "with open(articles_dict[articles[0].replace(' ','_')+'.txt']) as article:\n",
        "        doc = article.read()\n",
        "\n",
        "c_doc = text_cleaner(doc)\n",
        "sentences = nltk.sent_tokenize(c_doc)\n",
        "sentences = [[sent, topic, articles[0]] for sent in sentences]\n",
        "\n",
        "ndf = pd.DataFrame(sentences, columns=['text', 'topic', 'article'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "outputId": "57a19c5c-b3a0-4dbb-ac22-c29b36beccbe",
        "id": "5xrywIh-135V",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "cdc_idx_dict = {}\n",
        "cdc_idx_sent = {}\n",
        "cdc_idx_art = {}\n",
        "\n",
        "for i,claim in enumerate(ref_data['clean_Claim']):\n",
        "    check_complete = False\n",
        "    while check_complete == False:\n",
        "        for idx,sentence in enumerate(ndf['text']):\n",
        "            test = claim.lower() in sentence.lower()\n",
        "            if test:\n",
        "                article = ref_data['Article'][i]\n",
        "                cdc_idx_dict[idx] = claim\n",
        "                cdc_idx_sent[idx] = [claim, sentence]\n",
        "                cdc_idx_art[idx] = [claim, article]\n",
        "                check_complete = True\n",
        "            elif idx == (len(ndf['text'])-1):\n",
        "                check_complete = True\n",
        "\n",
        "len(cdc_idx_dict), ref_data.shape[0]"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(12, 1332)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 1335
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "outputId": "26ae742a-966b-49dc-943c-e9fff98abd8f",
        "id": "x4g8BIRT135W",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "cdc_idx_dict"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{14: 'Multitrack schedules reportedly bring many benefits to schools that use them',\n",
              " 18: 'for every three multitrack schools, one less school must be built',\n",
              " 25: 'students’ attitudes towards school did significantly increase as they spent more time on a year-round schedule',\n",
              " 26: 'Students who attend year-round school say that their calendar is more balanced than their peers who have a typical school calendar',\n",
              " 29: 'year-round schools showed a substantial gain in academic achievement for at-risk, low performing students',\n",
              " 30: 'More frequent, short breaks provide struggling students more time for help',\n",
              " 33: 'parents are in favor of the year-round schedule',\n",
              " 35: 'The year round schedule provides more opportunities for family vacations',\n",
              " 37: 'If schools are open for longer the operating and maintenance costs may increase',\n",
              " 41: 'Year round schooling may create difficulties for teens to be able to maintain part-time or summer job',\n",
              " 42: 'Students with attention learning disabilities may experience difficulties with longer school days',\n",
              " 45: 'Students that attend year round schooling may miss out on experiences'}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 1336
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "FZ-TeTyi135X",
        "colab": {}
      },
      "source": [
        "cdc = []\n",
        "\n",
        "for x in range(len(ndf)):\n",
        "    if x in list(cdc_idx_dict.keys()):\n",
        "        cdc.append(cdc_idx_dict.get(x))\n",
        "    else:\n",
        "        cdc.append('---')\n",
        "ndf['cdc'] = cdc\n",
        "\n",
        "df = pd.concat([ndf, df], axis=0, ignore_index=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "8uMQLmCE135Y"
      },
      "source": [
        "#### Article 1 "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "NeCvNlql135Y",
        "colab": {}
      },
      "source": [
        "with open(articles_dict[articles[1].replace(' ','_')+'.txt']) as article:\n",
        "        doc = article.read()\n",
        "\n",
        "c_doc = text_cleaner(doc)\n",
        "sentences = nltk.sent_tokenize(c_doc)\n",
        "sentences = [[sent, topic, articles[1]] for sent in sentences]\n",
        "\n",
        "ndf = pd.DataFrame(sentences, columns=['text', 'topic', 'article'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "outputId": "bc1d234a-75c7-4952-fe1d-c567a455e5e4",
        "id": "Ox9Or_My135a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "cdc_idx_dict = {}\n",
        "cdc_idx_sent = {}\n",
        "cdc_idx_art = {}\n",
        "\n",
        "for i,claim in enumerate(ref_data['clean_Claim']):\n",
        "    check_complete = False\n",
        "    while check_complete == False:\n",
        "        for idx,sentence in enumerate(ndf['text']):\n",
        "            test = claim.lower() in sentence.lower()\n",
        "            if test:\n",
        "                article = ref_data['Article'][i]\n",
        "                cdc_idx_dict[idx] = claim\n",
        "                cdc_idx_sent[idx] = [claim, sentence]\n",
        "                cdc_idx_art[idx] = [claim, article]\n",
        "                check_complete = True\n",
        "            elif idx == (len(ndf['text'])-1):\n",
        "                check_complete = True\n",
        "\n",
        "len(cdc_idx_dict), ref_data.shape[0]"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(2, 1332)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 1339
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "outputId": "9463d07a-f564-467f-8dc9-c1a3a607a281",
        "id": "XOMp3I7n135a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "cdc_idx_dict"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{6: 'summer vacation is a period when students’ rate of academic development declines relative to the school year',\n",
              " 7: 'All children lose academic skills during the summer months'}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 1340
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "A9pTHfv6135b",
        "colab": {}
      },
      "source": [
        "cdc = []\n",
        "\n",
        "for x in range(len(ndf)):\n",
        "    if x in list(cdc_idx_dict.keys()):\n",
        "        cdc.append(cdc_idx_dict.get(x))\n",
        "    else:\n",
        "        cdc.append('---')\n",
        "ndf['cdc'] = cdc\n",
        "\n",
        "df = pd.concat([df, ndf], axis=0, ignore_index=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "CsR5PkO2135b"
      },
      "source": [
        "#### Article 2 "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "FDDBTGUp135c",
        "colab": {}
      },
      "source": [
        "with open(articles_dict[articles[2].replace(' ','_')+'.txt']) as article:\n",
        "        doc = article.read()\n",
        "\n",
        "c_doc = text_cleaner(doc)\n",
        "sentences = nltk.sent_tokenize(c_doc)\n",
        "sentences = [[sent, topic, articles[2]] for sent in sentences]\n",
        "\n",
        "ndf = pd.DataFrame(sentences, columns=['text', 'topic', 'article'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "outputId": "a684676a-c360-45d0-ae15-35a5a38c0a20",
        "id": "mOSu7V3m135c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "cdc_idx_dict = {}\n",
        "cdc_idx_sent = {}\n",
        "cdc_idx_art = {}\n",
        "\n",
        "for i,claim in enumerate(ref_data['clean_Claim']):\n",
        "    check_complete = False\n",
        "    while check_complete == False:\n",
        "        for idx,sentence in enumerate(ndf['text']):\n",
        "            test = claim.lower() in sentence.lower()\n",
        "            if test:\n",
        "                article = ref_data['Article'][i]\n",
        "                cdc_idx_dict[idx] = claim\n",
        "                cdc_idx_sent[idx] = [claim, sentence]\n",
        "                cdc_idx_art[idx] = [claim, article]\n",
        "                check_complete = True\n",
        "            elif idx == (len(ndf['text'])-1):\n",
        "                check_complete = True\n",
        "\n",
        "len(cdc_idx_dict), ref_data.shape[0]"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(1, 1332)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 1343
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "outputId": "afa5371c-cc2e-4e83-e121-afae53fa4c22",
        "id": "7lFbsQUB135d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "cdc_idx_dict"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{4: 'children need the – months off to relax and also to take a break from other childhood stresses associated with school'}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 1344
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "SXKRTPe9135d",
        "colab": {}
      },
      "source": [
        "cdc = []\n",
        "\n",
        "for x in range(len(ndf)):\n",
        "    if x in list(cdc_idx_dict.keys()):\n",
        "        cdc.append(cdc_idx_dict.get(x))\n",
        "    else:\n",
        "        cdc.append('---')\n",
        "ndf['cdc'] = cdc\n",
        "\n",
        "df = pd.concat([ndf, df], axis=0, ignore_index=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "nbuIv30w135e"
      },
      "source": [
        "#### Article 3 "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "brsccLts135e",
        "colab": {}
      },
      "source": [
        "with open(articles_dict[articles[3].replace(' ','_')+'.txt']) as article:\n",
        "        doc = article.read()\n",
        "\n",
        "c_doc = text_cleaner(doc)\n",
        "sentences = nltk.sent_tokenize(c_doc)\n",
        "sentences = [[sent, topic, articles[3]] for sent in sentences]\n",
        "\n",
        "ndf = pd.DataFrame(sentences, columns=['text', 'topic', 'article'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "outputId": "b836f34c-7b15-4c30-d0e3-2cda6e2dd400",
        "id": "UseH1c4D135f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "cdc_idx_dict = {}\n",
        "cdc_idx_sent = {}\n",
        "cdc_idx_art = {}\n",
        "\n",
        "for i,claim in enumerate(ref_data['clean_Claim']):\n",
        "    check_complete = False\n",
        "    while check_complete == False:\n",
        "        for idx,sentence in enumerate(ndf['text']):\n",
        "            test = claim.lower() in sentence.lower()\n",
        "            if test:\n",
        "                article = ref_data['Article'][i]\n",
        "                cdc_idx_dict[idx] = claim\n",
        "                cdc_idx_sent[idx] = [claim, sentence]\n",
        "                cdc_idx_art[idx] = [claim, article]\n",
        "                check_complete = True\n",
        "            elif idx == (len(ndf['text'])-1):\n",
        "                check_complete = True\n",
        "\n",
        "len(cdc_idx_dict), ref_data.shape[0]"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(2, 1332)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 1347
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "outputId": "4757583b-cc82-4911-fccb-381eb11c5e32",
        "id": "CF2B6Qg8135g",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "cdc_idx_dict"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{9: 'working parents wish their children to be supervised',\n",
              " 10: 'if unsupervised, children may fall into criminal or undesirable activity'}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 1348
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "i0u5S4RG135h",
        "colab": {}
      },
      "source": [
        "cdc = []\n",
        "\n",
        "for x in range(len(ndf)):\n",
        "    if x in list(cdc_idx_dict.keys()):\n",
        "        cdc.append(cdc_idx_dict.get(x))\n",
        "    else:\n",
        "        cdc.append('---')\n",
        "ndf['cdc'] = cdc\n",
        "\n",
        "df = pd.concat([ndf, df], axis=0, ignore_index=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ylDqZiq3j9Zf",
        "colab_type": "text"
      },
      "source": [
        "### Topic - 'Europe should weaken its austerity measures to guarantee its citizens greater social support '"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a1N0KcIUj_xa",
        "colab_type": "code",
        "outputId": "e23cace7-e99c-42b7-af4d-a19ee241365e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "topic = 'Europe should weaken its austerity measures to guarantee its citizens greater social support '\n",
        "\n",
        "articles = topic_article_dict[topic]\n",
        "articles"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['Welfare state',\n",
              " 'Austerity',\n",
              " 'Greek government-debt crisis',\n",
              " 'Anti-austerity protests',\n",
              " 'Deficit spending']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 1350
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xjswibhutGg1",
        "colab_type": "text"
      },
      "source": [
        "#### Article 0 "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_oD8Gh1CkQ0_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "with open(articles_dict[articles[0].replace(' ','_')+'.txt']) as article:\n",
        "        doc = article.read()\n",
        "\n",
        "c_doc = text_cleaner(doc)\n",
        "sentences = nltk.sent_tokenize(c_doc)\n",
        "sentences = [[sent, topic, articles[0]] for sent in sentences]\n",
        "\n",
        "ndf = pd.DataFrame(sentences, columns=['text', 'topic', 'article'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hrGLbDxQowla",
        "colab_type": "code",
        "outputId": "e44daecd-7896-42c0-e476-4e5e8ac27076",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "cdc_idx_dict = {}\n",
        "cdc_idx_sent = {}\n",
        "cdc_idx_art = {}\n",
        "\n",
        "for i,claim in enumerate(ref_data['clean_Claim']):\n",
        "    check_complete = False\n",
        "    while check_complete == False:\n",
        "        for idx,sentence in enumerate(ndf['text']):\n",
        "            test = claim.lower() in sentence.lower()\n",
        "            if test:\n",
        "                article = ref_data['Article'][i]\n",
        "                cdc_idx_dict[idx] = claim\n",
        "                cdc_idx_sent[idx] = [claim, sentence]\n",
        "                cdc_idx_art[idx] = [claim, article]\n",
        "                check_complete = True\n",
        "            elif idx == (len(ndf['text'])-1):\n",
        "                check_complete = True\n",
        "\n",
        "len(cdc_idx_dict), ref_data.shape[0]"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(1, 1332)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 1352
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iHzPn1qipWC4",
        "colab_type": "code",
        "outputId": "c01dc44e-2a59-4d63-9171-82d4a889a3d0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "cdc_idx_dict"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{15: \"the state should provide citizens their demands in order to achieve people's well-being\"}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 1353
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gI68PJobpx0v",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "cdc = []\n",
        "\n",
        "for x in range(len(ndf)):\n",
        "    if x in list(cdc_idx_dict.keys()):\n",
        "        cdc.append(cdc_idx_dict.get(x))\n",
        "    else:\n",
        "        cdc.append('---')\n",
        "ndf['cdc'] = cdc\n",
        "\n",
        "df = pd.concat([ndf, df], axis=0, ignore_index=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XugiWXt0tPBW",
        "colab_type": "text"
      },
      "source": [
        "#### Article 1 "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "deCneBdRrj2k",
        "colab": {}
      },
      "source": [
        "with open(articles_dict[articles[1].replace(' ','_')+'.txt']) as article:\n",
        "        doc = article.read()\n",
        "\n",
        "c_doc = text_cleaner(doc)\n",
        "sentences = nltk.sent_tokenize(c_doc)\n",
        "sentences = [[sent, topic, articles[1]] for sent in sentences]\n",
        "\n",
        "ndf = pd.DataFrame(sentences, columns=['text', 'topic', 'article'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "outputId": "8993b61d-af9d-4cc3-fc88-8df123e4437b",
        "id": "fxCbOoPFrj2p",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "cdc_idx_dict = {}\n",
        "cdc_idx_sent = {}\n",
        "cdc_idx_art = {}\n",
        "\n",
        "for i,claim in enumerate(ref_data['clean_Claim']):\n",
        "    check_complete = False\n",
        "    while check_complete == False:\n",
        "        for idx,sentence in enumerate(ndf['text']):\n",
        "            test = claim.lower() in sentence.lower()\n",
        "            if test:\n",
        "                article = ref_data['Article'][i]\n",
        "                cdc_idx_dict[idx] = claim\n",
        "                cdc_idx_sent[idx] = [claim, sentence]\n",
        "                cdc_idx_art[idx] = [claim, article]\n",
        "                check_complete = True\n",
        "            elif idx == (len(ndf['text'])-1):\n",
        "                check_complete = True\n",
        "\n",
        "len(cdc_idx_dict), ref_data.shape[0]"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(5, 1332)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 1356
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "outputId": "a3327485-e373-4678-e812-35b8d8fd449d",
        "id": "HbYLKw7irj2s",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "cdc_idx_dict"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{4: 'government austerity can result in economic expansion',\n",
              " 5: 'expansion from austerity is very limited',\n",
              " 20: 'they tend to have an adverse impact on the poorest segments of the population',\n",
              " 27: 'austerity measures tend to depress economic growth',\n",
              " 28: 'austerity can engender deflation which inflates existing debt'}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 1357
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "shASawCMrj2u",
        "colab": {}
      },
      "source": [
        "cdc = []\n",
        "\n",
        "for x in range(len(ndf)):\n",
        "    if x in list(cdc_idx_dict.keys()):\n",
        "        cdc.append(cdc_idx_dict.get(x))\n",
        "    else:\n",
        "        cdc.append('---')\n",
        "ndf['cdc'] = cdc\n",
        "\n",
        "df = pd.concat([df, ndf], axis=0, ignore_index=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D2xX6rt2tO4g",
        "colab_type": "text"
      },
      "source": [
        "#### Article 2 "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "cesdIO9wrv8t",
        "colab": {}
      },
      "source": [
        "with open(articles_dict[articles[2].replace(' ','_')+'.txt']) as article:\n",
        "        doc = article.read()\n",
        "\n",
        "c_doc = text_cleaner(doc)\n",
        "sentences = nltk.sent_tokenize(c_doc)\n",
        "sentences = [[sent, topic, articles[2]] for sent in sentences]\n",
        "\n",
        "ndf = pd.DataFrame(sentences, columns=['text', 'topic', 'article'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "outputId": "8195d287-524c-434d-cc83-22d52c95a8a2",
        "id": "ziBDTrhHrv8x",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "cdc_idx_dict = {}\n",
        "cdc_idx_sent = {}\n",
        "cdc_idx_art = {}\n",
        "\n",
        "for i,claim in enumerate(ref_data['clean_Claim']):\n",
        "    check_complete = False\n",
        "    while check_complete == False:\n",
        "        for idx,sentence in enumerate(ndf['text']):\n",
        "            test = claim.lower() in sentence.lower()\n",
        "            if test:\n",
        "                article = ref_data['Article'][i]\n",
        "                cdc_idx_dict[idx] = claim\n",
        "                cdc_idx_sent[idx] = [claim, sentence]\n",
        "                cdc_idx_art[idx] = [claim, article]\n",
        "                check_complete = True\n",
        "            elif idx == (len(ndf['text'])-1):\n",
        "                check_complete = True\n",
        "\n",
        "len(cdc_idx_dict), ref_data.shape[0]"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(4, 1332)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 1360
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "outputId": "59a0f788-f70d-48e0-d765-d6356ba874ed",
        "id": "F-WR_-5orv8z",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "cdc_idx_dict"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{361: 'social disruption could have a significantly negative impact on investment and growth in the longer term',\n",
              " 362: 'policy makers consistently underestimated the disastrous effects of rigid spending cuts on economic growth',\n",
              " 384: 'short-term sacrifices necessary for long-term success',\n",
              " 418: \"Governments borrowed too much, now they're paying the price, and fiscal austerity is the only answer\"}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 1361
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "vhovDL0zrv81",
        "colab": {}
      },
      "source": [
        "cdc = []\n",
        "\n",
        "for x in range(len(ndf)):\n",
        "    if x in list(cdc_idx_dict.keys()):\n",
        "        cdc.append(cdc_idx_dict.get(x))\n",
        "    else:\n",
        "        cdc.append('---')\n",
        "ndf['cdc'] = cdc\n",
        "\n",
        "df = pd.concat([ndf, df], axis=0, ignore_index=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JyYXDm_DtOu0",
        "colab_type": "text"
      },
      "source": [
        "#### Article 3 "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "QNzLR75vuCfw",
        "colab": {}
      },
      "source": [
        "with open(articles_dict[articles[3].replace(' ','_')+'.txt']) as article:\n",
        "        doc = article.read()\n",
        "\n",
        "c_doc = text_cleaner(doc)\n",
        "sentences = nltk.sent_tokenize(c_doc)\n",
        "sentences = [[sent, topic, articles[3]] for sent in sentences]\n",
        "\n",
        "ndf = pd.DataFrame(sentences, columns=['text', 'topic', 'article'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "outputId": "71e85433-45a7-4ead-d141-08ca1ff162ba",
        "id": "gq2n0HpMuCf2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "cdc_idx_dict = {}\n",
        "cdc_idx_sent = {}\n",
        "cdc_idx_art = {}\n",
        "\n",
        "for i,claim in enumerate(ref_data['clean_Claim']):\n",
        "    check_complete = False\n",
        "    while check_complete == False:\n",
        "        for idx,sentence in enumerate(ndf['text']):\n",
        "            test = claim.lower() in sentence.lower()\n",
        "            if test:\n",
        "                article = ref_data['Article'][i]\n",
        "                cdc_idx_dict[idx] = claim\n",
        "                cdc_idx_sent[idx] = [claim, sentence]\n",
        "                cdc_idx_art[idx] = [claim, article]\n",
        "                check_complete = True\n",
        "            elif idx == (len(ndf['text'])-1):\n",
        "                check_complete = True\n",
        "\n",
        "len(cdc_idx_dict), ref_data.shape[0]"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(5, 1332)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 1364
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "outputId": "60e605d0-8fd1-4652-feb1-2630fc537547",
        "id": "4SUvGgZfuCf4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "cdc_idx_dict"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{10: 'they tend to have an impact on the poorest segments of the population',\n",
              " 22: \"rather than 'punish' the banks and others truly responsible for the crisis, the government is instead 'punishing' regular people for the 'crimes' of others\",\n",
              " 64: 'austerity measures tend to be counterproductive',\n",
              " 65: 'austerity simply depresses economic growth',\n",
              " 66: 'austerity can engender deflation which inflates existing debt'}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 1365
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "fohhL9R2uCf8",
        "colab": {}
      },
      "source": [
        "cdc = []\n",
        "\n",
        "for x in range(len(ndf)):\n",
        "    if x in list(cdc_idx_dict.keys()):\n",
        "        cdc.append(cdc_idx_dict.get(x))\n",
        "    else:\n",
        "        cdc.append('---')\n",
        "ndf['cdc'] = cdc\n",
        "\n",
        "df = pd.concat([ndf, df], axis=0, ignore_index=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "q8M95f4QtONe",
        "colab_type": "text"
      },
      "source": [
        "#### Article 4 "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "ReG2MpXcuDhI",
        "colab": {}
      },
      "source": [
        "with open(articles_dict[articles[4].replace(' ','_')+'.txt']) as article:\n",
        "        doc = article.read()\n",
        "\n",
        "c_doc = text_cleaner(doc)\n",
        "sentences = nltk.sent_tokenize(c_doc)\n",
        "sentences = [[sent, topic, articles[4]] for sent in sentences]\n",
        "\n",
        "ndf = pd.DataFrame(sentences, columns=['text', 'topic', 'article'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "outputId": "c92c4f86-b373-4615-c1ad-87bab17ed82d",
        "id": "JzIZ1Q5auDhL",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "cdc_idx_dict = {}\n",
        "cdc_idx_sent = {}\n",
        "cdc_idx_art = {}\n",
        "\n",
        "for i,claim in enumerate(ref_data['clean_Claim']):\n",
        "    check_complete = False\n",
        "    while check_complete == False:\n",
        "        for idx,sentence in enumerate(ndf['text']):\n",
        "            test = claim.lower() in sentence.lower()\n",
        "            if test:\n",
        "                article = ref_data['Article'][i]\n",
        "                cdc_idx_dict[idx] = claim\n",
        "                cdc_idx_sent[idx] = [claim, sentence]\n",
        "                cdc_idx_art[idx] = [claim, article]\n",
        "                check_complete = True\n",
        "            elif idx == (len(ndf['text'])-1):\n",
        "                check_complete = True\n",
        "\n",
        "len(cdc_idx_dict), ref_data.shape[0]"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(8, 1332)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 1368
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "outputId": "11b0d084-37df-411d-9872-da6940993436",
        "id": "MlT1FpzfuDhM",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "cdc_idx_dict"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{5: 'deficit spending is necessary',\n",
              " 6: 'government should always run a balanced budget',\n",
              " 10: 'one should have money before one spends it',\n",
              " 17: 'deficit spending is necessary',\n",
              " 18: 'deficit spending is logically necessary',\n",
              " 41: 'deficit spending permits the private sector to accumulate net worth',\n",
              " 59: 'deficit spending may create inflation',\n",
              " 63: 'an increase in government spending will lead to inflation'}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 1369
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "mQ_1WbsauDhP",
        "colab": {}
      },
      "source": [
        "cdc = []\n",
        "\n",
        "for x in range(len(ndf)):\n",
        "    if x in list(cdc_idx_dict.keys()):\n",
        "        cdc.append(cdc_idx_dict.get(x))\n",
        "    else:\n",
        "        cdc.append('---')\n",
        "ndf['cdc'] = cdc\n",
        "\n",
        "df = pd.concat([ndf, df], axis=0, ignore_index=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bgcNzXtVxZOk",
        "colab_type": "text"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w1dURm5KNQZu",
        "colab_type": "code",
        "outputId": "d61b9491-4ad6-4bf8-ef88-0bf0be0c5563",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 170
        }
      },
      "source": [
        "df.info()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 46086 entries, 0 to 46085\n",
            "Data columns (total 4 columns):\n",
            "text       46086 non-null object\n",
            "topic      46086 non-null object\n",
            "article    46086 non-null object\n",
            "cdc        46086 non-null object\n",
            "dtypes: object(4)\n",
            "memory usage: 1.4+ MB\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4mtAy37HRByo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "check = df.loc[df['cdc']!='---']"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d2Koj1G-RVFp",
        "colab_type": "code",
        "outputId": "4935e6f9-84d7-44f4-c501-4103805689c2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "len(check)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1332"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 1373
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VWpSm0T7I-NH",
        "colab_type": "text"
      },
      "source": [
        "## Save compiled data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NFzE-gMLRV4d",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "write_path = '/content/drive/My Drive/Colab Notebooks/Thinkful/Module 34 - Final Capstone/data/CDC Detection/cl_dat.csv'\n",
        "\n",
        "df.to_csv(write_path)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MnKXMha3SSdJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}