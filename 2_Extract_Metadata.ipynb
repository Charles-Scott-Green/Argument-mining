{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "2 - Extract Metadata",
      "provenance": [],
      "machine_shape": "hm",
      "mount_file_id": "1il9K4mqyysOz--Dtl7n_6gjA7qbomfSY",
      "authorship_tag": "ABX9TyMc2t1apYIYoJHR/TmndV+1",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Charles-Scott-Green/Argument-mining/blob/master/2_Extract_Metadata.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YmETIF-oJYdG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D6kKdZxU2ONN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#!python -m spacy download en_core_web_lg --quiet"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yhs2wfKqLhCW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#!pip install vaderSentiment"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lRmqarKsMknz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#!pip install spacy-wordnet"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RhEfzrnxNMrc",
        "colab_type": "text"
      },
      "source": [
        "## Import Libraries and initialize settings"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T_xmW-tgn57F",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "sns.set()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Yl6yZVn_kZhF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import re\n",
        "import string\n",
        "import math\n",
        "from tqdm import tqdm"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lUJVBAVoPVlF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import nltk\n",
        "from nltk import pos_tag\n",
        "from nltk.corpus import wordnet as wn\n",
        "from nltk.tokenize import sent_tokenize, word_tokenize\n",
        "from pprint import pprint\n",
        "from nltk.tokenize.punkt import PunktSentenceTokenizer, PunktTrainer"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A3eRocMNq8MK",
        "colab_type": "code",
        "outputId": "b6fd0d65-eaa5-42fb-f618-5df929e54e77",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        }
      },
      "source": [
        "import nltk\n",
        "nltk.download('punkt')\n",
        "nltk.download('wordnet')\n",
        "nltk.download('averaged_perceptron_tagger')\n",
        "nltk.download('omw')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Package wordnet is already up-to-date!\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
            "[nltk_data]       date!\n",
            "[nltk_data] Downloading package omw to /root/nltk_data...\n",
            "[nltk_data]   Package omw is already up-to-date!\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6HiWGQu21GJB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import spacy\n",
        "from spacy.matcher import Matcher \n",
        "from spacy.tokens import Span \n",
        "from spacy import displacy \n",
        "from spacy.lang.en.stop_words import STOP_WORDS\n",
        "from spacy_wordnet.wordnet_annotator import WordnetAnnotator\n",
        "\n",
        "nlp = spacy.load(\"en_core_web_lg\")\n",
        "nlp.add_pipe(WordnetAnnotator(nlp.lang), after='tagger')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-e6_JYeW5oSW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import warnings\n",
        "from vaderSentiment.vaderSentiment import SentimentIntensityAnalyzer\n",
        "warnings.filterwarnings('ignore')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xnB1h62XVNp2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.model_selection import train_test_split as tts \n",
        "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import confusion_matrix, recall_score, precision_score\n",
        "\n",
        "import lightgbm as lgb\n",
        "\n",
        "from imblearn.over_sampling import SMOTE"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pbtdTusiNX4y",
        "colab_type": "text"
      },
      "source": [
        "## Define Functions"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1eXoZatbBZbo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def topic_domains(topic):\n",
        "    raw_domains = []\n",
        "    common_domains = []\n",
        "\n",
        "    for chunk in nlp(topic).noun_chunks:\n",
        "        rt_nn = chunk.root\n",
        "        raw_domains.append(rt_nn._.wordnet.wordnet_domains())\n",
        "\n",
        "    if len(raw_domains) > 0:\n",
        "        reference = raw_domains[0]\n",
        "    else:\n",
        "        return list(raw_domains)\n",
        "        \n",
        "    for domain in raw_domains:\n",
        "        common_domains = set(reference) & set(domain)\n",
        "        \n",
        "    return list(common_domains)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cEPeCEFS5l_n",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def expanded_sentence_similarity(topic, sentence):\n",
        "    \n",
        "    extended_topic = []\n",
        "    domains = topic_domains(topic)\n",
        "    \n",
        "    if len(domains) < 1:\n",
        "        return nlp(topic).similarity(nlp(sentence))\n",
        "    else:\n",
        "        for token in nlp(topic):\n",
        "            synsets = token._.wordnet.wordnet_synsets_for_domain(domains)\n",
        "            if synsets: \n",
        "                lfs = []\n",
        "                for syn in synsets:\n",
        "                    lfs.extend(syn.lemma_names())\n",
        "                    extended_topic.append('({})'.format('|'.join(set(lfs))))\n",
        "            else:\n",
        "                extended_topic.append(token.text)\n",
        "\n",
        "        tokenized_extended_topic = nlp(' '.join(extended_topic))\n",
        "\n",
        "    return tokenized_extended_topic.similarity(nlp(sentence))            "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NyPM1vywDc49",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def subject_match(topic, sentence):\n",
        "    \n",
        "    ntopic = nlp(topic)\n",
        "    scores = []\n",
        "    for chunk in nlp(sentence).noun_chunks:\n",
        "        scores.append(chunk.similarity(ntopic))\n",
        "    \n",
        "    return np.mean(scores)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bciyullS1Qhj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def subject_match2(topic, sentence):\n",
        "    \n",
        "    ntopic = nlp(topic)\n",
        "    scores = []\n",
        "    for chnk in nlp(sentence).noun_chunks:\n",
        "        for tchnk in ntopic.noun_chunks:\n",
        "            scores.append(chnk.similarity(tchnk))\n",
        "    \n",
        "    return np.mean(scores)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JfPZ9FUAxeAb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def includes_that(sentence):\n",
        "    check = []\n",
        "    for tok in sentence:\n",
        "        if tok.tag_ == 'IN':\n",
        "            check.append(tok.text)\n",
        "    if 'that' in check:\n",
        "        return 1\n",
        "    else:\n",
        "        return 0"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XmneTg_p98Ze",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def patterns(sentence, pattern_type='dep'):\n",
        "    \n",
        "    pat = []\n",
        "    if pattern_type == 'dep':\n",
        "        pat = [tok.dep_ for tok in sentence]\n",
        "    elif pattern_type == 'tag':\n",
        "        pat = [tok.tag_ for tok in sentence]\n",
        "    \n",
        "    return '|'.join(pat)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qBm0yoGxC2dO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def pos_pattern(sentence):\n",
        "    pat = []\n",
        "    for tok in sentence:\n",
        "        pat.append(tok.pos_)\n",
        "\n",
        "    return '|'.join(pat)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8LDjYaZoEynE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def pattern_in_text(pattern, sentence):\n",
        "    text_pattern = pos_pattern(sentence)\n",
        "\n",
        "    if pattern in text_pattern:\n",
        "        return 1\n",
        "    else:\n",
        "        return 0"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WsALWpSqU57G",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def infinitive_verb_present(sentence):\n",
        "    text_pattern = pos_pattern(sentence)\n",
        "    infinitive_pattern = 'PART|VERB'\n",
        "\n",
        "    if infinitive_pattern in text_pattern:\n",
        "        return 1\n",
        "    else:\n",
        "        return 0\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aNQdINpkDV4h",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def sentiment_subjectivity(sentence, score_type='sentiment'):\n",
        "    analyzer = SentimentIntensityAnalyzer()\n",
        "\n",
        "    if score_type == 'sentiment':\n",
        "        pos = analyzer.polarity_scores(sentence)['pos']\n",
        "        neg = analyzer.polarity_scores(sentence)['neg']\n",
        "        return pos/neg\n",
        "    \n",
        "    else:\n",
        "        return analyzer.polarity_scores(sentence)['compound']"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GTmm35Dc1gTn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def is_sentence(clause):\n",
        "    nn = 2\n",
        "    vb = 1\n",
        "    cls = nlp(clause)\n",
        "    for tok in cls:\n",
        "        if tok.pos_ in ['NOUN', 'PROPN', 'PRON']:\n",
        "            nn -= 1\n",
        "        elif tok.pos_ in ['VERB']:\n",
        "            vb -= 1\n",
        "    if nn < 1 and vb < 1:\n",
        "        return True\n",
        "    else:\n",
        "        return False"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MBlrGISWuJIt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def get_clauses(sentence):\n",
        "    \"\"\"Sentence type is a string.\"\"\"\n",
        "    subtree_phrases = []\n",
        "    \n",
        "    for tok in nlp(sentence):\n",
        "        if tok.head.pos_ == 'VERB':\n",
        "            if len([tok for tok in tok.subtree]) >= 3:\n",
        "                subtree_prhase = ''.join(tok.text_with_ws for tok in tok.subtree)\n",
        "                if subtree_prhase != sentence:\n",
        "                    if is_sentence(subtree_prhase):\n",
        "                        splits = subtree_prhase.split(',')\n",
        "                        if len(splits) == 1:\n",
        "                            subtree_phrases.append(subtree_prhase)\n",
        "                        else:\n",
        "                            for split in splits:\n",
        "                                if is_sentence(split):\n",
        "                                    if split not in subtree_phrases:\n",
        "                                        subtree_phrases.append(split) \n",
        "    \n",
        "    raw_clauses = []\n",
        "    clauses = []\n",
        "\n",
        "    for phrase in subtree_phrases:\n",
        "        tok_phrase = nlp(phrase)\n",
        "        for chunk in tok_phrase.noun_chunks:\n",
        "            span = tok_phrase[chunk.root.head.left_edge.i:chunk.root.head.right_edge.i+1]\n",
        "            if span[0].pos_ in ['DET', 'ADP']:\n",
        "                if span[1:].text not in raw_clauses:\n",
        "                    if is_sentence(span[1:].text):\n",
        "                        raw_clauses.append(span[1:].text)\n",
        "            elif span.text not in raw_clauses:\n",
        "                if is_sentence(span.text):\n",
        "                    raw_clauses.append(span.text)\n",
        "    \n",
        "    if len(raw_clauses) == 0:\n",
        "        clauses.append(sentence)\n",
        "    else:\n",
        "        for clause in raw_clauses:\n",
        "            dup_checks = [(clause in check_clause) for check_clause in raw_clauses]\n",
        "            if sum(dup_checks) == 1:\n",
        "                clauses.append(clause)\n",
        "                \n",
        "    return clauses"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ud9h4KuFNEyP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def conf_matrix(y_true, y_predict):\n",
        "    \n",
        "    from sklearn.metrics import confusion_matrix\n",
        "    \n",
        "    data = confusion_matrix(y_true, y_predict)\n",
        "    index = ['Actual_0', 'Actual_1']\n",
        "    columns = ['Predicted_0', 'Predicted_1']\n",
        "    \n",
        "    return pd.DataFrame(data, index, columns)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ioFrxxxPT_Xm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def get_target_data(path):\n",
        "    df = pd.read_csv(path)\n",
        "    df['cdc_present'] = (df['cdc'] != '---').astype(int)\n",
        "\n",
        "    return df['cdc_present']"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9bJkmtsrXjJP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def count_sentiment_words(sentence):\n",
        "    analyzer = SentimentIntensityAnalyzer()\n",
        "    wd_cnt = 0\n",
        "\n",
        "    for tok in nlp(sentence):\n",
        "        if analyzer.polarity_scores(tok.text)['compound'] != 0:\n",
        "            wd_cnt += 1\n",
        "\n",
        "    return wd_cnt"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BZObCjI4Xi8X",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def count_syllables(sentence):\n",
        "    \"\"\"Given a string, calculates and returns the number of syllables of the word.\"\"\"\n",
        "    import string\n",
        "    \n",
        "    word_list = sentence.translate(string.punctuation).split()\n",
        "    vowels = \"aeiouy\"\n",
        "    tally = 0\n",
        "    \n",
        "    for word in word_list:\n",
        "        word = word.lower()\n",
        "        vowels = \"aeiouy\"\n",
        "        count = 0\n",
        "        \n",
        "        if word[0] in vowels:\n",
        "            count += 1\n",
        "\n",
        "        for i in range(1, len(word)):\n",
        "            if word[i] in vowels and word[i - 1] not in vowels:\n",
        "                count += 1\n",
        "\n",
        "        if word.endswith('e'):\n",
        "            count -= 1\n",
        "\n",
        "        if count == 0:\n",
        "            count += 1\n",
        "    \n",
        "        tally += count\n",
        "    \n",
        "    return tally"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3JB4e6FfXivO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def punct_marks(sentence):\n",
        "    \"\"\"Given a sentence, returns count and/or list of punctiation marks\"\"\"\n",
        "    \n",
        "    pm = []\n",
        "    \n",
        "    for tok in nlp(sentence):\n",
        "        if tok.pos_ == 'PUNCT':\n",
        "            pm.append(tok)\n",
        "    return len(pm)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KGQyY_WIXimq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def noun_counts(sentence):\n",
        "    \n",
        "    chnk = []\n",
        "    \n",
        "    for chunk in nlp(sentence).noun_chunks:\n",
        "        chnk.append(chunk)\n",
        "\n",
        "    return len(chnk)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QFxyYhI4Xidd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def word_count(sentence):\n",
        "    wds = []\n",
        "    for tok in nlp(sentence):\n",
        "        if tok.pos_ != 'PUNCT':\n",
        "            wds.append(tok)\n",
        "    return len(wds)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xx9h2Qo8XiMg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def phrase_chunks(sentence):\n",
        "    s = []\n",
        "    for tok in nlp(sentence):\n",
        "        if len([tok for tok in tok.subtree]) >=3:\n",
        "            if ''.join(tok.text_with_ws for tok in tok.subtree) != str(sentence):\n",
        "                s.append(''.join(tok.text_with_ws for tok in tok.subtree))\n",
        "    return len(s)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DSn9KextNbne",
        "colab_type": "text"
      },
      "source": [
        "## Load & Explore Data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Qy6nC-sMw8q_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# paths to articles and topics\n",
        "path = '/content/drive/My Drive/Colab Notebooks/Thinkful/Module 34 - Final Capstone/data/CDC Detection/cl_datt.csv'\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "PDALUIlNsBbk",
        "colab": {}
      },
      "source": [
        "# Load topic/article index data\n",
        "raw_data = pd.read_csv(path)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uLr6u-GGLEXo",
        "colab_type": "code",
        "outputId": "4ff942c1-c530-4a8c-9e21-6784e6ea42f4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "# Unique Claim counts\n",
        "raw_data.shape"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(41999, 5)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m4nv3cFIFPeY",
        "colab_type": "code",
        "outputId": "5c3cf03a-158a-464b-9635-eaa6f0cb3aec",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "raw_data.columns"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Index(['Unnamed: 0', 'text', 'topic', 'article', 'cdc'], dtype='object')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cJQCRpxorXUn",
        "colab_type": "code",
        "outputId": "71185546-e8dc-472e-cb24-b527996dd710",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        }
      },
      "source": [
        "# Explore columns and types.\n",
        "raw_data.head()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Unnamed: 0</th>\n",
              "      <th>text</th>\n",
              "      <th>topic</th>\n",
              "      <th>article</th>\n",
              "      <th>cdc</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>Deficit spending is the amount by which a gove...</td>\n",
              "      <td>Europe should weaken its austerity measures to...</td>\n",
              "      <td>Deficit spending</td>\n",
              "      <td>---</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>Government deficit spending is a central point...</td>\n",
              "      <td>Europe should weaken its austerity measures to...</td>\n",
              "      <td>Deficit spending</td>\n",
              "      <td>---</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>Government deficit spending is a central point...</td>\n",
              "      <td>Europe should weaken its austerity measures to...</td>\n",
              "      <td>Deficit spending</td>\n",
              "      <td>---</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3</td>\n",
              "      <td>The mainstream economics position is that defi...</td>\n",
              "      <td>Europe should weaken its austerity measures to...</td>\n",
              "      <td>Deficit spending</td>\n",
              "      <td>---</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4</td>\n",
              "      <td>This is derived from Keynesian economics, and ...</td>\n",
              "      <td>Europe should weaken its austerity measures to...</td>\n",
              "      <td>Deficit spending</td>\n",
              "      <td>---</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   Unnamed: 0  ...  cdc\n",
              "0           0  ...  ---\n",
              "1           1  ...  ---\n",
              "2           2  ...  ---\n",
              "3           3  ...  ---\n",
              "4           4  ...  ---\n",
              "\n",
              "[5 rows x 5 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 35
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uigvWFwWPa-L",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Convert target into a binary class\n",
        "raw_data['cdc_present'] = (raw_data['cdc'] != '---')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "o4F6ziFYUXbM",
        "colab_type": "text"
      },
      "source": [
        "### Topics"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AX-7tDhA94-M",
        "colab_type": "code",
        "outputId": "b083351d-c0c7-4d33-a705-e00c3d61e79d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# Review topics\n",
        "raw_data['topic'].unique()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array(['Europe should weaken its austerity measures to guarantee its citizens greater social support ',\n",
              "       'year round schooling ',\n",
              "       'wind power should be a primary focus of future energy supply ',\n",
              "       'trade aid',\n",
              "       'the use of performance enhancing drugs in professional sports ',\n",
              "       'the use of affirmative action ',\n",
              "       'the sale of violent video games to minors ',\n",
              "       'the one child policy of the republic of China ', 'the monarchy ',\n",
              "       \"the United States is responsible for Mexico's drugs war \",\n",
              "       'the US is justified in using force to prevent states from acquiring nuclear weapons ',\n",
              "       'that the right to asylum should not be absolute ',\n",
              "       'subsidise poor communities ', 'reintroduce national service ',\n",
              "       're engage with Myanmar ', 'partial birth abortions ',\n",
              "       'parents to genetically screen foetuses for heritable diseases ',\n",
              "       'multiculturalism ', 'make physical education compulsory ',\n",
              "       'limit the right to bear arms ', 'intellectual property rights ',\n",
              "       'institute a mandatory retirement age ',\n",
              "       'housewives should be paid for their work ', 'gambling ',\n",
              "       'endangered species should be protected ',\n",
              "       'democratic governments should require voters to present photo identification at the polling station ',\n",
              "       'countries with an imbalanced male female ratio skewed towards males should encourage parents to produce girls ',\n",
              "       'bribery is sometimes acceptable ', 'boxing ',\n",
              "       'atheism is the only way ',\n",
              "       'all nations have a right to nuclear weapons ',\n",
              "       'all collective bargaining rights claimed by trades unions ',\n",
              "       \"Google shouldn't censor its search results in China \"],\n",
              "      dtype=object)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 37
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t6bl4Q-tPkdE",
        "colab_type": "code",
        "outputId": "a12e31d2-f51f-4838-e1d8-03d630779a6c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "displacy.render(nlp('trade aide'), jupyter=True, \n",
        "                options={'compact':True, 'distance':100})"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<svg xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\" xml:lang=\"en\" id=\"22e4dff3320848de809d75ec5e1ead72-0\" class=\"displacy\" width=\"250\" height=\"187.0\" direction=\"ltr\" style=\"max-width: none; height: 187.0px; color: #000000; background: #ffffff; font-family: Arial; direction: ltr\">\n",
              "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"97.0\">\n",
              "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"50\">trade</tspan>\n",
              "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"50\">NOUN</tspan>\n",
              "</text>\n",
              "\n",
              "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"97.0\">\n",
              "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"150\">aide</tspan>\n",
              "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"150\">NOUN</tspan>\n",
              "</text>\n",
              "\n",
              "<g class=\"displacy-arrow\">\n",
              "    <path class=\"displacy-arc\" id=\"arrow-22e4dff3320848de809d75ec5e1ead72-0-0\" stroke-width=\"2px\" d=\"M62,52.0 62,35.33333333333333 150.0,35.33333333333333 150.0,52.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
              "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
              "        <textPath xlink:href=\"#arrow-22e4dff3320848de809d75ec5e1ead72-0-0\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">compound</textPath>\n",
              "    </text>\n",
              "    <path class=\"displacy-arrowhead\" d=\"M62,54.0 L58,46.0 66,46.0\" fill=\"currentColor\"/>\n",
              "</g>\n",
              "</svg>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IALO9xBMPwDV",
        "colab_type": "code",
        "outputId": "d7a1cae6-006c-46cc-a275-aa6d7a929f90",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "txt = 'Europe should weaken its austerity measures to guarantee its citizens greater social support'\n",
        "\n",
        "displacy.render(nlp(txt), jupyter=True, \n",
        "                options={'compact':True, 'distance':100})"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<svg xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\" xml:lang=\"en\" id=\"18a3a7fbeece418888face7498c03642-0\" class=\"displacy\" width=\"1350\" height=\"337.0\" direction=\"ltr\" style=\"max-width: none; height: 337.0px; color: #000000; background: #ffffff; font-family: Arial; direction: ltr\">\n",
              "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"247.0\">\n",
              "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"50\">Europe</tspan>\n",
              "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"50\">PROPN</tspan>\n",
              "</text>\n",
              "\n",
              "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"247.0\">\n",
              "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"150\">should</tspan>\n",
              "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"150\">VERB</tspan>\n",
              "</text>\n",
              "\n",
              "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"247.0\">\n",
              "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"250\">weaken</tspan>\n",
              "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"250\">VERB</tspan>\n",
              "</text>\n",
              "\n",
              "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"247.0\">\n",
              "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"350\">its</tspan>\n",
              "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"350\">DET</tspan>\n",
              "</text>\n",
              "\n",
              "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"247.0\">\n",
              "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"450\">austerity</tspan>\n",
              "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"450\">NOUN</tspan>\n",
              "</text>\n",
              "\n",
              "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"247.0\">\n",
              "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"550\">measures</tspan>\n",
              "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"550\">NOUN</tspan>\n",
              "</text>\n",
              "\n",
              "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"247.0\">\n",
              "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"650\">to</tspan>\n",
              "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"650\">PART</tspan>\n",
              "</text>\n",
              "\n",
              "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"247.0\">\n",
              "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"750\">guarantee</tspan>\n",
              "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"750\">VERB</tspan>\n",
              "</text>\n",
              "\n",
              "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"247.0\">\n",
              "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"850\">its</tspan>\n",
              "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"850\">DET</tspan>\n",
              "</text>\n",
              "\n",
              "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"247.0\">\n",
              "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"950\">citizens</tspan>\n",
              "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"950\">NOUN</tspan>\n",
              "</text>\n",
              "\n",
              "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"247.0\">\n",
              "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"1050\">greater</tspan>\n",
              "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"1050\">ADJ</tspan>\n",
              "</text>\n",
              "\n",
              "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"247.0\">\n",
              "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"1150\">social</tspan>\n",
              "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"1150\">ADJ</tspan>\n",
              "</text>\n",
              "\n",
              "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"247.0\">\n",
              "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"1250\">support</tspan>\n",
              "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"1250\">NOUN</tspan>\n",
              "</text>\n",
              "\n",
              "<g class=\"displacy-arrow\">\n",
              "    <path class=\"displacy-arc\" id=\"arrow-18a3a7fbeece418888face7498c03642-0-0\" stroke-width=\"2px\" d=\"M62,202.0 62,168.66666666666666 244.0,168.66666666666666 244.0,202.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
              "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
              "        <textPath xlink:href=\"#arrow-18a3a7fbeece418888face7498c03642-0-0\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">nsubj</textPath>\n",
              "    </text>\n",
              "    <path class=\"displacy-arrowhead\" d=\"M62,204.0 L58,196.0 66,196.0\" fill=\"currentColor\"/>\n",
              "</g>\n",
              "\n",
              "<g class=\"displacy-arrow\">\n",
              "    <path class=\"displacy-arc\" id=\"arrow-18a3a7fbeece418888face7498c03642-0-1\" stroke-width=\"2px\" d=\"M162,202.0 162,185.33333333333334 241.0,185.33333333333334 241.0,202.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
              "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
              "        <textPath xlink:href=\"#arrow-18a3a7fbeece418888face7498c03642-0-1\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">aux</textPath>\n",
              "    </text>\n",
              "    <path class=\"displacy-arrowhead\" d=\"M162,204.0 L158,196.0 166,196.0\" fill=\"currentColor\"/>\n",
              "</g>\n",
              "\n",
              "<g class=\"displacy-arrow\">\n",
              "    <path class=\"displacy-arc\" id=\"arrow-18a3a7fbeece418888face7498c03642-0-2\" stroke-width=\"2px\" d=\"M362,202.0 362,168.66666666666666 544.0,168.66666666666666 544.0,202.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
              "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
              "        <textPath xlink:href=\"#arrow-18a3a7fbeece418888face7498c03642-0-2\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">poss</textPath>\n",
              "    </text>\n",
              "    <path class=\"displacy-arrowhead\" d=\"M362,204.0 L358,196.0 366,196.0\" fill=\"currentColor\"/>\n",
              "</g>\n",
              "\n",
              "<g class=\"displacy-arrow\">\n",
              "    <path class=\"displacy-arc\" id=\"arrow-18a3a7fbeece418888face7498c03642-0-3\" stroke-width=\"2px\" d=\"M462,202.0 462,185.33333333333334 541.0,185.33333333333334 541.0,202.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
              "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
              "        <textPath xlink:href=\"#arrow-18a3a7fbeece418888face7498c03642-0-3\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">compound</textPath>\n",
              "    </text>\n",
              "    <path class=\"displacy-arrowhead\" d=\"M462,204.0 L458,196.0 466,196.0\" fill=\"currentColor\"/>\n",
              "</g>\n",
              "\n",
              "<g class=\"displacy-arrow\">\n",
              "    <path class=\"displacy-arc\" id=\"arrow-18a3a7fbeece418888face7498c03642-0-4\" stroke-width=\"2px\" d=\"M262,202.0 262,152.0 547.0,152.0 547.0,202.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
              "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
              "        <textPath xlink:href=\"#arrow-18a3a7fbeece418888face7498c03642-0-4\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">dobj</textPath>\n",
              "    </text>\n",
              "    <path class=\"displacy-arrowhead\" d=\"M547.0,204.0 L551.0,196.0 543.0,196.0\" fill=\"currentColor\"/>\n",
              "</g>\n",
              "\n",
              "<g class=\"displacy-arrow\">\n",
              "    <path class=\"displacy-arc\" id=\"arrow-18a3a7fbeece418888face7498c03642-0-5\" stroke-width=\"2px\" d=\"M662,202.0 662,185.33333333333334 741.0,185.33333333333334 741.0,202.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
              "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
              "        <textPath xlink:href=\"#arrow-18a3a7fbeece418888face7498c03642-0-5\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">aux</textPath>\n",
              "    </text>\n",
              "    <path class=\"displacy-arrowhead\" d=\"M662,204.0 L658,196.0 666,196.0\" fill=\"currentColor\"/>\n",
              "</g>\n",
              "\n",
              "<g class=\"displacy-arrow\">\n",
              "    <path class=\"displacy-arc\" id=\"arrow-18a3a7fbeece418888face7498c03642-0-6\" stroke-width=\"2px\" d=\"M562,202.0 562,168.66666666666666 744.0,168.66666666666666 744.0,202.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
              "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
              "        <textPath xlink:href=\"#arrow-18a3a7fbeece418888face7498c03642-0-6\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">relcl</textPath>\n",
              "    </text>\n",
              "    <path class=\"displacy-arrowhead\" d=\"M744.0,204.0 L748.0,196.0 740.0,196.0\" fill=\"currentColor\"/>\n",
              "</g>\n",
              "\n",
              "<g class=\"displacy-arrow\">\n",
              "    <path class=\"displacy-arc\" id=\"arrow-18a3a7fbeece418888face7498c03642-0-7\" stroke-width=\"2px\" d=\"M862,202.0 862,185.33333333333334 941.0,185.33333333333334 941.0,202.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
              "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
              "        <textPath xlink:href=\"#arrow-18a3a7fbeece418888face7498c03642-0-7\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">poss</textPath>\n",
              "    </text>\n",
              "    <path class=\"displacy-arrowhead\" d=\"M862,204.0 L858,196.0 866,196.0\" fill=\"currentColor\"/>\n",
              "</g>\n",
              "\n",
              "<g class=\"displacy-arrow\">\n",
              "    <path class=\"displacy-arc\" id=\"arrow-18a3a7fbeece418888face7498c03642-0-8\" stroke-width=\"2px\" d=\"M762,202.0 762,168.66666666666666 944.0,168.66666666666666 944.0,202.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
              "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
              "        <textPath xlink:href=\"#arrow-18a3a7fbeece418888face7498c03642-0-8\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">dative</textPath>\n",
              "    </text>\n",
              "    <path class=\"displacy-arrowhead\" d=\"M944.0,204.0 L948.0,196.0 940.0,196.0\" fill=\"currentColor\"/>\n",
              "</g>\n",
              "\n",
              "<g class=\"displacy-arrow\">\n",
              "    <path class=\"displacy-arc\" id=\"arrow-18a3a7fbeece418888face7498c03642-0-9\" stroke-width=\"2px\" d=\"M1062,202.0 1062,168.66666666666666 1244.0,168.66666666666666 1244.0,202.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
              "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
              "        <textPath xlink:href=\"#arrow-18a3a7fbeece418888face7498c03642-0-9\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">amod</textPath>\n",
              "    </text>\n",
              "    <path class=\"displacy-arrowhead\" d=\"M1062,204.0 L1058,196.0 1066,196.0\" fill=\"currentColor\"/>\n",
              "</g>\n",
              "\n",
              "<g class=\"displacy-arrow\">\n",
              "    <path class=\"displacy-arc\" id=\"arrow-18a3a7fbeece418888face7498c03642-0-10\" stroke-width=\"2px\" d=\"M1162,202.0 1162,185.33333333333334 1241.0,185.33333333333334 1241.0,202.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
              "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
              "        <textPath xlink:href=\"#arrow-18a3a7fbeece418888face7498c03642-0-10\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">amod</textPath>\n",
              "    </text>\n",
              "    <path class=\"displacy-arrowhead\" d=\"M1162,204.0 L1158,196.0 1166,196.0\" fill=\"currentColor\"/>\n",
              "</g>\n",
              "\n",
              "<g class=\"displacy-arrow\">\n",
              "    <path class=\"displacy-arc\" id=\"arrow-18a3a7fbeece418888face7498c03642-0-11\" stroke-width=\"2px\" d=\"M762,202.0 762,135.33333333333331 1250.0,135.33333333333331 1250.0,202.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
              "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
              "        <textPath xlink:href=\"#arrow-18a3a7fbeece418888face7498c03642-0-11\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">dobj</textPath>\n",
              "    </text>\n",
              "    <path class=\"displacy-arrowhead\" d=\"M1250.0,204.0 L1254.0,196.0 1246.0,196.0\" fill=\"currentColor\"/>\n",
              "</g>\n",
              "</svg>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0wUh0HnKNv-S",
        "colab_type": "text"
      },
      "source": [
        "Topics vary in structure.  In many cases, topics are not statements or even sentences, rather they are specific words, or word combinations, that are \"evaluative\".  \n",
        "\n",
        "In debate, evalutive terms are stand-alone terms that provide the general foundation, or context, of discussion or debate.  Additional phrase/sentence structures build on the context to frame a topic.  Take for example the diagramed topics:\n",
        "\n",
        "* \"trade aid\" - This is not a topic; it is a context.  \n",
        "\n",
        "* \"Europe should weakin its austerity measures to guarantee its citizens greater social support.\"  This a topic.  In this case, the context is \"austerity measures\".  \n",
        "\n",
        "Applying domain knowledge, the context of each unique \"topic\" will be extracted.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Bcq13NlV907z",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Contexts\n",
        "evaluatives = ['austerity measures', 'year round school', 'wind power', 'traid aid',\n",
        "               'performing enhancing drugs', 'affirmative aciton', \n",
        "               'violent video games', 'one child policy', 'monarchy', 'drug war', \n",
        "               'nuclear weapons', 'right to asylum', 'subsidise community', \n",
        "               'national service', 'Myanmar', 'abortions', 'genetic screening', \n",
        "               'multiculturalism', 'physical education', 'right to bear arms', \n",
        "               'intellectual property rights', 'retirement age', 'pay housewives', \n",
        "               'gambling', 'endangered species', 'voter identification', \n",
        "               'human sex ratio', 'bribery', 'boxing', 'atheism', 'nuclear weapons',\n",
        "               'collective bargaining', 'censorship']\n",
        "\n",
        "context_dict = {}\n",
        "\n",
        "for i,tpc in enumerate(raw_data['topic'].unique()):\n",
        "    context_dict[tpc] = evaluatives[i]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F71ezHblNOwg",
        "colab_type": "code",
        "outputId": "bfebf77e-9741-41e2-eec3-7dae061ee8c1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "raw_data['context'] = raw_data['topic'].apply(lambda x: context_dict.get(x))\n",
        "\n",
        "raw_data.head()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Unnamed: 0</th>\n",
              "      <th>text</th>\n",
              "      <th>topic</th>\n",
              "      <th>article</th>\n",
              "      <th>cdc</th>\n",
              "      <th>cdc_present</th>\n",
              "      <th>context</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>Deficit spending is the amount by which a gove...</td>\n",
              "      <td>Europe should weaken its austerity measures to...</td>\n",
              "      <td>Deficit spending</td>\n",
              "      <td>---</td>\n",
              "      <td>False</td>\n",
              "      <td>austerity measures</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>Government deficit spending is a central point...</td>\n",
              "      <td>Europe should weaken its austerity measures to...</td>\n",
              "      <td>Deficit spending</td>\n",
              "      <td>---</td>\n",
              "      <td>False</td>\n",
              "      <td>austerity measures</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>Government deficit spending is a central point...</td>\n",
              "      <td>Europe should weaken its austerity measures to...</td>\n",
              "      <td>Deficit spending</td>\n",
              "      <td>---</td>\n",
              "      <td>False</td>\n",
              "      <td>austerity measures</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3</td>\n",
              "      <td>The mainstream economics position is that defi...</td>\n",
              "      <td>Europe should weaken its austerity measures to...</td>\n",
              "      <td>Deficit spending</td>\n",
              "      <td>---</td>\n",
              "      <td>False</td>\n",
              "      <td>austerity measures</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4</td>\n",
              "      <td>This is derived from Keynesian economics, and ...</td>\n",
              "      <td>Europe should weaken its austerity measures to...</td>\n",
              "      <td>Deficit spending</td>\n",
              "      <td>---</td>\n",
              "      <td>False</td>\n",
              "      <td>austerity measures</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   Unnamed: 0  ...             context\n",
              "0           0  ...  austerity measures\n",
              "1           1  ...  austerity measures\n",
              "2           2  ...  austerity measures\n",
              "3           3  ...  austerity measures\n",
              "4           4  ...  austerity measures\n",
              "\n",
              "[5 rows x 7 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 41
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_aM6KsYGUjYi",
        "colab_type": "text"
      },
      "source": [
        "### Text\n",
        "\n",
        "Given the text data, some stats will be extracted for analysis:\n",
        "\n",
        "* word count for each sentence\n",
        "* syllable count for each sentence\n",
        "* count of sentiment words in sentence\n",
        "* punctuation count of each sentence\n",
        "* count of noun objects in each sentence\n",
        "* count of phrases in each sentence\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5Vf5DbpJImyo",
        "colab_type": "text"
      },
      "source": [
        "##### Stats"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ppF66PEV7Ixl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Exctract information from text for evaluation\n",
        "raw_data['text_words'] = raw_data['text'].apply(lambda x: word_count(x))\n",
        "raw_data['text_syllables'] = raw_data['text'].apply(lambda x: count_syllables(x))\n",
        "raw_data['text_sentiment_words'] = raw_data['text'].apply(lambda x: count_sentiment_words(x))\n",
        "raw_data['text_punctuation'] = raw_data['text'].apply(lambda x: punct_marks(x))\n",
        "raw_data['text_nouns'] = raw_data['text'].apply(lambda x: noun_counts(x))\n",
        "raw_data['text_phrases'] = raw_data['text'].apply(lambda x: phrase_chunks(x))\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bcpfR-D7Iy5j",
        "colab_type": "text"
      },
      "source": [
        "#### Sentence Cleaning\n",
        "\n",
        "When discussing topics, it was discovered that topic statements needed \"cleaning\" for context.  Similarly, sentences will require cleaning as well.  \n",
        "\n",
        "In many NLP cases, the removal of stopwords is part of the process.  Unfortunately, stopword removal can impact sentence context.  In order to retain context, stopwords will not be removed.  However, given the goal of extracting Context Dependent Claims, extracting independent clauses from sentences may help remove \"stop data\" from the sentence while retaining context.\n",
        "\n",
        "This can be done by:\n",
        "\n",
        "1. Identify sentence complexity.\n",
        " * Complex sentences can contain several clauses\n",
        " * Simple sentences are retained.\n",
        "2. Parse complext sentences into clauses\n",
        " * Dependent clauses discarded  \n",
        " * Independent clauses retained\n",
        "\n",
        " \n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y8CNN0CqhIh3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Calculate ratio of sentiment words to words in sentence\n",
        "raw_data['sent_rat'] = raw_data['text_sentiment_words'] / raw_data['text_words']\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pltzNA3oj_p8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Extract independent clauses found in each sentence\n",
        "raw_data['clauses'] = raw_data['text'].apply(lambda x: get_clauses(x))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FK6FQRp-MqbH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E8WUqgf7NklY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Count the number of clauses in each sentence\n",
        "raw_data['num_clauses'] = raw_data['clauses'].apply(lambda x: len(x))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ecvrNdv1TG2a",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Join independent clauses into a single sentence\n",
        "raw_data['claused_sentence'] = raw_data['clauses'].apply(lambda x: ','.join(x))\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6wayz3FxUCPT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Compute context similarity of each sentence\n",
        "context_similarity = []\n",
        "\n",
        "for i,txt in enumerate(raw_data['claused_sentence']):\n",
        "    context_similarity.append(subject_match(raw_data['context'][i], txt))\n",
        "\n",
        "raw_data['context_similarity'] = context_similarity"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5WdCcJalUI5Q",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Compute similarity of sentence with expanded context\n",
        "expanded_similarity = []\n",
        "for i,txt in enumerate(raw_data['claused_sentence']):\n",
        "    expanded_similarity.append(expanded_sentence_similarity(raw_data['context'][i], txt))\n",
        "\n",
        "raw_data['expanded_similarity'] = expanded_similarity"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kEJN01spbd5p",
        "colab_type": "code",
        "outputId": "e2eccac3-5dc2-40cf-e961-1fda54004247",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 669
        }
      },
      "source": [
        "raw_data[['context_similarity', 'expanded_similarity', 'cdc_present']].head(20)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>context_similarity</th>\n",
              "      <th>expanded_similarity</th>\n",
              "      <th>cdc_present</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.326836</td>\n",
              "      <td>0.259504</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.373849</td>\n",
              "      <td>0.267986</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.267243</td>\n",
              "      <td>0.106333</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0.461772</td>\n",
              "      <td>0.240641</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0.318571</td>\n",
              "      <td>0.306673</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>0.430850</td>\n",
              "      <td>0.267669</td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>0.419114</td>\n",
              "      <td>0.383118</td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>0.352407</td>\n",
              "      <td>0.277571</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>0.206059</td>\n",
              "      <td>0.233298</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>0.613701</td>\n",
              "      <td>0.162653</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>0.315903</td>\n",
              "      <td>0.269992</td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>0.353111</td>\n",
              "      <td>0.173475</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12</th>\n",
              "      <td>0.354165</td>\n",
              "      <td>0.193404</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13</th>\n",
              "      <td>0.378167</td>\n",
              "      <td>0.365357</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14</th>\n",
              "      <td>0.605527</td>\n",
              "      <td>0.084926</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15</th>\n",
              "      <td>0.333909</td>\n",
              "      <td>0.272324</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16</th>\n",
              "      <td>0.414341</td>\n",
              "      <td>0.177204</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>17</th>\n",
              "      <td>0.322399</td>\n",
              "      <td>0.339128</td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>18</th>\n",
              "      <td>0.331619</td>\n",
              "      <td>0.268934</td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19</th>\n",
              "      <td>0.437920</td>\n",
              "      <td>0.258412</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "    context_similarity  expanded_similarity  cdc_present\n",
              "0             0.326836             0.259504        False\n",
              "1             0.373849             0.267986        False\n",
              "2             0.267243             0.106333        False\n",
              "3             0.461772             0.240641        False\n",
              "4             0.318571             0.306673        False\n",
              "5             0.430850             0.267669         True\n",
              "6             0.419114             0.383118         True\n",
              "7             0.352407             0.277571        False\n",
              "8             0.206059             0.233298        False\n",
              "9             0.613701             0.162653        False\n",
              "10            0.315903             0.269992         True\n",
              "11            0.353111             0.173475        False\n",
              "12            0.354165             0.193404        False\n",
              "13            0.378167             0.365357        False\n",
              "14            0.605527             0.084926        False\n",
              "15            0.333909             0.272324        False\n",
              "16            0.414341             0.177204        False\n",
              "17            0.322399             0.339128         True\n",
              "18            0.331619             0.268934         True\n",
              "19            0.437920             0.258412        False"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 57
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EFYDQnxEiA7I",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "raw_data['subjectivity_score'] = raw_data['claused_sentence'].apply(lambda x: sentiment_subjectivity(x, 'subjectivity'))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ENLjJgI3zEE3",
        "colab_type": "code",
        "outputId": "c9c31c4c-2ad2-4618-865a-db6e1f1b685b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "raw_data.head(10).transpose()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "      <th>1</th>\n",
              "      <th>2</th>\n",
              "      <th>3</th>\n",
              "      <th>4</th>\n",
              "      <th>5</th>\n",
              "      <th>6</th>\n",
              "      <th>7</th>\n",
              "      <th>8</th>\n",
              "      <th>9</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>Unnamed: 0</th>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>3</td>\n",
              "      <td>4</td>\n",
              "      <td>5</td>\n",
              "      <td>6</td>\n",
              "      <td>7</td>\n",
              "      <td>8</td>\n",
              "      <td>9</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>text</th>\n",
              "      <td>Deficit spending is the amount by which a gove...</td>\n",
              "      <td>Government deficit spending is a central point...</td>\n",
              "      <td>Government deficit spending is a central point...</td>\n",
              "      <td>The mainstream economics position is that defi...</td>\n",
              "      <td>This is derived from Keynesian economics, and ...</td>\n",
              "      <td>The mainstream position is attacked from both ...</td>\n",
              "      <td>Advocates of sound finance (in the US known as...</td>\n",
              "      <td>Sound finance has academic support, predominan...</td>\n",
              "      <td>Proponents of sound finance date back to Adam ...</td>\n",
              "      <td>Sound finance was the dominant position until ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>topic</th>\n",
              "      <td>Europe should weaken its austerity measures to...</td>\n",
              "      <td>Europe should weaken its austerity measures to...</td>\n",
              "      <td>Europe should weaken its austerity measures to...</td>\n",
              "      <td>Europe should weaken its austerity measures to...</td>\n",
              "      <td>Europe should weaken its austerity measures to...</td>\n",
              "      <td>Europe should weaken its austerity measures to...</td>\n",
              "      <td>Europe should weaken its austerity measures to...</td>\n",
              "      <td>Europe should weaken its austerity measures to...</td>\n",
              "      <td>Europe should weaken its austerity measures to...</td>\n",
              "      <td>Europe should weaken its austerity measures to...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>article</th>\n",
              "      <td>Deficit spending</td>\n",
              "      <td>Deficit spending</td>\n",
              "      <td>Deficit spending</td>\n",
              "      <td>Deficit spending</td>\n",
              "      <td>Deficit spending</td>\n",
              "      <td>Deficit spending</td>\n",
              "      <td>Deficit spending</td>\n",
              "      <td>Deficit spending</td>\n",
              "      <td>Deficit spending</td>\n",
              "      <td>Deficit spending</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>cdc</th>\n",
              "      <td>---</td>\n",
              "      <td>---</td>\n",
              "      <td>---</td>\n",
              "      <td>---</td>\n",
              "      <td>---</td>\n",
              "      <td>deficit spending is necessary</td>\n",
              "      <td>government should always run a balanced budget</td>\n",
              "      <td>---</td>\n",
              "      <td>---</td>\n",
              "      <td>---</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>cdc_present</th>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>True</td>\n",
              "      <td>True</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>context</th>\n",
              "      <td>austerity measures</td>\n",
              "      <td>austerity measures</td>\n",
              "      <td>austerity measures</td>\n",
              "      <td>austerity measures</td>\n",
              "      <td>austerity measures</td>\n",
              "      <td>austerity measures</td>\n",
              "      <td>austerity measures</td>\n",
              "      <td>austerity measures</td>\n",
              "      <td>austerity measures</td>\n",
              "      <td>austerity measures</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>text_words</th>\n",
              "      <td>35</td>\n",
              "      <td>14</td>\n",
              "      <td>17</td>\n",
              "      <td>66</td>\n",
              "      <td>34</td>\n",
              "      <td>40</td>\n",
              "      <td>44</td>\n",
              "      <td>64</td>\n",
              "      <td>13</td>\n",
              "      <td>27</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>text_syllables</th>\n",
              "      <td>67</td>\n",
              "      <td>29</td>\n",
              "      <td>37</td>\n",
              "      <td>122</td>\n",
              "      <td>64</td>\n",
              "      <td>77</td>\n",
              "      <td>73</td>\n",
              "      <td>128</td>\n",
              "      <td>22</td>\n",
              "      <td>52</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>text_sentiment_words</th>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>7</td>\n",
              "      <td>3</td>\n",
              "      <td>6</td>\n",
              "      <td>8</td>\n",
              "      <td>7</td>\n",
              "      <td>0</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>text_punctuation</th>\n",
              "      <td>10</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>7</td>\n",
              "      <td>5</td>\n",
              "      <td>6</td>\n",
              "      <td>8</td>\n",
              "      <td>8</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>text_nouns</th>\n",
              "      <td>10</td>\n",
              "      <td>4</td>\n",
              "      <td>6</td>\n",
              "      <td>15</td>\n",
              "      <td>6</td>\n",
              "      <td>10</td>\n",
              "      <td>12</td>\n",
              "      <td>16</td>\n",
              "      <td>5</td>\n",
              "      <td>6</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>text_phrases</th>\n",
              "      <td>12</td>\n",
              "      <td>5</td>\n",
              "      <td>6</td>\n",
              "      <td>22</td>\n",
              "      <td>11</td>\n",
              "      <td>11</td>\n",
              "      <td>14</td>\n",
              "      <td>25</td>\n",
              "      <td>7</td>\n",
              "      <td>11</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>sent_rat</th>\n",
              "      <td>0.0857143</td>\n",
              "      <td>0.0714286</td>\n",
              "      <td>0.117647</td>\n",
              "      <td>0.106061</td>\n",
              "      <td>0.0882353</td>\n",
              "      <td>0.15</td>\n",
              "      <td>0.181818</td>\n",
              "      <td>0.109375</td>\n",
              "      <td>0</td>\n",
              "      <td>0.148148</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>clauses</th>\n",
              "      <td>[ or individual's spending exceeds income over...</td>\n",
              "      <td>[Government deficit spending is a central poin...</td>\n",
              "      <td>[prominent economists holding differing views]</td>\n",
              "      <td>[deficit spending is desirable and necessary a...</td>\n",
              "      <td>[has been the mainstream economics view (in th...</td>\n",
              "      <td>[mainstream position is attacked from both sid...</td>\n",
              "      <td>[Advocates of sound finance (in the US known a...</td>\n",
              "      <td>[the neoclassical-inclined Chicago school of e...</td>\n",
              "      <td>[Proponents of sound finance date back to Adam...</td>\n",
              "      <td>[government fiscal policy was ineffective]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>num_clauses</th>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>4</td>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "      <td>3</td>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>claused_sentence</th>\n",
              "      <td>or individual's spending exceeds income over ...</td>\n",
              "      <td>Government deficit spending is a central point...</td>\n",
              "      <td>prominent economists holding differing views</td>\n",
              "      <td>deficit spending is desirable and necessary as...</td>\n",
              "      <td>has been the mainstream economics view (in the...</td>\n",
              "      <td>mainstream position is attacked from both side...</td>\n",
              "      <td>Advocates of sound finance (in the US known as...</td>\n",
              "      <td>the neoclassical-inclined Chicago school of ec...</td>\n",
              "      <td>Proponents of sound finance date back to Adam ...</td>\n",
              "      <td>government fiscal policy was ineffective</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>context_similarity</th>\n",
              "      <td>0.326836</td>\n",
              "      <td>0.373849</td>\n",
              "      <td>0.267243</td>\n",
              "      <td>0.461772</td>\n",
              "      <td>0.318571</td>\n",
              "      <td>0.43085</td>\n",
              "      <td>0.419114</td>\n",
              "      <td>0.352407</td>\n",
              "      <td>0.206059</td>\n",
              "      <td>0.613701</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>expanded_similarity</th>\n",
              "      <td>0.259504</td>\n",
              "      <td>0.267986</td>\n",
              "      <td>0.106333</td>\n",
              "      <td>0.240641</td>\n",
              "      <td>0.306673</td>\n",
              "      <td>0.267669</td>\n",
              "      <td>0.383118</td>\n",
              "      <td>0.277571</td>\n",
              "      <td>0.233298</td>\n",
              "      <td>0.162653</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>subjectivity_score</th>\n",
              "      <td>0</td>\n",
              "      <td>-0.4019</td>\n",
              "      <td>0.3182</td>\n",
              "      <td>-0.928</td>\n",
              "      <td>0.3612</td>\n",
              "      <td>-0.7579</td>\n",
              "      <td>-0.3818</td>\n",
              "      <td>0.6652</td>\n",
              "      <td>0</td>\n",
              "      <td>-0.128</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                                      0  ...                                                  9\n",
              "Unnamed: 0                                                            0  ...                                                  9\n",
              "text                  Deficit spending is the amount by which a gove...  ...  Sound finance was the dominant position until ...\n",
              "topic                 Europe should weaken its austerity measures to...  ...  Europe should weaken its austerity measures to...\n",
              "article                                                Deficit spending  ...                                   Deficit spending\n",
              "cdc                                                                 ---  ...                                                ---\n",
              "cdc_present                                                       False  ...                                              False\n",
              "context                                              austerity measures  ...                                 austerity measures\n",
              "text_words                                                           35  ...                                                 27\n",
              "text_syllables                                                       67  ...                                                 52\n",
              "text_sentiment_words                                                  3  ...                                                  4\n",
              "text_punctuation                                                     10  ...                                                  2\n",
              "text_nouns                                                           10  ...                                                  6\n",
              "text_phrases                                                         12  ...                                                 11\n",
              "sent_rat                                                      0.0857143  ...                                           0.148148\n",
              "clauses               [ or individual's spending exceeds income over...  ...         [government fiscal policy was ineffective]\n",
              "num_clauses                                                           1  ...                                                  1\n",
              "claused_sentence       or individual's spending exceeds income over ...  ...           government fiscal policy was ineffective\n",
              "context_similarity                                             0.326836  ...                                           0.613701\n",
              "expanded_similarity                                            0.259504  ...                                           0.162653\n",
              "subjectivity_score                                                    0  ...                                             -0.128\n",
              "\n",
              "[20 rows x 10 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 59
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Tknt-PJjzGCt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "write_path = '/content/drive/My Drive/Colab Notebooks/Thinkful/Module 34 - Final Capstone/data/CDC Detection/cleaned.csv'\n",
        "\n",
        "raw_data.to_csv(write_path)"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}